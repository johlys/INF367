{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57325267",
   "metadata": {},
   "source": [
    "# Spaceship Titanic: TABM by Elias Ruud Aronsen\n",
    "\n",
    "Project: [Spaceship Titanic](https://www.kaggle.com/competitions/spaceship-titanic/overview)\n",
    "\n",
    "In this notebook, I will train a TABM model for the individual part of the project.\n",
    "\n",
    "TABM Github repository can be found here: [TABM GitHub](https://github.com/yandex-research/tabm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3618f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rand\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.tabm_reference import Model # This is our TABM model\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Read in preprocessed data, shown in 1-EDA-and-preprocessing.ipynb\n",
    "train = pd.read_csv('data/processed_train.csv')\n",
    "test = pd.read_csv('data/processed_test.csv')\n",
    "\n",
    "df_Y = train['Transported']\n",
    "df_X = train.drop(columns=['Transported'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff8b01",
   "metadata": {},
   "source": [
    "## TABM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b86a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 46 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   RoomService                8693 non-null   float64\n",
      " 1   FoodCourt                  8693 non-null   float64\n",
      " 2   ShoppingMall               8693 non-null   float64\n",
      " 3   Spa                        8693 non-null   float64\n",
      " 4   VRDeck                     8693 non-null   float64\n",
      " 5   Group                      8693 non-null   int64  \n",
      " 6   Id                         8693 non-null   int64  \n",
      " 7   Num                        8693 non-null   float64\n",
      " 8   FamilySize                 8693 non-null   float64\n",
      " 9   GroupSize                  8693 non-null   int64  \n",
      " 10  HomePlanet_Earth           8693 non-null   float64\n",
      " 11  HomePlanet_Europa          8693 non-null   float64\n",
      " 12  HomePlanet_Mars            8693 non-null   float64\n",
      " 13  HomePlanet_nan             8693 non-null   float64\n",
      " 14  CryoSleep_False            8693 non-null   float64\n",
      " 15  CryoSleep_True             8693 non-null   float64\n",
      " 16  CryoSleep_nan              8693 non-null   float64\n",
      " 17  Destination_55 Cancri e    8693 non-null   float64\n",
      " 18  Destination_PSO J318.5-22  8693 non-null   float64\n",
      " 19  Destination_TRAPPIST-1e    8693 non-null   float64\n",
      " 20  Destination_nan            8693 non-null   float64\n",
      " 21  VIP_False                  8693 non-null   float64\n",
      " 22  VIP_True                   8693 non-null   float64\n",
      " 23  VIP_nan                    8693 non-null   float64\n",
      " 24  Deck_A                     8693 non-null   float64\n",
      " 25  Deck_B                     8693 non-null   float64\n",
      " 26  Deck_C                     8693 non-null   float64\n",
      " 27  Deck_D                     8693 non-null   float64\n",
      " 28  Deck_E                     8693 non-null   float64\n",
      " 29  Deck_F                     8693 non-null   float64\n",
      " 30  Deck_G                     8693 non-null   float64\n",
      " 31  Deck_T                     8693 non-null   float64\n",
      " 32  Deck_nan                   8693 non-null   float64\n",
      " 33  Side_P                     8693 non-null   float64\n",
      " 34  Side_S                     8693 non-null   float64\n",
      " 35  Side_nan                   8693 non-null   float64\n",
      " 36  Age_0-4                    8693 non-null   float64\n",
      " 37  Age_10-14                  8693 non-null   float64\n",
      " 38  Age_15-19                  8693 non-null   float64\n",
      " 39  Age_20-29                  8693 non-null   float64\n",
      " 40  Age_30-39                  8693 non-null   float64\n",
      " 41  Age_40-49                  8693 non-null   float64\n",
      " 42  Age_5-9                    8693 non-null   float64\n",
      " 43  Age_50-59                  8693 non-null   float64\n",
      " 44  Age_60+                    8693 non-null   float64\n",
      " 45  Age_nan                    8693 non-null   float64\n",
      "dtypes: float64(43), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL DEFINITION AND SETUP\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split( df_X, df_Y, test_size=0.2, random_state=42, stratify=df_Y) # split our dataset # stratify makes sure train and test have same class distribution\n",
    "\n",
    "# we turn data int tensors as we will be using pytorch.\n",
    "train_x_tensor = torch.tensor(train_x.values, dtype=torch.float32)\n",
    "val_x_tensor = torch.tensor(val_x.values, dtype=torch.float32)\n",
    "train_y_tensor = torch.tensor(train_y.values, dtype=torch.long)\n",
    "val_y_tensor = torch.tensor(val_y.values, dtype=torch.long)\n",
    "\n",
    "# create the tensor datasets\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "val_dataset = TensorDataset(val_x_tensor, val_y_tensor)\n",
    "\n",
    "# create dataloaders for batches, speeds up training, self regularization, more stable updates etc.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512)\n",
    "\n",
    "\n",
    "### Model setup\n",
    "num_features = train_x_tensor.shape[1] # gives the amount of features, which is 46\n",
    "\n",
    "# setup function which defines our model, loss function and optimizer with given parameters.\n",
    "def setup( #default values\n",
    "    n_blocks=5, \n",
    "    d_block=256, \n",
    "    k=3, \n",
    "    dropout=0.1,\n",
    "    activation='ReLU', \n",
    "    lr=1e-3, \n",
    "    weight_decay=1e-4): # default settings\n",
    "\n",
    "    model = Model(\n",
    "        n_num_features=num_features,  # number of numeric features\n",
    "        cat_cardinalities=[],  # list with number of categories for each categorical feature, empty since we have converted everything to numeric\n",
    "        n_classes=2 ,  # number of output classes, 2 for binary\n",
    "        \n",
    "        backbone=dict(  # structure of the underlying MLPs\n",
    "            type='MLP',  # simple feedforward network\n",
    "            n_blocks=n_blocks,  # number of layers (depth)\n",
    "            d_block=d_block,  # width of each layer (hidden size)\n",
    "            dropout=dropout,  # dropout between layers for regularization\n",
    "            activation=activation,  # activation function like ReLU or GELU \n",
    "        ),\n",
    "    \n",
    "        bins=None,  # used if we had numerical binning, we used one hot encoding for age instead\n",
    "        num_embeddings=None,  # used if we had embedding of numeric features, we dont nees this\n",
    "        arch_type='tabm',  # architecture type, \"tabm\" for TabM model\n",
    "        k=k,  # number of experts the model can choose from at each layer\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) # we tune learning rate for speed and stability and weight decay for regularization\n",
    "    loss_function = nn.CrossEntropyLoss() # cross entropy is standard for binary classification\n",
    "\n",
    "    return model, optimizer, loss_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training the TABM MODEL\n",
    "# training function\n",
    "def run_tabm(\n",
    "    n_blocks=5, \n",
    "    d_block=256, \n",
    "    k=3, \n",
    "    dropout=0.1,\n",
    "    activation='ReLU',\n",
    "    lr=1e-3, \n",
    "    weight_decay=1e-4, \n",
    "    n_epochs=200, \n",
    "    patience=20 ):\n",
    "\n",
    "    # define our model optimizer and loss function parameters wiht given parameters\n",
    "    model, optimizer, loss_function = setup(n_blocks=n_blocks, d_block=d_block, k=k, dropout=dropout, activation=activation, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_loss = float('inf') # tracks current best validation loss reached\n",
    "    patience_counter = 0 # goes up when the model steps into a worse val loss.\n",
    "    \n",
    "    #Training loop with validation monitoring and early stopping.\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        #Training\n",
    "        model.train()\n",
    "        train_losses = [] # these will hold our losses for the batch, at the end of epoch take the average loss for each batch\n",
    "        train_preds_all = [] # stored predictions for each batch, for calculation of accuracy later\n",
    "        train_targets_all = [] # true labels for each batch, for calculation of accuracy later\n",
    "\n",
    "        for xb, yb in train_loader: # loading in batches\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(xb, None) # forward propogation\n",
    "            loss = loss_function(outputs.mean(dim=1), yb) # calculate loss\n",
    "            loss.backward() # backward propegation\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item()) # saves current batch loss\n",
    "            train_preds_all.append(outputs.mean(dim=1).argmax(dim=1)) # we take the average across k preds, pick the predicted class and store it for each batch\n",
    "            train_targets_all.append(yb) # stores the true labels\n",
    "            \n",
    "        # calculating accuracy for epoch\n",
    "        train_preds_all = torch.cat(train_preds_all) # stich all batch preds in one tensore\n",
    "        train_targets_all = torch.cat(train_targets_all) # \tsame for the true labels\n",
    "        train_acc = accuracy_score(train_targets_all.cpu(), train_preds_all.cpu()) # computes accuracy\n",
    "\n",
    "        # Validation, mostly these same just no training \n",
    "        model.eval()\n",
    "        val_losses = [] # these does the same thing as train_losses, train_preds_all and train_targets_all\n",
    "        val_preds_all = []\n",
    "        val_targets_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                val_outputs = model(xb, None)\n",
    "                val_loss = loss_function(val_outputs.mean(dim=1), yb)\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "                val_preds_all.append(val_outputs.mean(dim=1).argmax(dim=1))\n",
    "                val_targets_all.append(yb)\n",
    "\n",
    "        # calculating validation accuracy\n",
    "        val_preds_all = torch.cat(val_preds_all)\n",
    "        val_targets_all = torch.cat(val_targets_all)\n",
    "        val_acc = accuracy_score(val_targets_all.cpu(), val_preds_all.cpu())\n",
    "        val_loss_epoch = sum(val_losses) / len(val_losses)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Loss={sum(train_losses)/len(train_losses):.4f}, Train Acc={train_acc:.4f} ||| Val Loss={val_loss_epoch:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "        # early stopping check\n",
    "        if val_loss_epoch < best_val_loss:\n",
    "            best_val_loss = val_loss_epoch\n",
    "            patience_counter = 0 # we reset counter each time we find better\n",
    "            best_model_state = model.state_dict() # save state\n",
    "        else: # increase patience if new is not better\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience: # stop training if model has not produced a better val loss in the defined amount of epochs\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "    # Load back the best found model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9630d6e",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ad0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elias\\miniconda3\\envs\\TABM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-27 16:52:35,433] A new study created in memory with name: no-name-60be0ac5-c2a0-4e78-b558-45f50a391fd7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Trial 1 with params: {'n_blocks': 2, 'd_block': 128, 'k': 8, 'dropout': 0.4226779073013317, 'activation': 'GELU', 'lr': 0.0010017908773783256, 'weight_decay': 5.48391092738397e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=8.2198, Train Acc=0.6445 ||| Val Loss=1.2242, Val Acc=0.7550\n",
      "Epoch 2: Train Loss=2.2198, Train Acc=0.6622 ||| Val Loss=0.6161, Val Acc=0.7608\n",
      "Epoch 3: Train Loss=1.0650, Train Acc=0.6624 ||| Val Loss=0.6124, Val Acc=0.6665\n",
      "Epoch 4: Train Loss=0.7555, Train Acc=0.6695 ||| Val Loss=0.6185, Val Acc=0.6653\n",
      "Epoch 5: Train Loss=0.6752, Train Acc=0.6800 ||| Val Loss=0.6124, Val Acc=0.6665\n",
      "Epoch 6: Train Loss=0.6196, Train Acc=0.6926 ||| Val Loss=0.5936, Val Acc=0.6809\n",
      "Epoch 7: Train Loss=0.5952, Train Acc=0.7123 ||| Val Loss=0.5979, Val Acc=0.6711\n",
      "Epoch 8: Train Loss=0.5939, Train Acc=0.7094 ||| Val Loss=0.5940, Val Acc=0.6820\n",
      "Epoch 9: Train Loss=0.5802, Train Acc=0.7181 ||| Val Loss=0.5797, Val Acc=0.6855\n",
      "Epoch 10: Train Loss=0.5698, Train Acc=0.7216 ||| Val Loss=0.5812, Val Acc=0.6889\n",
      "Epoch 11: Train Loss=0.5579, Train Acc=0.7302 ||| Val Loss=0.5676, Val Acc=0.7234\n",
      "Epoch 12: Train Loss=0.5540, Train Acc=0.7321 ||| Val Loss=0.5655, Val Acc=0.6952\n",
      "Epoch 13: Train Loss=0.5476, Train Acc=0.7373 ||| Val Loss=0.5522, Val Acc=0.7182\n",
      "Epoch 14: Train Loss=0.5387, Train Acc=0.7455 ||| Val Loss=0.5331, Val Acc=0.7608\n",
      "Epoch 15: Train Loss=0.5376, Train Acc=0.7494 ||| Val Loss=0.5382, Val Acc=0.7286\n",
      "Epoch 16: Train Loss=0.5264, Train Acc=0.7494 ||| Val Loss=0.5330, Val Acc=0.7309\n",
      "Epoch 17: Train Loss=0.5303, Train Acc=0.7529 ||| Val Loss=0.5144, Val Acc=0.7665\n",
      "Epoch 18: Train Loss=0.5188, Train Acc=0.7610 ||| Val Loss=0.5235, Val Acc=0.7412\n",
      "Epoch 19: Train Loss=0.5228, Train Acc=0.7558 ||| Val Loss=0.5308, Val Acc=0.7246\n",
      "Epoch 20: Train Loss=0.5153, Train Acc=0.7613 ||| Val Loss=0.5106, Val Acc=0.7585\n",
      "Epoch 21: Train Loss=0.5153, Train Acc=0.7614 ||| Val Loss=0.5180, Val Acc=0.7481\n",
      "Epoch 22: Train Loss=0.5205, Train Acc=0.7601 ||| Val Loss=0.5124, Val Acc=0.7631\n",
      "Epoch 23: Train Loss=0.5148, Train Acc=0.7594 ||| Val Loss=0.5074, Val Acc=0.7734\n",
      "Epoch 24: Train Loss=0.5070, Train Acc=0.7719 ||| Val Loss=0.4999, Val Acc=0.7619\n",
      "Epoch 25: Train Loss=0.5106, Train Acc=0.7676 ||| Val Loss=0.5165, Val Acc=0.7527\n",
      "Epoch 26: Train Loss=0.5045, Train Acc=0.7716 ||| Val Loss=0.4933, Val Acc=0.7792\n",
      "Epoch 27: Train Loss=0.5014, Train Acc=0.7679 ||| Val Loss=0.4980, Val Acc=0.7723\n",
      "Epoch 28: Train Loss=0.5086, Train Acc=0.7706 ||| Val Loss=0.4992, Val Acc=0.7706\n",
      "Epoch 29: Train Loss=0.5015, Train Acc=0.7721 ||| Val Loss=0.5087, Val Acc=0.7550\n",
      "Epoch 30: Train Loss=0.4978, Train Acc=0.7696 ||| Val Loss=0.4978, Val Acc=0.7683\n",
      "Epoch 31: Train Loss=0.5038, Train Acc=0.7745 ||| Val Loss=0.5041, Val Acc=0.7694\n",
      "Epoch 32: Train Loss=0.4972, Train Acc=0.7755 ||| Val Loss=0.4934, Val Acc=0.7821\n",
      "Epoch 33: Train Loss=0.4969, Train Acc=0.7715 ||| Val Loss=0.4810, Val Acc=0.7878\n",
      "Epoch 34: Train Loss=0.4966, Train Acc=0.7757 ||| Val Loss=0.4931, Val Acc=0.7757\n",
      "Epoch 35: Train Loss=0.4889, Train Acc=0.7768 ||| Val Loss=0.4829, Val Acc=0.7763\n",
      "Epoch 36: Train Loss=0.4945, Train Acc=0.7761 ||| Val Loss=0.5031, Val Acc=0.7786\n",
      "Epoch 37: Train Loss=0.4867, Train Acc=0.7742 ||| Val Loss=0.4792, Val Acc=0.7780\n",
      "Epoch 38: Train Loss=0.4921, Train Acc=0.7747 ||| Val Loss=0.4772, Val Acc=0.7838\n",
      "Epoch 39: Train Loss=0.4804, Train Acc=0.7793 ||| Val Loss=0.4942, Val Acc=0.7769\n",
      "Epoch 40: Train Loss=0.4858, Train Acc=0.7813 ||| Val Loss=0.5089, Val Acc=0.7671\n",
      "Epoch 41: Train Loss=0.4853, Train Acc=0.7764 ||| Val Loss=0.5086, Val Acc=0.7786\n",
      "Epoch 42: Train Loss=0.4867, Train Acc=0.7778 ||| Val Loss=0.4830, Val Acc=0.7826\n",
      "Epoch 43: Train Loss=0.4861, Train Acc=0.7758 ||| Val Loss=0.4935, Val Acc=0.7924\n",
      "Epoch 44: Train Loss=0.4863, Train Acc=0.7811 ||| Val Loss=0.4839, Val Acc=0.7826\n",
      "Epoch 45: Train Loss=0.4778, Train Acc=0.7843 ||| Val Loss=0.5095, Val Acc=0.7832\n",
      "Epoch 46: Train Loss=0.4782, Train Acc=0.7880 ||| Val Loss=0.4775, Val Acc=0.7821\n",
      "Epoch 47: Train Loss=0.4827, Train Acc=0.7808 ||| Val Loss=0.4745, Val Acc=0.7821\n",
      "Epoch 48: Train Loss=0.4765, Train Acc=0.7834 ||| Val Loss=0.4802, Val Acc=0.7815\n",
      "Epoch 49: Train Loss=0.4749, Train Acc=0.7837 ||| Val Loss=0.4660, Val Acc=0.7941\n",
      "Epoch 50: Train Loss=0.4707, Train Acc=0.7817 ||| Val Loss=0.4661, Val Acc=0.7924\n",
      "Epoch 51: Train Loss=0.4653, Train Acc=0.7843 ||| Val Loss=0.4670, Val Acc=0.7941\n",
      "Epoch 52: Train Loss=0.4707, Train Acc=0.7850 ||| Val Loss=0.4616, Val Acc=0.7930\n",
      "Epoch 53: Train Loss=0.4674, Train Acc=0.7840 ||| Val Loss=0.4554, Val Acc=0.7959\n",
      "Epoch 54: Train Loss=0.4566, Train Acc=0.7872 ||| Val Loss=0.4474, Val Acc=0.7953\n",
      "Epoch 55: Train Loss=0.4614, Train Acc=0.7860 ||| Val Loss=0.4539, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4623, Train Acc=0.7872 ||| Val Loss=0.4510, Val Acc=0.7982\n",
      "Epoch 57: Train Loss=0.4548, Train Acc=0.7821 ||| Val Loss=0.4462, Val Acc=0.7872\n",
      "Epoch 58: Train Loss=0.4575, Train Acc=0.7866 ||| Val Loss=0.4481, Val Acc=0.7884\n",
      "Epoch 59: Train Loss=0.4534, Train Acc=0.7854 ||| Val Loss=0.4560, Val Acc=0.7872\n",
      "Epoch 60: Train Loss=0.4495, Train Acc=0.7852 ||| Val Loss=0.4525, Val Acc=0.7901\n",
      "Epoch 61: Train Loss=0.4548, Train Acc=0.7867 ||| Val Loss=0.4364, Val Acc=0.7982\n",
      "Epoch 62: Train Loss=0.4570, Train Acc=0.7870 ||| Val Loss=0.4444, Val Acc=0.7861\n",
      "Epoch 63: Train Loss=0.4517, Train Acc=0.7844 ||| Val Loss=0.4382, Val Acc=0.7884\n",
      "Epoch 64: Train Loss=0.4476, Train Acc=0.7889 ||| Val Loss=0.4457, Val Acc=0.7959\n",
      "Epoch 65: Train Loss=0.4443, Train Acc=0.7890 ||| Val Loss=0.4512, Val Acc=0.7832\n",
      "Epoch 66: Train Loss=0.4445, Train Acc=0.7850 ||| Val Loss=0.4368, Val Acc=0.7895\n",
      "Epoch 67: Train Loss=0.4482, Train Acc=0.7873 ||| Val Loss=0.4437, Val Acc=0.7844\n",
      "Epoch 68: Train Loss=0.4449, Train Acc=0.7900 ||| Val Loss=0.4594, Val Acc=0.7717\n",
      "Epoch 69: Train Loss=0.4407, Train Acc=0.7872 ||| Val Loss=0.4405, Val Acc=0.7872\n",
      "Epoch 70: Train Loss=0.4439, Train Acc=0.7823 ||| Val Loss=0.4540, Val Acc=0.7861\n",
      "Epoch 71: Train Loss=0.4456, Train Acc=0.7882 ||| Val Loss=0.4422, Val Acc=0.7907\n",
      "Epoch 72: Train Loss=0.4358, Train Acc=0.7853 ||| Val Loss=0.4319, Val Acc=0.7913\n",
      "Epoch 73: Train Loss=0.4390, Train Acc=0.7936 ||| Val Loss=0.4316, Val Acc=0.7884\n",
      "Epoch 74: Train Loss=0.4393, Train Acc=0.7889 ||| Val Loss=0.4360, Val Acc=0.7953\n",
      "Epoch 75: Train Loss=0.4404, Train Acc=0.7883 ||| Val Loss=0.4281, Val Acc=0.7936\n",
      "Epoch 76: Train Loss=0.4361, Train Acc=0.7886 ||| Val Loss=0.4314, Val Acc=0.7798\n",
      "Epoch 77: Train Loss=0.4372, Train Acc=0.7856 ||| Val Loss=0.4344, Val Acc=0.7792\n",
      "Epoch 78: Train Loss=0.4357, Train Acc=0.7905 ||| Val Loss=0.4306, Val Acc=0.7878\n",
      "Epoch 79: Train Loss=0.4400, Train Acc=0.7876 ||| Val Loss=0.4592, Val Acc=0.7734\n",
      "Epoch 80: Train Loss=0.4341, Train Acc=0.7923 ||| Val Loss=0.4295, Val Acc=0.7907\n",
      "Epoch 81: Train Loss=0.4309, Train Acc=0.7915 ||| Val Loss=0.4320, Val Acc=0.7924\n",
      "Epoch 82: Train Loss=0.4376, Train Acc=0.7902 ||| Val Loss=0.4436, Val Acc=0.7838\n",
      "Epoch 83: Train Loss=0.4343, Train Acc=0.7932 ||| Val Loss=0.4291, Val Acc=0.7746\n",
      "Epoch 84: Train Loss=0.4363, Train Acc=0.7915 ||| Val Loss=0.4356, Val Acc=0.7878\n",
      "Epoch 85: Train Loss=0.4323, Train Acc=0.7896 ||| Val Loss=0.4324, Val Acc=0.7855\n",
      "Epoch 86: Train Loss=0.4286, Train Acc=0.7905 ||| Val Loss=0.4262, Val Acc=0.7959\n",
      "Epoch 87: Train Loss=0.4269, Train Acc=0.7957 ||| Val Loss=0.4246, Val Acc=0.7895\n",
      "Epoch 88: Train Loss=0.4320, Train Acc=0.7959 ||| Val Loss=0.4273, Val Acc=0.7763\n",
      "Epoch 89: Train Loss=0.4306, Train Acc=0.7900 ||| Val Loss=0.4346, Val Acc=0.7918\n",
      "Epoch 90: Train Loss=0.4305, Train Acc=0.7977 ||| Val Loss=0.4256, Val Acc=0.7936\n",
      "Epoch 91: Train Loss=0.4253, Train Acc=0.7931 ||| Val Loss=0.4270, Val Acc=0.7993\n",
      "Epoch 92: Train Loss=0.4275, Train Acc=0.7936 ||| Val Loss=0.4219, Val Acc=0.7855\n",
      "Epoch 93: Train Loss=0.4317, Train Acc=0.7958 ||| Val Loss=0.4256, Val Acc=0.7993\n",
      "Epoch 94: Train Loss=0.4299, Train Acc=0.7980 ||| Val Loss=0.4292, Val Acc=0.7930\n",
      "Epoch 95: Train Loss=0.4314, Train Acc=0.7959 ||| Val Loss=0.4213, Val Acc=0.7947\n",
      "Epoch 96: Train Loss=0.4258, Train Acc=0.7955 ||| Val Loss=0.4233, Val Acc=0.7890\n",
      "Epoch 97: Train Loss=0.4258, Train Acc=0.7938 ||| Val Loss=0.4191, Val Acc=0.7970\n",
      "Epoch 98: Train Loss=0.4280, Train Acc=0.7890 ||| Val Loss=0.4246, Val Acc=0.7861\n",
      "Epoch 99: Train Loss=0.4232, Train Acc=0.7972 ||| Val Loss=0.4227, Val Acc=0.7861\n",
      "Epoch 100: Train Loss=0.4231, Train Acc=0.7965 ||| Val Loss=0.4192, Val Acc=0.7907\n",
      "Epoch 101: Train Loss=0.4231, Train Acc=0.7959 ||| Val Loss=0.4257, Val Acc=0.7878\n",
      "Epoch 102: Train Loss=0.4238, Train Acc=0.7981 ||| Val Loss=0.4198, Val Acc=0.7872\n",
      "Epoch 103: Train Loss=0.4255, Train Acc=0.7915 ||| Val Loss=0.4247, Val Acc=0.7792\n",
      "Epoch 104: Train Loss=0.4171, Train Acc=0.7974 ||| Val Loss=0.4163, Val Acc=0.7976\n",
      "Epoch 105: Train Loss=0.4287, Train Acc=0.7909 ||| Val Loss=0.4232, Val Acc=0.7838\n",
      "Epoch 106: Train Loss=0.4233, Train Acc=0.7978 ||| Val Loss=0.4205, Val Acc=0.7918\n",
      "Epoch 107: Train Loss=0.4186, Train Acc=0.7978 ||| Val Loss=0.4238, Val Acc=0.7901\n",
      "Epoch 108: Train Loss=0.4235, Train Acc=0.7968 ||| Val Loss=0.4182, Val Acc=0.7861\n",
      "Epoch 109: Train Loss=0.4137, Train Acc=0.7964 ||| Val Loss=0.4203, Val Acc=0.7872\n",
      "Epoch 110: Train Loss=0.4182, Train Acc=0.7968 ||| Val Loss=0.4162, Val Acc=0.7855\n",
      "Epoch 111: Train Loss=0.4187, Train Acc=0.7981 ||| Val Loss=0.4239, Val Acc=0.7964\n",
      "Epoch 112: Train Loss=0.4221, Train Acc=0.7967 ||| Val Loss=0.4266, Val Acc=0.7953\n",
      "Epoch 113: Train Loss=0.4216, Train Acc=0.7981 ||| Val Loss=0.4256, Val Acc=0.7855\n",
      "Epoch 114: Train Loss=0.4141, Train Acc=0.7967 ||| Val Loss=0.4171, Val Acc=0.7953\n",
      "Epoch 115: Train Loss=0.4166, Train Acc=0.8011 ||| Val Loss=0.4232, Val Acc=0.7964\n",
      "Epoch 116: Train Loss=0.4190, Train Acc=0.7995 ||| Val Loss=0.4177, Val Acc=0.7970\n",
      "Epoch 117: Train Loss=0.4182, Train Acc=0.8021 ||| Val Loss=0.4161, Val Acc=0.7930\n",
      "Epoch 118: Train Loss=0.4188, Train Acc=0.7993 ||| Val Loss=0.4211, Val Acc=0.7941\n",
      "Epoch 119: Train Loss=0.4190, Train Acc=0.8007 ||| Val Loss=0.4199, Val Acc=0.7964\n",
      "Epoch 120: Train Loss=0.4150, Train Acc=0.8016 ||| Val Loss=0.4179, Val Acc=0.7924\n",
      "Epoch 121: Train Loss=0.4187, Train Acc=0.8028 ||| Val Loss=0.4243, Val Acc=0.7809\n",
      "Epoch 122: Train Loss=0.4150, Train Acc=0.8021 ||| Val Loss=0.4189, Val Acc=0.7924\n",
      "Epoch 123: Train Loss=0.4134, Train Acc=0.8003 ||| Val Loss=0.4158, Val Acc=0.7913\n",
      "Epoch 124: Train Loss=0.4165, Train Acc=0.8004 ||| Val Loss=0.4154, Val Acc=0.7890\n",
      "Epoch 125: Train Loss=0.4115, Train Acc=0.8005 ||| Val Loss=0.4205, Val Acc=0.7947\n",
      "Epoch 126: Train Loss=0.4113, Train Acc=0.8001 ||| Val Loss=0.4192, Val Acc=0.7803\n",
      "Epoch 127: Train Loss=0.4082, Train Acc=0.7975 ||| Val Loss=0.4193, Val Acc=0.7861\n",
      "Epoch 128: Train Loss=0.4121, Train Acc=0.8026 ||| Val Loss=0.4202, Val Acc=0.7815\n",
      "Epoch 129: Train Loss=0.4120, Train Acc=0.8005 ||| Val Loss=0.4165, Val Acc=0.8028\n",
      "Epoch 130: Train Loss=0.4144, Train Acc=0.8011 ||| Val Loss=0.4274, Val Acc=0.7803\n",
      "Epoch 131: Train Loss=0.4098, Train Acc=0.8023 ||| Val Loss=0.4137, Val Acc=0.7901\n",
      "Epoch 132: Train Loss=0.4117, Train Acc=0.8016 ||| Val Loss=0.4121, Val Acc=0.7941\n",
      "Epoch 133: Train Loss=0.4114, Train Acc=0.8004 ||| Val Loss=0.4225, Val Acc=0.7792\n",
      "Epoch 134: Train Loss=0.4105, Train Acc=0.8020 ||| Val Loss=0.4176, Val Acc=0.7941\n",
      "Epoch 135: Train Loss=0.4052, Train Acc=0.8024 ||| Val Loss=0.4098, Val Acc=0.7964\n",
      "Epoch 136: Train Loss=0.4077, Train Acc=0.8034 ||| Val Loss=0.4112, Val Acc=0.7895\n",
      "Epoch 137: Train Loss=0.4102, Train Acc=0.8041 ||| Val Loss=0.4194, Val Acc=0.7913\n",
      "Epoch 138: Train Loss=0.4098, Train Acc=0.8074 ||| Val Loss=0.4202, Val Acc=0.7861\n",
      "Epoch 139: Train Loss=0.4096, Train Acc=0.8060 ||| Val Loss=0.4192, Val Acc=0.7924\n",
      "Epoch 140: Train Loss=0.4097, Train Acc=0.8049 ||| Val Loss=0.4154, Val Acc=0.7798\n",
      "Epoch 141: Train Loss=0.4082, Train Acc=0.8014 ||| Val Loss=0.4220, Val Acc=0.7907\n",
      "Epoch 142: Train Loss=0.4085, Train Acc=0.8007 ||| Val Loss=0.4192, Val Acc=0.7959\n",
      "Epoch 143: Train Loss=0.4030, Train Acc=0.8051 ||| Val Loss=0.4165, Val Acc=0.7775\n",
      "Epoch 144: Train Loss=0.4081, Train Acc=0.8049 ||| Val Loss=0.4202, Val Acc=0.7878\n",
      "Epoch 145: Train Loss=0.4089, Train Acc=0.8083 ||| Val Loss=0.4134, Val Acc=0.7918\n",
      "Epoch 146: Train Loss=0.4048, Train Acc=0.8031 ||| Val Loss=0.4206, Val Acc=0.7849\n",
      "Epoch 147: Train Loss=0.4021, Train Acc=0.8093 ||| Val Loss=0.4134, Val Acc=0.7930\n",
      "Epoch 148: Train Loss=0.4044, Train Acc=0.8074 ||| Val Loss=0.4121, Val Acc=0.7895\n",
      "Epoch 149: Train Loss=0.4014, Train Acc=0.8074 ||| Val Loss=0.4134, Val Acc=0.7907\n",
      "Epoch 150: Train Loss=0.4070, Train Acc=0.8069 ||| Val Loss=0.4156, Val Acc=0.7964\n",
      "Epoch 151: Train Loss=0.4046, Train Acc=0.8096 ||| Val Loss=0.4130, Val Acc=0.7959\n",
      "Epoch 152: Train Loss=0.4028, Train Acc=0.8108 ||| Val Loss=0.4076, Val Acc=0.7947\n",
      "Epoch 153: Train Loss=0.4013, Train Acc=0.8064 ||| Val Loss=0.4148, Val Acc=0.7861\n",
      "Epoch 154: Train Loss=0.3960, Train Acc=0.8079 ||| Val Loss=0.4161, Val Acc=0.7936\n",
      "Epoch 155: Train Loss=0.4007, Train Acc=0.8109 ||| Val Loss=0.4139, Val Acc=0.7964\n",
      "Epoch 156: Train Loss=0.3967, Train Acc=0.8109 ||| Val Loss=0.4105, Val Acc=0.7936\n",
      "Epoch 157: Train Loss=0.4011, Train Acc=0.8141 ||| Val Loss=0.4191, Val Acc=0.7884\n",
      "Epoch 158: Train Loss=0.4024, Train Acc=0.8059 ||| Val Loss=0.4115, Val Acc=0.7895\n",
      "Epoch 159: Train Loss=0.3999, Train Acc=0.8121 ||| Val Loss=0.4161, Val Acc=0.7901\n",
      "Epoch 160: Train Loss=0.4037, Train Acc=0.8087 ||| Val Loss=0.4128, Val Acc=0.7941\n",
      "Epoch 161: Train Loss=0.3993, Train Acc=0.8138 ||| Val Loss=0.4132, Val Acc=0.7953\n",
      "Epoch 162: Train Loss=0.3999, Train Acc=0.8102 ||| Val Loss=0.4133, Val Acc=0.7872\n",
      "Epoch 163: Train Loss=0.4023, Train Acc=0.8118 ||| Val Loss=0.4139, Val Acc=0.7936\n",
      "Epoch 164: Train Loss=0.4015, Train Acc=0.8131 ||| Val Loss=0.4120, Val Acc=0.7907\n",
      "Epoch 165: Train Loss=0.3997, Train Acc=0.8133 ||| Val Loss=0.4166, Val Acc=0.7924\n",
      "Epoch 166: Train Loss=0.3986, Train Acc=0.8105 ||| Val Loss=0.4158, Val Acc=0.7890\n",
      "Epoch 167: Train Loss=0.3986, Train Acc=0.8122 ||| Val Loss=0.4150, Val Acc=0.7953\n",
      "Epoch 168: Train Loss=0.3956, Train Acc=0.8118 ||| Val Loss=0.4099, Val Acc=0.7890\n",
      "Epoch 169: Train Loss=0.3935, Train Acc=0.8155 ||| Val Loss=0.4071, Val Acc=0.7918\n",
      "Epoch 170: Train Loss=0.3933, Train Acc=0.8112 ||| Val Loss=0.4106, Val Acc=0.7867\n",
      "Epoch 171: Train Loss=0.3957, Train Acc=0.8110 ||| Val Loss=0.4131, Val Acc=0.7907\n",
      "Epoch 172: Train Loss=0.3943, Train Acc=0.8152 ||| Val Loss=0.4075, Val Acc=0.7964\n",
      "Epoch 173: Train Loss=0.3967, Train Acc=0.8133 ||| Val Loss=0.4123, Val Acc=0.7895\n",
      "Epoch 174: Train Loss=0.3946, Train Acc=0.8115 ||| Val Loss=0.4096, Val Acc=0.7872\n",
      "Epoch 175: Train Loss=0.3923, Train Acc=0.8106 ||| Val Loss=0.4074, Val Acc=0.7907\n",
      "Epoch 176: Train Loss=0.3926, Train Acc=0.8144 ||| Val Loss=0.4136, Val Acc=0.7947\n",
      "Epoch 177: Train Loss=0.3920, Train Acc=0.8145 ||| Val Loss=0.4168, Val Acc=0.7867\n",
      "Epoch 178: Train Loss=0.3918, Train Acc=0.8158 ||| Val Loss=0.4067, Val Acc=0.7947\n",
      "Epoch 179: Train Loss=0.3913, Train Acc=0.8097 ||| Val Loss=0.4046, Val Acc=0.7941\n",
      "Epoch 180: Train Loss=0.3954, Train Acc=0.8112 ||| Val Loss=0.4110, Val Acc=0.7947\n",
      "Epoch 181: Train Loss=0.3961, Train Acc=0.8105 ||| Val Loss=0.4083, Val Acc=0.8005\n",
      "Epoch 182: Train Loss=0.3947, Train Acc=0.8148 ||| Val Loss=0.4077, Val Acc=0.7953\n",
      "Epoch 183: Train Loss=0.3890, Train Acc=0.8159 ||| Val Loss=0.4079, Val Acc=0.7999\n",
      "Epoch 184: Train Loss=0.3908, Train Acc=0.8138 ||| Val Loss=0.4089, Val Acc=0.7867\n",
      "Epoch 185: Train Loss=0.3940, Train Acc=0.8159 ||| Val Loss=0.4047, Val Acc=0.7941\n",
      "Epoch 186: Train Loss=0.3880, Train Acc=0.8146 ||| Val Loss=0.4076, Val Acc=0.7918\n",
      "Epoch 187: Train Loss=0.3890, Train Acc=0.8142 ||| Val Loss=0.4094, Val Acc=0.7953\n",
      "Epoch 188: Train Loss=0.3911, Train Acc=0.8148 ||| Val Loss=0.4097, Val Acc=0.8010\n",
      "Epoch 189: Train Loss=0.3883, Train Acc=0.8149 ||| Val Loss=0.4043, Val Acc=0.8028\n",
      "Epoch 190: Train Loss=0.3898, Train Acc=0.8136 ||| Val Loss=0.4094, Val Acc=0.7924\n",
      "Epoch 191: Train Loss=0.3878, Train Acc=0.8200 ||| Val Loss=0.4141, Val Acc=0.8010\n",
      "Epoch 192: Train Loss=0.3907, Train Acc=0.8135 ||| Val Loss=0.4136, Val Acc=0.8028\n",
      "Epoch 193: Train Loss=0.3840, Train Acc=0.8164 ||| Val Loss=0.4075, Val Acc=0.8028\n",
      "Epoch 194: Train Loss=0.3869, Train Acc=0.8159 ||| Val Loss=0.4139, Val Acc=0.7930\n",
      "Epoch 195: Train Loss=0.3873, Train Acc=0.8210 ||| Val Loss=0.4062, Val Acc=0.7982\n",
      "Epoch 196: Train Loss=0.3867, Train Acc=0.8200 ||| Val Loss=0.4044, Val Acc=0.7999\n",
      "Epoch 197: Train Loss=0.3882, Train Acc=0.8184 ||| Val Loss=0.4148, Val Acc=0.7993\n",
      "Epoch 198: Train Loss=0.3886, Train Acc=0.8154 ||| Val Loss=0.4164, Val Acc=0.7941\n",
      "Epoch 199: Train Loss=0.3839, Train Acc=0.8221 ||| Val Loss=0.4095, Val Acc=0.7924\n",
      "Epoch 200: Train Loss=0.3838, Train Acc=0.8174 ||| Val Loss=0.4091, Val Acc=0.7976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 16:53:17,548] Trial 0 finished with value: 0.7975848188614146 and parameters: {'n_blocks': 2, 'd_block': 128, 'k': 8, 'dropout': 0.4226779073013317, 'activation': 'GELU', 'lr': 0.0010017908773783256, 'weight_decay': 5.48391092738397e-06}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7976\n",
      "\n",
      " Trial 2 with params: {'n_blocks': 6, 'd_block': 128, 'k': 7, 'dropout': 0.3788069684528431, 'activation': 'GELU', 'lr': 0.00023978507077590286, 'weight_decay': 1.0413895371304064e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.1420, Train Acc=0.5055 ||| Val Loss=0.6769, Val Acc=0.6360\n",
      "Epoch 2: Train Loss=0.7770, Train Acc=0.5315 ||| Val Loss=0.6726, Val Acc=0.6705\n",
      "Epoch 3: Train Loss=0.7341, Train Acc=0.5309 ||| Val Loss=0.6708, Val Acc=0.6049\n",
      "Epoch 4: Train Loss=0.7016, Train Acc=0.5587 ||| Val Loss=0.6639, Val Acc=0.6274\n",
      "Epoch 5: Train Loss=0.6865, Train Acc=0.5742 ||| Val Loss=0.6475, Val Acc=0.6504\n",
      "Epoch 6: Train Loss=0.6630, Train Acc=0.6011 ||| Val Loss=0.6131, Val Acc=0.6849\n",
      "Epoch 7: Train Loss=0.6401, Train Acc=0.6435 ||| Val Loss=0.5779, Val Acc=0.7154\n",
      "Epoch 8: Train Loss=0.6122, Train Acc=0.6690 ||| Val Loss=0.5624, Val Acc=0.7182\n",
      "Epoch 9: Train Loss=0.5942, Train Acc=0.6887 ||| Val Loss=0.5672, Val Acc=0.7131\n",
      "Epoch 10: Train Loss=0.5880, Train Acc=0.7081 ||| Val Loss=0.5571, Val Acc=0.7257\n",
      "Epoch 11: Train Loss=0.5764, Train Acc=0.7225 ||| Val Loss=0.5459, Val Acc=0.7464\n",
      "Epoch 12: Train Loss=0.5647, Train Acc=0.7288 ||| Val Loss=0.5347, Val Acc=0.7711\n",
      "Epoch 13: Train Loss=0.5628, Train Acc=0.7327 ||| Val Loss=0.5348, Val Acc=0.7706\n",
      "Epoch 14: Train Loss=0.5541, Train Acc=0.7387 ||| Val Loss=0.5288, Val Acc=0.7740\n",
      "Epoch 15: Train Loss=0.5446, Train Acc=0.7471 ||| Val Loss=0.5225, Val Acc=0.7826\n",
      "Epoch 16: Train Loss=0.5420, Train Acc=0.7564 ||| Val Loss=0.5147, Val Acc=0.7798\n",
      "Epoch 17: Train Loss=0.5388, Train Acc=0.7606 ||| Val Loss=0.5131, Val Acc=0.7861\n",
      "Epoch 18: Train Loss=0.5361, Train Acc=0.7624 ||| Val Loss=0.5119, Val Acc=0.7849\n",
      "Epoch 19: Train Loss=0.5272, Train Acc=0.7686 ||| Val Loss=0.5063, Val Acc=0.7855\n",
      "Epoch 20: Train Loss=0.5292, Train Acc=0.7643 ||| Val Loss=0.5078, Val Acc=0.7878\n",
      "Epoch 21: Train Loss=0.5231, Train Acc=0.7728 ||| Val Loss=0.5061, Val Acc=0.7907\n",
      "Epoch 22: Train Loss=0.5176, Train Acc=0.7703 ||| Val Loss=0.5007, Val Acc=0.7884\n",
      "Epoch 23: Train Loss=0.5201, Train Acc=0.7721 ||| Val Loss=0.4995, Val Acc=0.7924\n",
      "Epoch 24: Train Loss=0.5175, Train Acc=0.7739 ||| Val Loss=0.5041, Val Acc=0.7867\n",
      "Epoch 25: Train Loss=0.5117, Train Acc=0.7768 ||| Val Loss=0.5041, Val Acc=0.7884\n",
      "Epoch 26: Train Loss=0.5144, Train Acc=0.7721 ||| Val Loss=0.4991, Val Acc=0.7884\n",
      "Epoch 27: Train Loss=0.5102, Train Acc=0.7767 ||| Val Loss=0.5015, Val Acc=0.7918\n",
      "Epoch 28: Train Loss=0.5103, Train Acc=0.7785 ||| Val Loss=0.4974, Val Acc=0.7901\n",
      "Epoch 29: Train Loss=0.5061, Train Acc=0.7801 ||| Val Loss=0.5057, Val Acc=0.7907\n",
      "Epoch 30: Train Loss=0.5081, Train Acc=0.7781 ||| Val Loss=0.4991, Val Acc=0.7895\n",
      "Epoch 31: Train Loss=0.5035, Train Acc=0.7833 ||| Val Loss=0.4990, Val Acc=0.7930\n",
      "Epoch 32: Train Loss=0.5056, Train Acc=0.7824 ||| Val Loss=0.4988, Val Acc=0.7901\n",
      "Epoch 33: Train Loss=0.5053, Train Acc=0.7810 ||| Val Loss=0.4961, Val Acc=0.7884\n",
      "Epoch 34: Train Loss=0.4992, Train Acc=0.7830 ||| Val Loss=0.4965, Val Acc=0.7936\n",
      "Epoch 35: Train Loss=0.5031, Train Acc=0.7816 ||| Val Loss=0.4966, Val Acc=0.7953\n",
      "Epoch 36: Train Loss=0.5011, Train Acc=0.7834 ||| Val Loss=0.5003, Val Acc=0.7907\n",
      "Epoch 37: Train Loss=0.5038, Train Acc=0.7817 ||| Val Loss=0.5020, Val Acc=0.7884\n",
      "Epoch 38: Train Loss=0.4957, Train Acc=0.7872 ||| Val Loss=0.4954, Val Acc=0.7953\n",
      "Epoch 39: Train Loss=0.5016, Train Acc=0.7836 ||| Val Loss=0.4927, Val Acc=0.7930\n",
      "Epoch 40: Train Loss=0.5014, Train Acc=0.7839 ||| Val Loss=0.4954, Val Acc=0.7936\n",
      "Epoch 41: Train Loss=0.4922, Train Acc=0.7862 ||| Val Loss=0.4879, Val Acc=0.7959\n",
      "Epoch 42: Train Loss=0.5018, Train Acc=0.7830 ||| Val Loss=0.4885, Val Acc=0.7964\n",
      "Epoch 43: Train Loss=0.4962, Train Acc=0.7852 ||| Val Loss=0.4908, Val Acc=0.7930\n",
      "Epoch 44: Train Loss=0.4922, Train Acc=0.7877 ||| Val Loss=0.4942, Val Acc=0.7976\n",
      "Epoch 45: Train Loss=0.4905, Train Acc=0.7853 ||| Val Loss=0.4879, Val Acc=0.7953\n",
      "Epoch 46: Train Loss=0.4919, Train Acc=0.7860 ||| Val Loss=0.4879, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.4886, Train Acc=0.7850 ||| Val Loss=0.4845, Val Acc=0.7959\n",
      "Epoch 48: Train Loss=0.4897, Train Acc=0.7873 ||| Val Loss=0.4835, Val Acc=0.7964\n",
      "Epoch 49: Train Loss=0.4890, Train Acc=0.7842 ||| Val Loss=0.4832, Val Acc=0.7964\n",
      "Epoch 50: Train Loss=0.4849, Train Acc=0.7854 ||| Val Loss=0.4794, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4806, Train Acc=0.7879 ||| Val Loss=0.4763, Val Acc=0.7982\n",
      "Epoch 52: Train Loss=0.4833, Train Acc=0.7876 ||| Val Loss=0.4740, Val Acc=0.7947\n",
      "Epoch 53: Train Loss=0.4795, Train Acc=0.7892 ||| Val Loss=0.4751, Val Acc=0.7964\n",
      "Epoch 54: Train Loss=0.4781, Train Acc=0.7863 ||| Val Loss=0.4799, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4808, Train Acc=0.7898 ||| Val Loss=0.4798, Val Acc=0.7999\n",
      "Epoch 56: Train Loss=0.4746, Train Acc=0.7900 ||| Val Loss=0.4676, Val Acc=0.7999\n",
      "Epoch 57: Train Loss=0.4761, Train Acc=0.7885 ||| Val Loss=0.4719, Val Acc=0.7982\n",
      "Epoch 58: Train Loss=0.4723, Train Acc=0.7857 ||| Val Loss=0.4682, Val Acc=0.8005\n",
      "Epoch 59: Train Loss=0.4753, Train Acc=0.7849 ||| Val Loss=0.4695, Val Acc=0.7982\n",
      "Epoch 60: Train Loss=0.4694, Train Acc=0.7867 ||| Val Loss=0.4589, Val Acc=0.7999\n",
      "Epoch 61: Train Loss=0.4669, Train Acc=0.7873 ||| Val Loss=0.4578, Val Acc=0.8005\n",
      "Epoch 62: Train Loss=0.4642, Train Acc=0.7882 ||| Val Loss=0.4514, Val Acc=0.8016\n",
      "Epoch 63: Train Loss=0.4680, Train Acc=0.7898 ||| Val Loss=0.4484, Val Acc=0.7993\n",
      "Epoch 64: Train Loss=0.4678, Train Acc=0.7911 ||| Val Loss=0.4516, Val Acc=0.8005\n",
      "Epoch 65: Train Loss=0.4616, Train Acc=0.7893 ||| Val Loss=0.4452, Val Acc=0.8016\n",
      "Epoch 66: Train Loss=0.4622, Train Acc=0.7875 ||| Val Loss=0.4494, Val Acc=0.8010\n",
      "Epoch 67: Train Loss=0.4572, Train Acc=0.7879 ||| Val Loss=0.4440, Val Acc=0.8016\n",
      "Epoch 68: Train Loss=0.4598, Train Acc=0.7872 ||| Val Loss=0.4414, Val Acc=0.7993\n",
      "Epoch 69: Train Loss=0.4562, Train Acc=0.7900 ||| Val Loss=0.4400, Val Acc=0.7982\n",
      "Epoch 70: Train Loss=0.4537, Train Acc=0.7903 ||| Val Loss=0.4324, Val Acc=0.7970\n",
      "Epoch 71: Train Loss=0.4509, Train Acc=0.7875 ||| Val Loss=0.4351, Val Acc=0.7982\n",
      "Epoch 72: Train Loss=0.4439, Train Acc=0.7883 ||| Val Loss=0.4325, Val Acc=0.7982\n",
      "Epoch 73: Train Loss=0.4478, Train Acc=0.7905 ||| Val Loss=0.4491, Val Acc=0.8005\n",
      "Epoch 74: Train Loss=0.4438, Train Acc=0.7939 ||| Val Loss=0.4464, Val Acc=0.7987\n",
      "Epoch 75: Train Loss=0.4462, Train Acc=0.7934 ||| Val Loss=0.4361, Val Acc=0.7970\n",
      "Epoch 76: Train Loss=0.4451, Train Acc=0.7890 ||| Val Loss=0.4276, Val Acc=0.7970\n",
      "Epoch 77: Train Loss=0.4385, Train Acc=0.7892 ||| Val Loss=0.4283, Val Acc=0.7947\n",
      "Epoch 78: Train Loss=0.4465, Train Acc=0.7951 ||| Val Loss=0.4268, Val Acc=0.7987\n",
      "Epoch 79: Train Loss=0.4367, Train Acc=0.7925 ||| Val Loss=0.4310, Val Acc=0.8005\n",
      "Epoch 80: Train Loss=0.4337, Train Acc=0.7948 ||| Val Loss=0.4250, Val Acc=0.7999\n",
      "Epoch 81: Train Loss=0.4364, Train Acc=0.7942 ||| Val Loss=0.4264, Val Acc=0.7999\n",
      "Epoch 82: Train Loss=0.4348, Train Acc=0.7900 ||| Val Loss=0.4234, Val Acc=0.7999\n",
      "Epoch 83: Train Loss=0.4395, Train Acc=0.7934 ||| Val Loss=0.4307, Val Acc=0.8010\n",
      "Epoch 84: Train Loss=0.4362, Train Acc=0.7919 ||| Val Loss=0.4237, Val Acc=0.7987\n",
      "Epoch 85: Train Loss=0.4397, Train Acc=0.7934 ||| Val Loss=0.4320, Val Acc=0.8022\n",
      "Epoch 86: Train Loss=0.4329, Train Acc=0.7918 ||| Val Loss=0.4259, Val Acc=0.8056\n",
      "Epoch 87: Train Loss=0.4354, Train Acc=0.7935 ||| Val Loss=0.4314, Val Acc=0.8022\n",
      "Epoch 88: Train Loss=0.4354, Train Acc=0.7889 ||| Val Loss=0.4274, Val Acc=0.8022\n",
      "Epoch 89: Train Loss=0.4307, Train Acc=0.7955 ||| Val Loss=0.4282, Val Acc=0.8039\n",
      "Epoch 90: Train Loss=0.4349, Train Acc=0.7929 ||| Val Loss=0.4238, Val Acc=0.8016\n",
      "Epoch 91: Train Loss=0.4312, Train Acc=0.7981 ||| Val Loss=0.4250, Val Acc=0.7976\n",
      "Epoch 92: Train Loss=0.4329, Train Acc=0.7925 ||| Val Loss=0.4333, Val Acc=0.8062\n",
      "Epoch 93: Train Loss=0.4368, Train Acc=0.7974 ||| Val Loss=0.4312, Val Acc=0.7964\n",
      "Epoch 94: Train Loss=0.4314, Train Acc=0.7918 ||| Val Loss=0.4268, Val Acc=0.7970\n",
      "Epoch 95: Train Loss=0.4286, Train Acc=0.7934 ||| Val Loss=0.4267, Val Acc=0.7982\n",
      "Epoch 96: Train Loss=0.4278, Train Acc=0.7957 ||| Val Loss=0.4223, Val Acc=0.7999\n",
      "Epoch 97: Train Loss=0.4307, Train Acc=0.7958 ||| Val Loss=0.4283, Val Acc=0.7964\n",
      "Epoch 98: Train Loss=0.4267, Train Acc=0.7958 ||| Val Loss=0.4248, Val Acc=0.7987\n",
      "Epoch 99: Train Loss=0.4261, Train Acc=0.7984 ||| Val Loss=0.4248, Val Acc=0.8028\n",
      "Epoch 100: Train Loss=0.4323, Train Acc=0.7958 ||| Val Loss=0.4256, Val Acc=0.7964\n",
      "Epoch 101: Train Loss=0.4288, Train Acc=0.7934 ||| Val Loss=0.4259, Val Acc=0.7953\n",
      "Epoch 102: Train Loss=0.4238, Train Acc=0.7971 ||| Val Loss=0.4242, Val Acc=0.7959\n",
      "Epoch 103: Train Loss=0.4266, Train Acc=0.7934 ||| Val Loss=0.4234, Val Acc=0.7976\n",
      "Epoch 104: Train Loss=0.4292, Train Acc=0.7958 ||| Val Loss=0.4247, Val Acc=0.7999\n",
      "Epoch 105: Train Loss=0.4275, Train Acc=0.7932 ||| Val Loss=0.4244, Val Acc=0.7987\n",
      "Epoch 106: Train Loss=0.4274, Train Acc=0.7941 ||| Val Loss=0.4250, Val Acc=0.8022\n",
      "Epoch 107: Train Loss=0.4267, Train Acc=0.7958 ||| Val Loss=0.4252, Val Acc=0.7913\n",
      "Epoch 108: Train Loss=0.4252, Train Acc=0.7964 ||| Val Loss=0.4262, Val Acc=0.7941\n",
      "Epoch 109: Train Loss=0.4239, Train Acc=0.7931 ||| Val Loss=0.4258, Val Acc=0.7959\n",
      "Epoch 110: Train Loss=0.4255, Train Acc=0.7957 ||| Val Loss=0.4267, Val Acc=0.7953\n",
      "Epoch 111: Train Loss=0.4226, Train Acc=0.7957 ||| Val Loss=0.4221, Val Acc=0.7987\n",
      "Epoch 112: Train Loss=0.4238, Train Acc=0.7931 ||| Val Loss=0.4224, Val Acc=0.7987\n",
      "Epoch 113: Train Loss=0.4219, Train Acc=0.7952 ||| Val Loss=0.4237, Val Acc=0.7970\n",
      "Epoch 114: Train Loss=0.4228, Train Acc=0.7941 ||| Val Loss=0.4208, Val Acc=0.8010\n",
      "Epoch 115: Train Loss=0.4216, Train Acc=0.7965 ||| Val Loss=0.4230, Val Acc=0.7953\n",
      "Epoch 116: Train Loss=0.4255, Train Acc=0.7958 ||| Val Loss=0.4221, Val Acc=0.7970\n",
      "Epoch 117: Train Loss=0.4257, Train Acc=0.7948 ||| Val Loss=0.4220, Val Acc=0.7959\n",
      "Epoch 118: Train Loss=0.4224, Train Acc=0.7957 ||| Val Loss=0.4235, Val Acc=0.7941\n",
      "Epoch 119: Train Loss=0.4238, Train Acc=0.7936 ||| Val Loss=0.4288, Val Acc=0.7901\n",
      "Epoch 120: Train Loss=0.4220, Train Acc=0.7974 ||| Val Loss=0.4263, Val Acc=0.7907\n",
      "Epoch 121: Train Loss=0.4203, Train Acc=0.7993 ||| Val Loss=0.4255, Val Acc=0.7872\n",
      "Epoch 122: Train Loss=0.4213, Train Acc=0.7965 ||| Val Loss=0.4255, Val Acc=0.7901\n",
      "Epoch 123: Train Loss=0.4217, Train Acc=0.7954 ||| Val Loss=0.4243, Val Acc=0.7895\n",
      "Epoch 124: Train Loss=0.4178, Train Acc=0.7970 ||| Val Loss=0.4229, Val Acc=0.7936\n",
      "Epoch 125: Train Loss=0.4248, Train Acc=0.7955 ||| Val Loss=0.4248, Val Acc=0.7895\n",
      "Epoch 126: Train Loss=0.4195, Train Acc=0.7947 ||| Val Loss=0.4230, Val Acc=0.7907\n",
      "Epoch 127: Train Loss=0.4174, Train Acc=0.7988 ||| Val Loss=0.4229, Val Acc=0.7907\n",
      "Epoch 128: Train Loss=0.4205, Train Acc=0.7975 ||| Val Loss=0.4225, Val Acc=0.7964\n",
      "Epoch 129: Train Loss=0.4187, Train Acc=0.7972 ||| Val Loss=0.4209, Val Acc=0.7970\n",
      "Epoch 130: Train Loss=0.4202, Train Acc=0.7991 ||| Val Loss=0.4256, Val Acc=0.7941\n",
      "Epoch 131: Train Loss=0.4189, Train Acc=0.7965 ||| Val Loss=0.4255, Val Acc=0.7867\n",
      "Epoch 132: Train Loss=0.4156, Train Acc=0.8001 ||| Val Loss=0.4230, Val Acc=0.7941\n",
      "Epoch 133: Train Loss=0.4172, Train Acc=0.7974 ||| Val Loss=0.4212, Val Acc=0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 16:54:18,600] Trial 1 finished with value: 0.7952846463484762 and parameters: {'n_blocks': 6, 'd_block': 128, 'k': 7, 'dropout': 0.3788069684528431, 'activation': 'GELU', 'lr': 0.00023978507077590286, 'weight_decay': 1.0413895371304064e-06}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: Train Loss=0.4156, Train Acc=0.8014 ||| Val Loss=0.4214, Val Acc=0.7953\n",
      "Early stopping triggered at epoch 134\n",
      "Validation Accuracy: 0.7953\n",
      "\n",
      " Trial 3 with params: {'n_blocks': 4, 'd_block': 512, 'k': 4, 'dropout': 0.16415412641921137, 'activation': 'LeakyReLU', 'lr': 0.00018308527448903479, 'weight_decay': 2.235440297775048e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.6864, Train Acc=0.6543 ||| Val Loss=0.8722, Val Acc=0.5405\n",
      "Epoch 2: Train Loss=0.8285, Train Acc=0.6836 ||| Val Loss=0.5288, Val Acc=0.7907\n",
      "Epoch 3: Train Loss=0.6766, Train Acc=0.6989 ||| Val Loss=0.5203, Val Acc=0.7769\n",
      "Epoch 4: Train Loss=0.6184, Train Acc=0.7089 ||| Val Loss=0.5169, Val Acc=0.7792\n",
      "Epoch 5: Train Loss=0.5888, Train Acc=0.7236 ||| Val Loss=0.5176, Val Acc=0.7821\n",
      "Epoch 6: Train Loss=0.5642, Train Acc=0.7308 ||| Val Loss=0.5083, Val Acc=0.7844\n",
      "Epoch 7: Train Loss=0.5617, Train Acc=0.7366 ||| Val Loss=0.5039, Val Acc=0.7913\n",
      "Epoch 8: Train Loss=0.5611, Train Acc=0.7410 ||| Val Loss=0.5129, Val Acc=0.7855\n",
      "Epoch 9: Train Loss=0.5406, Train Acc=0.7483 ||| Val Loss=0.5082, Val Acc=0.7930\n",
      "Epoch 10: Train Loss=0.5267, Train Acc=0.7564 ||| Val Loss=0.5134, Val Acc=0.7924\n",
      "Epoch 11: Train Loss=0.5280, Train Acc=0.7597 ||| Val Loss=0.5146, Val Acc=0.7941\n",
      "Epoch 12: Train Loss=0.5271, Train Acc=0.7558 ||| Val Loss=0.5227, Val Acc=0.7493\n",
      "Epoch 13: Train Loss=0.5212, Train Acc=0.7675 ||| Val Loss=0.5263, Val Acc=0.7734\n",
      "Epoch 14: Train Loss=0.5151, Train Acc=0.7714 ||| Val Loss=0.5208, Val Acc=0.7780\n",
      "Epoch 15: Train Loss=0.5182, Train Acc=0.7632 ||| Val Loss=0.5047, Val Acc=0.7918\n",
      "Epoch 16: Train Loss=0.5074, Train Acc=0.7714 ||| Val Loss=0.4981, Val Acc=0.7913\n",
      "Epoch 17: Train Loss=0.5112, Train Acc=0.7770 ||| Val Loss=0.4927, Val Acc=0.7884\n",
      "Epoch 18: Train Loss=0.5117, Train Acc=0.7702 ||| Val Loss=0.4823, Val Acc=0.7941\n",
      "Epoch 19: Train Loss=0.5071, Train Acc=0.7716 ||| Val Loss=0.4899, Val Acc=0.7947\n",
      "Epoch 20: Train Loss=0.5063, Train Acc=0.7755 ||| Val Loss=0.4959, Val Acc=0.7953\n",
      "Epoch 21: Train Loss=0.5039, Train Acc=0.7770 ||| Val Loss=0.5038, Val Acc=0.7924\n",
      "Epoch 22: Train Loss=0.5047, Train Acc=0.7745 ||| Val Loss=0.4929, Val Acc=0.7918\n",
      "Epoch 23: Train Loss=0.5028, Train Acc=0.7764 ||| Val Loss=0.4936, Val Acc=0.7982\n",
      "Epoch 24: Train Loss=0.4985, Train Acc=0.7821 ||| Val Loss=0.4875, Val Acc=0.7959\n",
      "Epoch 25: Train Loss=0.4968, Train Acc=0.7811 ||| Val Loss=0.4884, Val Acc=0.7936\n",
      "Epoch 26: Train Loss=0.4936, Train Acc=0.7801 ||| Val Loss=0.4817, Val Acc=0.7941\n",
      "Epoch 27: Train Loss=0.4906, Train Acc=0.7839 ||| Val Loss=0.4891, Val Acc=0.7930\n",
      "Epoch 28: Train Loss=0.4887, Train Acc=0.7852 ||| Val Loss=0.4805, Val Acc=0.7913\n",
      "Epoch 29: Train Loss=0.4902, Train Acc=0.7831 ||| Val Loss=0.5081, Val Acc=0.7803\n",
      "Epoch 30: Train Loss=0.4914, Train Acc=0.7807 ||| Val Loss=0.4766, Val Acc=0.7947\n",
      "Epoch 31: Train Loss=0.4874, Train Acc=0.7862 ||| Val Loss=0.4835, Val Acc=0.7993\n",
      "Epoch 32: Train Loss=0.4865, Train Acc=0.7837 ||| Val Loss=0.4752, Val Acc=0.7953\n",
      "Epoch 33: Train Loss=0.4870, Train Acc=0.7846 ||| Val Loss=0.4812, Val Acc=0.7936\n",
      "Epoch 34: Train Loss=0.4862, Train Acc=0.7859 ||| Val Loss=0.4733, Val Acc=0.7987\n",
      "Epoch 35: Train Loss=0.4849, Train Acc=0.7850 ||| Val Loss=0.4802, Val Acc=0.7947\n",
      "Epoch 36: Train Loss=0.4774, Train Acc=0.7882 ||| Val Loss=0.4718, Val Acc=0.7953\n",
      "Epoch 37: Train Loss=0.4782, Train Acc=0.7829 ||| Val Loss=0.4995, Val Acc=0.7953\n",
      "Epoch 38: Train Loss=0.4794, Train Acc=0.7833 ||| Val Loss=0.4650, Val Acc=0.7941\n",
      "Epoch 39: Train Loss=0.4796, Train Acc=0.7857 ||| Val Loss=0.4910, Val Acc=0.8005\n",
      "Epoch 40: Train Loss=0.4748, Train Acc=0.7840 ||| Val Loss=0.4882, Val Acc=0.7884\n",
      "Epoch 41: Train Loss=0.4808, Train Acc=0.7829 ||| Val Loss=0.4653, Val Acc=0.7959\n",
      "Epoch 42: Train Loss=0.4714, Train Acc=0.7850 ||| Val Loss=0.4747, Val Acc=0.7976\n",
      "Epoch 43: Train Loss=0.4721, Train Acc=0.7844 ||| Val Loss=0.4610, Val Acc=0.7947\n",
      "Epoch 44: Train Loss=0.4654, Train Acc=0.7839 ||| Val Loss=0.4600, Val Acc=0.7947\n",
      "Epoch 45: Train Loss=0.4670, Train Acc=0.7856 ||| Val Loss=0.4594, Val Acc=0.7924\n",
      "Epoch 46: Train Loss=0.4698, Train Acc=0.7840 ||| Val Loss=0.4592, Val Acc=0.7982\n",
      "Epoch 47: Train Loss=0.4662, Train Acc=0.7824 ||| Val Loss=0.4727, Val Acc=0.7907\n",
      "Epoch 48: Train Loss=0.4595, Train Acc=0.7857 ||| Val Loss=0.4545, Val Acc=0.7941\n",
      "Epoch 49: Train Loss=0.4613, Train Acc=0.7860 ||| Val Loss=0.4800, Val Acc=0.7740\n",
      "Epoch 50: Train Loss=0.4587, Train Acc=0.7862 ||| Val Loss=0.4619, Val Acc=0.7930\n",
      "Epoch 51: Train Loss=0.4595, Train Acc=0.7877 ||| Val Loss=0.4533, Val Acc=0.7930\n",
      "Epoch 52: Train Loss=0.4540, Train Acc=0.7876 ||| Val Loss=0.4531, Val Acc=0.7964\n",
      "Epoch 53: Train Loss=0.4561, Train Acc=0.7819 ||| Val Loss=0.4541, Val Acc=0.7959\n",
      "Epoch 54: Train Loss=0.4518, Train Acc=0.7843 ||| Val Loss=0.4552, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4534, Train Acc=0.7877 ||| Val Loss=0.4461, Val Acc=0.7964\n",
      "Epoch 56: Train Loss=0.4513, Train Acc=0.7890 ||| Val Loss=0.4526, Val Acc=0.7947\n",
      "Epoch 57: Train Loss=0.4489, Train Acc=0.7896 ||| Val Loss=0.4537, Val Acc=0.7964\n",
      "Epoch 58: Train Loss=0.4450, Train Acc=0.7846 ||| Val Loss=0.4546, Val Acc=0.7941\n",
      "Epoch 59: Train Loss=0.4477, Train Acc=0.7865 ||| Val Loss=0.4497, Val Acc=0.7907\n",
      "Epoch 60: Train Loss=0.4457, Train Acc=0.7842 ||| Val Loss=0.4486, Val Acc=0.7947\n",
      "Epoch 61: Train Loss=0.4473, Train Acc=0.7863 ||| Val Loss=0.4481, Val Acc=0.7964\n",
      "Epoch 62: Train Loss=0.4444, Train Acc=0.7890 ||| Val Loss=0.4506, Val Acc=0.7993\n",
      "Epoch 63: Train Loss=0.4426, Train Acc=0.7880 ||| Val Loss=0.4474, Val Acc=0.7947\n",
      "Epoch 64: Train Loss=0.4454, Train Acc=0.7876 ||| Val Loss=0.4436, Val Acc=0.7959\n",
      "Epoch 65: Train Loss=0.4455, Train Acc=0.7899 ||| Val Loss=0.4500, Val Acc=0.7941\n",
      "Epoch 66: Train Loss=0.4407, Train Acc=0.7908 ||| Val Loss=0.4435, Val Acc=0.7947\n",
      "Epoch 67: Train Loss=0.4410, Train Acc=0.7842 ||| Val Loss=0.4490, Val Acc=0.7970\n",
      "Epoch 68: Train Loss=0.4406, Train Acc=0.7900 ||| Val Loss=0.4489, Val Acc=0.7924\n",
      "Epoch 69: Train Loss=0.4427, Train Acc=0.7886 ||| Val Loss=0.4615, Val Acc=0.7936\n",
      "Epoch 70: Train Loss=0.4402, Train Acc=0.7905 ||| Val Loss=0.4498, Val Acc=0.7924\n",
      "Epoch 71: Train Loss=0.4368, Train Acc=0.7885 ||| Val Loss=0.4470, Val Acc=0.7970\n",
      "Epoch 72: Train Loss=0.4388, Train Acc=0.7859 ||| Val Loss=0.4454, Val Acc=0.7936\n",
      "Epoch 73: Train Loss=0.4368, Train Acc=0.7908 ||| Val Loss=0.4459, Val Acc=0.7964\n",
      "Epoch 74: Train Loss=0.4368, Train Acc=0.7882 ||| Val Loss=0.4483, Val Acc=0.7930\n",
      "Epoch 75: Train Loss=0.4353, Train Acc=0.7905 ||| Val Loss=0.4467, Val Acc=0.7936\n",
      "Epoch 76: Train Loss=0.4345, Train Acc=0.7886 ||| Val Loss=0.4386, Val Acc=0.7964\n",
      "Epoch 77: Train Loss=0.4360, Train Acc=0.7895 ||| Val Loss=0.4337, Val Acc=0.7999\n",
      "Epoch 78: Train Loss=0.4346, Train Acc=0.7902 ||| Val Loss=0.4401, Val Acc=0.7976\n",
      "Epoch 79: Train Loss=0.4336, Train Acc=0.7908 ||| Val Loss=0.4415, Val Acc=0.7993\n",
      "Epoch 80: Train Loss=0.4359, Train Acc=0.7856 ||| Val Loss=0.4444, Val Acc=0.8005\n",
      "Epoch 81: Train Loss=0.4308, Train Acc=0.7928 ||| Val Loss=0.4395, Val Acc=0.7970\n",
      "Epoch 82: Train Loss=0.4339, Train Acc=0.7911 ||| Val Loss=0.4351, Val Acc=0.7999\n",
      "Epoch 83: Train Loss=0.4331, Train Acc=0.7873 ||| Val Loss=0.4486, Val Acc=0.7982\n",
      "Epoch 84: Train Loss=0.4316, Train Acc=0.7931 ||| Val Loss=0.4384, Val Acc=0.7987\n",
      "Epoch 85: Train Loss=0.4328, Train Acc=0.7932 ||| Val Loss=0.4374, Val Acc=0.7947\n",
      "Epoch 86: Train Loss=0.4274, Train Acc=0.7909 ||| Val Loss=0.4434, Val Acc=0.7993\n",
      "Epoch 87: Train Loss=0.4273, Train Acc=0.7896 ||| Val Loss=0.4419, Val Acc=0.7941\n",
      "Epoch 88: Train Loss=0.4279, Train Acc=0.7905 ||| Val Loss=0.4362, Val Acc=0.7970\n",
      "Epoch 89: Train Loss=0.4275, Train Acc=0.7919 ||| Val Loss=0.4529, Val Acc=0.7982\n",
      "Epoch 90: Train Loss=0.4265, Train Acc=0.7896 ||| Val Loss=0.4501, Val Acc=0.7976\n",
      "Epoch 91: Train Loss=0.4279, Train Acc=0.7948 ||| Val Loss=0.4435, Val Acc=0.7970\n",
      "Epoch 92: Train Loss=0.4248, Train Acc=0.7926 ||| Val Loss=0.4442, Val Acc=0.7941\n",
      "Epoch 93: Train Loss=0.4234, Train Acc=0.7961 ||| Val Loss=0.4368, Val Acc=0.7964\n",
      "Epoch 94: Train Loss=0.4249, Train Acc=0.7977 ||| Val Loss=0.4461, Val Acc=0.7941\n",
      "Epoch 95: Train Loss=0.4290, Train Acc=0.7934 ||| Val Loss=0.4329, Val Acc=0.7930\n",
      "Epoch 96: Train Loss=0.4227, Train Acc=0.7962 ||| Val Loss=0.4365, Val Acc=0.7970\n",
      "Epoch 97: Train Loss=0.4240, Train Acc=0.7899 ||| Val Loss=0.4352, Val Acc=0.7947\n",
      "Epoch 98: Train Loss=0.4224, Train Acc=0.7935 ||| Val Loss=0.4370, Val Acc=0.7953\n",
      "Epoch 99: Train Loss=0.4243, Train Acc=0.7932 ||| Val Loss=0.4343, Val Acc=0.7953\n",
      "Epoch 100: Train Loss=0.4262, Train Acc=0.7975 ||| Val Loss=0.4351, Val Acc=0.7964\n",
      "Epoch 101: Train Loss=0.4224, Train Acc=0.7921 ||| Val Loss=0.4353, Val Acc=0.7918\n",
      "Epoch 102: Train Loss=0.4217, Train Acc=0.7942 ||| Val Loss=0.4350, Val Acc=0.7941\n",
      "Epoch 103: Train Loss=0.4230, Train Acc=0.7928 ||| Val Loss=0.4445, Val Acc=0.7941\n",
      "Epoch 104: Train Loss=0.4221, Train Acc=0.7954 ||| Val Loss=0.4377, Val Acc=0.7953\n",
      "Epoch 105: Train Loss=0.4207, Train Acc=0.7944 ||| Val Loss=0.4394, Val Acc=0.7941\n",
      "Epoch 106: Train Loss=0.4202, Train Acc=0.7958 ||| Val Loss=0.4344, Val Acc=0.7964\n",
      "Epoch 107: Train Loss=0.4206, Train Acc=0.7948 ||| Val Loss=0.4398, Val Acc=0.7890\n",
      "Epoch 108: Train Loss=0.4196, Train Acc=0.7981 ||| Val Loss=0.4436, Val Acc=0.7907\n",
      "Epoch 109: Train Loss=0.4199, Train Acc=0.8004 ||| Val Loss=0.4376, Val Acc=0.7947\n",
      "Epoch 110: Train Loss=0.4179, Train Acc=0.7981 ||| Val Loss=0.4450, Val Acc=0.7936\n",
      "Epoch 111: Train Loss=0.4190, Train Acc=0.7961 ||| Val Loss=0.4375, Val Acc=0.7941\n",
      "Epoch 112: Train Loss=0.4199, Train Acc=0.7931 ||| Val Loss=0.4393, Val Acc=0.7913\n",
      "Epoch 113: Train Loss=0.4197, Train Acc=0.7949 ||| Val Loss=0.4429, Val Acc=0.7964\n",
      "Epoch 114: Train Loss=0.4177, Train Acc=0.7964 ||| Val Loss=0.4370, Val Acc=0.7941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 16:55:25,361] Trial 2 finished with value: 0.7952846463484762 and parameters: {'n_blocks': 4, 'd_block': 512, 'k': 4, 'dropout': 0.16415412641921137, 'activation': 'LeakyReLU', 'lr': 0.00018308527448903479, 'weight_decay': 2.235440297775048e-06}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: Train Loss=0.4135, Train Acc=0.8021 ||| Val Loss=0.4513, Val Acc=0.7953\n",
      "Early stopping triggered at epoch 115\n",
      "Validation Accuracy: 0.7953\n",
      "\n",
      " Trial 4 with params: {'n_blocks': 4, 'd_block': 512, 'k': 11, 'dropout': 0.4861056500848959, 'activation': 'GELU', 'lr': 0.0009034158014843336, 'weight_decay': 0.0008700519756372972}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.6913, Train Acc=0.5661 ||| Val Loss=0.5603, Val Acc=0.7320\n",
      "Epoch 2: Train Loss=0.7774, Train Acc=0.6332 ||| Val Loss=0.5788, Val Acc=0.7993\n",
      "Epoch 3: Train Loss=0.6352, Train Acc=0.6786 ||| Val Loss=0.5604, Val Acc=0.7849\n",
      "Epoch 4: Train Loss=0.5885, Train Acc=0.6999 ||| Val Loss=0.5664, Val Acc=0.7608\n",
      "Epoch 5: Train Loss=0.5734, Train Acc=0.7189 ||| Val Loss=0.5410, Val Acc=0.7752\n",
      "Epoch 6: Train Loss=0.5654, Train Acc=0.7243 ||| Val Loss=0.5466, Val Acc=0.7855\n",
      "Epoch 7: Train Loss=0.5498, Train Acc=0.7429 ||| Val Loss=0.5231, Val Acc=0.7884\n",
      "Epoch 8: Train Loss=0.5455, Train Acc=0.7505 ||| Val Loss=0.5346, Val Acc=0.7878\n",
      "Epoch 9: Train Loss=0.5339, Train Acc=0.7571 ||| Val Loss=0.5263, Val Acc=0.7884\n",
      "Epoch 10: Train Loss=0.5398, Train Acc=0.7573 ||| Val Loss=0.5147, Val Acc=0.7936\n",
      "Epoch 11: Train Loss=0.5340, Train Acc=0.7622 ||| Val Loss=0.5289, Val Acc=0.7832\n",
      "Epoch 12: Train Loss=0.5265, Train Acc=0.7676 ||| Val Loss=0.5155, Val Acc=0.7861\n",
      "Epoch 13: Train Loss=0.5266, Train Acc=0.7675 ||| Val Loss=0.5071, Val Acc=0.7918\n",
      "Epoch 14: Train Loss=0.5147, Train Acc=0.7716 ||| Val Loss=0.5054, Val Acc=0.7941\n",
      "Epoch 15: Train Loss=0.5183, Train Acc=0.7705 ||| Val Loss=0.5036, Val Acc=0.7964\n",
      "Epoch 16: Train Loss=0.5130, Train Acc=0.7752 ||| Val Loss=0.4980, Val Acc=0.7947\n",
      "Epoch 17: Train Loss=0.5114, Train Acc=0.7778 ||| Val Loss=0.4951, Val Acc=0.7918\n",
      "Epoch 18: Train Loss=0.5121, Train Acc=0.7781 ||| Val Loss=0.4929, Val Acc=0.7924\n",
      "Epoch 19: Train Loss=0.5074, Train Acc=0.7794 ||| Val Loss=0.4931, Val Acc=0.7872\n",
      "Epoch 20: Train Loss=0.5051, Train Acc=0.7804 ||| Val Loss=0.4907, Val Acc=0.7872\n",
      "Epoch 21: Train Loss=0.5056, Train Acc=0.7785 ||| Val Loss=0.4882, Val Acc=0.7907\n",
      "Epoch 22: Train Loss=0.5057, Train Acc=0.7797 ||| Val Loss=0.4878, Val Acc=0.7924\n",
      "Epoch 23: Train Loss=0.5085, Train Acc=0.7800 ||| Val Loss=0.4867, Val Acc=0.7947\n",
      "Epoch 24: Train Loss=0.5096, Train Acc=0.7814 ||| Val Loss=0.4876, Val Acc=0.7936\n",
      "Epoch 25: Train Loss=0.5010, Train Acc=0.7823 ||| Val Loss=0.4887, Val Acc=0.7895\n",
      "Epoch 26: Train Loss=0.5061, Train Acc=0.7780 ||| Val Loss=0.4888, Val Acc=0.7936\n",
      "Epoch 27: Train Loss=0.5039, Train Acc=0.7831 ||| Val Loss=0.4886, Val Acc=0.7907\n",
      "Epoch 28: Train Loss=0.5024, Train Acc=0.7788 ||| Val Loss=0.4885, Val Acc=0.7890\n",
      "Epoch 29: Train Loss=0.5053, Train Acc=0.7807 ||| Val Loss=0.4881, Val Acc=0.7901\n",
      "Epoch 30: Train Loss=0.5024, Train Acc=0.7814 ||| Val Loss=0.4883, Val Acc=0.7895\n",
      "Epoch 31: Train Loss=0.5053, Train Acc=0.7813 ||| Val Loss=0.4929, Val Acc=0.7901\n",
      "Epoch 32: Train Loss=0.5090, Train Acc=0.7801 ||| Val Loss=0.4890, Val Acc=0.7890\n",
      "Epoch 33: Train Loss=0.5040, Train Acc=0.7804 ||| Val Loss=0.4880, Val Acc=0.7895\n",
      "Epoch 34: Train Loss=0.5003, Train Acc=0.7803 ||| Val Loss=0.4873, Val Acc=0.7895\n",
      "Epoch 35: Train Loss=0.5024, Train Acc=0.7801 ||| Val Loss=0.4884, Val Acc=0.7901\n",
      "Epoch 36: Train Loss=0.5030, Train Acc=0.7813 ||| Val Loss=0.4873, Val Acc=0.7895\n",
      "Epoch 37: Train Loss=0.5010, Train Acc=0.7819 ||| Val Loss=0.4868, Val Acc=0.7878\n",
      "Epoch 38: Train Loss=0.5009, Train Acc=0.7829 ||| Val Loss=0.4905, Val Acc=0.7901\n",
      "Epoch 39: Train Loss=0.5039, Train Acc=0.7836 ||| Val Loss=0.4877, Val Acc=0.7878\n",
      "Epoch 40: Train Loss=0.4999, Train Acc=0.7824 ||| Val Loss=0.4883, Val Acc=0.7913\n",
      "Epoch 41: Train Loss=0.4974, Train Acc=0.7839 ||| Val Loss=0.4873, Val Acc=0.7895\n",
      "Epoch 42: Train Loss=0.5036, Train Acc=0.7829 ||| Val Loss=0.4864, Val Acc=0.7918\n",
      "Epoch 43: Train Loss=0.5020, Train Acc=0.7824 ||| Val Loss=0.4858, Val Acc=0.7924\n",
      "Epoch 44: Train Loss=0.4997, Train Acc=0.7816 ||| Val Loss=0.4866, Val Acc=0.7895\n",
      "Epoch 45: Train Loss=0.4987, Train Acc=0.7840 ||| Val Loss=0.4862, Val Acc=0.7901\n",
      "Epoch 46: Train Loss=0.5019, Train Acc=0.7844 ||| Val Loss=0.4849, Val Acc=0.7930\n",
      "Epoch 47: Train Loss=0.4999, Train Acc=0.7817 ||| Val Loss=0.4835, Val Acc=0.7936\n",
      "Epoch 48: Train Loss=0.4970, Train Acc=0.7821 ||| Val Loss=0.4879, Val Acc=0.7941\n",
      "Epoch 49: Train Loss=0.5013, Train Acc=0.7830 ||| Val Loss=0.4848, Val Acc=0.7941\n",
      "Epoch 50: Train Loss=0.4969, Train Acc=0.7847 ||| Val Loss=0.4833, Val Acc=0.7918\n",
      "Epoch 51: Train Loss=0.4966, Train Acc=0.7827 ||| Val Loss=0.4832, Val Acc=0.7941\n",
      "Epoch 52: Train Loss=0.5013, Train Acc=0.7854 ||| Val Loss=0.4842, Val Acc=0.7930\n",
      "Epoch 53: Train Loss=0.4968, Train Acc=0.7852 ||| Val Loss=0.4832, Val Acc=0.7901\n",
      "Epoch 54: Train Loss=0.4990, Train Acc=0.7829 ||| Val Loss=0.4827, Val Acc=0.7930\n",
      "Epoch 55: Train Loss=0.4966, Train Acc=0.7852 ||| Val Loss=0.4815, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4948, Train Acc=0.7830 ||| Val Loss=0.4856, Val Acc=0.7970\n",
      "Epoch 57: Train Loss=0.4958, Train Acc=0.7856 ||| Val Loss=0.4847, Val Acc=0.7941\n",
      "Epoch 58: Train Loss=0.4984, Train Acc=0.7817 ||| Val Loss=0.4806, Val Acc=0.7936\n",
      "Epoch 59: Train Loss=0.4989, Train Acc=0.7836 ||| Val Loss=0.4832, Val Acc=0.7941\n",
      "Epoch 60: Train Loss=0.4949, Train Acc=0.7883 ||| Val Loss=0.4820, Val Acc=0.7913\n",
      "Epoch 61: Train Loss=0.4976, Train Acc=0.7820 ||| Val Loss=0.4806, Val Acc=0.7930\n",
      "Epoch 62: Train Loss=0.5015, Train Acc=0.7866 ||| Val Loss=0.4814, Val Acc=0.7918\n",
      "Epoch 63: Train Loss=0.4959, Train Acc=0.7852 ||| Val Loss=0.4816, Val Acc=0.7936\n",
      "Epoch 64: Train Loss=0.5002, Train Acc=0.7826 ||| Val Loss=0.4822, Val Acc=0.7953\n",
      "Epoch 65: Train Loss=0.4980, Train Acc=0.7839 ||| Val Loss=0.4800, Val Acc=0.7930\n",
      "Epoch 66: Train Loss=0.4966, Train Acc=0.7862 ||| Val Loss=0.4825, Val Acc=0.7976\n",
      "Epoch 67: Train Loss=0.4987, Train Acc=0.7847 ||| Val Loss=0.4794, Val Acc=0.7930\n",
      "Epoch 68: Train Loss=0.4967, Train Acc=0.7829 ||| Val Loss=0.4803, Val Acc=0.7936\n",
      "Epoch 69: Train Loss=0.4979, Train Acc=0.7842 ||| Val Loss=0.4793, Val Acc=0.7941\n",
      "Epoch 70: Train Loss=0.4963, Train Acc=0.7842 ||| Val Loss=0.4777, Val Acc=0.7930\n",
      "Epoch 71: Train Loss=0.4950, Train Acc=0.7826 ||| Val Loss=0.4781, Val Acc=0.7930\n",
      "Epoch 72: Train Loss=0.4929, Train Acc=0.7843 ||| Val Loss=0.4786, Val Acc=0.7924\n",
      "Epoch 73: Train Loss=0.4918, Train Acc=0.7834 ||| Val Loss=0.4775, Val Acc=0.7941\n",
      "Epoch 74: Train Loss=0.4935, Train Acc=0.7856 ||| Val Loss=0.4779, Val Acc=0.7913\n",
      "Epoch 75: Train Loss=0.4934, Train Acc=0.7867 ||| Val Loss=0.4764, Val Acc=0.7930\n",
      "Epoch 76: Train Loss=0.4904, Train Acc=0.7856 ||| Val Loss=0.4764, Val Acc=0.7947\n",
      "Epoch 77: Train Loss=0.4929, Train Acc=0.7860 ||| Val Loss=0.4758, Val Acc=0.7936\n",
      "Epoch 78: Train Loss=0.4932, Train Acc=0.7834 ||| Val Loss=0.4774, Val Acc=0.7930\n",
      "Epoch 79: Train Loss=0.4926, Train Acc=0.7850 ||| Val Loss=0.4759, Val Acc=0.7930\n",
      "Epoch 80: Train Loss=0.4936, Train Acc=0.7857 ||| Val Loss=0.4758, Val Acc=0.7941\n",
      "Epoch 81: Train Loss=0.4907, Train Acc=0.7853 ||| Val Loss=0.4738, Val Acc=0.7941\n",
      "Epoch 82: Train Loss=0.4941, Train Acc=0.7870 ||| Val Loss=0.4774, Val Acc=0.7907\n",
      "Epoch 83: Train Loss=0.4898, Train Acc=0.7849 ||| Val Loss=0.4737, Val Acc=0.7918\n",
      "Epoch 84: Train Loss=0.4937, Train Acc=0.7850 ||| Val Loss=0.4740, Val Acc=0.7907\n",
      "Epoch 85: Train Loss=0.4891, Train Acc=0.7849 ||| Val Loss=0.4744, Val Acc=0.7947\n",
      "Epoch 86: Train Loss=0.4904, Train Acc=0.7856 ||| Val Loss=0.4757, Val Acc=0.7941\n",
      "Epoch 87: Train Loss=0.4903, Train Acc=0.7833 ||| Val Loss=0.4752, Val Acc=0.7901\n",
      "Epoch 88: Train Loss=0.4871, Train Acc=0.7865 ||| Val Loss=0.4735, Val Acc=0.7913\n",
      "Epoch 89: Train Loss=0.4938, Train Acc=0.7844 ||| Val Loss=0.4749, Val Acc=0.7901\n",
      "Epoch 90: Train Loss=0.4890, Train Acc=0.7860 ||| Val Loss=0.4733, Val Acc=0.7907\n",
      "Epoch 91: Train Loss=0.4860, Train Acc=0.7854 ||| Val Loss=0.4729, Val Acc=0.7924\n",
      "Epoch 92: Train Loss=0.4870, Train Acc=0.7846 ||| Val Loss=0.4740, Val Acc=0.7907\n",
      "Epoch 93: Train Loss=0.4864, Train Acc=0.7856 ||| Val Loss=0.4735, Val Acc=0.7924\n",
      "Epoch 94: Train Loss=0.4849, Train Acc=0.7856 ||| Val Loss=0.4739, Val Acc=0.7913\n",
      "Epoch 95: Train Loss=0.4900, Train Acc=0.7875 ||| Val Loss=0.4711, Val Acc=0.7936\n",
      "Epoch 96: Train Loss=0.4916, Train Acc=0.7857 ||| Val Loss=0.4722, Val Acc=0.7930\n",
      "Epoch 97: Train Loss=0.4858, Train Acc=0.7862 ||| Val Loss=0.4748, Val Acc=0.7953\n",
      "Epoch 98: Train Loss=0.4911, Train Acc=0.7863 ||| Val Loss=0.4701, Val Acc=0.7907\n",
      "Epoch 99: Train Loss=0.4915, Train Acc=0.7865 ||| Val Loss=0.4700, Val Acc=0.7930\n",
      "Epoch 100: Train Loss=0.4861, Train Acc=0.7873 ||| Val Loss=0.4701, Val Acc=0.7924\n",
      "Epoch 101: Train Loss=0.4856, Train Acc=0.7886 ||| Val Loss=0.4693, Val Acc=0.7913\n",
      "Epoch 102: Train Loss=0.4915, Train Acc=0.7839 ||| Val Loss=0.4692, Val Acc=0.7953\n",
      "Epoch 103: Train Loss=0.4839, Train Acc=0.7866 ||| Val Loss=0.4703, Val Acc=0.7930\n",
      "Epoch 104: Train Loss=0.4848, Train Acc=0.7873 ||| Val Loss=0.4689, Val Acc=0.7930\n",
      "Epoch 105: Train Loss=0.4891, Train Acc=0.7873 ||| Val Loss=0.4702, Val Acc=0.7930\n",
      "Epoch 106: Train Loss=0.4875, Train Acc=0.7863 ||| Val Loss=0.4702, Val Acc=0.7913\n",
      "Epoch 107: Train Loss=0.4879, Train Acc=0.7852 ||| Val Loss=0.4700, Val Acc=0.7918\n",
      "Epoch 108: Train Loss=0.4851, Train Acc=0.7879 ||| Val Loss=0.4703, Val Acc=0.7936\n",
      "Epoch 109: Train Loss=0.4831, Train Acc=0.7867 ||| Val Loss=0.4700, Val Acc=0.7947\n",
      "Epoch 110: Train Loss=0.4866, Train Acc=0.7875 ||| Val Loss=0.4684, Val Acc=0.7907\n",
      "Epoch 111: Train Loss=0.4863, Train Acc=0.7837 ||| Val Loss=0.4703, Val Acc=0.7941\n",
      "Epoch 112: Train Loss=0.4873, Train Acc=0.7880 ||| Val Loss=0.4681, Val Acc=0.7936\n",
      "Epoch 113: Train Loss=0.4891, Train Acc=0.7833 ||| Val Loss=0.4691, Val Acc=0.7890\n",
      "Epoch 114: Train Loss=0.4880, Train Acc=0.7869 ||| Val Loss=0.4677, Val Acc=0.7895\n",
      "Epoch 115: Train Loss=0.4874, Train Acc=0.7880 ||| Val Loss=0.4704, Val Acc=0.7936\n",
      "Epoch 116: Train Loss=0.4874, Train Acc=0.7830 ||| Val Loss=0.4686, Val Acc=0.7924\n",
      "Epoch 117: Train Loss=0.4835, Train Acc=0.7880 ||| Val Loss=0.4694, Val Acc=0.7924\n",
      "Epoch 118: Train Loss=0.4812, Train Acc=0.7866 ||| Val Loss=0.4689, Val Acc=0.7913\n",
      "Epoch 119: Train Loss=0.4860, Train Acc=0.7863 ||| Val Loss=0.4677, Val Acc=0.7930\n",
      "Epoch 120: Train Loss=0.4818, Train Acc=0.7879 ||| Val Loss=0.4692, Val Acc=0.7941\n",
      "Epoch 121: Train Loss=0.4803, Train Acc=0.7870 ||| Val Loss=0.4669, Val Acc=0.7941\n",
      "Epoch 122: Train Loss=0.4843, Train Acc=0.7844 ||| Val Loss=0.4672, Val Acc=0.7924\n",
      "Epoch 123: Train Loss=0.4863, Train Acc=0.7880 ||| Val Loss=0.4682, Val Acc=0.7941\n",
      "Epoch 124: Train Loss=0.4813, Train Acc=0.7885 ||| Val Loss=0.4680, Val Acc=0.7930\n",
      "Epoch 125: Train Loss=0.4840, Train Acc=0.7856 ||| Val Loss=0.4671, Val Acc=0.7924\n",
      "Epoch 126: Train Loss=0.4828, Train Acc=0.7867 ||| Val Loss=0.4670, Val Acc=0.7936\n",
      "Epoch 127: Train Loss=0.4836, Train Acc=0.7882 ||| Val Loss=0.4675, Val Acc=0.7930\n",
      "Epoch 128: Train Loss=0.4880, Train Acc=0.7866 ||| Val Loss=0.4676, Val Acc=0.7947\n",
      "Epoch 129: Train Loss=0.4779, Train Acc=0.7899 ||| Val Loss=0.4682, Val Acc=0.7918\n",
      "Epoch 130: Train Loss=0.4858, Train Acc=0.7853 ||| Val Loss=0.4668, Val Acc=0.7930\n",
      "Epoch 131: Train Loss=0.4839, Train Acc=0.7856 ||| Val Loss=0.4672, Val Acc=0.7918\n",
      "Epoch 132: Train Loss=0.4846, Train Acc=0.7866 ||| Val Loss=0.4673, Val Acc=0.7913\n",
      "Epoch 133: Train Loss=0.4840, Train Acc=0.7885 ||| Val Loss=0.4668, Val Acc=0.7936\n",
      "Epoch 134: Train Loss=0.4781, Train Acc=0.7889 ||| Val Loss=0.4665, Val Acc=0.7924\n",
      "Epoch 135: Train Loss=0.4842, Train Acc=0.7849 ||| Val Loss=0.4672, Val Acc=0.7936\n",
      "Epoch 136: Train Loss=0.4832, Train Acc=0.7870 ||| Val Loss=0.4676, Val Acc=0.7895\n",
      "Epoch 137: Train Loss=0.4829, Train Acc=0.7865 ||| Val Loss=0.4674, Val Acc=0.7913\n",
      "Epoch 138: Train Loss=0.4818, Train Acc=0.7890 ||| Val Loss=0.4685, Val Acc=0.7936\n",
      "Epoch 139: Train Loss=0.4863, Train Acc=0.7879 ||| Val Loss=0.4669, Val Acc=0.7941\n",
      "Epoch 140: Train Loss=0.4835, Train Acc=0.7853 ||| Val Loss=0.4665, Val Acc=0.7918\n",
      "Epoch 141: Train Loss=0.4831, Train Acc=0.7865 ||| Val Loss=0.4664, Val Acc=0.7941\n",
      "Epoch 142: Train Loss=0.4884, Train Acc=0.7876 ||| Val Loss=0.4669, Val Acc=0.7924\n",
      "Epoch 143: Train Loss=0.4865, Train Acc=0.7843 ||| Val Loss=0.4676, Val Acc=0.7936\n",
      "Epoch 144: Train Loss=0.4833, Train Acc=0.7852 ||| Val Loss=0.4678, Val Acc=0.7936\n",
      "Epoch 145: Train Loss=0.4864, Train Acc=0.7866 ||| Val Loss=0.4668, Val Acc=0.7930\n",
      "Epoch 146: Train Loss=0.4850, Train Acc=0.7836 ||| Val Loss=0.4663, Val Acc=0.7924\n",
      "Epoch 147: Train Loss=0.4825, Train Acc=0.7886 ||| Val Loss=0.4671, Val Acc=0.7930\n",
      "Epoch 148: Train Loss=0.4876, Train Acc=0.7856 ||| Val Loss=0.4663, Val Acc=0.7918\n",
      "Epoch 149: Train Loss=0.4884, Train Acc=0.7875 ||| Val Loss=0.4675, Val Acc=0.7924\n",
      "Epoch 150: Train Loss=0.4822, Train Acc=0.7876 ||| Val Loss=0.4670, Val Acc=0.7947\n",
      "Epoch 151: Train Loss=0.4825, Train Acc=0.7862 ||| Val Loss=0.4669, Val Acc=0.7924\n",
      "Epoch 152: Train Loss=0.4825, Train Acc=0.7873 ||| Val Loss=0.4654, Val Acc=0.7913\n",
      "Epoch 153: Train Loss=0.4830, Train Acc=0.7906 ||| Val Loss=0.4659, Val Acc=0.7930\n",
      "Epoch 154: Train Loss=0.4820, Train Acc=0.7882 ||| Val Loss=0.4656, Val Acc=0.7924\n",
      "Epoch 155: Train Loss=0.4799, Train Acc=0.7882 ||| Val Loss=0.4661, Val Acc=0.7913\n",
      "Epoch 156: Train Loss=0.4832, Train Acc=0.7870 ||| Val Loss=0.4668, Val Acc=0.7918\n",
      "Epoch 157: Train Loss=0.4821, Train Acc=0.7893 ||| Val Loss=0.4689, Val Acc=0.7930\n",
      "Epoch 158: Train Loss=0.4848, Train Acc=0.7890 ||| Val Loss=0.4693, Val Acc=0.7947\n",
      "Epoch 159: Train Loss=0.4861, Train Acc=0.7857 ||| Val Loss=0.4669, Val Acc=0.7918\n",
      "Epoch 160: Train Loss=0.4838, Train Acc=0.7860 ||| Val Loss=0.4669, Val Acc=0.7936\n",
      "Epoch 161: Train Loss=0.4827, Train Acc=0.7876 ||| Val Loss=0.4667, Val Acc=0.7959\n",
      "Epoch 162: Train Loss=0.4841, Train Acc=0.7866 ||| Val Loss=0.4654, Val Acc=0.7918\n",
      "Epoch 163: Train Loss=0.4899, Train Acc=0.7876 ||| Val Loss=0.4662, Val Acc=0.7913\n",
      "Epoch 164: Train Loss=0.4796, Train Acc=0.7888 ||| Val Loss=0.4668, Val Acc=0.7895\n",
      "Epoch 165: Train Loss=0.4889, Train Acc=0.7842 ||| Val Loss=0.4668, Val Acc=0.7918\n",
      "Epoch 166: Train Loss=0.4828, Train Acc=0.7880 ||| Val Loss=0.4676, Val Acc=0.7907\n",
      "Epoch 167: Train Loss=0.4857, Train Acc=0.7859 ||| Val Loss=0.4666, Val Acc=0.7959\n",
      "Epoch 168: Train Loss=0.4866, Train Acc=0.7846 ||| Val Loss=0.4653, Val Acc=0.7924\n",
      "Epoch 169: Train Loss=0.4850, Train Acc=0.7876 ||| Val Loss=0.4672, Val Acc=0.7913\n",
      "Epoch 170: Train Loss=0.4822, Train Acc=0.7873 ||| Val Loss=0.4661, Val Acc=0.7924\n",
      "Epoch 171: Train Loss=0.4806, Train Acc=0.7896 ||| Val Loss=0.4664, Val Acc=0.7924\n",
      "Epoch 172: Train Loss=0.4839, Train Acc=0.7862 ||| Val Loss=0.4656, Val Acc=0.7976\n",
      "Epoch 173: Train Loss=0.4817, Train Acc=0.7852 ||| Val Loss=0.4653, Val Acc=0.7913\n",
      "Epoch 174: Train Loss=0.4839, Train Acc=0.7869 ||| Val Loss=0.4651, Val Acc=0.7918\n",
      "Epoch 175: Train Loss=0.4755, Train Acc=0.7880 ||| Val Loss=0.4649, Val Acc=0.7924\n",
      "Epoch 176: Train Loss=0.4831, Train Acc=0.7869 ||| Val Loss=0.4669, Val Acc=0.7924\n",
      "Epoch 177: Train Loss=0.4851, Train Acc=0.7872 ||| Val Loss=0.4661, Val Acc=0.7970\n",
      "Epoch 178: Train Loss=0.4813, Train Acc=0.7873 ||| Val Loss=0.4649, Val Acc=0.7930\n",
      "Epoch 179: Train Loss=0.4857, Train Acc=0.7882 ||| Val Loss=0.4653, Val Acc=0.7924\n",
      "Epoch 180: Train Loss=0.4814, Train Acc=0.7885 ||| Val Loss=0.4662, Val Acc=0.7993\n",
      "Epoch 181: Train Loss=0.4768, Train Acc=0.7888 ||| Val Loss=0.4660, Val Acc=0.7924\n",
      "Epoch 182: Train Loss=0.4832, Train Acc=0.7870 ||| Val Loss=0.4653, Val Acc=0.7924\n",
      "Epoch 183: Train Loss=0.4834, Train Acc=0.7860 ||| Val Loss=0.4657, Val Acc=0.7936\n",
      "Epoch 184: Train Loss=0.4823, Train Acc=0.7882 ||| Val Loss=0.4648, Val Acc=0.7913\n",
      "Epoch 185: Train Loss=0.4815, Train Acc=0.7893 ||| Val Loss=0.4654, Val Acc=0.7913\n",
      "Epoch 186: Train Loss=0.4839, Train Acc=0.7856 ||| Val Loss=0.4661, Val Acc=0.7913\n",
      "Epoch 187: Train Loss=0.4839, Train Acc=0.7877 ||| Val Loss=0.4649, Val Acc=0.7913\n",
      "Epoch 188: Train Loss=0.4845, Train Acc=0.7865 ||| Val Loss=0.4646, Val Acc=0.7953\n",
      "Epoch 189: Train Loss=0.4821, Train Acc=0.7880 ||| Val Loss=0.4645, Val Acc=0.7918\n",
      "Epoch 190: Train Loss=0.4828, Train Acc=0.7831 ||| Val Loss=0.4654, Val Acc=0.7924\n",
      "Epoch 191: Train Loss=0.4821, Train Acc=0.7883 ||| Val Loss=0.4667, Val Acc=0.7901\n",
      "Epoch 192: Train Loss=0.4841, Train Acc=0.7890 ||| Val Loss=0.4657, Val Acc=0.7947\n",
      "Epoch 193: Train Loss=0.4825, Train Acc=0.7893 ||| Val Loss=0.4652, Val Acc=0.7901\n",
      "Epoch 194: Train Loss=0.4818, Train Acc=0.7889 ||| Val Loss=0.4664, Val Acc=0.7907\n",
      "Epoch 195: Train Loss=0.4837, Train Acc=0.7849 ||| Val Loss=0.4670, Val Acc=0.7918\n",
      "Epoch 196: Train Loss=0.4793, Train Acc=0.7876 ||| Val Loss=0.4672, Val Acc=0.7907\n",
      "Epoch 197: Train Loss=0.4845, Train Acc=0.7886 ||| Val Loss=0.4664, Val Acc=0.7924\n",
      "Epoch 198: Train Loss=0.4831, Train Acc=0.7877 ||| Val Loss=0.4668, Val Acc=0.7924\n",
      "Epoch 199: Train Loss=0.4813, Train Acc=0.7870 ||| Val Loss=0.4654, Val Acc=0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 16:59:42,483] Trial 3 finished with value: 0.7918343875790684 and parameters: {'n_blocks': 4, 'd_block': 512, 'k': 11, 'dropout': 0.4861056500848959, 'activation': 'GELU', 'lr': 0.0009034158014843336, 'weight_decay': 0.0008700519756372972}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Train Loss=0.4807, Train Acc=0.7857 ||| Val Loss=0.4656, Val Acc=0.7918\n",
      "Validation Accuracy: 0.7918\n",
      "\n",
      " Trial 5 with params: {'n_blocks': 4, 'd_block': 128, 'k': 5, 'dropout': 0.4986705411191349, 'activation': 'GELU', 'lr': 0.012773167071090876, 'weight_decay': 0.00033187674234220094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.1243, Train Acc=0.6110 ||| Val Loss=0.5993, Val Acc=0.6607\n",
      "Epoch 2: Train Loss=0.6152, Train Acc=0.6810 ||| Val Loss=0.5835, Val Acc=0.6878\n",
      "Epoch 3: Train Loss=0.5860, Train Acc=0.7065 ||| Val Loss=0.5696, Val Acc=0.7263\n",
      "Epoch 4: Train Loss=0.5732, Train Acc=0.7236 ||| Val Loss=0.5264, Val Acc=0.7734\n",
      "Epoch 5: Train Loss=0.5469, Train Acc=0.7476 ||| Val Loss=0.5059, Val Acc=0.7838\n",
      "Epoch 6: Train Loss=0.5412, Train Acc=0.7555 ||| Val Loss=0.5001, Val Acc=0.7861\n",
      "Epoch 7: Train Loss=0.5295, Train Acc=0.7679 ||| Val Loss=0.5115, Val Acc=0.7821\n",
      "Epoch 8: Train Loss=0.5188, Train Acc=0.7787 ||| Val Loss=0.5199, Val Acc=0.7821\n",
      "Epoch 9: Train Loss=0.5151, Train Acc=0.7791 ||| Val Loss=0.4908, Val Acc=0.7901\n",
      "Epoch 10: Train Loss=0.5107, Train Acc=0.7808 ||| Val Loss=0.4979, Val Acc=0.7895\n",
      "Epoch 11: Train Loss=0.5105, Train Acc=0.7829 ||| Val Loss=0.4894, Val Acc=0.7947\n",
      "Epoch 12: Train Loss=0.5017, Train Acc=0.7847 ||| Val Loss=0.4815, Val Acc=0.7936\n",
      "Epoch 13: Train Loss=0.4992, Train Acc=0.7877 ||| Val Loss=0.4792, Val Acc=0.7976\n",
      "Epoch 14: Train Loss=0.5009, Train Acc=0.7888 ||| Val Loss=0.4784, Val Acc=0.7941\n",
      "Epoch 15: Train Loss=0.5004, Train Acc=0.7849 ||| Val Loss=0.4839, Val Acc=0.7959\n",
      "Epoch 16: Train Loss=0.4972, Train Acc=0.7866 ||| Val Loss=0.4809, Val Acc=0.7982\n",
      "Epoch 17: Train Loss=0.4924, Train Acc=0.7850 ||| Val Loss=0.4756, Val Acc=0.7936\n",
      "Epoch 18: Train Loss=0.4888, Train Acc=0.7885 ||| Val Loss=0.4689, Val Acc=0.7918\n",
      "Epoch 19: Train Loss=0.4969, Train Acc=0.7847 ||| Val Loss=0.4714, Val Acc=0.7970\n",
      "Epoch 20: Train Loss=0.4929, Train Acc=0.7834 ||| Val Loss=0.4666, Val Acc=0.7947\n",
      "Epoch 21: Train Loss=0.4938, Train Acc=0.7879 ||| Val Loss=0.4734, Val Acc=0.7953\n",
      "Epoch 22: Train Loss=0.4914, Train Acc=0.7890 ||| Val Loss=0.4735, Val Acc=0.7913\n",
      "Epoch 23: Train Loss=0.4891, Train Acc=0.7872 ||| Val Loss=0.4741, Val Acc=0.7924\n",
      "Epoch 24: Train Loss=0.4872, Train Acc=0.7895 ||| Val Loss=0.4748, Val Acc=0.7907\n",
      "Epoch 25: Train Loss=0.4934, Train Acc=0.7872 ||| Val Loss=0.4717, Val Acc=0.7924\n",
      "Epoch 26: Train Loss=0.4891, Train Acc=0.7893 ||| Val Loss=0.4711, Val Acc=0.7918\n",
      "Epoch 27: Train Loss=0.4864, Train Acc=0.7890 ||| Val Loss=0.4643, Val Acc=0.7930\n",
      "Epoch 28: Train Loss=0.4866, Train Acc=0.7899 ||| Val Loss=0.4678, Val Acc=0.7936\n",
      "Epoch 29: Train Loss=0.4896, Train Acc=0.7877 ||| Val Loss=0.4640, Val Acc=0.7953\n",
      "Epoch 30: Train Loss=0.4895, Train Acc=0.7877 ||| Val Loss=0.4730, Val Acc=0.7964\n",
      "Epoch 31: Train Loss=0.4898, Train Acc=0.7902 ||| Val Loss=0.4680, Val Acc=0.7930\n",
      "Epoch 32: Train Loss=0.4855, Train Acc=0.7854 ||| Val Loss=0.4632, Val Acc=0.7964\n",
      "Epoch 33: Train Loss=0.4920, Train Acc=0.7885 ||| Val Loss=0.4727, Val Acc=0.7918\n",
      "Epoch 34: Train Loss=0.4900, Train Acc=0.7875 ||| Val Loss=0.4693, Val Acc=0.7959\n",
      "Epoch 35: Train Loss=0.4866, Train Acc=0.7898 ||| Val Loss=0.4767, Val Acc=0.7947\n",
      "Epoch 36: Train Loss=0.4883, Train Acc=0.7870 ||| Val Loss=0.4630, Val Acc=0.7901\n",
      "Epoch 37: Train Loss=0.4881, Train Acc=0.7909 ||| Val Loss=0.4748, Val Acc=0.7936\n",
      "Epoch 38: Train Loss=0.4881, Train Acc=0.7872 ||| Val Loss=0.4771, Val Acc=0.7878\n",
      "Epoch 39: Train Loss=0.4900, Train Acc=0.7856 ||| Val Loss=0.4713, Val Acc=0.7953\n",
      "Epoch 40: Train Loss=0.4905, Train Acc=0.7875 ||| Val Loss=0.4739, Val Acc=0.7959\n",
      "Epoch 41: Train Loss=0.4901, Train Acc=0.7882 ||| Val Loss=0.4711, Val Acc=0.7964\n",
      "Epoch 42: Train Loss=0.4916, Train Acc=0.7905 ||| Val Loss=0.4657, Val Acc=0.7959\n",
      "Epoch 43: Train Loss=0.4911, Train Acc=0.7877 ||| Val Loss=0.4742, Val Acc=0.7930\n",
      "Epoch 44: Train Loss=0.4883, Train Acc=0.7866 ||| Val Loss=0.4732, Val Acc=0.7855\n",
      "Epoch 45: Train Loss=0.4904, Train Acc=0.7867 ||| Val Loss=0.4677, Val Acc=0.7947\n",
      "Epoch 46: Train Loss=0.4943, Train Acc=0.7865 ||| Val Loss=0.4650, Val Acc=0.7993\n",
      "Epoch 47: Train Loss=0.4864, Train Acc=0.7888 ||| Val Loss=0.4659, Val Acc=0.7959\n",
      "Epoch 48: Train Loss=0.4874, Train Acc=0.7869 ||| Val Loss=0.4762, Val Acc=0.7999\n",
      "Epoch 49: Train Loss=0.4885, Train Acc=0.7896 ||| Val Loss=0.4631, Val Acc=0.7976\n",
      "Epoch 50: Train Loss=0.4894, Train Acc=0.7857 ||| Val Loss=0.4683, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4925, Train Acc=0.7869 ||| Val Loss=0.4698, Val Acc=0.7930\n",
      "Epoch 52: Train Loss=0.4856, Train Acc=0.7862 ||| Val Loss=0.4806, Val Acc=0.7964\n",
      "Epoch 53: Train Loss=0.4975, Train Acc=0.7872 ||| Val Loss=0.4649, Val Acc=0.7947\n",
      "Epoch 54: Train Loss=0.4891, Train Acc=0.7879 ||| Val Loss=0.4631, Val Acc=0.7918\n",
      "Epoch 55: Train Loss=0.4910, Train Acc=0.7869 ||| Val Loss=0.4694, Val Acc=0.7953\n",
      "Epoch 56: Train Loss=0.4942, Train Acc=0.7850 ||| Val Loss=0.4620, Val Acc=0.8010\n",
      "Epoch 57: Train Loss=0.4868, Train Acc=0.7876 ||| Val Loss=0.4693, Val Acc=0.7930\n",
      "Epoch 58: Train Loss=0.4959, Train Acc=0.7847 ||| Val Loss=0.4654, Val Acc=0.7976\n",
      "Epoch 59: Train Loss=0.4903, Train Acc=0.7873 ||| Val Loss=0.4655, Val Acc=0.7924\n",
      "Epoch 60: Train Loss=0.4908, Train Acc=0.7849 ||| Val Loss=0.4686, Val Acc=0.7993\n",
      "Epoch 61: Train Loss=0.4950, Train Acc=0.7892 ||| Val Loss=0.4697, Val Acc=0.8022\n",
      "Epoch 62: Train Loss=0.4969, Train Acc=0.7885 ||| Val Loss=0.4742, Val Acc=0.7941\n",
      "Epoch 63: Train Loss=0.4956, Train Acc=0.7846 ||| Val Loss=0.4753, Val Acc=0.7941\n",
      "Epoch 64: Train Loss=0.5012, Train Acc=0.7856 ||| Val Loss=0.4728, Val Acc=0.7970\n",
      "Epoch 65: Train Loss=0.4959, Train Acc=0.7853 ||| Val Loss=0.4770, Val Acc=0.7947\n",
      "Epoch 66: Train Loss=0.4970, Train Acc=0.7852 ||| Val Loss=0.4899, Val Acc=0.7901\n",
      "Epoch 67: Train Loss=0.4927, Train Acc=0.7877 ||| Val Loss=0.4761, Val Acc=0.7970\n",
      "Epoch 68: Train Loss=0.4932, Train Acc=0.7829 ||| Val Loss=0.4812, Val Acc=0.7982\n",
      "Epoch 69: Train Loss=0.4944, Train Acc=0.7852 ||| Val Loss=0.4715, Val Acc=0.7936\n",
      "Epoch 70: Train Loss=0.4924, Train Acc=0.7836 ||| Val Loss=0.4686, Val Acc=0.7947\n",
      "Epoch 71: Train Loss=0.4978, Train Acc=0.7842 ||| Val Loss=0.4745, Val Acc=0.7918\n",
      "Epoch 72: Train Loss=0.4981, Train Acc=0.7834 ||| Val Loss=0.4787, Val Acc=0.7936\n",
      "Epoch 73: Train Loss=0.4911, Train Acc=0.7860 ||| Val Loss=0.4695, Val Acc=0.7924\n",
      "Epoch 74: Train Loss=0.4894, Train Acc=0.7863 ||| Val Loss=0.4718, Val Acc=0.7941\n",
      "Epoch 75: Train Loss=0.4979, Train Acc=0.7863 ||| Val Loss=0.4718, Val Acc=0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:00:08,371] Trial 4 finished with value: 0.7947096032202415 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 5, 'dropout': 0.4986705411191349, 'activation': 'GELU', 'lr': 0.012773167071090876, 'weight_decay': 0.00033187674234220094}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Train Loss=0.5051, Train Acc=0.7840 ||| Val Loss=0.4694, Val Acc=0.7947\n",
      "Early stopping triggered at epoch 76\n",
      "Validation Accuracy: 0.7947\n",
      "\n",
      " Trial 6 with params: {'n_blocks': 6, 'd_block': 128, 'k': 5, 'dropout': 0.42152741422212603, 'activation': 'ReLU', 'lr': 0.0002689515344605779, 'weight_decay': 0.00048682323175334356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3758, Train Acc=0.5030 ||| Val Loss=0.6722, Val Acc=0.6578\n",
      "Epoch 2: Train Loss=0.8480, Train Acc=0.5047 ||| Val Loss=0.6769, Val Acc=0.5716\n",
      "Epoch 3: Train Loss=0.7517, Train Acc=0.5178 ||| Val Loss=0.6751, Val Acc=0.6722\n",
      "Epoch 4: Train Loss=0.7266, Train Acc=0.5262 ||| Val Loss=0.6757, Val Acc=0.6584\n",
      "Epoch 5: Train Loss=0.7035, Train Acc=0.5430 ||| Val Loss=0.6714, Val Acc=0.6682\n",
      "Epoch 6: Train Loss=0.6968, Train Acc=0.5503 ||| Val Loss=0.6678, Val Acc=0.6297\n",
      "Epoch 7: Train Loss=0.6876, Train Acc=0.5643 ||| Val Loss=0.6566, Val Acc=0.6642\n",
      "Epoch 8: Train Loss=0.6709, Train Acc=0.5933 ||| Val Loss=0.6442, Val Acc=0.6532\n",
      "Epoch 9: Train Loss=0.6576, Train Acc=0.6079 ||| Val Loss=0.6232, Val Acc=0.6975\n",
      "Epoch 10: Train Loss=0.6391, Train Acc=0.6326 ||| Val Loss=0.6047, Val Acc=0.7136\n",
      "Epoch 11: Train Loss=0.6229, Train Acc=0.6563 ||| Val Loss=0.5836, Val Acc=0.7493\n",
      "Epoch 12: Train Loss=0.6109, Train Acc=0.6667 ||| Val Loss=0.5676, Val Acc=0.7706\n",
      "Epoch 13: Train Loss=0.5940, Train Acc=0.6920 ||| Val Loss=0.5570, Val Acc=0.7792\n",
      "Epoch 14: Train Loss=0.5770, Train Acc=0.7128 ||| Val Loss=0.5442, Val Acc=0.7838\n",
      "Epoch 15: Train Loss=0.5724, Train Acc=0.7230 ||| Val Loss=0.5427, Val Acc=0.7803\n",
      "Epoch 16: Train Loss=0.5701, Train Acc=0.7261 ||| Val Loss=0.5358, Val Acc=0.7844\n",
      "Epoch 17: Train Loss=0.5610, Train Acc=0.7358 ||| Val Loss=0.5282, Val Acc=0.7861\n",
      "Epoch 18: Train Loss=0.5471, Train Acc=0.7492 ||| Val Loss=0.5248, Val Acc=0.7861\n",
      "Epoch 19: Train Loss=0.5475, Train Acc=0.7481 ||| Val Loss=0.5263, Val Acc=0.7849\n",
      "Epoch 20: Train Loss=0.5406, Train Acc=0.7521 ||| Val Loss=0.5243, Val Acc=0.7844\n",
      "Epoch 21: Train Loss=0.5399, Train Acc=0.7599 ||| Val Loss=0.5186, Val Acc=0.7884\n",
      "Epoch 22: Train Loss=0.5351, Train Acc=0.7662 ||| Val Loss=0.5152, Val Acc=0.7890\n",
      "Epoch 23: Train Loss=0.5341, Train Acc=0.7607 ||| Val Loss=0.5161, Val Acc=0.7867\n",
      "Epoch 24: Train Loss=0.5339, Train Acc=0.7688 ||| Val Loss=0.5195, Val Acc=0.7844\n",
      "Epoch 25: Train Loss=0.5224, Train Acc=0.7721 ||| Val Loss=0.5147, Val Acc=0.7855\n",
      "Epoch 26: Train Loss=0.5236, Train Acc=0.7702 ||| Val Loss=0.5091, Val Acc=0.7884\n",
      "Epoch 27: Train Loss=0.5237, Train Acc=0.7752 ||| Val Loss=0.5039, Val Acc=0.7907\n",
      "Epoch 28: Train Loss=0.5209, Train Acc=0.7725 ||| Val Loss=0.5086, Val Acc=0.7872\n",
      "Epoch 29: Train Loss=0.5214, Train Acc=0.7774 ||| Val Loss=0.5028, Val Acc=0.7901\n",
      "Epoch 30: Train Loss=0.5187, Train Acc=0.7794 ||| Val Loss=0.5071, Val Acc=0.7855\n",
      "Epoch 31: Train Loss=0.5173, Train Acc=0.7775 ||| Val Loss=0.5000, Val Acc=0.7895\n",
      "Epoch 32: Train Loss=0.5145, Train Acc=0.7771 ||| Val Loss=0.4957, Val Acc=0.7907\n",
      "Epoch 33: Train Loss=0.5114, Train Acc=0.7783 ||| Val Loss=0.4995, Val Acc=0.7895\n",
      "Epoch 34: Train Loss=0.5164, Train Acc=0.7775 ||| Val Loss=0.5007, Val Acc=0.7895\n",
      "Epoch 35: Train Loss=0.5099, Train Acc=0.7816 ||| Val Loss=0.4913, Val Acc=0.7913\n",
      "Epoch 36: Train Loss=0.5081, Train Acc=0.7807 ||| Val Loss=0.4941, Val Acc=0.7901\n",
      "Epoch 37: Train Loss=0.5101, Train Acc=0.7798 ||| Val Loss=0.4923, Val Acc=0.7895\n",
      "Epoch 38: Train Loss=0.5077, Train Acc=0.7793 ||| Val Loss=0.4900, Val Acc=0.7913\n",
      "Epoch 39: Train Loss=0.5060, Train Acc=0.7836 ||| Val Loss=0.4911, Val Acc=0.7890\n",
      "Epoch 40: Train Loss=0.5093, Train Acc=0.7797 ||| Val Loss=0.4937, Val Acc=0.7890\n",
      "Epoch 41: Train Loss=0.4992, Train Acc=0.7804 ||| Val Loss=0.4878, Val Acc=0.7918\n",
      "Epoch 42: Train Loss=0.5018, Train Acc=0.7843 ||| Val Loss=0.4924, Val Acc=0.7878\n",
      "Epoch 43: Train Loss=0.5044, Train Acc=0.7817 ||| Val Loss=0.4882, Val Acc=0.7924\n",
      "Epoch 44: Train Loss=0.4991, Train Acc=0.7823 ||| Val Loss=0.4895, Val Acc=0.7895\n",
      "Epoch 45: Train Loss=0.4992, Train Acc=0.7850 ||| Val Loss=0.4874, Val Acc=0.7930\n",
      "Epoch 46: Train Loss=0.5004, Train Acc=0.7834 ||| Val Loss=0.4848, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.5005, Train Acc=0.7840 ||| Val Loss=0.4888, Val Acc=0.7930\n",
      "Epoch 48: Train Loss=0.4973, Train Acc=0.7853 ||| Val Loss=0.4849, Val Acc=0.7953\n",
      "Epoch 49: Train Loss=0.4949, Train Acc=0.7870 ||| Val Loss=0.4836, Val Acc=0.7947\n",
      "Epoch 50: Train Loss=0.5004, Train Acc=0.7834 ||| Val Loss=0.4833, Val Acc=0.7953\n",
      "Epoch 51: Train Loss=0.4994, Train Acc=0.7842 ||| Val Loss=0.4833, Val Acc=0.7947\n",
      "Epoch 52: Train Loss=0.5003, Train Acc=0.7885 ||| Val Loss=0.4844, Val Acc=0.7947\n",
      "Epoch 53: Train Loss=0.4945, Train Acc=0.7862 ||| Val Loss=0.4824, Val Acc=0.7947\n",
      "Epoch 54: Train Loss=0.4936, Train Acc=0.7859 ||| Val Loss=0.4819, Val Acc=0.7947\n",
      "Epoch 55: Train Loss=0.4911, Train Acc=0.7865 ||| Val Loss=0.4807, Val Acc=0.7964\n",
      "Epoch 56: Train Loss=0.4932, Train Acc=0.7844 ||| Val Loss=0.4804, Val Acc=0.7959\n",
      "Epoch 57: Train Loss=0.4934, Train Acc=0.7882 ||| Val Loss=0.4802, Val Acc=0.7970\n",
      "Epoch 58: Train Loss=0.4937, Train Acc=0.7872 ||| Val Loss=0.4805, Val Acc=0.7970\n",
      "Epoch 59: Train Loss=0.4918, Train Acc=0.7882 ||| Val Loss=0.4799, Val Acc=0.7976\n",
      "Epoch 60: Train Loss=0.4938, Train Acc=0.7875 ||| Val Loss=0.4800, Val Acc=0.7936\n",
      "Epoch 61: Train Loss=0.4900, Train Acc=0.7873 ||| Val Loss=0.4799, Val Acc=0.7970\n",
      "Epoch 62: Train Loss=0.4926, Train Acc=0.7902 ||| Val Loss=0.4797, Val Acc=0.7947\n",
      "Epoch 63: Train Loss=0.4948, Train Acc=0.7883 ||| Val Loss=0.4795, Val Acc=0.7959\n",
      "Epoch 64: Train Loss=0.4870, Train Acc=0.7898 ||| Val Loss=0.4790, Val Acc=0.7976\n",
      "Epoch 65: Train Loss=0.4910, Train Acc=0.7872 ||| Val Loss=0.4779, Val Acc=0.7976\n",
      "Epoch 66: Train Loss=0.4875, Train Acc=0.7886 ||| Val Loss=0.4790, Val Acc=0.7947\n",
      "Epoch 67: Train Loss=0.4858, Train Acc=0.7895 ||| Val Loss=0.4781, Val Acc=0.7982\n",
      "Epoch 68: Train Loss=0.4884, Train Acc=0.7872 ||| Val Loss=0.4775, Val Acc=0.7947\n",
      "Epoch 69: Train Loss=0.4877, Train Acc=0.7905 ||| Val Loss=0.4782, Val Acc=0.7941\n",
      "Epoch 70: Train Loss=0.4852, Train Acc=0.7890 ||| Val Loss=0.4776, Val Acc=0.7947\n",
      "Epoch 71: Train Loss=0.4889, Train Acc=0.7873 ||| Val Loss=0.4781, Val Acc=0.7936\n",
      "Epoch 72: Train Loss=0.4881, Train Acc=0.7889 ||| Val Loss=0.4792, Val Acc=0.7964\n",
      "Epoch 73: Train Loss=0.4908, Train Acc=0.7852 ||| Val Loss=0.4782, Val Acc=0.7953\n",
      "Epoch 74: Train Loss=0.4902, Train Acc=0.7870 ||| Val Loss=0.4780, Val Acc=0.7953\n",
      "Epoch 75: Train Loss=0.4856, Train Acc=0.7866 ||| Val Loss=0.4769, Val Acc=0.7970\n",
      "Epoch 76: Train Loss=0.4871, Train Acc=0.7880 ||| Val Loss=0.4778, Val Acc=0.7976\n",
      "Epoch 77: Train Loss=0.4878, Train Acc=0.7880 ||| Val Loss=0.4777, Val Acc=0.7959\n",
      "Epoch 78: Train Loss=0.4881, Train Acc=0.7882 ||| Val Loss=0.4781, Val Acc=0.7959\n",
      "Epoch 79: Train Loss=0.4852, Train Acc=0.7876 ||| Val Loss=0.4788, Val Acc=0.7947\n",
      "Epoch 80: Train Loss=0.4853, Train Acc=0.7899 ||| Val Loss=0.4784, Val Acc=0.7941\n",
      "Epoch 81: Train Loss=0.4834, Train Acc=0.7893 ||| Val Loss=0.4785, Val Acc=0.7959\n",
      "Epoch 82: Train Loss=0.4844, Train Acc=0.7873 ||| Val Loss=0.4778, Val Acc=0.7959\n",
      "Epoch 83: Train Loss=0.4843, Train Acc=0.7893 ||| Val Loss=0.4772, Val Acc=0.7953\n",
      "Epoch 84: Train Loss=0.4846, Train Acc=0.7869 ||| Val Loss=0.4779, Val Acc=0.7953\n",
      "Epoch 85: Train Loss=0.4808, Train Acc=0.7885 ||| Val Loss=0.4771, Val Acc=0.7930\n",
      "Epoch 86: Train Loss=0.4867, Train Acc=0.7882 ||| Val Loss=0.4765, Val Acc=0.7959\n",
      "Epoch 87: Train Loss=0.4849, Train Acc=0.7882 ||| Val Loss=0.4752, Val Acc=0.7924\n",
      "Epoch 88: Train Loss=0.4859, Train Acc=0.7870 ||| Val Loss=0.4739, Val Acc=0.7924\n",
      "Epoch 89: Train Loss=0.4872, Train Acc=0.7849 ||| Val Loss=0.4765, Val Acc=0.7964\n",
      "Epoch 90: Train Loss=0.4842, Train Acc=0.7883 ||| Val Loss=0.4762, Val Acc=0.7953\n",
      "Epoch 91: Train Loss=0.4857, Train Acc=0.7869 ||| Val Loss=0.4756, Val Acc=0.7924\n",
      "Epoch 92: Train Loss=0.4819, Train Acc=0.7870 ||| Val Loss=0.4738, Val Acc=0.7913\n",
      "Epoch 93: Train Loss=0.4863, Train Acc=0.7869 ||| Val Loss=0.4741, Val Acc=0.7918\n",
      "Epoch 94: Train Loss=0.4838, Train Acc=0.7886 ||| Val Loss=0.4757, Val Acc=0.7953\n",
      "Epoch 95: Train Loss=0.4835, Train Acc=0.7875 ||| Val Loss=0.4758, Val Acc=0.7964\n",
      "Epoch 96: Train Loss=0.4804, Train Acc=0.7906 ||| Val Loss=0.4768, Val Acc=0.7976\n",
      "Epoch 97: Train Loss=0.4829, Train Acc=0.7899 ||| Val Loss=0.4757, Val Acc=0.7953\n",
      "Epoch 98: Train Loss=0.4802, Train Acc=0.7896 ||| Val Loss=0.4753, Val Acc=0.7953\n",
      "Epoch 99: Train Loss=0.4814, Train Acc=0.7912 ||| Val Loss=0.4751, Val Acc=0.7953\n",
      "Epoch 100: Train Loss=0.4813, Train Acc=0.7893 ||| Val Loss=0.4739, Val Acc=0.7941\n",
      "Epoch 101: Train Loss=0.4795, Train Acc=0.7865 ||| Val Loss=0.4740, Val Acc=0.7959\n",
      "Epoch 102: Train Loss=0.4787, Train Acc=0.7892 ||| Val Loss=0.4732, Val Acc=0.7936\n",
      "Epoch 103: Train Loss=0.4832, Train Acc=0.7895 ||| Val Loss=0.4729, Val Acc=0.7947\n",
      "Epoch 104: Train Loss=0.4812, Train Acc=0.7886 ||| Val Loss=0.4736, Val Acc=0.7964\n",
      "Epoch 105: Train Loss=0.4831, Train Acc=0.7889 ||| Val Loss=0.4723, Val Acc=0.7959\n",
      "Epoch 106: Train Loss=0.4794, Train Acc=0.7902 ||| Val Loss=0.4730, Val Acc=0.7953\n",
      "Epoch 107: Train Loss=0.4798, Train Acc=0.7890 ||| Val Loss=0.4719, Val Acc=0.7936\n",
      "Epoch 108: Train Loss=0.4825, Train Acc=0.7846 ||| Val Loss=0.4703, Val Acc=0.7976\n",
      "Epoch 109: Train Loss=0.4757, Train Acc=0.7879 ||| Val Loss=0.4704, Val Acc=0.7936\n",
      "Epoch 110: Train Loss=0.4778, Train Acc=0.7895 ||| Val Loss=0.4703, Val Acc=0.7964\n",
      "Epoch 111: Train Loss=0.4760, Train Acc=0.7912 ||| Val Loss=0.4698, Val Acc=0.7964\n",
      "Epoch 112: Train Loss=0.4763, Train Acc=0.7872 ||| Val Loss=0.4706, Val Acc=0.7970\n",
      "Epoch 113: Train Loss=0.4801, Train Acc=0.7880 ||| Val Loss=0.4695, Val Acc=0.7959\n",
      "Epoch 114: Train Loss=0.4795, Train Acc=0.7885 ||| Val Loss=0.4703, Val Acc=0.7953\n",
      "Epoch 115: Train Loss=0.4776, Train Acc=0.7873 ||| Val Loss=0.4695, Val Acc=0.7959\n",
      "Epoch 116: Train Loss=0.4761, Train Acc=0.7915 ||| Val Loss=0.4700, Val Acc=0.7947\n",
      "Epoch 117: Train Loss=0.4794, Train Acc=0.7866 ||| Val Loss=0.4680, Val Acc=0.7959\n",
      "Epoch 118: Train Loss=0.4759, Train Acc=0.7902 ||| Val Loss=0.4677, Val Acc=0.7970\n",
      "Epoch 119: Train Loss=0.4782, Train Acc=0.7886 ||| Val Loss=0.4672, Val Acc=0.7941\n",
      "Epoch 120: Train Loss=0.4761, Train Acc=0.7885 ||| Val Loss=0.4661, Val Acc=0.7947\n",
      "Epoch 121: Train Loss=0.4768, Train Acc=0.7898 ||| Val Loss=0.4669, Val Acc=0.7964\n",
      "Epoch 122: Train Loss=0.4788, Train Acc=0.7892 ||| Val Loss=0.4665, Val Acc=0.7947\n",
      "Epoch 123: Train Loss=0.4744, Train Acc=0.7892 ||| Val Loss=0.4679, Val Acc=0.7964\n",
      "Epoch 124: Train Loss=0.4744, Train Acc=0.7911 ||| Val Loss=0.4658, Val Acc=0.7964\n",
      "Epoch 125: Train Loss=0.4707, Train Acc=0.7906 ||| Val Loss=0.4638, Val Acc=0.7970\n",
      "Epoch 126: Train Loss=0.4745, Train Acc=0.7869 ||| Val Loss=0.4649, Val Acc=0.7964\n",
      "Epoch 127: Train Loss=0.4741, Train Acc=0.7900 ||| Val Loss=0.4634, Val Acc=0.7947\n",
      "Epoch 128: Train Loss=0.4746, Train Acc=0.7876 ||| Val Loss=0.4632, Val Acc=0.7959\n",
      "Epoch 129: Train Loss=0.4737, Train Acc=0.7899 ||| Val Loss=0.4633, Val Acc=0.7947\n",
      "Epoch 130: Train Loss=0.4746, Train Acc=0.7870 ||| Val Loss=0.4624, Val Acc=0.7947\n",
      "Epoch 131: Train Loss=0.4723, Train Acc=0.7880 ||| Val Loss=0.4618, Val Acc=0.7936\n",
      "Epoch 132: Train Loss=0.4743, Train Acc=0.7883 ||| Val Loss=0.4622, Val Acc=0.7959\n",
      "Epoch 133: Train Loss=0.4723, Train Acc=0.7902 ||| Val Loss=0.4619, Val Acc=0.7941\n",
      "Epoch 134: Train Loss=0.4726, Train Acc=0.7863 ||| Val Loss=0.4612, Val Acc=0.7953\n",
      "Epoch 135: Train Loss=0.4727, Train Acc=0.7853 ||| Val Loss=0.4613, Val Acc=0.7959\n",
      "Epoch 136: Train Loss=0.4702, Train Acc=0.7879 ||| Val Loss=0.4608, Val Acc=0.7947\n",
      "Epoch 137: Train Loss=0.4696, Train Acc=0.7893 ||| Val Loss=0.4605, Val Acc=0.7953\n",
      "Epoch 138: Train Loss=0.4705, Train Acc=0.7889 ||| Val Loss=0.4603, Val Acc=0.7959\n",
      "Epoch 139: Train Loss=0.4692, Train Acc=0.7886 ||| Val Loss=0.4598, Val Acc=0.7947\n",
      "Epoch 140: Train Loss=0.4664, Train Acc=0.7896 ||| Val Loss=0.4590, Val Acc=0.7959\n",
      "Epoch 141: Train Loss=0.4694, Train Acc=0.7869 ||| Val Loss=0.4588, Val Acc=0.7953\n",
      "Epoch 142: Train Loss=0.4716, Train Acc=0.7893 ||| Val Loss=0.4585, Val Acc=0.7936\n",
      "Epoch 143: Train Loss=0.4667, Train Acc=0.7883 ||| Val Loss=0.4591, Val Acc=0.7947\n",
      "Epoch 144: Train Loss=0.4660, Train Acc=0.7892 ||| Val Loss=0.4579, Val Acc=0.7959\n",
      "Epoch 145: Train Loss=0.4685, Train Acc=0.7896 ||| Val Loss=0.4579, Val Acc=0.7964\n",
      "Epoch 146: Train Loss=0.4670, Train Acc=0.7879 ||| Val Loss=0.4565, Val Acc=0.7953\n",
      "Epoch 147: Train Loss=0.4735, Train Acc=0.7925 ||| Val Loss=0.4568, Val Acc=0.7959\n",
      "Epoch 148: Train Loss=0.4718, Train Acc=0.7896 ||| Val Loss=0.4563, Val Acc=0.7947\n",
      "Epoch 149: Train Loss=0.4696, Train Acc=0.7879 ||| Val Loss=0.4552, Val Acc=0.7959\n",
      "Epoch 150: Train Loss=0.4685, Train Acc=0.7906 ||| Val Loss=0.4561, Val Acc=0.7959\n",
      "Epoch 151: Train Loss=0.4688, Train Acc=0.7870 ||| Val Loss=0.4557, Val Acc=0.7959\n",
      "Epoch 152: Train Loss=0.4653, Train Acc=0.7879 ||| Val Loss=0.4562, Val Acc=0.7959\n",
      "Epoch 153: Train Loss=0.4667, Train Acc=0.7876 ||| Val Loss=0.4558, Val Acc=0.7982\n",
      "Epoch 154: Train Loss=0.4685, Train Acc=0.7880 ||| Val Loss=0.4558, Val Acc=0.7953\n",
      "Epoch 155: Train Loss=0.4643, Train Acc=0.7892 ||| Val Loss=0.4537, Val Acc=0.7959\n",
      "Epoch 156: Train Loss=0.4639, Train Acc=0.7902 ||| Val Loss=0.4536, Val Acc=0.7970\n",
      "Epoch 157: Train Loss=0.4662, Train Acc=0.7882 ||| Val Loss=0.4537, Val Acc=0.7953\n",
      "Epoch 158: Train Loss=0.4664, Train Acc=0.7915 ||| Val Loss=0.4528, Val Acc=0.7953\n",
      "Epoch 159: Train Loss=0.4706, Train Acc=0.7866 ||| Val Loss=0.4525, Val Acc=0.7936\n",
      "Epoch 160: Train Loss=0.4688, Train Acc=0.7888 ||| Val Loss=0.4529, Val Acc=0.7924\n",
      "Epoch 161: Train Loss=0.4662, Train Acc=0.7862 ||| Val Loss=0.4521, Val Acc=0.7941\n",
      "Epoch 162: Train Loss=0.4674, Train Acc=0.7870 ||| Val Loss=0.4524, Val Acc=0.7953\n",
      "Epoch 163: Train Loss=0.4663, Train Acc=0.7883 ||| Val Loss=0.4520, Val Acc=0.7953\n",
      "Epoch 164: Train Loss=0.4625, Train Acc=0.7890 ||| Val Loss=0.4518, Val Acc=0.7947\n",
      "Epoch 165: Train Loss=0.4657, Train Acc=0.7886 ||| Val Loss=0.4515, Val Acc=0.7970\n",
      "Epoch 166: Train Loss=0.4647, Train Acc=0.7876 ||| Val Loss=0.4503, Val Acc=0.7947\n",
      "Epoch 167: Train Loss=0.4628, Train Acc=0.7909 ||| Val Loss=0.4505, Val Acc=0.7970\n",
      "Epoch 168: Train Loss=0.4618, Train Acc=0.7900 ||| Val Loss=0.4514, Val Acc=0.7976\n",
      "Epoch 169: Train Loss=0.4693, Train Acc=0.7886 ||| Val Loss=0.4497, Val Acc=0.7953\n",
      "Epoch 170: Train Loss=0.4634, Train Acc=0.7873 ||| Val Loss=0.4510, Val Acc=0.7947\n",
      "Epoch 171: Train Loss=0.4662, Train Acc=0.7875 ||| Val Loss=0.4509, Val Acc=0.7947\n",
      "Epoch 172: Train Loss=0.4638, Train Acc=0.7912 ||| Val Loss=0.4492, Val Acc=0.7953\n",
      "Epoch 173: Train Loss=0.4607, Train Acc=0.7893 ||| Val Loss=0.4474, Val Acc=0.7970\n",
      "Epoch 174: Train Loss=0.4640, Train Acc=0.7886 ||| Val Loss=0.4485, Val Acc=0.7953\n",
      "Epoch 175: Train Loss=0.4626, Train Acc=0.7899 ||| Val Loss=0.4474, Val Acc=0.7964\n",
      "Epoch 176: Train Loss=0.4622, Train Acc=0.7872 ||| Val Loss=0.4472, Val Acc=0.7959\n",
      "Epoch 177: Train Loss=0.4638, Train Acc=0.7860 ||| Val Loss=0.4483, Val Acc=0.7959\n",
      "Epoch 178: Train Loss=0.4653, Train Acc=0.7872 ||| Val Loss=0.4474, Val Acc=0.7964\n",
      "Epoch 179: Train Loss=0.4624, Train Acc=0.7863 ||| Val Loss=0.4465, Val Acc=0.7982\n",
      "Epoch 180: Train Loss=0.4617, Train Acc=0.7880 ||| Val Loss=0.4473, Val Acc=0.7953\n",
      "Epoch 181: Train Loss=0.4575, Train Acc=0.7902 ||| Val Loss=0.4478, Val Acc=0.7941\n",
      "Epoch 182: Train Loss=0.4617, Train Acc=0.7883 ||| Val Loss=0.4506, Val Acc=0.7976\n",
      "Epoch 183: Train Loss=0.4635, Train Acc=0.7843 ||| Val Loss=0.4470, Val Acc=0.7970\n",
      "Epoch 184: Train Loss=0.4665, Train Acc=0.7865 ||| Val Loss=0.4474, Val Acc=0.7987\n",
      "Epoch 185: Train Loss=0.4665, Train Acc=0.7896 ||| Val Loss=0.4473, Val Acc=0.7993\n",
      "Epoch 186: Train Loss=0.4673, Train Acc=0.7873 ||| Val Loss=0.4464, Val Acc=0.7982\n",
      "Epoch 187: Train Loss=0.4668, Train Acc=0.7873 ||| Val Loss=0.4487, Val Acc=0.7982\n",
      "Epoch 188: Train Loss=0.4609, Train Acc=0.7902 ||| Val Loss=0.4465, Val Acc=0.7964\n",
      "Epoch 189: Train Loss=0.4655, Train Acc=0.7869 ||| Val Loss=0.4462, Val Acc=0.7964\n",
      "Epoch 190: Train Loss=0.4633, Train Acc=0.7899 ||| Val Loss=0.4472, Val Acc=0.7976\n",
      "Epoch 191: Train Loss=0.4619, Train Acc=0.7882 ||| Val Loss=0.4474, Val Acc=0.7982\n",
      "Epoch 192: Train Loss=0.4609, Train Acc=0.7908 ||| Val Loss=0.4463, Val Acc=0.7959\n",
      "Epoch 193: Train Loss=0.4630, Train Acc=0.7888 ||| Val Loss=0.4469, Val Acc=0.7947\n",
      "Epoch 194: Train Loss=0.4635, Train Acc=0.7854 ||| Val Loss=0.4453, Val Acc=0.7976\n",
      "Epoch 195: Train Loss=0.4619, Train Acc=0.7846 ||| Val Loss=0.4453, Val Acc=0.7970\n",
      "Epoch 196: Train Loss=0.4634, Train Acc=0.7895 ||| Val Loss=0.4447, Val Acc=0.7959\n",
      "Epoch 197: Train Loss=0.4640, Train Acc=0.7859 ||| Val Loss=0.4446, Val Acc=0.7982\n",
      "Epoch 198: Train Loss=0.4549, Train Acc=0.7906 ||| Val Loss=0.4444, Val Acc=0.7976\n",
      "Epoch 199: Train Loss=0.4602, Train Acc=0.7906 ||| Val Loss=0.4450, Val Acc=0.7941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:01:26,016] Trial 5 finished with value: 0.79700977573318 and parameters: {'n_blocks': 6, 'd_block': 128, 'k': 5, 'dropout': 0.42152741422212603, 'activation': 'ReLU', 'lr': 0.0002689515344605779, 'weight_decay': 0.00048682323175334356}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Train Loss=0.4671, Train Acc=0.7849 ||| Val Loss=0.4544, Val Acc=0.7970\n",
      "Validation Accuracy: 0.7970\n",
      "\n",
      " Trial 7 with params: {'n_blocks': 3, 'd_block': 256, 'k': 5, 'dropout': 0.2420801689089526, 'activation': 'GELU', 'lr': 0.0012204628354878094, 'weight_decay': 4.929218255047628e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.1315, Train Acc=0.6345 ||| Val Loss=0.6060, Val Acc=0.7119\n",
      "Epoch 2: Train Loss=0.6584, Train Acc=0.6826 ||| Val Loss=0.6050, Val Acc=0.7412\n",
      "Epoch 3: Train Loss=0.6023, Train Acc=0.7003 ||| Val Loss=0.5789, Val Acc=0.7136\n",
      "Epoch 4: Train Loss=0.5964, Train Acc=0.7167 ||| Val Loss=0.5534, Val Acc=0.7389\n",
      "Epoch 5: Train Loss=0.5886, Train Acc=0.7242 ||| Val Loss=0.5328, Val Acc=0.7625\n",
      "Epoch 6: Train Loss=0.5555, Train Acc=0.7446 ||| Val Loss=0.5275, Val Acc=0.7550\n",
      "Epoch 7: Train Loss=0.5445, Train Acc=0.7472 ||| Val Loss=0.5207, Val Acc=0.7648\n",
      "Epoch 8: Train Loss=0.5364, Train Acc=0.7558 ||| Val Loss=0.5181, Val Acc=0.7619\n",
      "Epoch 9: Train Loss=0.5283, Train Acc=0.7653 ||| Val Loss=0.5072, Val Acc=0.7757\n",
      "Epoch 10: Train Loss=0.5205, Train Acc=0.7689 ||| Val Loss=0.5153, Val Acc=0.7757\n",
      "Epoch 11: Train Loss=0.5116, Train Acc=0.7689 ||| Val Loss=0.5012, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.5090, Train Acc=0.7688 ||| Val Loss=0.4934, Val Acc=0.7844\n",
      "Epoch 13: Train Loss=0.5065, Train Acc=0.7728 ||| Val Loss=0.5048, Val Acc=0.7947\n",
      "Epoch 14: Train Loss=0.5051, Train Acc=0.7712 ||| Val Loss=0.4917, Val Acc=0.7826\n",
      "Epoch 15: Train Loss=0.5065, Train Acc=0.7745 ||| Val Loss=0.4869, Val Acc=0.7941\n",
      "Epoch 16: Train Loss=0.4925, Train Acc=0.7793 ||| Val Loss=0.5009, Val Acc=0.7849\n",
      "Epoch 17: Train Loss=0.5010, Train Acc=0.7788 ||| Val Loss=0.4822, Val Acc=0.7930\n",
      "Epoch 18: Train Loss=0.4940, Train Acc=0.7785 ||| Val Loss=0.4835, Val Acc=0.7844\n",
      "Epoch 19: Train Loss=0.4890, Train Acc=0.7810 ||| Val Loss=0.4811, Val Acc=0.7855\n",
      "Epoch 20: Train Loss=0.4931, Train Acc=0.7833 ||| Val Loss=0.4784, Val Acc=0.7924\n",
      "Epoch 21: Train Loss=0.4891, Train Acc=0.7819 ||| Val Loss=0.4771, Val Acc=0.7913\n",
      "Epoch 22: Train Loss=0.4918, Train Acc=0.7811 ||| Val Loss=0.4716, Val Acc=0.7959\n",
      "Epoch 23: Train Loss=0.4870, Train Acc=0.7808 ||| Val Loss=0.4777, Val Acc=0.7855\n",
      "Epoch 24: Train Loss=0.4860, Train Acc=0.7819 ||| Val Loss=0.4961, Val Acc=0.7913\n",
      "Epoch 25: Train Loss=0.4810, Train Acc=0.7842 ||| Val Loss=0.4714, Val Acc=0.7953\n",
      "Epoch 26: Train Loss=0.4947, Train Acc=0.7853 ||| Val Loss=0.4825, Val Acc=0.7959\n",
      "Epoch 27: Train Loss=0.4941, Train Acc=0.7823 ||| Val Loss=0.4700, Val Acc=0.7941\n",
      "Epoch 28: Train Loss=0.4834, Train Acc=0.7827 ||| Val Loss=0.4851, Val Acc=0.7861\n",
      "Epoch 29: Train Loss=0.4855, Train Acc=0.7817 ||| Val Loss=0.4676, Val Acc=0.7970\n",
      "Epoch 30: Train Loss=0.4809, Train Acc=0.7833 ||| Val Loss=0.4774, Val Acc=0.7855\n",
      "Epoch 31: Train Loss=0.4762, Train Acc=0.7893 ||| Val Loss=0.4720, Val Acc=0.7941\n",
      "Epoch 32: Train Loss=0.4808, Train Acc=0.7837 ||| Val Loss=0.4718, Val Acc=0.7964\n",
      "Epoch 33: Train Loss=0.4757, Train Acc=0.7842 ||| Val Loss=0.4751, Val Acc=0.7924\n",
      "Epoch 34: Train Loss=0.4764, Train Acc=0.7880 ||| Val Loss=0.4773, Val Acc=0.7890\n",
      "Epoch 35: Train Loss=0.4808, Train Acc=0.7839 ||| Val Loss=0.4759, Val Acc=0.7941\n",
      "Epoch 36: Train Loss=0.4743, Train Acc=0.7877 ||| Val Loss=0.4667, Val Acc=0.7999\n",
      "Epoch 37: Train Loss=0.4774, Train Acc=0.7866 ||| Val Loss=0.4653, Val Acc=0.7976\n",
      "Epoch 38: Train Loss=0.4713, Train Acc=0.7893 ||| Val Loss=0.4664, Val Acc=0.7959\n",
      "Epoch 39: Train Loss=0.4766, Train Acc=0.7869 ||| Val Loss=0.4666, Val Acc=0.7976\n",
      "Epoch 40: Train Loss=0.4714, Train Acc=0.7872 ||| Val Loss=0.4726, Val Acc=0.7907\n",
      "Epoch 41: Train Loss=0.4725, Train Acc=0.7872 ||| Val Loss=0.4670, Val Acc=0.7941\n",
      "Epoch 42: Train Loss=0.4733, Train Acc=0.7882 ||| Val Loss=0.4751, Val Acc=0.7844\n",
      "Epoch 43: Train Loss=0.4707, Train Acc=0.7862 ||| Val Loss=0.4717, Val Acc=0.7924\n",
      "Epoch 44: Train Loss=0.4686, Train Acc=0.7905 ||| Val Loss=0.4814, Val Acc=0.7821\n",
      "Epoch 45: Train Loss=0.4672, Train Acc=0.7896 ||| Val Loss=0.4632, Val Acc=0.7941\n",
      "Epoch 46: Train Loss=0.4631, Train Acc=0.7893 ||| Val Loss=0.4542, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.4670, Train Acc=0.7853 ||| Val Loss=0.4586, Val Acc=0.7918\n",
      "Epoch 48: Train Loss=0.4617, Train Acc=0.7885 ||| Val Loss=0.4604, Val Acc=0.7947\n",
      "Epoch 49: Train Loss=0.4669, Train Acc=0.7888 ||| Val Loss=0.4572, Val Acc=0.7964\n",
      "Epoch 50: Train Loss=0.4602, Train Acc=0.7886 ||| Val Loss=0.4537, Val Acc=0.7930\n",
      "Epoch 51: Train Loss=0.4593, Train Acc=0.7896 ||| Val Loss=0.4541, Val Acc=0.7947\n",
      "Epoch 52: Train Loss=0.4565, Train Acc=0.7902 ||| Val Loss=0.4547, Val Acc=0.7844\n",
      "Epoch 53: Train Loss=0.4539, Train Acc=0.7913 ||| Val Loss=0.4509, Val Acc=0.7959\n",
      "Epoch 54: Train Loss=0.4537, Train Acc=0.7886 ||| Val Loss=0.4604, Val Acc=0.7867\n",
      "Epoch 55: Train Loss=0.4521, Train Acc=0.7922 ||| Val Loss=0.4725, Val Acc=0.7976\n",
      "Epoch 56: Train Loss=0.4527, Train Acc=0.7899 ||| Val Loss=0.4529, Val Acc=0.7924\n",
      "Epoch 57: Train Loss=0.4535, Train Acc=0.7936 ||| Val Loss=0.4500, Val Acc=0.7964\n",
      "Epoch 58: Train Loss=0.4527, Train Acc=0.7908 ||| Val Loss=0.4549, Val Acc=0.7941\n",
      "Epoch 59: Train Loss=0.4562, Train Acc=0.7908 ||| Val Loss=0.4572, Val Acc=0.7976\n",
      "Epoch 60: Train Loss=0.4571, Train Acc=0.7882 ||| Val Loss=0.4444, Val Acc=0.7895\n",
      "Epoch 61: Train Loss=0.4480, Train Acc=0.7898 ||| Val Loss=0.4566, Val Acc=0.7941\n",
      "Epoch 62: Train Loss=0.4527, Train Acc=0.7906 ||| Val Loss=0.4495, Val Acc=0.7890\n",
      "Epoch 63: Train Loss=0.4454, Train Acc=0.7939 ||| Val Loss=0.4512, Val Acc=0.7890\n",
      "Epoch 64: Train Loss=0.4509, Train Acc=0.7888 ||| Val Loss=0.4447, Val Acc=0.7982\n",
      "Epoch 65: Train Loss=0.4423, Train Acc=0.7905 ||| Val Loss=0.4403, Val Acc=0.7913\n",
      "Epoch 66: Train Loss=0.4453, Train Acc=0.7906 ||| Val Loss=0.4497, Val Acc=0.7947\n",
      "Epoch 67: Train Loss=0.4448, Train Acc=0.7918 ||| Val Loss=0.4426, Val Acc=0.7815\n",
      "Epoch 68: Train Loss=0.4405, Train Acc=0.7918 ||| Val Loss=0.4506, Val Acc=0.7970\n",
      "Epoch 69: Train Loss=0.4429, Train Acc=0.7928 ||| Val Loss=0.4466, Val Acc=0.7872\n",
      "Epoch 70: Train Loss=0.4450, Train Acc=0.7906 ||| Val Loss=0.4467, Val Acc=0.7993\n",
      "Epoch 71: Train Loss=0.4397, Train Acc=0.7892 ||| Val Loss=0.4414, Val Acc=0.7982\n",
      "Epoch 72: Train Loss=0.4442, Train Acc=0.7922 ||| Val Loss=0.4533, Val Acc=0.7936\n",
      "Epoch 73: Train Loss=0.4421, Train Acc=0.7954 ||| Val Loss=0.4424, Val Acc=0.7936\n",
      "Epoch 74: Train Loss=0.4390, Train Acc=0.7925 ||| Val Loss=0.4475, Val Acc=0.7878\n",
      "Epoch 75: Train Loss=0.4358, Train Acc=0.7906 ||| Val Loss=0.4417, Val Acc=0.7930\n",
      "Epoch 76: Train Loss=0.4379, Train Acc=0.7938 ||| Val Loss=0.4446, Val Acc=0.7918\n",
      "Epoch 77: Train Loss=0.4339, Train Acc=0.7896 ||| Val Loss=0.4347, Val Acc=0.7918\n",
      "Epoch 78: Train Loss=0.4365, Train Acc=0.7921 ||| Val Loss=0.4404, Val Acc=0.7936\n",
      "Epoch 79: Train Loss=0.4352, Train Acc=0.7915 ||| Val Loss=0.4455, Val Acc=0.7953\n",
      "Epoch 80: Train Loss=0.4329, Train Acc=0.7915 ||| Val Loss=0.4472, Val Acc=0.7901\n",
      "Epoch 81: Train Loss=0.4331, Train Acc=0.7926 ||| Val Loss=0.4503, Val Acc=0.7872\n",
      "Epoch 82: Train Loss=0.4377, Train Acc=0.7915 ||| Val Loss=0.4458, Val Acc=0.7780\n",
      "Epoch 83: Train Loss=0.4341, Train Acc=0.7938 ||| Val Loss=0.4356, Val Acc=0.7947\n",
      "Epoch 84: Train Loss=0.4344, Train Acc=0.7934 ||| Val Loss=0.4385, Val Acc=0.7907\n",
      "Epoch 85: Train Loss=0.4331, Train Acc=0.7919 ||| Val Loss=0.4541, Val Acc=0.7815\n",
      "Epoch 86: Train Loss=0.4327, Train Acc=0.7902 ||| Val Loss=0.4381, Val Acc=0.7901\n",
      "Epoch 87: Train Loss=0.4299, Train Acc=0.7949 ||| Val Loss=0.4407, Val Acc=0.7861\n",
      "Epoch 88: Train Loss=0.4299, Train Acc=0.7939 ||| Val Loss=0.4393, Val Acc=0.7976\n",
      "Epoch 89: Train Loss=0.4303, Train Acc=0.7902 ||| Val Loss=0.4395, Val Acc=0.7947\n",
      "Epoch 90: Train Loss=0.4305, Train Acc=0.7892 ||| Val Loss=0.4370, Val Acc=0.7964\n",
      "Epoch 91: Train Loss=0.4264, Train Acc=0.7957 ||| Val Loss=0.4315, Val Acc=0.7930\n",
      "Epoch 92: Train Loss=0.4282, Train Acc=0.7906 ||| Val Loss=0.4410, Val Acc=0.7936\n",
      "Epoch 93: Train Loss=0.4269, Train Acc=0.7909 ||| Val Loss=0.4394, Val Acc=0.7924\n",
      "Epoch 94: Train Loss=0.4273, Train Acc=0.7959 ||| Val Loss=0.4388, Val Acc=0.7982\n",
      "Epoch 95: Train Loss=0.4278, Train Acc=0.7945 ||| Val Loss=0.4391, Val Acc=0.7924\n",
      "Epoch 96: Train Loss=0.4302, Train Acc=0.7890 ||| Val Loss=0.4428, Val Acc=0.7884\n",
      "Epoch 97: Train Loss=0.4317, Train Acc=0.7922 ||| Val Loss=0.4400, Val Acc=0.7982\n",
      "Epoch 98: Train Loss=0.4296, Train Acc=0.7925 ||| Val Loss=0.4376, Val Acc=0.7924\n",
      "Epoch 99: Train Loss=0.4284, Train Acc=0.7958 ||| Val Loss=0.4415, Val Acc=0.7976\n",
      "Epoch 100: Train Loss=0.4286, Train Acc=0.7911 ||| Val Loss=0.4352, Val Acc=0.7918\n",
      "Epoch 101: Train Loss=0.4289, Train Acc=0.7961 ||| Val Loss=0.4428, Val Acc=0.7849\n",
      "Epoch 102: Train Loss=0.4265, Train Acc=0.7925 ||| Val Loss=0.4381, Val Acc=0.7844\n",
      "Epoch 103: Train Loss=0.4268, Train Acc=0.7905 ||| Val Loss=0.4363, Val Acc=0.7947\n",
      "Epoch 104: Train Loss=0.4228, Train Acc=0.7968 ||| Val Loss=0.4318, Val Acc=0.7941\n",
      "Epoch 105: Train Loss=0.4247, Train Acc=0.7955 ||| Val Loss=0.4506, Val Acc=0.7930\n",
      "Epoch 106: Train Loss=0.4239, Train Acc=0.7939 ||| Val Loss=0.4352, Val Acc=0.7947\n",
      "Epoch 107: Train Loss=0.4260, Train Acc=0.7928 ||| Val Loss=0.4402, Val Acc=0.7913\n",
      "Epoch 108: Train Loss=0.4189, Train Acc=0.7970 ||| Val Loss=0.4320, Val Acc=0.7884\n",
      "Epoch 109: Train Loss=0.4206, Train Acc=0.7970 ||| Val Loss=0.4388, Val Acc=0.7930\n",
      "Epoch 110: Train Loss=0.4200, Train Acc=0.7942 ||| Val Loss=0.4292, Val Acc=0.7918\n",
      "Epoch 111: Train Loss=0.4200, Train Acc=0.7967 ||| Val Loss=0.4339, Val Acc=0.7884\n",
      "Epoch 112: Train Loss=0.4182, Train Acc=0.7918 ||| Val Loss=0.4333, Val Acc=0.7959\n",
      "Epoch 113: Train Loss=0.4204, Train Acc=0.7938 ||| Val Loss=0.4302, Val Acc=0.7867\n",
      "Epoch 114: Train Loss=0.4175, Train Acc=0.7965 ||| Val Loss=0.4383, Val Acc=0.7872\n",
      "Epoch 115: Train Loss=0.4188, Train Acc=0.7942 ||| Val Loss=0.4294, Val Acc=0.7844\n",
      "Epoch 116: Train Loss=0.4173, Train Acc=0.7972 ||| Val Loss=0.4375, Val Acc=0.7890\n",
      "Epoch 117: Train Loss=0.4212, Train Acc=0.7998 ||| Val Loss=0.4316, Val Acc=0.7872\n",
      "Epoch 118: Train Loss=0.4223, Train Acc=0.7948 ||| Val Loss=0.4298, Val Acc=0.7867\n",
      "Epoch 119: Train Loss=0.4184, Train Acc=0.7938 ||| Val Loss=0.4303, Val Acc=0.7930\n",
      "Epoch 120: Train Loss=0.4160, Train Acc=0.8027 ||| Val Loss=0.4289, Val Acc=0.7907\n",
      "Epoch 121: Train Loss=0.4224, Train Acc=0.7957 ||| Val Loss=0.4307, Val Acc=0.7947\n",
      "Epoch 122: Train Loss=0.4127, Train Acc=0.7970 ||| Val Loss=0.4367, Val Acc=0.7821\n",
      "Epoch 123: Train Loss=0.4182, Train Acc=0.7974 ||| Val Loss=0.4294, Val Acc=0.7832\n",
      "Epoch 124: Train Loss=0.4163, Train Acc=0.7980 ||| Val Loss=0.4341, Val Acc=0.7913\n",
      "Epoch 125: Train Loss=0.4168, Train Acc=0.7975 ||| Val Loss=0.4363, Val Acc=0.7993\n",
      "Epoch 126: Train Loss=0.4173, Train Acc=0.7985 ||| Val Loss=0.4263, Val Acc=0.7861\n",
      "Epoch 127: Train Loss=0.4164, Train Acc=0.7948 ||| Val Loss=0.4327, Val Acc=0.7878\n",
      "Epoch 128: Train Loss=0.4142, Train Acc=0.7962 ||| Val Loss=0.4325, Val Acc=0.7895\n",
      "Epoch 129: Train Loss=0.4135, Train Acc=0.7970 ||| Val Loss=0.4416, Val Acc=0.7924\n",
      "Epoch 130: Train Loss=0.4124, Train Acc=0.7998 ||| Val Loss=0.4415, Val Acc=0.7826\n",
      "Epoch 131: Train Loss=0.4143, Train Acc=0.7944 ||| Val Loss=0.4294, Val Acc=0.7890\n",
      "Epoch 132: Train Loss=0.4119, Train Acc=0.7972 ||| Val Loss=0.4431, Val Acc=0.7878\n",
      "Epoch 133: Train Loss=0.4157, Train Acc=0.7972 ||| Val Loss=0.4319, Val Acc=0.7947\n",
      "Epoch 134: Train Loss=0.4134, Train Acc=0.7972 ||| Val Loss=0.4349, Val Acc=0.7884\n",
      "Epoch 135: Train Loss=0.4133, Train Acc=0.8027 ||| Val Loss=0.4301, Val Acc=0.7855\n",
      "Epoch 136: Train Loss=0.4104, Train Acc=0.7978 ||| Val Loss=0.4311, Val Acc=0.7861\n",
      "Epoch 137: Train Loss=0.4095, Train Acc=0.8017 ||| Val Loss=0.4244, Val Acc=0.7907\n",
      "Epoch 138: Train Loss=0.4170, Train Acc=0.7985 ||| Val Loss=0.4378, Val Acc=0.7786\n",
      "Epoch 139: Train Loss=0.4113, Train Acc=0.8001 ||| Val Loss=0.4355, Val Acc=0.7832\n",
      "Epoch 140: Train Loss=0.4113, Train Acc=0.8020 ||| Val Loss=0.4327, Val Acc=0.7895\n",
      "Epoch 141: Train Loss=0.4119, Train Acc=0.8003 ||| Val Loss=0.4322, Val Acc=0.7861\n",
      "Epoch 142: Train Loss=0.4135, Train Acc=0.8021 ||| Val Loss=0.4338, Val Acc=0.7953\n",
      "Epoch 143: Train Loss=0.4105, Train Acc=0.8031 ||| Val Loss=0.4376, Val Acc=0.7895\n",
      "Epoch 144: Train Loss=0.4104, Train Acc=0.7998 ||| Val Loss=0.4342, Val Acc=0.7844\n",
      "Epoch 145: Train Loss=0.4064, Train Acc=0.8017 ||| Val Loss=0.4338, Val Acc=0.7913\n",
      "Epoch 146: Train Loss=0.4085, Train Acc=0.8024 ||| Val Loss=0.4328, Val Acc=0.7838\n",
      "Epoch 147: Train Loss=0.4069, Train Acc=0.8026 ||| Val Loss=0.4353, Val Acc=0.7959\n",
      "Epoch 148: Train Loss=0.4069, Train Acc=0.8039 ||| Val Loss=0.4361, Val Acc=0.7855\n",
      "Epoch 149: Train Loss=0.4067, Train Acc=0.8053 ||| Val Loss=0.4361, Val Acc=0.7907\n",
      "Epoch 150: Train Loss=0.4115, Train Acc=0.7982 ||| Val Loss=0.4317, Val Acc=0.7855\n",
      "Epoch 151: Train Loss=0.4057, Train Acc=0.8047 ||| Val Loss=0.4301, Val Acc=0.7964\n",
      "Epoch 152: Train Loss=0.4030, Train Acc=0.8044 ||| Val Loss=0.4358, Val Acc=0.7832\n",
      "Epoch 153: Train Loss=0.4111, Train Acc=0.8043 ||| Val Loss=0.4287, Val Acc=0.7855\n",
      "Epoch 154: Train Loss=0.4111, Train Acc=0.8017 ||| Val Loss=0.4287, Val Acc=0.7930\n",
      "Epoch 155: Train Loss=0.4076, Train Acc=0.8021 ||| Val Loss=0.4298, Val Acc=0.7947\n",
      "Epoch 156: Train Loss=0.4024, Train Acc=0.8041 ||| Val Loss=0.4314, Val Acc=0.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:02:14,269] Trial 6 finished with value: 0.7849338700402531 and parameters: {'n_blocks': 3, 'd_block': 256, 'k': 5, 'dropout': 0.2420801689089526, 'activation': 'GELU', 'lr': 0.0012204628354878094, 'weight_decay': 4.929218255047628e-05}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157: Train Loss=0.4107, Train Acc=0.7998 ||| Val Loss=0.4348, Val Acc=0.7849\n",
      "Early stopping triggered at epoch 157\n",
      "Validation Accuracy: 0.7849\n",
      "\n",
      " Trial 8 with params: {'n_blocks': 3, 'd_block': 128, 'k': 7, 'dropout': 0.13421047430650393, 'activation': 'GELU', 'lr': 0.023715545769525163, 'weight_decay': 1.4723360765830886e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=9.8055, Train Acc=0.7184 ||| Val Loss=0.5068, Val Acc=0.7901\n",
      "Epoch 2: Train Loss=0.5376, Train Acc=0.7709 ||| Val Loss=0.6090, Val Acc=0.7522\n",
      "Epoch 3: Train Loss=0.5460, Train Acc=0.7577 ||| Val Loss=0.4982, Val Acc=0.7844\n",
      "Epoch 4: Train Loss=0.5126, Train Acc=0.7748 ||| Val Loss=0.4939, Val Acc=0.7792\n",
      "Epoch 5: Train Loss=0.4936, Train Acc=0.7843 ||| Val Loss=0.4942, Val Acc=0.7872\n",
      "Epoch 6: Train Loss=0.5003, Train Acc=0.7798 ||| Val Loss=0.4601, Val Acc=0.7970\n",
      "Epoch 7: Train Loss=0.4792, Train Acc=0.7787 ||| Val Loss=0.4578, Val Acc=0.7964\n",
      "Epoch 8: Train Loss=0.4991, Train Acc=0.7814 ||| Val Loss=0.4498, Val Acc=0.7970\n",
      "Epoch 9: Train Loss=0.4842, Train Acc=0.7808 ||| Val Loss=0.4334, Val Acc=0.7884\n",
      "Epoch 10: Train Loss=0.4735, Train Acc=0.7834 ||| Val Loss=0.4478, Val Acc=0.7878\n",
      "Epoch 11: Train Loss=0.5475, Train Acc=0.7659 ||| Val Loss=0.4441, Val Acc=0.7993\n",
      "Epoch 12: Train Loss=0.4580, Train Acc=0.7844 ||| Val Loss=0.4383, Val Acc=0.7976\n",
      "Epoch 13: Train Loss=0.5052, Train Acc=0.7755 ||| Val Loss=0.4663, Val Acc=0.7924\n",
      "Epoch 14: Train Loss=0.4905, Train Acc=0.7785 ||| Val Loss=0.4328, Val Acc=0.7959\n",
      "Epoch 15: Train Loss=0.4874, Train Acc=0.7791 ||| Val Loss=0.4480, Val Acc=0.7987\n",
      "Epoch 16: Train Loss=0.5144, Train Acc=0.7714 ||| Val Loss=0.4784, Val Acc=0.7878\n",
      "Epoch 17: Train Loss=0.7069, Train Acc=0.7468 ||| Val Loss=0.4765, Val Acc=0.7849\n",
      "Epoch 18: Train Loss=0.6420, Train Acc=0.7460 ||| Val Loss=0.5905, Val Acc=0.7527\n",
      "Epoch 19: Train Loss=0.6198, Train Acc=0.7517 ||| Val Loss=0.4708, Val Acc=0.7734\n",
      "Epoch 20: Train Loss=0.7972, Train Acc=0.7393 ||| Val Loss=0.4684, Val Acc=0.7872\n",
      "Epoch 21: Train Loss=0.4848, Train Acc=0.7702 ||| Val Loss=0.4465, Val Acc=0.7855\n",
      "Epoch 22: Train Loss=0.4572, Train Acc=0.7775 ||| Val Loss=0.4284, Val Acc=0.7878\n",
      "Epoch 23: Train Loss=0.4587, Train Acc=0.7806 ||| Val Loss=0.4324, Val Acc=0.7838\n",
      "Epoch 24: Train Loss=0.4462, Train Acc=0.7829 ||| Val Loss=0.4333, Val Acc=0.7895\n",
      "Epoch 25: Train Loss=0.4556, Train Acc=0.7807 ||| Val Loss=0.4217, Val Acc=0.7987\n",
      "Epoch 26: Train Loss=0.4537, Train Acc=0.7840 ||| Val Loss=0.4255, Val Acc=0.7982\n",
      "Epoch 27: Train Loss=0.4533, Train Acc=0.7827 ||| Val Loss=0.4314, Val Acc=0.7959\n",
      "Epoch 28: Train Loss=0.4491, Train Acc=0.7821 ||| Val Loss=0.4278, Val Acc=0.7901\n",
      "Epoch 29: Train Loss=0.4536, Train Acc=0.7817 ||| Val Loss=0.4470, Val Acc=0.7890\n",
      "Epoch 30: Train Loss=0.4436, Train Acc=0.7853 ||| Val Loss=0.4354, Val Acc=0.7838\n",
      "Epoch 31: Train Loss=0.4367, Train Acc=0.7938 ||| Val Loss=0.4559, Val Acc=0.7890\n",
      "Epoch 32: Train Loss=0.4383, Train Acc=0.7882 ||| Val Loss=0.4299, Val Acc=0.8022\n",
      "Epoch 33: Train Loss=0.4327, Train Acc=0.7936 ||| Val Loss=0.4184, Val Acc=0.8028\n",
      "Epoch 34: Train Loss=0.4341, Train Acc=0.7903 ||| Val Loss=0.4266, Val Acc=0.7901\n",
      "Epoch 35: Train Loss=0.4316, Train Acc=0.7935 ||| Val Loss=0.4125, Val Acc=0.7941\n",
      "Epoch 36: Train Loss=0.4402, Train Acc=0.7895 ||| Val Loss=0.4217, Val Acc=0.7936\n",
      "Epoch 37: Train Loss=0.4693, Train Acc=0.7803 ||| Val Loss=0.4530, Val Acc=0.7936\n",
      "Epoch 38: Train Loss=0.4555, Train Acc=0.7854 ||| Val Loss=0.4239, Val Acc=0.7930\n",
      "Epoch 39: Train Loss=0.4715, Train Acc=0.7790 ||| Val Loss=0.4472, Val Acc=0.7878\n",
      "Epoch 40: Train Loss=0.4748, Train Acc=0.7771 ||| Val Loss=0.4372, Val Acc=0.7918\n",
      "Epoch 41: Train Loss=0.4525, Train Acc=0.7834 ||| Val Loss=0.4203, Val Acc=0.7970\n",
      "Epoch 42: Train Loss=0.4409, Train Acc=0.7903 ||| Val Loss=0.4193, Val Acc=0.7999\n",
      "Epoch 43: Train Loss=0.4492, Train Acc=0.7905 ||| Val Loss=0.4309, Val Acc=0.7930\n",
      "Epoch 44: Train Loss=0.4499, Train Acc=0.7836 ||| Val Loss=0.4326, Val Acc=0.7947\n",
      "Epoch 45: Train Loss=0.4546, Train Acc=0.7896 ||| Val Loss=0.4511, Val Acc=0.7913\n",
      "Epoch 46: Train Loss=0.4931, Train Acc=0.7819 ||| Val Loss=0.4926, Val Acc=0.7826\n",
      "Epoch 47: Train Loss=0.9900, Train Acc=0.7348 ||| Val Loss=1.3013, Val Acc=0.7499\n",
      "Epoch 48: Train Loss=41.4267, Train Acc=0.6152 ||| Val Loss=69.4729, Val Acc=0.5141\n",
      "Epoch 49: Train Loss=76.9337, Train Acc=0.5892 ||| Val Loss=160.5370, Val Acc=0.6205\n",
      "Epoch 50: Train Loss=105.6216, Train Acc=0.5447 ||| Val Loss=85.1240, Val Acc=0.6567\n",
      "Epoch 51: Train Loss=69.5081, Train Acc=0.5224 ||| Val Loss=2.1027, Val Acc=0.4503\n",
      "Epoch 52: Train Loss=11.7649, Train Acc=0.5039 ||| Val Loss=7.0715, Val Acc=0.5009\n",
      "Epoch 53: Train Loss=11.1875, Train Acc=0.5210 ||| Val Loss=1.1888, Val Acc=0.5382\n",
      "Epoch 54: Train Loss=9.6622, Train Acc=0.5181 ||| Val Loss=1.2880, Val Acc=0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:02:29,628] Trial 7 finished with value: 0.6175963197239793 and parameters: {'n_blocks': 3, 'd_block': 128, 'k': 7, 'dropout': 0.13421047430650393, 'activation': 'GELU', 'lr': 0.023715545769525163, 'weight_decay': 1.4723360765830886e-05}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss=1.9006, Train Acc=0.5121 ||| Val Loss=0.7247, Val Acc=0.6176\n",
      "Early stopping triggered at epoch 55\n",
      "Validation Accuracy: 0.6176\n",
      "\n",
      " Trial 9 with params: {'n_blocks': 6, 'd_block': 512, 'k': 4, 'dropout': 0.4125798645567976, 'activation': 'ReLU', 'lr': 0.0004273952160210739, 'weight_decay': 1.5715345641888542e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.1995, Train Acc=0.5421 ||| Val Loss=0.6397, Val Acc=0.6498\n",
      "Epoch 2: Train Loss=0.6962, Train Acc=0.6087 ||| Val Loss=0.5930, Val Acc=0.6998\n",
      "Epoch 3: Train Loss=0.6255, Train Acc=0.6613 ||| Val Loss=0.5595, Val Acc=0.7234\n",
      "Epoch 4: Train Loss=0.6027, Train Acc=0.6913 ||| Val Loss=0.5671, Val Acc=0.7159\n",
      "Epoch 5: Train Loss=0.5802, Train Acc=0.7084 ||| Val Loss=0.5424, Val Acc=0.7809\n",
      "Epoch 6: Train Loss=0.5629, Train Acc=0.7255 ||| Val Loss=0.5456, Val Acc=0.7671\n",
      "Epoch 7: Train Loss=0.5560, Train Acc=0.7334 ||| Val Loss=0.5204, Val Acc=0.7803\n",
      "Epoch 8: Train Loss=0.5485, Train Acc=0.7413 ||| Val Loss=0.5244, Val Acc=0.7861\n",
      "Epoch 9: Train Loss=0.5410, Train Acc=0.7486 ||| Val Loss=0.5254, Val Acc=0.7665\n",
      "Epoch 10: Train Loss=0.5381, Train Acc=0.7504 ||| Val Loss=0.5323, Val Acc=0.7717\n",
      "Epoch 11: Train Loss=0.5364, Train Acc=0.7551 ||| Val Loss=0.5187, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.5262, Train Acc=0.7685 ||| Val Loss=0.5060, Val Acc=0.7844\n",
      "Epoch 13: Train Loss=0.5222, Train Acc=0.7670 ||| Val Loss=0.5104, Val Acc=0.7838\n",
      "Epoch 14: Train Loss=0.5225, Train Acc=0.7639 ||| Val Loss=0.5132, Val Acc=0.7867\n",
      "Epoch 15: Train Loss=0.5209, Train Acc=0.7675 ||| Val Loss=0.5034, Val Acc=0.7832\n",
      "Epoch 16: Train Loss=0.5107, Train Acc=0.7768 ||| Val Loss=0.5141, Val Acc=0.7798\n",
      "Epoch 17: Train Loss=0.5120, Train Acc=0.7741 ||| Val Loss=0.5055, Val Acc=0.7826\n",
      "Epoch 18: Train Loss=0.5148, Train Acc=0.7764 ||| Val Loss=0.4977, Val Acc=0.7907\n",
      "Epoch 19: Train Loss=0.5073, Train Acc=0.7757 ||| Val Loss=0.5036, Val Acc=0.7849\n",
      "Epoch 20: Train Loss=0.5074, Train Acc=0.7741 ||| Val Loss=0.5012, Val Acc=0.7884\n",
      "Epoch 21: Train Loss=0.5101, Train Acc=0.7798 ||| Val Loss=0.5016, Val Acc=0.7907\n",
      "Epoch 22: Train Loss=0.5062, Train Acc=0.7807 ||| Val Loss=0.4930, Val Acc=0.7861\n",
      "Epoch 23: Train Loss=0.5019, Train Acc=0.7810 ||| Val Loss=0.5033, Val Acc=0.7815\n",
      "Epoch 24: Train Loss=0.4999, Train Acc=0.7829 ||| Val Loss=0.5000, Val Acc=0.7815\n",
      "Epoch 25: Train Loss=0.4980, Train Acc=0.7811 ||| Val Loss=0.5192, Val Acc=0.7711\n",
      "Epoch 26: Train Loss=0.4974, Train Acc=0.7816 ||| Val Loss=0.5110, Val Acc=0.7901\n",
      "Epoch 27: Train Loss=0.5001, Train Acc=0.7833 ||| Val Loss=0.5083, Val Acc=0.7861\n",
      "Epoch 28: Train Loss=0.4953, Train Acc=0.7801 ||| Val Loss=0.5068, Val Acc=0.7832\n",
      "Epoch 29: Train Loss=0.5003, Train Acc=0.7824 ||| Val Loss=0.5087, Val Acc=0.7924\n",
      "Epoch 30: Train Loss=0.4961, Train Acc=0.7821 ||| Val Loss=0.4948, Val Acc=0.7878\n",
      "Epoch 31: Train Loss=0.4945, Train Acc=0.7857 ||| Val Loss=0.4867, Val Acc=0.7936\n",
      "Epoch 32: Train Loss=0.4903, Train Acc=0.7839 ||| Val Loss=0.4953, Val Acc=0.7844\n",
      "Epoch 33: Train Loss=0.4901, Train Acc=0.7833 ||| Val Loss=0.5012, Val Acc=0.7924\n",
      "Epoch 34: Train Loss=0.4853, Train Acc=0.7823 ||| Val Loss=0.4899, Val Acc=0.7867\n",
      "Epoch 35: Train Loss=0.4859, Train Acc=0.7836 ||| Val Loss=0.4953, Val Acc=0.7826\n",
      "Epoch 36: Train Loss=0.4834, Train Acc=0.7885 ||| Val Loss=0.4850, Val Acc=0.7901\n",
      "Epoch 37: Train Loss=0.4862, Train Acc=0.7846 ||| Val Loss=0.4637, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4835, Train Acc=0.7847 ||| Val Loss=0.4657, Val Acc=0.7953\n",
      "Epoch 39: Train Loss=0.4759, Train Acc=0.7863 ||| Val Loss=0.4554, Val Acc=0.7947\n",
      "Epoch 40: Train Loss=0.4777, Train Acc=0.7844 ||| Val Loss=0.4643, Val Acc=0.7930\n",
      "Epoch 41: Train Loss=0.4771, Train Acc=0.7877 ||| Val Loss=0.4623, Val Acc=0.7941\n",
      "Epoch 42: Train Loss=0.4716, Train Acc=0.7895 ||| Val Loss=0.4551, Val Acc=0.8005\n",
      "Epoch 43: Train Loss=0.4683, Train Acc=0.7860 ||| Val Loss=0.4629, Val Acc=0.7918\n",
      "Epoch 44: Train Loss=0.4638, Train Acc=0.7865 ||| Val Loss=0.4753, Val Acc=0.7959\n",
      "Epoch 45: Train Loss=0.4683, Train Acc=0.7860 ||| Val Loss=0.4629, Val Acc=0.7930\n",
      "Epoch 46: Train Loss=0.4686, Train Acc=0.7863 ||| Val Loss=0.4662, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.4642, Train Acc=0.7872 ||| Val Loss=0.4588, Val Acc=0.7959\n",
      "Epoch 48: Train Loss=0.4604, Train Acc=0.7873 ||| Val Loss=0.4600, Val Acc=0.7959\n",
      "Epoch 49: Train Loss=0.4638, Train Acc=0.7875 ||| Val Loss=0.4517, Val Acc=0.7936\n",
      "Epoch 50: Train Loss=0.4560, Train Acc=0.7885 ||| Val Loss=0.4562, Val Acc=0.7959\n",
      "Epoch 51: Train Loss=0.4596, Train Acc=0.7882 ||| Val Loss=0.4566, Val Acc=0.7959\n",
      "Epoch 52: Train Loss=0.4554, Train Acc=0.7889 ||| Val Loss=0.4547, Val Acc=0.7993\n",
      "Epoch 53: Train Loss=0.4527, Train Acc=0.7889 ||| Val Loss=0.4476, Val Acc=0.7976\n",
      "Epoch 54: Train Loss=0.4566, Train Acc=0.7895 ||| Val Loss=0.4523, Val Acc=0.7947\n",
      "Epoch 55: Train Loss=0.4589, Train Acc=0.7893 ||| Val Loss=0.4551, Val Acc=0.7999\n",
      "Epoch 56: Train Loss=0.4528, Train Acc=0.7883 ||| Val Loss=0.4441, Val Acc=0.7987\n",
      "Epoch 57: Train Loss=0.4487, Train Acc=0.7890 ||| Val Loss=0.4589, Val Acc=0.7936\n",
      "Epoch 58: Train Loss=0.4513, Train Acc=0.7895 ||| Val Loss=0.4532, Val Acc=0.7970\n",
      "Epoch 59: Train Loss=0.4464, Train Acc=0.7903 ||| Val Loss=0.4542, Val Acc=0.7999\n",
      "Epoch 60: Train Loss=0.4501, Train Acc=0.7879 ||| Val Loss=0.4497, Val Acc=0.7999\n",
      "Epoch 61: Train Loss=0.4471, Train Acc=0.7921 ||| Val Loss=0.4495, Val Acc=0.7970\n",
      "Epoch 62: Train Loss=0.4507, Train Acc=0.7895 ||| Val Loss=0.4491, Val Acc=0.7953\n",
      "Epoch 63: Train Loss=0.4499, Train Acc=0.7889 ||| Val Loss=0.4473, Val Acc=0.7947\n",
      "Epoch 64: Train Loss=0.4461, Train Acc=0.7880 ||| Val Loss=0.4484, Val Acc=0.7947\n",
      "Epoch 65: Train Loss=0.4474, Train Acc=0.7911 ||| Val Loss=0.4523, Val Acc=0.7936\n",
      "Epoch 66: Train Loss=0.4491, Train Acc=0.7908 ||| Val Loss=0.4556, Val Acc=0.7976\n",
      "Epoch 67: Train Loss=0.4467, Train Acc=0.7895 ||| Val Loss=0.4477, Val Acc=0.7947\n",
      "Epoch 68: Train Loss=0.4411, Train Acc=0.7942 ||| Val Loss=0.4594, Val Acc=0.7970\n",
      "Epoch 69: Train Loss=0.4447, Train Acc=0.7872 ||| Val Loss=0.4464, Val Acc=0.7947\n",
      "Epoch 70: Train Loss=0.4404, Train Acc=0.7926 ||| Val Loss=0.4451, Val Acc=0.7930\n",
      "Epoch 71: Train Loss=0.4483, Train Acc=0.7877 ||| Val Loss=0.4438, Val Acc=0.7941\n",
      "Epoch 72: Train Loss=0.4415, Train Acc=0.7888 ||| Val Loss=0.4458, Val Acc=0.7941\n",
      "Epoch 73: Train Loss=0.4412, Train Acc=0.7885 ||| Val Loss=0.4518, Val Acc=0.7941\n",
      "Epoch 74: Train Loss=0.4441, Train Acc=0.7908 ||| Val Loss=0.4357, Val Acc=0.7959\n",
      "Epoch 75: Train Loss=0.4410, Train Acc=0.7926 ||| Val Loss=0.4337, Val Acc=0.7982\n",
      "Epoch 76: Train Loss=0.4398, Train Acc=0.7913 ||| Val Loss=0.4313, Val Acc=0.7959\n",
      "Epoch 77: Train Loss=0.4405, Train Acc=0.7857 ||| Val Loss=0.4345, Val Acc=0.7976\n",
      "Epoch 78: Train Loss=0.4401, Train Acc=0.7896 ||| Val Loss=0.4343, Val Acc=0.7959\n",
      "Epoch 79: Train Loss=0.4366, Train Acc=0.7900 ||| Val Loss=0.4375, Val Acc=0.7964\n",
      "Epoch 80: Train Loss=0.4408, Train Acc=0.7872 ||| Val Loss=0.4388, Val Acc=0.7936\n",
      "Epoch 81: Train Loss=0.4352, Train Acc=0.7929 ||| Val Loss=0.4441, Val Acc=0.7936\n",
      "Epoch 82: Train Loss=0.4358, Train Acc=0.7931 ||| Val Loss=0.4383, Val Acc=0.7930\n",
      "Epoch 83: Train Loss=0.4367, Train Acc=0.7922 ||| Val Loss=0.4426, Val Acc=0.7947\n",
      "Epoch 84: Train Loss=0.4393, Train Acc=0.7906 ||| Val Loss=0.4388, Val Acc=0.7959\n",
      "Epoch 85: Train Loss=0.4352, Train Acc=0.7925 ||| Val Loss=0.4424, Val Acc=0.7890\n",
      "Epoch 86: Train Loss=0.4371, Train Acc=0.7889 ||| Val Loss=0.4313, Val Acc=0.7918\n",
      "Epoch 87: Train Loss=0.4316, Train Acc=0.7911 ||| Val Loss=0.4363, Val Acc=0.7901\n",
      "Epoch 88: Train Loss=0.4392, Train Acc=0.7922 ||| Val Loss=0.4413, Val Acc=0.7918\n",
      "Epoch 89: Train Loss=0.4379, Train Acc=0.7922 ||| Val Loss=0.4435, Val Acc=0.7959\n",
      "Epoch 90: Train Loss=0.4388, Train Acc=0.7926 ||| Val Loss=0.4401, Val Acc=0.7936\n",
      "Epoch 91: Train Loss=0.4322, Train Acc=0.7939 ||| Val Loss=0.4377, Val Acc=0.7901\n",
      "Epoch 92: Train Loss=0.4311, Train Acc=0.7922 ||| Val Loss=0.4396, Val Acc=0.7930\n",
      "Epoch 93: Train Loss=0.4330, Train Acc=0.7931 ||| Val Loss=0.4444, Val Acc=0.7947\n",
      "Epoch 94: Train Loss=0.4358, Train Acc=0.7919 ||| Val Loss=0.4426, Val Acc=0.7907\n",
      "Epoch 95: Train Loss=0.4359, Train Acc=0.7928 ||| Val Loss=0.4393, Val Acc=0.7941\n",
      "Epoch 96: Train Loss=0.4315, Train Acc=0.7954 ||| Val Loss=0.4334, Val Acc=0.7924\n",
      "Epoch 97: Train Loss=0.4327, Train Acc=0.7906 ||| Val Loss=0.4390, Val Acc=0.7936\n",
      "Epoch 98: Train Loss=0.4335, Train Acc=0.7929 ||| Val Loss=0.4448, Val Acc=0.7924\n",
      "Epoch 99: Train Loss=0.4328, Train Acc=0.7945 ||| Val Loss=0.4356, Val Acc=0.7936\n",
      "Epoch 100: Train Loss=0.4317, Train Acc=0.7939 ||| Val Loss=0.4339, Val Acc=0.7918\n",
      "Epoch 101: Train Loss=0.4317, Train Acc=0.7952 ||| Val Loss=0.4358, Val Acc=0.7884\n",
      "Epoch 102: Train Loss=0.4294, Train Acc=0.7938 ||| Val Loss=0.4354, Val Acc=0.7959\n",
      "Epoch 103: Train Loss=0.4277, Train Acc=0.7923 ||| Val Loss=0.4441, Val Acc=0.7913\n",
      "Epoch 104: Train Loss=0.4309, Train Acc=0.7935 ||| Val Loss=0.4372, Val Acc=0.7936\n",
      "Epoch 105: Train Loss=0.4259, Train Acc=0.7962 ||| Val Loss=0.4342, Val Acc=0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:03:54,729] Trial 8 finished with value: 0.7912593444508338 and parameters: {'n_blocks': 6, 'd_block': 512, 'k': 4, 'dropout': 0.4125798645567976, 'activation': 'ReLU', 'lr': 0.0004273952160210739, 'weight_decay': 1.5715345641888542e-05}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: Train Loss=0.4286, Train Acc=0.7926 ||| Val Loss=0.4359, Val Acc=0.7913\n",
      "Early stopping triggered at epoch 106\n",
      "Validation Accuracy: 0.7913\n",
      "\n",
      " Trial 10 with params: {'n_blocks': 5, 'd_block': 128, 'k': 8, 'dropout': 0.43195593796688025, 'activation': 'LeakyReLU', 'lr': 0.0005265073582125093, 'weight_decay': 0.0023648770046333254}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.4864, Train Acc=0.5279 ||| Val Loss=0.6573, Val Acc=0.6348\n",
      "Epoch 2: Train Loss=0.8060, Train Acc=0.5372 ||| Val Loss=0.6597, Val Acc=0.6141\n",
      "Epoch 3: Train Loss=0.7084, Train Acc=0.5768 ||| Val Loss=0.6494, Val Acc=0.6274\n",
      "Epoch 4: Train Loss=0.6658, Train Acc=0.6066 ||| Val Loss=0.6252, Val Acc=0.6734\n",
      "Epoch 5: Train Loss=0.6348, Train Acc=0.6389 ||| Val Loss=0.5967, Val Acc=0.7062\n",
      "Epoch 6: Train Loss=0.6000, Train Acc=0.6780 ||| Val Loss=0.5686, Val Acc=0.7228\n",
      "Epoch 7: Train Loss=0.5796, Train Acc=0.7033 ||| Val Loss=0.5542, Val Acc=0.7320\n",
      "Epoch 8: Train Loss=0.5643, Train Acc=0.7233 ||| Val Loss=0.5407, Val Acc=0.7562\n",
      "Epoch 9: Train Loss=0.5556, Train Acc=0.7249 ||| Val Loss=0.5309, Val Acc=0.7792\n",
      "Epoch 10: Train Loss=0.5468, Train Acc=0.7400 ||| Val Loss=0.5265, Val Acc=0.7752\n",
      "Epoch 11: Train Loss=0.5450, Train Acc=0.7458 ||| Val Loss=0.5224, Val Acc=0.7786\n",
      "Epoch 12: Train Loss=0.5399, Train Acc=0.7505 ||| Val Loss=0.5187, Val Acc=0.7792\n",
      "Epoch 13: Train Loss=0.5317, Train Acc=0.7610 ||| Val Loss=0.5181, Val Acc=0.7752\n",
      "Epoch 14: Train Loss=0.5322, Train Acc=0.7596 ||| Val Loss=0.5139, Val Acc=0.7826\n",
      "Epoch 15: Train Loss=0.5252, Train Acc=0.7673 ||| Val Loss=0.5122, Val Acc=0.7821\n",
      "Epoch 16: Train Loss=0.5240, Train Acc=0.7636 ||| Val Loss=0.5096, Val Acc=0.7809\n",
      "Epoch 17: Train Loss=0.5219, Train Acc=0.7676 ||| Val Loss=0.5076, Val Acc=0.7867\n",
      "Epoch 18: Train Loss=0.5202, Train Acc=0.7702 ||| Val Loss=0.5066, Val Acc=0.7878\n",
      "Epoch 19: Train Loss=0.5207, Train Acc=0.7703 ||| Val Loss=0.5057, Val Acc=0.7890\n",
      "Epoch 20: Train Loss=0.5207, Train Acc=0.7752 ||| Val Loss=0.5065, Val Acc=0.7878\n",
      "Epoch 21: Train Loss=0.5187, Train Acc=0.7715 ||| Val Loss=0.5076, Val Acc=0.7815\n",
      "Epoch 22: Train Loss=0.5170, Train Acc=0.7696 ||| Val Loss=0.5054, Val Acc=0.7890\n",
      "Epoch 23: Train Loss=0.5225, Train Acc=0.7734 ||| Val Loss=0.5078, Val Acc=0.7844\n",
      "Epoch 24: Train Loss=0.5224, Train Acc=0.7732 ||| Val Loss=0.5067, Val Acc=0.7890\n",
      "Epoch 25: Train Loss=0.5225, Train Acc=0.7729 ||| Val Loss=0.5098, Val Acc=0.7832\n",
      "Epoch 26: Train Loss=0.5224, Train Acc=0.7767 ||| Val Loss=0.5077, Val Acc=0.7849\n",
      "Epoch 27: Train Loss=0.5242, Train Acc=0.7734 ||| Val Loss=0.5066, Val Acc=0.7878\n",
      "Epoch 28: Train Loss=0.5241, Train Acc=0.7724 ||| Val Loss=0.5061, Val Acc=0.7890\n",
      "Epoch 29: Train Loss=0.5207, Train Acc=0.7735 ||| Val Loss=0.5074, Val Acc=0.7849\n",
      "Epoch 30: Train Loss=0.5293, Train Acc=0.7749 ||| Val Loss=0.5076, Val Acc=0.7872\n",
      "Epoch 31: Train Loss=0.5214, Train Acc=0.7747 ||| Val Loss=0.5049, Val Acc=0.7844\n",
      "Epoch 32: Train Loss=0.5250, Train Acc=0.7738 ||| Val Loss=0.5069, Val Acc=0.7855\n",
      "Epoch 33: Train Loss=0.5207, Train Acc=0.7767 ||| Val Loss=0.5067, Val Acc=0.7849\n",
      "Epoch 34: Train Loss=0.5230, Train Acc=0.7745 ||| Val Loss=0.5076, Val Acc=0.7849\n",
      "Epoch 35: Train Loss=0.5184, Train Acc=0.7748 ||| Val Loss=0.5060, Val Acc=0.7872\n",
      "Epoch 36: Train Loss=0.5236, Train Acc=0.7714 ||| Val Loss=0.5061, Val Acc=0.7878\n",
      "Epoch 37: Train Loss=0.5232, Train Acc=0.7708 ||| Val Loss=0.5054, Val Acc=0.7849\n",
      "Epoch 38: Train Loss=0.5226, Train Acc=0.7747 ||| Val Loss=0.5051, Val Acc=0.7890\n",
      "Epoch 39: Train Loss=0.5206, Train Acc=0.7757 ||| Val Loss=0.5052, Val Acc=0.7855\n",
      "Epoch 40: Train Loss=0.5239, Train Acc=0.7754 ||| Val Loss=0.5053, Val Acc=0.7855\n",
      "Epoch 41: Train Loss=0.5229, Train Acc=0.7764 ||| Val Loss=0.5055, Val Acc=0.7872\n",
      "Epoch 42: Train Loss=0.5258, Train Acc=0.7760 ||| Val Loss=0.5053, Val Acc=0.7907\n",
      "Epoch 43: Train Loss=0.5244, Train Acc=0.7726 ||| Val Loss=0.5057, Val Acc=0.7867\n",
      "Epoch 44: Train Loss=0.5218, Train Acc=0.7739 ||| Val Loss=0.5057, Val Acc=0.7855\n",
      "Epoch 45: Train Loss=0.5231, Train Acc=0.7721 ||| Val Loss=0.5047, Val Acc=0.7890\n",
      "Epoch 46: Train Loss=0.5292, Train Acc=0.7719 ||| Val Loss=0.5065, Val Acc=0.7867\n",
      "Epoch 47: Train Loss=0.5226, Train Acc=0.7755 ||| Val Loss=0.5039, Val Acc=0.7878\n",
      "Epoch 48: Train Loss=0.5199, Train Acc=0.7731 ||| Val Loss=0.5026, Val Acc=0.7861\n",
      "Epoch 49: Train Loss=0.5182, Train Acc=0.7764 ||| Val Loss=0.5036, Val Acc=0.7890\n",
      "Epoch 50: Train Loss=0.5202, Train Acc=0.7749 ||| Val Loss=0.5033, Val Acc=0.7844\n",
      "Epoch 51: Train Loss=0.5246, Train Acc=0.7744 ||| Val Loss=0.5047, Val Acc=0.7884\n",
      "Epoch 52: Train Loss=0.5247, Train Acc=0.7757 ||| Val Loss=0.5046, Val Acc=0.7895\n",
      "Epoch 53: Train Loss=0.5231, Train Acc=0.7755 ||| Val Loss=0.5037, Val Acc=0.7867\n",
      "Epoch 54: Train Loss=0.5229, Train Acc=0.7752 ||| Val Loss=0.5039, Val Acc=0.7884\n",
      "Epoch 55: Train Loss=0.5232, Train Acc=0.7765 ||| Val Loss=0.5048, Val Acc=0.7861\n",
      "Epoch 56: Train Loss=0.5191, Train Acc=0.7785 ||| Val Loss=0.5031, Val Acc=0.7907\n",
      "Epoch 57: Train Loss=0.5212, Train Acc=0.7796 ||| Val Loss=0.5037, Val Acc=0.7884\n",
      "Epoch 58: Train Loss=0.5199, Train Acc=0.7778 ||| Val Loss=0.5037, Val Acc=0.7878\n",
      "Epoch 59: Train Loss=0.5272, Train Acc=0.7780 ||| Val Loss=0.5056, Val Acc=0.7844\n",
      "Epoch 60: Train Loss=0.5247, Train Acc=0.7770 ||| Val Loss=0.5036, Val Acc=0.7872\n",
      "Epoch 61: Train Loss=0.5242, Train Acc=0.7735 ||| Val Loss=0.5027, Val Acc=0.7890\n",
      "Epoch 62: Train Loss=0.5203, Train Acc=0.7783 ||| Val Loss=0.5017, Val Acc=0.7890\n",
      "Epoch 63: Train Loss=0.5225, Train Acc=0.7794 ||| Val Loss=0.5025, Val Acc=0.7890\n",
      "Epoch 64: Train Loss=0.5210, Train Acc=0.7768 ||| Val Loss=0.5014, Val Acc=0.7890\n",
      "Epoch 65: Train Loss=0.5202, Train Acc=0.7790 ||| Val Loss=0.5032, Val Acc=0.7884\n",
      "Epoch 66: Train Loss=0.5222, Train Acc=0.7771 ||| Val Loss=0.5032, Val Acc=0.7907\n",
      "Epoch 67: Train Loss=0.5221, Train Acc=0.7777 ||| Val Loss=0.5010, Val Acc=0.7895\n",
      "Epoch 68: Train Loss=0.5240, Train Acc=0.7787 ||| Val Loss=0.5020, Val Acc=0.7941\n",
      "Epoch 69: Train Loss=0.5181, Train Acc=0.7796 ||| Val Loss=0.5022, Val Acc=0.7895\n",
      "Epoch 70: Train Loss=0.5229, Train Acc=0.7754 ||| Val Loss=0.5021, Val Acc=0.7918\n",
      "Epoch 71: Train Loss=0.5176, Train Acc=0.7807 ||| Val Loss=0.5006, Val Acc=0.7907\n",
      "Epoch 72: Train Loss=0.5160, Train Acc=0.7827 ||| Val Loss=0.5008, Val Acc=0.7901\n",
      "Epoch 73: Train Loss=0.5212, Train Acc=0.7774 ||| Val Loss=0.5010, Val Acc=0.7930\n",
      "Epoch 74: Train Loss=0.5236, Train Acc=0.7811 ||| Val Loss=0.5019, Val Acc=0.7890\n",
      "Epoch 75: Train Loss=0.5194, Train Acc=0.7764 ||| Val Loss=0.4984, Val Acc=0.7918\n",
      "Epoch 76: Train Loss=0.5148, Train Acc=0.7804 ||| Val Loss=0.4981, Val Acc=0.7936\n",
      "Epoch 77: Train Loss=0.5194, Train Acc=0.7811 ||| Val Loss=0.4989, Val Acc=0.7918\n",
      "Epoch 78: Train Loss=0.5150, Train Acc=0.7804 ||| Val Loss=0.4966, Val Acc=0.7918\n",
      "Epoch 79: Train Loss=0.5145, Train Acc=0.7836 ||| Val Loss=0.4970, Val Acc=0.7918\n",
      "Epoch 80: Train Loss=0.5134, Train Acc=0.7813 ||| Val Loss=0.4976, Val Acc=0.7930\n",
      "Epoch 81: Train Loss=0.5179, Train Acc=0.7810 ||| Val Loss=0.4956, Val Acc=0.7924\n",
      "Epoch 82: Train Loss=0.5141, Train Acc=0.7811 ||| Val Loss=0.4959, Val Acc=0.7907\n",
      "Epoch 83: Train Loss=0.5173, Train Acc=0.7829 ||| Val Loss=0.4964, Val Acc=0.7913\n",
      "Epoch 84: Train Loss=0.5205, Train Acc=0.7804 ||| Val Loss=0.4972, Val Acc=0.7924\n",
      "Epoch 85: Train Loss=0.5122, Train Acc=0.7819 ||| Val Loss=0.4960, Val Acc=0.7918\n",
      "Epoch 86: Train Loss=0.5180, Train Acc=0.7807 ||| Val Loss=0.4977, Val Acc=0.7907\n",
      "Epoch 87: Train Loss=0.5153, Train Acc=0.7806 ||| Val Loss=0.4970, Val Acc=0.7901\n",
      "Epoch 88: Train Loss=0.5164, Train Acc=0.7810 ||| Val Loss=0.4956, Val Acc=0.7901\n",
      "Epoch 89: Train Loss=0.5223, Train Acc=0.7793 ||| Val Loss=0.4969, Val Acc=0.7918\n",
      "Epoch 90: Train Loss=0.5136, Train Acc=0.7817 ||| Val Loss=0.4957, Val Acc=0.7924\n",
      "Epoch 91: Train Loss=0.5184, Train Acc=0.7793 ||| Val Loss=0.4970, Val Acc=0.7913\n",
      "Epoch 92: Train Loss=0.5139, Train Acc=0.7836 ||| Val Loss=0.4957, Val Acc=0.7930\n",
      "Epoch 93: Train Loss=0.5144, Train Acc=0.7811 ||| Val Loss=0.4933, Val Acc=0.7918\n",
      "Epoch 94: Train Loss=0.5139, Train Acc=0.7806 ||| Val Loss=0.4941, Val Acc=0.7918\n",
      "Epoch 95: Train Loss=0.5136, Train Acc=0.7813 ||| Val Loss=0.4932, Val Acc=0.7918\n",
      "Epoch 96: Train Loss=0.5143, Train Acc=0.7804 ||| Val Loss=0.4928, Val Acc=0.7924\n",
      "Epoch 97: Train Loss=0.5087, Train Acc=0.7846 ||| Val Loss=0.4922, Val Acc=0.7930\n",
      "Epoch 98: Train Loss=0.5135, Train Acc=0.7824 ||| Val Loss=0.4928, Val Acc=0.7924\n",
      "Epoch 99: Train Loss=0.5175, Train Acc=0.7790 ||| Val Loss=0.4941, Val Acc=0.7941\n",
      "Epoch 100: Train Loss=0.5171, Train Acc=0.7810 ||| Val Loss=0.4921, Val Acc=0.7936\n",
      "Epoch 101: Train Loss=0.5171, Train Acc=0.7811 ||| Val Loss=0.4944, Val Acc=0.7924\n",
      "Epoch 102: Train Loss=0.5109, Train Acc=0.7856 ||| Val Loss=0.4925, Val Acc=0.7936\n",
      "Epoch 103: Train Loss=0.5163, Train Acc=0.7801 ||| Val Loss=0.4923, Val Acc=0.7936\n",
      "Epoch 104: Train Loss=0.5134, Train Acc=0.7817 ||| Val Loss=0.4917, Val Acc=0.7907\n",
      "Epoch 105: Train Loss=0.5155, Train Acc=0.7819 ||| Val Loss=0.4906, Val Acc=0.7930\n",
      "Epoch 106: Train Loss=0.5080, Train Acc=0.7856 ||| Val Loss=0.4899, Val Acc=0.7930\n",
      "Epoch 107: Train Loss=0.5128, Train Acc=0.7831 ||| Val Loss=0.4892, Val Acc=0.7924\n",
      "Epoch 108: Train Loss=0.5126, Train Acc=0.7819 ||| Val Loss=0.4927, Val Acc=0.7901\n",
      "Epoch 109: Train Loss=0.5123, Train Acc=0.7823 ||| Val Loss=0.4912, Val Acc=0.7924\n",
      "Epoch 110: Train Loss=0.5156, Train Acc=0.7823 ||| Val Loss=0.4913, Val Acc=0.7924\n",
      "Epoch 111: Train Loss=0.5103, Train Acc=0.7807 ||| Val Loss=0.4910, Val Acc=0.7930\n",
      "Epoch 112: Train Loss=0.5107, Train Acc=0.7798 ||| Val Loss=0.4894, Val Acc=0.7936\n",
      "Epoch 113: Train Loss=0.5162, Train Acc=0.7824 ||| Val Loss=0.4904, Val Acc=0.7936\n",
      "Epoch 114: Train Loss=0.5123, Train Acc=0.7824 ||| Val Loss=0.4919, Val Acc=0.7913\n",
      "Epoch 115: Train Loss=0.5111, Train Acc=0.7826 ||| Val Loss=0.4888, Val Acc=0.7930\n",
      "Epoch 116: Train Loss=0.5079, Train Acc=0.7831 ||| Val Loss=0.4902, Val Acc=0.7936\n",
      "Epoch 117: Train Loss=0.5075, Train Acc=0.7829 ||| Val Loss=0.4868, Val Acc=0.7941\n",
      "Epoch 118: Train Loss=0.5119, Train Acc=0.7846 ||| Val Loss=0.4876, Val Acc=0.7936\n",
      "Epoch 119: Train Loss=0.5109, Train Acc=0.7849 ||| Val Loss=0.4891, Val Acc=0.7936\n",
      "Epoch 120: Train Loss=0.5089, Train Acc=0.7844 ||| Val Loss=0.4884, Val Acc=0.7930\n",
      "Epoch 121: Train Loss=0.5116, Train Acc=0.7857 ||| Val Loss=0.4877, Val Acc=0.7936\n",
      "Epoch 122: Train Loss=0.5131, Train Acc=0.7847 ||| Val Loss=0.4868, Val Acc=0.7930\n",
      "Epoch 123: Train Loss=0.5151, Train Acc=0.7847 ||| Val Loss=0.4883, Val Acc=0.7924\n",
      "Epoch 124: Train Loss=0.5118, Train Acc=0.7819 ||| Val Loss=0.4866, Val Acc=0.7947\n",
      "Epoch 125: Train Loss=0.5136, Train Acc=0.7806 ||| Val Loss=0.4917, Val Acc=0.7941\n",
      "Epoch 126: Train Loss=0.5105, Train Acc=0.7842 ||| Val Loss=0.4890, Val Acc=0.7947\n",
      "Epoch 127: Train Loss=0.5151, Train Acc=0.7821 ||| Val Loss=0.4899, Val Acc=0.7924\n",
      "Epoch 128: Train Loss=0.5130, Train Acc=0.7844 ||| Val Loss=0.4887, Val Acc=0.7947\n",
      "Epoch 129: Train Loss=0.5110, Train Acc=0.7831 ||| Val Loss=0.4870, Val Acc=0.7930\n",
      "Epoch 130: Train Loss=0.5089, Train Acc=0.7827 ||| Val Loss=0.4871, Val Acc=0.7947\n",
      "Epoch 131: Train Loss=0.5120, Train Acc=0.7813 ||| Val Loss=0.4866, Val Acc=0.7930\n",
      "Epoch 132: Train Loss=0.5094, Train Acc=0.7849 ||| Val Loss=0.4857, Val Acc=0.7941\n",
      "Epoch 133: Train Loss=0.5087, Train Acc=0.7866 ||| Val Loss=0.4887, Val Acc=0.7913\n",
      "Epoch 134: Train Loss=0.5148, Train Acc=0.7831 ||| Val Loss=0.4908, Val Acc=0.7947\n",
      "Epoch 135: Train Loss=0.5130, Train Acc=0.7829 ||| Val Loss=0.4891, Val Acc=0.7936\n",
      "Epoch 136: Train Loss=0.5110, Train Acc=0.7831 ||| Val Loss=0.4880, Val Acc=0.7924\n",
      "Epoch 137: Train Loss=0.5092, Train Acc=0.7830 ||| Val Loss=0.4873, Val Acc=0.7936\n",
      "Epoch 138: Train Loss=0.5088, Train Acc=0.7808 ||| Val Loss=0.4893, Val Acc=0.7936\n",
      "Epoch 139: Train Loss=0.5109, Train Acc=0.7854 ||| Val Loss=0.4863, Val Acc=0.7936\n",
      "Epoch 140: Train Loss=0.5104, Train Acc=0.7840 ||| Val Loss=0.4859, Val Acc=0.7930\n",
      "Epoch 141: Train Loss=0.5111, Train Acc=0.7844 ||| Val Loss=0.4895, Val Acc=0.7930\n",
      "Epoch 142: Train Loss=0.5089, Train Acc=0.7849 ||| Val Loss=0.4877, Val Acc=0.7936\n",
      "Epoch 143: Train Loss=0.5068, Train Acc=0.7840 ||| Val Loss=0.4880, Val Acc=0.7941\n",
      "Epoch 144: Train Loss=0.5107, Train Acc=0.7827 ||| Val Loss=0.4864, Val Acc=0.7953\n",
      "Epoch 145: Train Loss=0.5120, Train Acc=0.7830 ||| Val Loss=0.4872, Val Acc=0.7930\n",
      "Epoch 146: Train Loss=0.5139, Train Acc=0.7842 ||| Val Loss=0.4872, Val Acc=0.7936\n",
      "Epoch 147: Train Loss=0.5122, Train Acc=0.7869 ||| Val Loss=0.4886, Val Acc=0.7936\n",
      "Epoch 148: Train Loss=0.5135, Train Acc=0.7870 ||| Val Loss=0.4862, Val Acc=0.7936\n",
      "Epoch 149: Train Loss=0.5145, Train Acc=0.7830 ||| Val Loss=0.4871, Val Acc=0.7941\n",
      "Epoch 150: Train Loss=0.5099, Train Acc=0.7834 ||| Val Loss=0.4876, Val Acc=0.7936\n",
      "Epoch 151: Train Loss=0.5078, Train Acc=0.7854 ||| Val Loss=0.4855, Val Acc=0.7936\n",
      "Epoch 152: Train Loss=0.5113, Train Acc=0.7829 ||| Val Loss=0.4881, Val Acc=0.7930\n",
      "Epoch 153: Train Loss=0.5133, Train Acc=0.7837 ||| Val Loss=0.4873, Val Acc=0.7936\n",
      "Epoch 154: Train Loss=0.5117, Train Acc=0.7843 ||| Val Loss=0.4873, Val Acc=0.7936\n",
      "Epoch 155: Train Loss=0.5064, Train Acc=0.7857 ||| Val Loss=0.4870, Val Acc=0.7936\n",
      "Epoch 156: Train Loss=0.5107, Train Acc=0.7843 ||| Val Loss=0.4850, Val Acc=0.7936\n",
      "Epoch 157: Train Loss=0.5112, Train Acc=0.7839 ||| Val Loss=0.4855, Val Acc=0.7941\n",
      "Epoch 158: Train Loss=0.5070, Train Acc=0.7836 ||| Val Loss=0.4853, Val Acc=0.7947\n",
      "Epoch 159: Train Loss=0.5062, Train Acc=0.7860 ||| Val Loss=0.4859, Val Acc=0.7941\n",
      "Epoch 160: Train Loss=0.5128, Train Acc=0.7850 ||| Val Loss=0.4874, Val Acc=0.7947\n",
      "Epoch 161: Train Loss=0.5070, Train Acc=0.7872 ||| Val Loss=0.4866, Val Acc=0.7947\n",
      "Epoch 162: Train Loss=0.5095, Train Acc=0.7814 ||| Val Loss=0.4867, Val Acc=0.7936\n",
      "Epoch 163: Train Loss=0.5139, Train Acc=0.7824 ||| Val Loss=0.4856, Val Acc=0.7941\n",
      "Epoch 164: Train Loss=0.5131, Train Acc=0.7836 ||| Val Loss=0.4870, Val Acc=0.7947\n",
      "Epoch 165: Train Loss=0.5063, Train Acc=0.7847 ||| Val Loss=0.4853, Val Acc=0.7947\n",
      "Epoch 166: Train Loss=0.5138, Train Acc=0.7833 ||| Val Loss=0.4857, Val Acc=0.7936\n",
      "Epoch 167: Train Loss=0.5158, Train Acc=0.7854 ||| Val Loss=0.4878, Val Acc=0.7947\n",
      "Epoch 168: Train Loss=0.5137, Train Acc=0.7843 ||| Val Loss=0.4872, Val Acc=0.7936\n",
      "Epoch 169: Train Loss=0.5115, Train Acc=0.7846 ||| Val Loss=0.4857, Val Acc=0.7930\n",
      "Epoch 170: Train Loss=0.5100, Train Acc=0.7817 ||| Val Loss=0.4872, Val Acc=0.7930\n",
      "Epoch 171: Train Loss=0.5111, Train Acc=0.7813 ||| Val Loss=0.4864, Val Acc=0.7930\n",
      "Epoch 172: Train Loss=0.5098, Train Acc=0.7837 ||| Val Loss=0.4873, Val Acc=0.7936\n",
      "Epoch 173: Train Loss=0.5102, Train Acc=0.7849 ||| Val Loss=0.4865, Val Acc=0.7936\n",
      "Epoch 174: Train Loss=0.5139, Train Acc=0.7844 ||| Val Loss=0.4852, Val Acc=0.7941\n",
      "Epoch 175: Train Loss=0.5083, Train Acc=0.7856 ||| Val Loss=0.4867, Val Acc=0.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:04:53,326] Trial 9 finished with value: 0.7935595169637722 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 8, 'dropout': 0.43195593796688025, 'activation': 'LeakyReLU', 'lr': 0.0005265073582125093, 'weight_decay': 0.0023648770046333254}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: Train Loss=0.5149, Train Acc=0.7859 ||| Val Loss=0.4865, Val Acc=0.7936\n",
      "Early stopping triggered at epoch 176\n",
      "Validation Accuracy: 0.7936\n",
      "\n",
      " Trial 11 with params: {'n_blocks': 2, 'd_block': 256, 'k': 11, 'dropout': 0.3089038693370183, 'activation': 'ReLU', 'lr': 0.005148146117543533, 'weight_decay': 0.008945115186488151}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=6.2094, Train Acc=0.6644 ||| Val Loss=0.5815, Val Acc=0.7257\n",
      "Epoch 2: Train Loss=0.5617, Train Acc=0.7249 ||| Val Loss=0.5157, Val Acc=0.7832\n",
      "Epoch 3: Train Loss=0.5451, Train Acc=0.7407 ||| Val Loss=0.5177, Val Acc=0.7838\n",
      "Epoch 4: Train Loss=0.5336, Train Acc=0.7552 ||| Val Loss=0.5121, Val Acc=0.7890\n",
      "Epoch 5: Train Loss=0.5229, Train Acc=0.7632 ||| Val Loss=0.5101, Val Acc=0.7723\n",
      "Epoch 6: Train Loss=0.5209, Train Acc=0.7659 ||| Val Loss=0.5092, Val Acc=0.7821\n",
      "Epoch 7: Train Loss=0.5227, Train Acc=0.7699 ||| Val Loss=0.5120, Val Acc=0.7890\n",
      "Epoch 8: Train Loss=0.5175, Train Acc=0.7777 ||| Val Loss=0.5101, Val Acc=0.7941\n",
      "Epoch 9: Train Loss=0.5157, Train Acc=0.7735 ||| Val Loss=0.5053, Val Acc=0.7861\n",
      "Epoch 10: Train Loss=0.5183, Train Acc=0.7780 ||| Val Loss=0.5053, Val Acc=0.7895\n",
      "Epoch 11: Train Loss=0.5198, Train Acc=0.7774 ||| Val Loss=0.5033, Val Acc=0.7867\n",
      "Epoch 12: Train Loss=0.5216, Train Acc=0.7762 ||| Val Loss=0.5061, Val Acc=0.7844\n",
      "Epoch 13: Train Loss=0.5203, Train Acc=0.7784 ||| Val Loss=0.5069, Val Acc=0.7844\n",
      "Epoch 14: Train Loss=0.5234, Train Acc=0.7781 ||| Val Loss=0.5069, Val Acc=0.7901\n",
      "Epoch 15: Train Loss=0.5261, Train Acc=0.7765 ||| Val Loss=0.5130, Val Acc=0.7809\n",
      "Epoch 16: Train Loss=0.5207, Train Acc=0.7811 ||| Val Loss=0.5051, Val Acc=0.7855\n",
      "Epoch 17: Train Loss=0.5249, Train Acc=0.7734 ||| Val Loss=0.5059, Val Acc=0.7838\n",
      "Epoch 18: Train Loss=0.5237, Train Acc=0.7780 ||| Val Loss=0.5071, Val Acc=0.7849\n",
      "Epoch 19: Train Loss=0.5213, Train Acc=0.7760 ||| Val Loss=0.5067, Val Acc=0.7884\n",
      "Epoch 20: Train Loss=0.5258, Train Acc=0.7758 ||| Val Loss=0.5100, Val Acc=0.7803\n",
      "Epoch 21: Train Loss=0.5226, Train Acc=0.7760 ||| Val Loss=0.5097, Val Acc=0.7803\n",
      "Epoch 22: Train Loss=0.5274, Train Acc=0.7718 ||| Val Loss=0.5086, Val Acc=0.7826\n",
      "Epoch 23: Train Loss=0.5252, Train Acc=0.7737 ||| Val Loss=0.5136, Val Acc=0.7884\n",
      "Epoch 24: Train Loss=0.5229, Train Acc=0.7747 ||| Val Loss=0.5237, Val Acc=0.7637\n",
      "Epoch 25: Train Loss=0.5232, Train Acc=0.7742 ||| Val Loss=0.5111, Val Acc=0.7832\n",
      "Epoch 26: Train Loss=0.5280, Train Acc=0.7732 ||| Val Loss=0.5146, Val Acc=0.7895\n",
      "Epoch 27: Train Loss=0.5301, Train Acc=0.7749 ||| Val Loss=0.5105, Val Acc=0.7838\n",
      "Epoch 28: Train Loss=0.5233, Train Acc=0.7767 ||| Val Loss=0.5097, Val Acc=0.7838\n",
      "Epoch 29: Train Loss=0.5251, Train Acc=0.7767 ||| Val Loss=0.5041, Val Acc=0.7832\n",
      "Epoch 30: Train Loss=0.5278, Train Acc=0.7737 ||| Val Loss=0.5091, Val Acc=0.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:05:01,931] Trial 10 finished with value: 0.78205865439908 and parameters: {'n_blocks': 2, 'd_block': 256, 'k': 11, 'dropout': 0.3089038693370183, 'activation': 'ReLU', 'lr': 0.005148146117543533, 'weight_decay': 0.008945115186488151}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=0.5265, Train Acc=0.7765 ||| Val Loss=0.5038, Val Acc=0.7821\n",
      "Early stopping triggered at epoch 31\n",
      "Validation Accuracy: 0.7821\n",
      "\n",
      " Trial 12 with params: {'n_blocks': 2, 'd_block': 128, 'k': 9, 'dropout': 0.33743869567188, 'activation': 'ReLU', 'lr': 0.0001107506909386638, 'weight_decay': 9.955168400040347e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=12.0710, Train Acc=0.5722 ||| Val Loss=3.0306, Val Acc=0.7136\n",
      "Epoch 2: Train Loss=8.4917, Train Acc=0.6107 ||| Val Loss=1.5742, Val Acc=0.7867\n",
      "Epoch 3: Train Loss=6.4579, Train Acc=0.6455 ||| Val Loss=1.7486, Val Acc=0.7723\n",
      "Epoch 4: Train Loss=5.2123, Train Acc=0.6474 ||| Val Loss=1.4477, Val Acc=0.7734\n",
      "Epoch 5: Train Loss=4.1804, Train Acc=0.6595 ||| Val Loss=1.2687, Val Acc=0.6970\n",
      "Epoch 6: Train Loss=3.5824, Train Acc=0.6644 ||| Val Loss=1.2326, Val Acc=0.6475\n",
      "Epoch 7: Train Loss=2.9638, Train Acc=0.6537 ||| Val Loss=0.9033, Val Acc=0.7637\n",
      "Epoch 8: Train Loss=2.4821, Train Acc=0.6599 ||| Val Loss=0.7684, Val Acc=0.7642\n",
      "Epoch 9: Train Loss=2.1771, Train Acc=0.6688 ||| Val Loss=0.6695, Val Acc=0.7671\n",
      "Epoch 10: Train Loss=1.8491, Train Acc=0.6662 ||| Val Loss=0.6316, Val Acc=0.7516\n",
      "Epoch 11: Train Loss=1.6308, Train Acc=0.6661 ||| Val Loss=0.5828, Val Acc=0.7654\n",
      "Epoch 12: Train Loss=1.4574, Train Acc=0.6707 ||| Val Loss=0.5781, Val Acc=0.7355\n",
      "Epoch 13: Train Loss=1.2695, Train Acc=0.6647 ||| Val Loss=0.5890, Val Acc=0.7125\n",
      "Epoch 14: Train Loss=1.2095, Train Acc=0.6612 ||| Val Loss=0.5854, Val Acc=0.7102\n",
      "Epoch 15: Train Loss=1.0641, Train Acc=0.6662 ||| Val Loss=0.5731, Val Acc=0.7257\n",
      "Epoch 16: Train Loss=1.0132, Train Acc=0.6704 ||| Val Loss=0.5717, Val Acc=0.7315\n",
      "Epoch 17: Train Loss=0.9438, Train Acc=0.6675 ||| Val Loss=0.5693, Val Acc=0.7407\n",
      "Epoch 18: Train Loss=0.8720, Train Acc=0.6723 ||| Val Loss=0.5706, Val Acc=0.7453\n",
      "Epoch 19: Train Loss=0.8210, Train Acc=0.6743 ||| Val Loss=0.5757, Val Acc=0.7401\n",
      "Epoch 20: Train Loss=0.7638, Train Acc=0.6777 ||| Val Loss=0.5799, Val Acc=0.7441\n",
      "Epoch 21: Train Loss=0.7432, Train Acc=0.6743 ||| Val Loss=0.5828, Val Acc=0.7487\n",
      "Epoch 22: Train Loss=0.7303, Train Acc=0.6754 ||| Val Loss=0.5838, Val Acc=0.7435\n",
      "Epoch 23: Train Loss=0.7009, Train Acc=0.6838 ||| Val Loss=0.5795, Val Acc=0.7637\n",
      "Epoch 24: Train Loss=0.6806, Train Acc=0.6841 ||| Val Loss=0.5789, Val Acc=0.7522\n",
      "Epoch 25: Train Loss=0.6712, Train Acc=0.6976 ||| Val Loss=0.5736, Val Acc=0.7527\n",
      "Epoch 26: Train Loss=0.6452, Train Acc=0.6918 ||| Val Loss=0.5673, Val Acc=0.7694\n",
      "Epoch 27: Train Loss=0.6476, Train Acc=0.7002 ||| Val Loss=0.5702, Val Acc=0.7637\n",
      "Epoch 28: Train Loss=0.6409, Train Acc=0.6921 ||| Val Loss=0.5661, Val Acc=0.7625\n",
      "Epoch 29: Train Loss=0.6180, Train Acc=0.7058 ||| Val Loss=0.5613, Val Acc=0.7706\n",
      "Epoch 30: Train Loss=0.6150, Train Acc=0.7091 ||| Val Loss=0.5601, Val Acc=0.7711\n",
      "Epoch 31: Train Loss=0.6166, Train Acc=0.7065 ||| Val Loss=0.5625, Val Acc=0.7522\n",
      "Epoch 32: Train Loss=0.6017, Train Acc=0.7156 ||| Val Loss=0.5600, Val Acc=0.7487\n",
      "Epoch 33: Train Loss=0.5859, Train Acc=0.7216 ||| Val Loss=0.5538, Val Acc=0.7504\n",
      "Epoch 34: Train Loss=0.5827, Train Acc=0.7204 ||| Val Loss=0.5511, Val Acc=0.7642\n",
      "Epoch 35: Train Loss=0.5733, Train Acc=0.7210 ||| Val Loss=0.5561, Val Acc=0.7481\n",
      "Epoch 36: Train Loss=0.5820, Train Acc=0.7209 ||| Val Loss=0.5463, Val Acc=0.7522\n",
      "Epoch 37: Train Loss=0.5686, Train Acc=0.7338 ||| Val Loss=0.5447, Val Acc=0.7550\n",
      "Epoch 38: Train Loss=0.5648, Train Acc=0.7322 ||| Val Loss=0.5405, Val Acc=0.7579\n",
      "Epoch 39: Train Loss=0.5616, Train Acc=0.7301 ||| Val Loss=0.5413, Val Acc=0.7573\n",
      "Epoch 40: Train Loss=0.5644, Train Acc=0.7351 ||| Val Loss=0.5423, Val Acc=0.7591\n",
      "Epoch 41: Train Loss=0.5645, Train Acc=0.7338 ||| Val Loss=0.5369, Val Acc=0.7654\n",
      "Epoch 42: Train Loss=0.5528, Train Acc=0.7370 ||| Val Loss=0.5338, Val Acc=0.7694\n",
      "Epoch 43: Train Loss=0.5524, Train Acc=0.7367 ||| Val Loss=0.5309, Val Acc=0.7734\n",
      "Epoch 44: Train Loss=0.5526, Train Acc=0.7417 ||| Val Loss=0.5314, Val Acc=0.7752\n",
      "Epoch 45: Train Loss=0.5522, Train Acc=0.7420 ||| Val Loss=0.5262, Val Acc=0.7746\n",
      "Epoch 46: Train Loss=0.5495, Train Acc=0.7504 ||| Val Loss=0.5283, Val Acc=0.7740\n",
      "Epoch 47: Train Loss=0.5428, Train Acc=0.7491 ||| Val Loss=0.5253, Val Acc=0.7798\n",
      "Epoch 48: Train Loss=0.5446, Train Acc=0.7499 ||| Val Loss=0.5242, Val Acc=0.7746\n",
      "Epoch 49: Train Loss=0.5377, Train Acc=0.7565 ||| Val Loss=0.5233, Val Acc=0.7769\n",
      "Epoch 50: Train Loss=0.5429, Train Acc=0.7495 ||| Val Loss=0.5249, Val Acc=0.7815\n",
      "Epoch 51: Train Loss=0.5383, Train Acc=0.7528 ||| Val Loss=0.5189, Val Acc=0.7821\n",
      "Epoch 52: Train Loss=0.5412, Train Acc=0.7531 ||| Val Loss=0.5234, Val Acc=0.7769\n",
      "Epoch 53: Train Loss=0.5358, Train Acc=0.7578 ||| Val Loss=0.5193, Val Acc=0.7815\n",
      "Epoch 54: Train Loss=0.5311, Train Acc=0.7624 ||| Val Loss=0.5137, Val Acc=0.7832\n",
      "Epoch 55: Train Loss=0.5298, Train Acc=0.7594 ||| Val Loss=0.5144, Val Acc=0.7838\n",
      "Epoch 56: Train Loss=0.5296, Train Acc=0.7629 ||| Val Loss=0.5156, Val Acc=0.7769\n",
      "Epoch 57: Train Loss=0.5275, Train Acc=0.7600 ||| Val Loss=0.5137, Val Acc=0.7809\n",
      "Epoch 58: Train Loss=0.5226, Train Acc=0.7636 ||| Val Loss=0.5076, Val Acc=0.7849\n",
      "Epoch 59: Train Loss=0.5205, Train Acc=0.7709 ||| Val Loss=0.5128, Val Acc=0.7815\n",
      "Epoch 60: Train Loss=0.5195, Train Acc=0.7655 ||| Val Loss=0.5086, Val Acc=0.7821\n",
      "Epoch 61: Train Loss=0.5206, Train Acc=0.7682 ||| Val Loss=0.5074, Val Acc=0.7821\n",
      "Epoch 62: Train Loss=0.5173, Train Acc=0.7728 ||| Val Loss=0.5063, Val Acc=0.7826\n",
      "Epoch 63: Train Loss=0.5182, Train Acc=0.7734 ||| Val Loss=0.5042, Val Acc=0.7844\n",
      "Epoch 64: Train Loss=0.5118, Train Acc=0.7716 ||| Val Loss=0.5054, Val Acc=0.7844\n",
      "Epoch 65: Train Loss=0.5088, Train Acc=0.7731 ||| Val Loss=0.5021, Val Acc=0.7844\n",
      "Epoch 66: Train Loss=0.5118, Train Acc=0.7715 ||| Val Loss=0.5027, Val Acc=0.7855\n",
      "Epoch 67: Train Loss=0.5116, Train Acc=0.7712 ||| Val Loss=0.5046, Val Acc=0.7844\n",
      "Epoch 68: Train Loss=0.5090, Train Acc=0.7758 ||| Val Loss=0.5052, Val Acc=0.7861\n",
      "Epoch 69: Train Loss=0.5052, Train Acc=0.7761 ||| Val Loss=0.4999, Val Acc=0.7849\n",
      "Epoch 70: Train Loss=0.5071, Train Acc=0.7777 ||| Val Loss=0.4987, Val Acc=0.7861\n",
      "Epoch 71: Train Loss=0.5018, Train Acc=0.7762 ||| Val Loss=0.4992, Val Acc=0.7861\n",
      "Epoch 72: Train Loss=0.5065, Train Acc=0.7764 ||| Val Loss=0.4998, Val Acc=0.7867\n",
      "Epoch 73: Train Loss=0.5034, Train Acc=0.7783 ||| Val Loss=0.4988, Val Acc=0.7838\n",
      "Epoch 74: Train Loss=0.5073, Train Acc=0.7773 ||| Val Loss=0.5013, Val Acc=0.7844\n",
      "Epoch 75: Train Loss=0.5004, Train Acc=0.7777 ||| Val Loss=0.4968, Val Acc=0.7855\n",
      "Epoch 76: Train Loss=0.5056, Train Acc=0.7749 ||| Val Loss=0.4968, Val Acc=0.7821\n",
      "Epoch 77: Train Loss=0.4949, Train Acc=0.7798 ||| Val Loss=0.4940, Val Acc=0.7855\n",
      "Epoch 78: Train Loss=0.4996, Train Acc=0.7827 ||| Val Loss=0.4983, Val Acc=0.7849\n",
      "Epoch 79: Train Loss=0.4970, Train Acc=0.7790 ||| Val Loss=0.4984, Val Acc=0.7844\n",
      "Epoch 80: Train Loss=0.4992, Train Acc=0.7808 ||| Val Loss=0.4938, Val Acc=0.7861\n",
      "Epoch 81: Train Loss=0.4970, Train Acc=0.7816 ||| Val Loss=0.4926, Val Acc=0.7861\n",
      "Epoch 82: Train Loss=0.4915, Train Acc=0.7788 ||| Val Loss=0.4912, Val Acc=0.7838\n",
      "Epoch 83: Train Loss=0.4986, Train Acc=0.7781 ||| Val Loss=0.4936, Val Acc=0.7855\n",
      "Epoch 84: Train Loss=0.4939, Train Acc=0.7814 ||| Val Loss=0.4938, Val Acc=0.7861\n",
      "Epoch 85: Train Loss=0.4944, Train Acc=0.7816 ||| Val Loss=0.4932, Val Acc=0.7849\n",
      "Epoch 86: Train Loss=0.4951, Train Acc=0.7810 ||| Val Loss=0.4924, Val Acc=0.7867\n",
      "Epoch 87: Train Loss=0.4914, Train Acc=0.7811 ||| Val Loss=0.4892, Val Acc=0.7861\n",
      "Epoch 88: Train Loss=0.4924, Train Acc=0.7807 ||| Val Loss=0.4901, Val Acc=0.7849\n",
      "Epoch 89: Train Loss=0.4920, Train Acc=0.7814 ||| Val Loss=0.4906, Val Acc=0.7832\n",
      "Epoch 90: Train Loss=0.4907, Train Acc=0.7817 ||| Val Loss=0.4857, Val Acc=0.7861\n",
      "Epoch 91: Train Loss=0.4883, Train Acc=0.7811 ||| Val Loss=0.4850, Val Acc=0.7872\n",
      "Epoch 92: Train Loss=0.4907, Train Acc=0.7803 ||| Val Loss=0.4831, Val Acc=0.7861\n",
      "Epoch 93: Train Loss=0.4896, Train Acc=0.7824 ||| Val Loss=0.4844, Val Acc=0.7861\n",
      "Epoch 94: Train Loss=0.4886, Train Acc=0.7824 ||| Val Loss=0.4826, Val Acc=0.7867\n",
      "Epoch 95: Train Loss=0.4895, Train Acc=0.7830 ||| Val Loss=0.4814, Val Acc=0.7878\n",
      "Epoch 96: Train Loss=0.4865, Train Acc=0.7813 ||| Val Loss=0.4793, Val Acc=0.7884\n",
      "Epoch 97: Train Loss=0.4868, Train Acc=0.7830 ||| Val Loss=0.4848, Val Acc=0.7849\n",
      "Epoch 98: Train Loss=0.4812, Train Acc=0.7831 ||| Val Loss=0.4803, Val Acc=0.7838\n",
      "Epoch 99: Train Loss=0.4835, Train Acc=0.7806 ||| Val Loss=0.4789, Val Acc=0.7849\n",
      "Epoch 100: Train Loss=0.4839, Train Acc=0.7839 ||| Val Loss=0.4820, Val Acc=0.7832\n",
      "Epoch 101: Train Loss=0.4861, Train Acc=0.7839 ||| Val Loss=0.4799, Val Acc=0.7838\n",
      "Epoch 102: Train Loss=0.4810, Train Acc=0.7827 ||| Val Loss=0.4746, Val Acc=0.7844\n",
      "Epoch 103: Train Loss=0.4801, Train Acc=0.7840 ||| Val Loss=0.4796, Val Acc=0.7849\n",
      "Epoch 104: Train Loss=0.4770, Train Acc=0.7853 ||| Val Loss=0.4778, Val Acc=0.7838\n",
      "Epoch 105: Train Loss=0.4814, Train Acc=0.7862 ||| Val Loss=0.4801, Val Acc=0.7832\n",
      "Epoch 106: Train Loss=0.4791, Train Acc=0.7842 ||| Val Loss=0.4800, Val Acc=0.7844\n",
      "Epoch 107: Train Loss=0.4798, Train Acc=0.7820 ||| Val Loss=0.4769, Val Acc=0.7844\n",
      "Epoch 108: Train Loss=0.4758, Train Acc=0.7862 ||| Val Loss=0.4774, Val Acc=0.7838\n",
      "Epoch 109: Train Loss=0.4779, Train Acc=0.7839 ||| Val Loss=0.4755, Val Acc=0.7855\n",
      "Epoch 110: Train Loss=0.4762, Train Acc=0.7829 ||| Val Loss=0.4710, Val Acc=0.7867\n",
      "Epoch 111: Train Loss=0.4768, Train Acc=0.7821 ||| Val Loss=0.4719, Val Acc=0.7849\n",
      "Epoch 112: Train Loss=0.4744, Train Acc=0.7836 ||| Val Loss=0.4763, Val Acc=0.7826\n",
      "Epoch 113: Train Loss=0.4719, Train Acc=0.7826 ||| Val Loss=0.4765, Val Acc=0.7821\n",
      "Epoch 114: Train Loss=0.4726, Train Acc=0.7869 ||| Val Loss=0.4717, Val Acc=0.7838\n",
      "Epoch 115: Train Loss=0.4741, Train Acc=0.7842 ||| Val Loss=0.4729, Val Acc=0.7838\n",
      "Epoch 116: Train Loss=0.4715, Train Acc=0.7862 ||| Val Loss=0.4721, Val Acc=0.7826\n",
      "Epoch 117: Train Loss=0.4704, Train Acc=0.7879 ||| Val Loss=0.4730, Val Acc=0.7832\n",
      "Epoch 118: Train Loss=0.4685, Train Acc=0.7847 ||| Val Loss=0.4703, Val Acc=0.7826\n",
      "Epoch 119: Train Loss=0.4700, Train Acc=0.7856 ||| Val Loss=0.4702, Val Acc=0.7849\n",
      "Epoch 120: Train Loss=0.4721, Train Acc=0.7853 ||| Val Loss=0.4719, Val Acc=0.7844\n",
      "Epoch 121: Train Loss=0.4688, Train Acc=0.7876 ||| Val Loss=0.4722, Val Acc=0.7838\n",
      "Epoch 122: Train Loss=0.4709, Train Acc=0.7849 ||| Val Loss=0.4723, Val Acc=0.7826\n",
      "Epoch 123: Train Loss=0.4690, Train Acc=0.7863 ||| Val Loss=0.4735, Val Acc=0.7832\n",
      "Epoch 124: Train Loss=0.4665, Train Acc=0.7863 ||| Val Loss=0.4736, Val Acc=0.7821\n",
      "Epoch 125: Train Loss=0.4682, Train Acc=0.7854 ||| Val Loss=0.4715, Val Acc=0.7826\n",
      "Epoch 126: Train Loss=0.4654, Train Acc=0.7859 ||| Val Loss=0.4695, Val Acc=0.7849\n",
      "Epoch 127: Train Loss=0.4663, Train Acc=0.7843 ||| Val Loss=0.4686, Val Acc=0.7849\n",
      "Epoch 128: Train Loss=0.4664, Train Acc=0.7854 ||| Val Loss=0.4715, Val Acc=0.7803\n",
      "Epoch 129: Train Loss=0.4611, Train Acc=0.7869 ||| Val Loss=0.4688, Val Acc=0.7821\n",
      "Epoch 130: Train Loss=0.4644, Train Acc=0.7840 ||| Val Loss=0.4698, Val Acc=0.7844\n",
      "Epoch 131: Train Loss=0.4623, Train Acc=0.7872 ||| Val Loss=0.4692, Val Acc=0.7844\n",
      "Epoch 132: Train Loss=0.4686, Train Acc=0.7870 ||| Val Loss=0.4699, Val Acc=0.7826\n",
      "Epoch 133: Train Loss=0.4656, Train Acc=0.7846 ||| Val Loss=0.4727, Val Acc=0.7780\n",
      "Epoch 134: Train Loss=0.4646, Train Acc=0.7859 ||| Val Loss=0.4688, Val Acc=0.7826\n",
      "Epoch 135: Train Loss=0.4622, Train Acc=0.7867 ||| Val Loss=0.4686, Val Acc=0.7832\n",
      "Epoch 136: Train Loss=0.4614, Train Acc=0.7873 ||| Val Loss=0.4662, Val Acc=0.7855\n",
      "Epoch 137: Train Loss=0.4630, Train Acc=0.7867 ||| Val Loss=0.4662, Val Acc=0.7821\n",
      "Epoch 138: Train Loss=0.4630, Train Acc=0.7889 ||| Val Loss=0.4695, Val Acc=0.7832\n",
      "Epoch 139: Train Loss=0.4595, Train Acc=0.7840 ||| Val Loss=0.4688, Val Acc=0.7815\n",
      "Epoch 140: Train Loss=0.4635, Train Acc=0.7863 ||| Val Loss=0.4674, Val Acc=0.7809\n",
      "Epoch 141: Train Loss=0.4606, Train Acc=0.7873 ||| Val Loss=0.4626, Val Acc=0.7855\n",
      "Epoch 142: Train Loss=0.4593, Train Acc=0.7866 ||| Val Loss=0.4710, Val Acc=0.7821\n",
      "Epoch 143: Train Loss=0.4580, Train Acc=0.7867 ||| Val Loss=0.4636, Val Acc=0.7832\n",
      "Epoch 144: Train Loss=0.4585, Train Acc=0.7877 ||| Val Loss=0.4670, Val Acc=0.7838\n",
      "Epoch 145: Train Loss=0.4632, Train Acc=0.7883 ||| Val Loss=0.4673, Val Acc=0.7815\n",
      "Epoch 146: Train Loss=0.4581, Train Acc=0.7892 ||| Val Loss=0.4689, Val Acc=0.7832\n",
      "Epoch 147: Train Loss=0.4610, Train Acc=0.7863 ||| Val Loss=0.4674, Val Acc=0.7861\n",
      "Epoch 148: Train Loss=0.4595, Train Acc=0.7885 ||| Val Loss=0.4675, Val Acc=0.7821\n",
      "Epoch 149: Train Loss=0.4582, Train Acc=0.7869 ||| Val Loss=0.4646, Val Acc=0.7872\n",
      "Epoch 150: Train Loss=0.4549, Train Acc=0.7882 ||| Val Loss=0.4651, Val Acc=0.7867\n",
      "Epoch 151: Train Loss=0.4571, Train Acc=0.7875 ||| Val Loss=0.4691, Val Acc=0.7832\n",
      "Epoch 152: Train Loss=0.4578, Train Acc=0.7876 ||| Val Loss=0.4674, Val Acc=0.7867\n",
      "Epoch 153: Train Loss=0.4581, Train Acc=0.7865 ||| Val Loss=0.4712, Val Acc=0.7844\n",
      "Epoch 154: Train Loss=0.4525, Train Acc=0.7886 ||| Val Loss=0.4650, Val Acc=0.7878\n",
      "Epoch 155: Train Loss=0.4567, Train Acc=0.7843 ||| Val Loss=0.4662, Val Acc=0.7878\n",
      "Epoch 156: Train Loss=0.4592, Train Acc=0.7875 ||| Val Loss=0.4648, Val Acc=0.7878\n",
      "Epoch 157: Train Loss=0.4516, Train Acc=0.7879 ||| Val Loss=0.4617, Val Acc=0.7878\n",
      "Epoch 158: Train Loss=0.4561, Train Acc=0.7875 ||| Val Loss=0.4675, Val Acc=0.7878\n",
      "Epoch 159: Train Loss=0.4559, Train Acc=0.7892 ||| Val Loss=0.4656, Val Acc=0.7872\n",
      "Epoch 160: Train Loss=0.4580, Train Acc=0.7873 ||| Val Loss=0.4648, Val Acc=0.7872\n",
      "Epoch 161: Train Loss=0.4539, Train Acc=0.7883 ||| Val Loss=0.4645, Val Acc=0.7878\n",
      "Epoch 162: Train Loss=0.4508, Train Acc=0.7872 ||| Val Loss=0.4668, Val Acc=0.7844\n",
      "Epoch 163: Train Loss=0.4564, Train Acc=0.7862 ||| Val Loss=0.4697, Val Acc=0.7821\n",
      "Epoch 164: Train Loss=0.4544, Train Acc=0.7892 ||| Val Loss=0.4671, Val Acc=0.7844\n",
      "Epoch 165: Train Loss=0.4529, Train Acc=0.7865 ||| Val Loss=0.4669, Val Acc=0.7832\n",
      "Epoch 166: Train Loss=0.4534, Train Acc=0.7876 ||| Val Loss=0.4688, Val Acc=0.7844\n",
      "Epoch 167: Train Loss=0.4552, Train Acc=0.7865 ||| Val Loss=0.4657, Val Acc=0.7844\n",
      "Epoch 168: Train Loss=0.4522, Train Acc=0.7880 ||| Val Loss=0.4636, Val Acc=0.7849\n",
      "Epoch 169: Train Loss=0.4529, Train Acc=0.7876 ||| Val Loss=0.4699, Val Acc=0.7821\n",
      "Epoch 170: Train Loss=0.4554, Train Acc=0.7837 ||| Val Loss=0.4703, Val Acc=0.7815\n",
      "Epoch 171: Train Loss=0.4528, Train Acc=0.7867 ||| Val Loss=0.4633, Val Acc=0.7867\n",
      "Epoch 172: Train Loss=0.4535, Train Acc=0.7892 ||| Val Loss=0.4702, Val Acc=0.7826\n",
      "Epoch 173: Train Loss=0.4515, Train Acc=0.7886 ||| Val Loss=0.4728, Val Acc=0.7809\n",
      "Epoch 174: Train Loss=0.4546, Train Acc=0.7865 ||| Val Loss=0.4674, Val Acc=0.7803\n",
      "Epoch 175: Train Loss=0.4523, Train Acc=0.7879 ||| Val Loss=0.4687, Val Acc=0.7792\n",
      "Epoch 176: Train Loss=0.4546, Train Acc=0.7892 ||| Val Loss=0.4667, Val Acc=0.7849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:05:36,796] Trial 11 finished with value: 0.7843588269120184 and parameters: {'n_blocks': 2, 'd_block': 128, 'k': 9, 'dropout': 0.33743869567188, 'activation': 'ReLU', 'lr': 0.0001107506909386638, 'weight_decay': 9.955168400040347e-05}. Best is trial 0 with value: 0.7975848188614146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: Train Loss=0.4518, Train Acc=0.7913 ||| Val Loss=0.4657, Val Acc=0.7844\n",
      "Early stopping triggered at epoch 177\n",
      "Validation Accuracy: 0.7844\n",
      "\n",
      " Trial 13 with params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.2475771551049411, 'activation': 'ReLU', 'lr': 0.0027183970293804946, 'weight_decay': 5.486607463330976e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7485, Train Acc=0.6567 ||| Val Loss=0.5513, Val Acc=0.7527\n",
      "Epoch 2: Train Loss=0.5391, Train Acc=0.7560 ||| Val Loss=0.4994, Val Acc=0.7861\n",
      "Epoch 3: Train Loss=0.5210, Train Acc=0.7761 ||| Val Loss=0.4917, Val Acc=0.7872\n",
      "Epoch 4: Train Loss=0.5181, Train Acc=0.7731 ||| Val Loss=0.4835, Val Acc=0.7953\n",
      "Epoch 5: Train Loss=0.5018, Train Acc=0.7840 ||| Val Loss=0.4802, Val Acc=0.7941\n",
      "Epoch 6: Train Loss=0.4906, Train Acc=0.7872 ||| Val Loss=0.4817, Val Acc=0.7936\n",
      "Epoch 7: Train Loss=0.4891, Train Acc=0.7817 ||| Val Loss=0.4698, Val Acc=0.7953\n",
      "Epoch 8: Train Loss=0.4796, Train Acc=0.7806 ||| Val Loss=0.4741, Val Acc=0.7964\n",
      "Epoch 9: Train Loss=0.4718, Train Acc=0.7913 ||| Val Loss=0.4755, Val Acc=0.7964\n",
      "Epoch 10: Train Loss=0.4643, Train Acc=0.7919 ||| Val Loss=0.4390, Val Acc=0.7918\n",
      "Epoch 11: Train Loss=0.4608, Train Acc=0.7915 ||| Val Loss=0.4429, Val Acc=0.7959\n",
      "Epoch 12: Train Loss=0.4500, Train Acc=0.7915 ||| Val Loss=0.4362, Val Acc=0.7907\n",
      "Epoch 13: Train Loss=0.4452, Train Acc=0.7885 ||| Val Loss=0.4296, Val Acc=0.7930\n",
      "Epoch 14: Train Loss=0.4386, Train Acc=0.7908 ||| Val Loss=0.4257, Val Acc=0.7959\n",
      "Epoch 15: Train Loss=0.4359, Train Acc=0.7925 ||| Val Loss=0.4325, Val Acc=0.7953\n",
      "Epoch 16: Train Loss=0.4324, Train Acc=0.7921 ||| Val Loss=0.4228, Val Acc=0.7976\n",
      "Epoch 17: Train Loss=0.4340, Train Acc=0.7928 ||| Val Loss=0.4297, Val Acc=0.7947\n",
      "Epoch 18: Train Loss=0.4275, Train Acc=0.7951 ||| Val Loss=0.4241, Val Acc=0.7959\n",
      "Epoch 19: Train Loss=0.4289, Train Acc=0.7936 ||| Val Loss=0.4166, Val Acc=0.7964\n",
      "Epoch 20: Train Loss=0.4265, Train Acc=0.7958 ||| Val Loss=0.4213, Val Acc=0.7970\n",
      "Epoch 21: Train Loss=0.4295, Train Acc=0.7938 ||| Val Loss=0.4190, Val Acc=0.7982\n",
      "Epoch 22: Train Loss=0.4307, Train Acc=0.7921 ||| Val Loss=0.4209, Val Acc=0.7930\n",
      "Epoch 23: Train Loss=0.4217, Train Acc=0.7947 ||| Val Loss=0.4185, Val Acc=0.7953\n",
      "Epoch 24: Train Loss=0.4257, Train Acc=0.7972 ||| Val Loss=0.4212, Val Acc=0.7953\n",
      "Epoch 25: Train Loss=0.4214, Train Acc=0.7972 ||| Val Loss=0.4219, Val Acc=0.7964\n",
      "Epoch 26: Train Loss=0.4257, Train Acc=0.7961 ||| Val Loss=0.4275, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4226, Train Acc=0.7965 ||| Val Loss=0.4296, Val Acc=0.7924\n",
      "Epoch 28: Train Loss=0.4200, Train Acc=0.8004 ||| Val Loss=0.4147, Val Acc=0.7953\n",
      "Epoch 29: Train Loss=0.4192, Train Acc=0.7981 ||| Val Loss=0.4145, Val Acc=0.7953\n",
      "Epoch 30: Train Loss=0.4196, Train Acc=0.7975 ||| Val Loss=0.4168, Val Acc=0.7913\n",
      "Epoch 31: Train Loss=0.4207, Train Acc=0.7965 ||| Val Loss=0.4124, Val Acc=0.7964\n",
      "Epoch 32: Train Loss=0.4195, Train Acc=0.8010 ||| Val Loss=0.4166, Val Acc=0.7993\n",
      "Epoch 33: Train Loss=0.4171, Train Acc=0.7981 ||| Val Loss=0.4303, Val Acc=0.7924\n",
      "Epoch 34: Train Loss=0.4178, Train Acc=0.7974 ||| Val Loss=0.4178, Val Acc=0.7953\n",
      "Epoch 35: Train Loss=0.4181, Train Acc=0.7998 ||| Val Loss=0.4162, Val Acc=0.7924\n",
      "Epoch 36: Train Loss=0.4188, Train Acc=0.7981 ||| Val Loss=0.4136, Val Acc=0.7936\n",
      "Epoch 37: Train Loss=0.4150, Train Acc=0.7982 ||| Val Loss=0.4138, Val Acc=0.7924\n",
      "Epoch 38: Train Loss=0.4150, Train Acc=0.7962 ||| Val Loss=0.4097, Val Acc=0.7982\n",
      "Epoch 39: Train Loss=0.4135, Train Acc=0.8050 ||| Val Loss=0.4132, Val Acc=0.7930\n",
      "Epoch 40: Train Loss=0.4147, Train Acc=0.8021 ||| Val Loss=0.4154, Val Acc=0.7947\n",
      "Epoch 41: Train Loss=0.4144, Train Acc=0.8028 ||| Val Loss=0.4175, Val Acc=0.7970\n",
      "Epoch 42: Train Loss=0.4154, Train Acc=0.7974 ||| Val Loss=0.4130, Val Acc=0.7982\n",
      "Epoch 43: Train Loss=0.4167, Train Acc=0.7971 ||| Val Loss=0.4170, Val Acc=0.8005\n",
      "Epoch 44: Train Loss=0.4150, Train Acc=0.7972 ||| Val Loss=0.4115, Val Acc=0.7999\n",
      "Epoch 45: Train Loss=0.4144, Train Acc=0.8021 ||| Val Loss=0.4118, Val Acc=0.8005\n",
      "Epoch 46: Train Loss=0.4119, Train Acc=0.8034 ||| Val Loss=0.4155, Val Acc=0.8016\n",
      "Epoch 47: Train Loss=0.4168, Train Acc=0.7993 ||| Val Loss=0.4216, Val Acc=0.7924\n",
      "Epoch 48: Train Loss=0.4149, Train Acc=0.8013 ||| Val Loss=0.4087, Val Acc=0.7964\n",
      "Epoch 49: Train Loss=0.4106, Train Acc=0.8013 ||| Val Loss=0.4107, Val Acc=0.8016\n",
      "Epoch 50: Train Loss=0.4153, Train Acc=0.8008 ||| Val Loss=0.4113, Val Acc=0.7987\n",
      "Epoch 51: Train Loss=0.4147, Train Acc=0.7994 ||| Val Loss=0.4113, Val Acc=0.7959\n",
      "Epoch 52: Train Loss=0.4135, Train Acc=0.7994 ||| Val Loss=0.4180, Val Acc=0.7890\n",
      "Epoch 53: Train Loss=0.4144, Train Acc=0.8004 ||| Val Loss=0.4098, Val Acc=0.7947\n",
      "Epoch 54: Train Loss=0.4108, Train Acc=0.8046 ||| Val Loss=0.4089, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4086, Train Acc=0.8031 ||| Val Loss=0.4055, Val Acc=0.8028\n",
      "Epoch 56: Train Loss=0.4093, Train Acc=0.8023 ||| Val Loss=0.4096, Val Acc=0.8028\n",
      "Epoch 57: Train Loss=0.4096, Train Acc=0.8018 ||| Val Loss=0.4090, Val Acc=0.8010\n",
      "Epoch 58: Train Loss=0.4080, Train Acc=0.8027 ||| Val Loss=0.4086, Val Acc=0.7993\n",
      "Epoch 59: Train Loss=0.4114, Train Acc=0.8049 ||| Val Loss=0.4103, Val Acc=0.7982\n",
      "Epoch 60: Train Loss=0.4076, Train Acc=0.8005 ||| Val Loss=0.4084, Val Acc=0.7959\n",
      "Epoch 61: Train Loss=0.4061, Train Acc=0.8037 ||| Val Loss=0.4015, Val Acc=0.8022\n",
      "Epoch 62: Train Loss=0.4064, Train Acc=0.8033 ||| Val Loss=0.4066, Val Acc=0.7970\n",
      "Epoch 63: Train Loss=0.4077, Train Acc=0.8004 ||| Val Loss=0.4036, Val Acc=0.7959\n",
      "Epoch 64: Train Loss=0.4098, Train Acc=0.8007 ||| Val Loss=0.4103, Val Acc=0.8033\n",
      "Epoch 65: Train Loss=0.4100, Train Acc=0.8082 ||| Val Loss=0.4059, Val Acc=0.8022\n",
      "Epoch 66: Train Loss=0.4048, Train Acc=0.8046 ||| Val Loss=0.4065, Val Acc=0.8051\n",
      "Epoch 67: Train Loss=0.4066, Train Acc=0.8050 ||| Val Loss=0.4101, Val Acc=0.7964\n",
      "Epoch 68: Train Loss=0.4093, Train Acc=0.8013 ||| Val Loss=0.4126, Val Acc=0.8033\n",
      "Epoch 69: Train Loss=0.4051, Train Acc=0.8041 ||| Val Loss=0.4061, Val Acc=0.7947\n",
      "Epoch 70: Train Loss=0.4029, Train Acc=0.8062 ||| Val Loss=0.4091, Val Acc=0.8010\n",
      "Epoch 71: Train Loss=0.4020, Train Acc=0.8062 ||| Val Loss=0.4099, Val Acc=0.8033\n",
      "Epoch 72: Train Loss=0.4006, Train Acc=0.8083 ||| Val Loss=0.4053, Val Acc=0.8016\n",
      "Epoch 73: Train Loss=0.4032, Train Acc=0.8063 ||| Val Loss=0.4020, Val Acc=0.8068\n",
      "Epoch 74: Train Loss=0.4036, Train Acc=0.8097 ||| Val Loss=0.4069, Val Acc=0.7936\n",
      "Epoch 75: Train Loss=0.4017, Train Acc=0.8044 ||| Val Loss=0.4050, Val Acc=0.8039\n",
      "Epoch 76: Train Loss=0.4026, Train Acc=0.8064 ||| Val Loss=0.4085, Val Acc=0.7964\n",
      "Epoch 77: Train Loss=0.4004, Train Acc=0.8057 ||| Val Loss=0.4093, Val Acc=0.7970\n",
      "Epoch 78: Train Loss=0.3992, Train Acc=0.8082 ||| Val Loss=0.4058, Val Acc=0.8068\n",
      "Epoch 79: Train Loss=0.4013, Train Acc=0.8086 ||| Val Loss=0.4112, Val Acc=0.7976\n",
      "Epoch 80: Train Loss=0.3964, Train Acc=0.8087 ||| Val Loss=0.4118, Val Acc=0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:06:06,178] Trial 12 finished with value: 0.7993099482461185 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.2475771551049411, 'activation': 'ReLU', 'lr': 0.0027183970293804946, 'weight_decay': 5.486607463330976e-06}. Best is trial 12 with value: 0.7993099482461185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train Loss=0.3967, Train Acc=0.8082 ||| Val Loss=0.4105, Val Acc=0.7993\n",
      "Early stopping triggered at epoch 81\n",
      "Validation Accuracy: 0.7993\n",
      "\n",
      " Trial 14 with params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.22242292358131166, 'activation': 'ReLU', 'lr': 0.004070611397840372, 'weight_decay': 4.672432428590436e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7370, Train Acc=0.6739 ||| Val Loss=0.5079, Val Acc=0.7924\n",
      "Epoch 2: Train Loss=0.5297, Train Acc=0.7675 ||| Val Loss=0.5092, Val Acc=0.7936\n",
      "Epoch 3: Train Loss=0.5218, Train Acc=0.7761 ||| Val Loss=0.4806, Val Acc=0.7959\n",
      "Epoch 4: Train Loss=0.5052, Train Acc=0.7854 ||| Val Loss=0.4770, Val Acc=0.7913\n",
      "Epoch 5: Train Loss=0.4928, Train Acc=0.7837 ||| Val Loss=0.4915, Val Acc=0.7941\n",
      "Epoch 6: Train Loss=0.4814, Train Acc=0.7817 ||| Val Loss=0.4604, Val Acc=0.8005\n",
      "Epoch 7: Train Loss=0.4686, Train Acc=0.7889 ||| Val Loss=0.4346, Val Acc=0.7987\n",
      "Epoch 8: Train Loss=0.4513, Train Acc=0.7880 ||| Val Loss=0.4355, Val Acc=0.7941\n",
      "Epoch 9: Train Loss=0.4505, Train Acc=0.7890 ||| Val Loss=0.4252, Val Acc=0.7918\n",
      "Epoch 10: Train Loss=0.4415, Train Acc=0.7908 ||| Val Loss=0.4242, Val Acc=0.7953\n",
      "Epoch 11: Train Loss=0.4335, Train Acc=0.7942 ||| Val Loss=0.4241, Val Acc=0.7999\n",
      "Epoch 12: Train Loss=0.4302, Train Acc=0.7915 ||| Val Loss=0.4204, Val Acc=0.7953\n",
      "Epoch 13: Train Loss=0.4295, Train Acc=0.7934 ||| Val Loss=0.4200, Val Acc=0.7982\n",
      "Epoch 14: Train Loss=0.4317, Train Acc=0.7929 ||| Val Loss=0.4343, Val Acc=0.7907\n",
      "Epoch 15: Train Loss=0.4311, Train Acc=0.7945 ||| Val Loss=0.4106, Val Acc=0.7987\n",
      "Epoch 16: Train Loss=0.4278, Train Acc=0.7929 ||| Val Loss=0.4199, Val Acc=0.7895\n",
      "Epoch 17: Train Loss=0.4251, Train Acc=0.7955 ||| Val Loss=0.4122, Val Acc=0.7993\n",
      "Epoch 18: Train Loss=0.4248, Train Acc=0.7967 ||| Val Loss=0.4261, Val Acc=0.7855\n",
      "Epoch 19: Train Loss=0.4278, Train Acc=0.7978 ||| Val Loss=0.4127, Val Acc=0.7982\n",
      "Epoch 20: Train Loss=0.4243, Train Acc=0.7965 ||| Val Loss=0.4175, Val Acc=0.7964\n",
      "Epoch 21: Train Loss=0.4267, Train Acc=0.8010 ||| Val Loss=0.4202, Val Acc=0.8010\n",
      "Epoch 22: Train Loss=0.4232, Train Acc=0.7975 ||| Val Loss=0.4184, Val Acc=0.8005\n",
      "Epoch 23: Train Loss=0.4196, Train Acc=0.8011 ||| Val Loss=0.4124, Val Acc=0.7982\n",
      "Epoch 24: Train Loss=0.4213, Train Acc=0.7988 ||| Val Loss=0.4216, Val Acc=0.7993\n",
      "Epoch 25: Train Loss=0.4231, Train Acc=0.7965 ||| Val Loss=0.4066, Val Acc=0.8016\n",
      "Epoch 26: Train Loss=0.4206, Train Acc=0.7981 ||| Val Loss=0.4178, Val Acc=0.7953\n",
      "Epoch 27: Train Loss=0.4236, Train Acc=0.8010 ||| Val Loss=0.4139, Val Acc=0.7953\n",
      "Epoch 28: Train Loss=0.4208, Train Acc=0.7985 ||| Val Loss=0.4062, Val Acc=0.7959\n",
      "Epoch 29: Train Loss=0.4198, Train Acc=0.7952 ||| Val Loss=0.4044, Val Acc=0.7987\n",
      "Epoch 30: Train Loss=0.4185, Train Acc=0.7984 ||| Val Loss=0.4114, Val Acc=0.7959\n",
      "Epoch 31: Train Loss=0.4169, Train Acc=0.7980 ||| Val Loss=0.4147, Val Acc=0.7941\n",
      "Epoch 32: Train Loss=0.4169, Train Acc=0.8016 ||| Val Loss=0.4105, Val Acc=0.7993\n",
      "Epoch 33: Train Loss=0.4160, Train Acc=0.8034 ||| Val Loss=0.4119, Val Acc=0.7959\n",
      "Epoch 34: Train Loss=0.4120, Train Acc=0.8008 ||| Val Loss=0.4093, Val Acc=0.7999\n",
      "Epoch 35: Train Loss=0.4182, Train Acc=0.8020 ||| Val Loss=0.4046, Val Acc=0.7982\n",
      "Epoch 36: Train Loss=0.4147, Train Acc=0.8018 ||| Val Loss=0.4084, Val Acc=0.8010\n",
      "Epoch 37: Train Loss=0.4168, Train Acc=0.7984 ||| Val Loss=0.4036, Val Acc=0.7993\n",
      "Epoch 38: Train Loss=0.4142, Train Acc=0.8016 ||| Val Loss=0.4086, Val Acc=0.8022\n",
      "Epoch 39: Train Loss=0.4173, Train Acc=0.8039 ||| Val Loss=0.4054, Val Acc=0.7999\n",
      "Epoch 40: Train Loss=0.4096, Train Acc=0.8039 ||| Val Loss=0.4149, Val Acc=0.7982\n",
      "Epoch 41: Train Loss=0.4118, Train Acc=0.8011 ||| Val Loss=0.4044, Val Acc=0.8010\n",
      "Epoch 42: Train Loss=0.4107, Train Acc=0.8037 ||| Val Loss=0.4067, Val Acc=0.8056\n",
      "Epoch 43: Train Loss=0.4084, Train Acc=0.7997 ||| Val Loss=0.4050, Val Acc=0.8120\n",
      "Epoch 44: Train Loss=0.4136, Train Acc=0.7997 ||| Val Loss=0.4121, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4133, Train Acc=0.8003 ||| Val Loss=0.4054, Val Acc=0.8022\n",
      "Epoch 46: Train Loss=0.4054, Train Acc=0.8085 ||| Val Loss=0.4121, Val Acc=0.8022\n",
      "Epoch 47: Train Loss=0.4135, Train Acc=0.8011 ||| Val Loss=0.4110, Val Acc=0.7993\n",
      "Epoch 48: Train Loss=0.4076, Train Acc=0.8047 ||| Val Loss=0.4198, Val Acc=0.8074\n",
      "Epoch 49: Train Loss=0.4088, Train Acc=0.8070 ||| Val Loss=0.4075, Val Acc=0.7999\n",
      "Epoch 50: Train Loss=0.4090, Train Acc=0.8060 ||| Val Loss=0.4128, Val Acc=0.8062\n",
      "Epoch 51: Train Loss=0.4071, Train Acc=0.8097 ||| Val Loss=0.4108, Val Acc=0.7999\n",
      "Epoch 52: Train Loss=0.4054, Train Acc=0.8059 ||| Val Loss=0.4064, Val Acc=0.8039\n",
      "Epoch 53: Train Loss=0.4070, Train Acc=0.8076 ||| Val Loss=0.4064, Val Acc=0.8056\n",
      "Epoch 54: Train Loss=0.4066, Train Acc=0.8077 ||| Val Loss=0.4064, Val Acc=0.8033\n",
      "Epoch 55: Train Loss=0.4073, Train Acc=0.8089 ||| Val Loss=0.4033, Val Acc=0.8068\n",
      "Epoch 56: Train Loss=0.4064, Train Acc=0.8085 ||| Val Loss=0.4096, Val Acc=0.8051\n",
      "Epoch 57: Train Loss=0.4052, Train Acc=0.8112 ||| Val Loss=0.4081, Val Acc=0.8091\n",
      "Epoch 58: Train Loss=0.4047, Train Acc=0.8106 ||| Val Loss=0.4053, Val Acc=0.8085\n",
      "Epoch 59: Train Loss=0.4037, Train Acc=0.8074 ||| Val Loss=0.4127, Val Acc=0.8016\n",
      "Epoch 60: Train Loss=0.4044, Train Acc=0.8099 ||| Val Loss=0.4102, Val Acc=0.7947\n",
      "Epoch 61: Train Loss=0.4037, Train Acc=0.8031 ||| Val Loss=0.4179, Val Acc=0.7970\n",
      "Epoch 62: Train Loss=0.4031, Train Acc=0.8062 ||| Val Loss=0.4070, Val Acc=0.7982\n",
      "Epoch 63: Train Loss=0.4037, Train Acc=0.8080 ||| Val Loss=0.4109, Val Acc=0.7987\n",
      "Epoch 64: Train Loss=0.4011, Train Acc=0.8129 ||| Val Loss=0.4118, Val Acc=0.8005\n",
      "Epoch 65: Train Loss=0.4031, Train Acc=0.8102 ||| Val Loss=0.4093, Val Acc=0.8045\n",
      "Epoch 66: Train Loss=0.4036, Train Acc=0.8095 ||| Val Loss=0.4086, Val Acc=0.8010\n",
      "Epoch 67: Train Loss=0.4021, Train Acc=0.8086 ||| Val Loss=0.4086, Val Acc=0.8010\n",
      "Epoch 68: Train Loss=0.4032, Train Acc=0.8085 ||| Val Loss=0.4118, Val Acc=0.8016\n",
      "Epoch 69: Train Loss=0.4005, Train Acc=0.8062 ||| Val Loss=0.4165, Val Acc=0.7993\n",
      "Epoch 70: Train Loss=0.3951, Train Acc=0.8133 ||| Val Loss=0.4159, Val Acc=0.7999\n",
      "Epoch 71: Train Loss=0.3980, Train Acc=0.8125 ||| Val Loss=0.4146, Val Acc=0.7970\n",
      "Epoch 72: Train Loss=0.3974, Train Acc=0.8116 ||| Val Loss=0.4140, Val Acc=0.7970\n",
      "Epoch 73: Train Loss=0.4032, Train Acc=0.8072 ||| Val Loss=0.4129, Val Acc=0.7959\n",
      "Epoch 74: Train Loss=0.3969, Train Acc=0.8096 ||| Val Loss=0.4083, Val Acc=0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:06:33,358] Trial 13 finished with value: 0.8067855089131685 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.22242292358131166, 'activation': 'ReLU', 'lr': 0.004070611397840372, 'weight_decay': 4.672432428590436e-06}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train Loss=0.3956, Train Acc=0.8053 ||| Val Loss=0.4138, Val Acc=0.8068\n",
      "Early stopping triggered at epoch 75\n",
      "Validation Accuracy: 0.8068\n",
      "\n",
      " Trial 15 with params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.22303030403997218, 'activation': 'ReLU', 'lr': 0.004099862119126689, 'weight_decay': 5.27735244168503e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7099, Train Acc=0.6923 ||| Val Loss=0.5067, Val Acc=0.7901\n",
      "Epoch 2: Train Loss=0.5336, Train Acc=0.7678 ||| Val Loss=0.5072, Val Acc=0.7838\n",
      "Epoch 3: Train Loss=0.5165, Train Acc=0.7790 ||| Val Loss=0.4908, Val Acc=0.7901\n",
      "Epoch 4: Train Loss=0.4989, Train Acc=0.7810 ||| Val Loss=0.4957, Val Acc=0.7809\n",
      "Epoch 5: Train Loss=0.4918, Train Acc=0.7827 ||| Val Loss=0.4654, Val Acc=0.7936\n",
      "Epoch 6: Train Loss=0.4720, Train Acc=0.7877 ||| Val Loss=0.4495, Val Acc=0.8010\n",
      "Epoch 7: Train Loss=0.4699, Train Acc=0.7849 ||| Val Loss=0.4535, Val Acc=0.7878\n",
      "Epoch 8: Train Loss=0.4505, Train Acc=0.7919 ||| Val Loss=0.4523, Val Acc=0.7947\n",
      "Epoch 9: Train Loss=0.4452, Train Acc=0.7911 ||| Val Loss=0.4262, Val Acc=0.7947\n",
      "Epoch 10: Train Loss=0.4379, Train Acc=0.7913 ||| Val Loss=0.4168, Val Acc=0.7953\n",
      "Epoch 11: Train Loss=0.4318, Train Acc=0.7949 ||| Val Loss=0.4251, Val Acc=0.7941\n",
      "Epoch 12: Train Loss=0.4354, Train Acc=0.7908 ||| Val Loss=0.4258, Val Acc=0.7941\n",
      "Epoch 13: Train Loss=0.4285, Train Acc=0.7942 ||| Val Loss=0.4167, Val Acc=0.7959\n",
      "Epoch 14: Train Loss=0.4288, Train Acc=0.7959 ||| Val Loss=0.4238, Val Acc=0.7982\n",
      "Epoch 15: Train Loss=0.4291, Train Acc=0.7959 ||| Val Loss=0.4195, Val Acc=0.7941\n",
      "Epoch 16: Train Loss=0.4261, Train Acc=0.7941 ||| Val Loss=0.4160, Val Acc=0.7953\n",
      "Epoch 17: Train Loss=0.4306, Train Acc=0.7967 ||| Val Loss=0.4274, Val Acc=0.7941\n",
      "Epoch 18: Train Loss=0.4214, Train Acc=0.7958 ||| Val Loss=0.4123, Val Acc=0.7982\n",
      "Epoch 19: Train Loss=0.4191, Train Acc=0.7954 ||| Val Loss=0.4164, Val Acc=0.7970\n",
      "Epoch 20: Train Loss=0.4218, Train Acc=0.7931 ||| Val Loss=0.4114, Val Acc=0.7982\n",
      "Epoch 21: Train Loss=0.4209, Train Acc=0.7970 ||| Val Loss=0.4181, Val Acc=0.8005\n",
      "Epoch 22: Train Loss=0.4213, Train Acc=0.7942 ||| Val Loss=0.4165, Val Acc=0.7970\n",
      "Epoch 23: Train Loss=0.4210, Train Acc=0.7974 ||| Val Loss=0.4210, Val Acc=0.7947\n",
      "Epoch 24: Train Loss=0.4270, Train Acc=0.7955 ||| Val Loss=0.4235, Val Acc=0.7953\n",
      "Epoch 25: Train Loss=0.4243, Train Acc=0.7962 ||| Val Loss=0.4174, Val Acc=0.7959\n",
      "Epoch 26: Train Loss=0.4209, Train Acc=0.8016 ||| Val Loss=0.4145, Val Acc=0.8068\n",
      "Epoch 27: Train Loss=0.4169, Train Acc=0.7974 ||| Val Loss=0.4216, Val Acc=0.7970\n",
      "Epoch 28: Train Loss=0.4209, Train Acc=0.7958 ||| Val Loss=0.4097, Val Acc=0.8056\n",
      "Epoch 29: Train Loss=0.4172, Train Acc=0.7984 ||| Val Loss=0.4134, Val Acc=0.8051\n",
      "Epoch 30: Train Loss=0.4180, Train Acc=0.7962 ||| Val Loss=0.4102, Val Acc=0.7947\n",
      "Epoch 31: Train Loss=0.4164, Train Acc=0.7952 ||| Val Loss=0.4097, Val Acc=0.8074\n",
      "Epoch 32: Train Loss=0.4179, Train Acc=0.8001 ||| Val Loss=0.4167, Val Acc=0.8033\n",
      "Epoch 33: Train Loss=0.4131, Train Acc=0.8031 ||| Val Loss=0.4167, Val Acc=0.8022\n",
      "Epoch 34: Train Loss=0.4123, Train Acc=0.8076 ||| Val Loss=0.4121, Val Acc=0.7999\n",
      "Epoch 35: Train Loss=0.4131, Train Acc=0.8037 ||| Val Loss=0.4128, Val Acc=0.8068\n",
      "Epoch 36: Train Loss=0.4131, Train Acc=0.8013 ||| Val Loss=0.4097, Val Acc=0.8056\n",
      "Epoch 37: Train Loss=0.4112, Train Acc=0.8031 ||| Val Loss=0.4092, Val Acc=0.8039\n",
      "Epoch 38: Train Loss=0.4155, Train Acc=0.8011 ||| Val Loss=0.4156, Val Acc=0.8016\n",
      "Epoch 39: Train Loss=0.4123, Train Acc=0.8050 ||| Val Loss=0.4148, Val Acc=0.8022\n",
      "Epoch 40: Train Loss=0.4106, Train Acc=0.8047 ||| Val Loss=0.4136, Val Acc=0.8051\n",
      "Epoch 41: Train Loss=0.4109, Train Acc=0.8007 ||| Val Loss=0.4091, Val Acc=0.8079\n",
      "Epoch 42: Train Loss=0.4092, Train Acc=0.8054 ||| Val Loss=0.4205, Val Acc=0.8033\n",
      "Epoch 43: Train Loss=0.4083, Train Acc=0.8064 ||| Val Loss=0.4139, Val Acc=0.7987\n",
      "Epoch 44: Train Loss=0.4074, Train Acc=0.8092 ||| Val Loss=0.4111, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4080, Train Acc=0.8063 ||| Val Loss=0.4101, Val Acc=0.8085\n",
      "Epoch 46: Train Loss=0.4073, Train Acc=0.8076 ||| Val Loss=0.4092, Val Acc=0.8091\n",
      "Epoch 47: Train Loss=0.4094, Train Acc=0.8056 ||| Val Loss=0.4142, Val Acc=0.8045\n",
      "Epoch 48: Train Loss=0.4075, Train Acc=0.8049 ||| Val Loss=0.4195, Val Acc=0.8079\n",
      "Epoch 49: Train Loss=0.4095, Train Acc=0.8077 ||| Val Loss=0.4103, Val Acc=0.8051\n",
      "Epoch 50: Train Loss=0.4085, Train Acc=0.8023 ||| Val Loss=0.4202, Val Acc=0.8022\n",
      "Epoch 51: Train Loss=0.4122, Train Acc=0.7993 ||| Val Loss=0.4231, Val Acc=0.7826\n",
      "Epoch 52: Train Loss=0.4123, Train Acc=0.8056 ||| Val Loss=0.4100, Val Acc=0.8068\n",
      "Epoch 53: Train Loss=0.4058, Train Acc=0.8069 ||| Val Loss=0.4199, Val Acc=0.8028\n",
      "Epoch 54: Train Loss=0.4088, Train Acc=0.8034 ||| Val Loss=0.4111, Val Acc=0.8045\n",
      "Epoch 55: Train Loss=0.4047, Train Acc=0.8102 ||| Val Loss=0.4132, Val Acc=0.8074\n",
      "Epoch 56: Train Loss=0.4094, Train Acc=0.8072 ||| Val Loss=0.4118, Val Acc=0.8005\n",
      "Epoch 57: Train Loss=0.4028, Train Acc=0.8105 ||| Val Loss=0.4188, Val Acc=0.7982\n",
      "Epoch 58: Train Loss=0.4074, Train Acc=0.8050 ||| Val Loss=0.4144, Val Acc=0.8062\n",
      "Epoch 59: Train Loss=0.4041, Train Acc=0.8087 ||| Val Loss=0.4108, Val Acc=0.8102\n",
      "Epoch 60: Train Loss=0.4098, Train Acc=0.8047 ||| Val Loss=0.4170, Val Acc=0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:06:56,176] Trial 14 finished with value: 0.80448533640023 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.22303030403997218, 'activation': 'ReLU', 'lr': 0.004099862119126689, 'weight_decay': 5.27735244168503e-06}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train Loss=0.4098, Train Acc=0.8047 ||| Val Loss=0.4211, Val Acc=0.8045\n",
      "Early stopping triggered at epoch 61\n",
      "Validation Accuracy: 0.8045\n",
      "\n",
      " Trial 16 with params: {'n_blocks': 5, 'd_block': 256, 'k': 12, 'dropout': 0.22021430390146038, 'activation': 'ReLU', 'lr': 0.006096229836076245, 'weight_decay': 3.400438765809951e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.4804, Train Acc=0.6704 ||| Val Loss=0.5239, Val Acc=0.7838\n",
      "Epoch 2: Train Loss=0.5281, Train Acc=0.7728 ||| Val Loss=0.5002, Val Acc=0.7913\n",
      "Epoch 3: Train Loss=0.5164, Train Acc=0.7716 ||| Val Loss=0.5079, Val Acc=0.7941\n",
      "Epoch 4: Train Loss=0.5193, Train Acc=0.7788 ||| Val Loss=0.4868, Val Acc=0.7947\n",
      "Epoch 5: Train Loss=0.5045, Train Acc=0.7823 ||| Val Loss=0.4988, Val Acc=0.7826\n",
      "Epoch 6: Train Loss=0.4970, Train Acc=0.7821 ||| Val Loss=0.5004, Val Acc=0.7890\n",
      "Epoch 7: Train Loss=0.4956, Train Acc=0.7849 ||| Val Loss=0.4716, Val Acc=0.7953\n",
      "Epoch 8: Train Loss=0.4897, Train Acc=0.7867 ||| Val Loss=0.4685, Val Acc=0.7930\n",
      "Epoch 9: Train Loss=0.4845, Train Acc=0.7876 ||| Val Loss=0.4703, Val Acc=0.7815\n",
      "Epoch 10: Train Loss=0.4766, Train Acc=0.7867 ||| Val Loss=0.4553, Val Acc=0.7970\n",
      "Epoch 11: Train Loss=0.4742, Train Acc=0.7866 ||| Val Loss=0.4602, Val Acc=0.7895\n",
      "Epoch 12: Train Loss=0.4828, Train Acc=0.7824 ||| Val Loss=0.4655, Val Acc=0.7982\n",
      "Epoch 13: Train Loss=0.4706, Train Acc=0.7893 ||| Val Loss=0.4641, Val Acc=0.7884\n",
      "Epoch 14: Train Loss=0.4755, Train Acc=0.7882 ||| Val Loss=0.4610, Val Acc=0.7976\n",
      "Epoch 15: Train Loss=0.4763, Train Acc=0.7879 ||| Val Loss=0.4595, Val Acc=0.7953\n",
      "Epoch 16: Train Loss=0.4772, Train Acc=0.7883 ||| Val Loss=0.4695, Val Acc=0.7913\n",
      "Epoch 17: Train Loss=0.4669, Train Acc=0.7918 ||| Val Loss=0.4571, Val Acc=0.7941\n",
      "Epoch 18: Train Loss=0.4686, Train Acc=0.7888 ||| Val Loss=0.4655, Val Acc=0.7941\n",
      "Epoch 19: Train Loss=0.4669, Train Acc=0.7919 ||| Val Loss=0.4511, Val Acc=0.7930\n",
      "Epoch 20: Train Loss=0.4622, Train Acc=0.7918 ||| Val Loss=0.4610, Val Acc=0.7901\n",
      "Epoch 21: Train Loss=0.4697, Train Acc=0.7906 ||| Val Loss=0.4526, Val Acc=0.7941\n",
      "Epoch 22: Train Loss=0.4674, Train Acc=0.7912 ||| Val Loss=0.4615, Val Acc=0.8016\n",
      "Epoch 23: Train Loss=0.4648, Train Acc=0.7906 ||| Val Loss=0.4503, Val Acc=0.7953\n",
      "Epoch 24: Train Loss=0.4602, Train Acc=0.7876 ||| Val Loss=0.4487, Val Acc=0.7936\n",
      "Epoch 25: Train Loss=0.4613, Train Acc=0.7906 ||| Val Loss=0.4564, Val Acc=0.7924\n",
      "Epoch 26: Train Loss=0.4600, Train Acc=0.7886 ||| Val Loss=0.4585, Val Acc=0.7895\n",
      "Epoch 27: Train Loss=0.4573, Train Acc=0.7890 ||| Val Loss=0.4484, Val Acc=0.7936\n",
      "Epoch 28: Train Loss=0.4569, Train Acc=0.7865 ||| Val Loss=0.4675, Val Acc=0.7936\n",
      "Epoch 29: Train Loss=0.4616, Train Acc=0.7893 ||| Val Loss=0.4496, Val Acc=0.7947\n",
      "Epoch 30: Train Loss=0.4703, Train Acc=0.7903 ||| Val Loss=0.4581, Val Acc=0.7964\n",
      "Epoch 31: Train Loss=0.4615, Train Acc=0.7886 ||| Val Loss=0.4461, Val Acc=0.8010\n",
      "Epoch 32: Train Loss=0.4535, Train Acc=0.7911 ||| Val Loss=0.4655, Val Acc=0.7970\n",
      "Epoch 33: Train Loss=0.4602, Train Acc=0.7898 ||| Val Loss=0.4559, Val Acc=0.7970\n",
      "Epoch 34: Train Loss=0.4539, Train Acc=0.7928 ||| Val Loss=0.4484, Val Acc=0.7970\n",
      "Epoch 35: Train Loss=0.4530, Train Acc=0.7926 ||| Val Loss=0.4541, Val Acc=0.7936\n",
      "Epoch 36: Train Loss=0.4560, Train Acc=0.7890 ||| Val Loss=0.4455, Val Acc=0.8005\n",
      "Epoch 37: Train Loss=0.4540, Train Acc=0.7902 ||| Val Loss=0.4521, Val Acc=0.7947\n",
      "Epoch 38: Train Loss=0.4539, Train Acc=0.7939 ||| Val Loss=0.4484, Val Acc=0.8016\n",
      "Epoch 39: Train Loss=0.4605, Train Acc=0.7896 ||| Val Loss=0.4489, Val Acc=0.7959\n",
      "Epoch 40: Train Loss=0.4516, Train Acc=0.7909 ||| Val Loss=0.4458, Val Acc=0.7999\n",
      "Epoch 41: Train Loss=0.4539, Train Acc=0.7903 ||| Val Loss=0.4588, Val Acc=0.7901\n",
      "Epoch 42: Train Loss=0.4583, Train Acc=0.7895 ||| Val Loss=0.4554, Val Acc=0.7884\n",
      "Epoch 43: Train Loss=0.4575, Train Acc=0.7909 ||| Val Loss=0.4500, Val Acc=0.7976\n",
      "Epoch 44: Train Loss=0.4618, Train Acc=0.7915 ||| Val Loss=0.4484, Val Acc=0.7976\n",
      "Epoch 45: Train Loss=0.4573, Train Acc=0.7896 ||| Val Loss=0.4492, Val Acc=0.8016\n",
      "Epoch 46: Train Loss=0.4541, Train Acc=0.7923 ||| Val Loss=0.4498, Val Acc=0.7982\n",
      "Epoch 47: Train Loss=0.4545, Train Acc=0.7883 ||| Val Loss=0.4462, Val Acc=0.8016\n",
      "Epoch 48: Train Loss=0.4545, Train Acc=0.7921 ||| Val Loss=0.4596, Val Acc=0.8010\n",
      "Epoch 49: Train Loss=0.4510, Train Acc=0.7926 ||| Val Loss=0.4443, Val Acc=0.8016\n",
      "Epoch 50: Train Loss=0.4523, Train Acc=0.7895 ||| Val Loss=0.4563, Val Acc=0.7999\n",
      "Epoch 51: Train Loss=0.4562, Train Acc=0.7898 ||| Val Loss=0.4480, Val Acc=0.8028\n",
      "Epoch 52: Train Loss=0.4521, Train Acc=0.7935 ||| Val Loss=0.4426, Val Acc=0.8022\n",
      "Epoch 53: Train Loss=0.4509, Train Acc=0.7885 ||| Val Loss=0.4486, Val Acc=0.8022\n",
      "Epoch 54: Train Loss=0.4482, Train Acc=0.7918 ||| Val Loss=0.4421, Val Acc=0.8010\n",
      "Epoch 55: Train Loss=0.4537, Train Acc=0.7906 ||| Val Loss=0.4444, Val Acc=0.8056\n",
      "Epoch 56: Train Loss=0.4497, Train Acc=0.7895 ||| Val Loss=0.4423, Val Acc=0.8010\n",
      "Epoch 57: Train Loss=0.4536, Train Acc=0.7876 ||| Val Loss=0.4624, Val Acc=0.7936\n",
      "Epoch 58: Train Loss=0.4624, Train Acc=0.7909 ||| Val Loss=0.4569, Val Acc=0.7953\n",
      "Epoch 59: Train Loss=0.4611, Train Acc=0.7935 ||| Val Loss=0.4580, Val Acc=0.7993\n",
      "Epoch 60: Train Loss=0.4558, Train Acc=0.7923 ||| Val Loss=0.4520, Val Acc=0.8010\n",
      "Epoch 61: Train Loss=0.4539, Train Acc=0.7911 ||| Val Loss=0.4532, Val Acc=0.7970\n",
      "Epoch 62: Train Loss=0.4542, Train Acc=0.7923 ||| Val Loss=0.4513, Val Acc=0.7970\n",
      "Epoch 63: Train Loss=0.4549, Train Acc=0.7919 ||| Val Loss=0.4529, Val Acc=0.7987\n",
      "Epoch 64: Train Loss=0.4532, Train Acc=0.7931 ||| Val Loss=0.4536, Val Acc=0.7999\n",
      "Epoch 65: Train Loss=0.4530, Train Acc=0.7932 ||| Val Loss=0.4474, Val Acc=0.7976\n",
      "Epoch 66: Train Loss=0.4466, Train Acc=0.7928 ||| Val Loss=0.4431, Val Acc=0.7976\n",
      "Epoch 67: Train Loss=0.4505, Train Acc=0.7925 ||| Val Loss=0.4481, Val Acc=0.7947\n",
      "Epoch 68: Train Loss=0.4563, Train Acc=0.7895 ||| Val Loss=0.4525, Val Acc=0.7936\n",
      "Epoch 69: Train Loss=0.4534, Train Acc=0.7915 ||| Val Loss=0.4491, Val Acc=0.7964\n",
      "Epoch 70: Train Loss=0.4579, Train Acc=0.7860 ||| Val Loss=0.4490, Val Acc=0.7964\n",
      "Epoch 71: Train Loss=0.4594, Train Acc=0.7908 ||| Val Loss=0.4390, Val Acc=0.7976\n",
      "Epoch 72: Train Loss=0.4407, Train Acc=0.7900 ||| Val Loss=0.4421, Val Acc=0.7936\n",
      "Epoch 73: Train Loss=0.4375, Train Acc=0.7852 ||| Val Loss=0.4273, Val Acc=0.7803\n",
      "Epoch 74: Train Loss=0.4344, Train Acc=0.7885 ||| Val Loss=0.4233, Val Acc=0.7959\n",
      "Epoch 75: Train Loss=0.4427, Train Acc=0.7882 ||| Val Loss=0.4217, Val Acc=0.7895\n",
      "Epoch 76: Train Loss=0.4308, Train Acc=0.7863 ||| Val Loss=0.4245, Val Acc=0.8028\n",
      "Epoch 77: Train Loss=0.4304, Train Acc=0.7928 ||| Val Loss=0.4239, Val Acc=0.7970\n",
      "Epoch 78: Train Loss=0.4338, Train Acc=0.7880 ||| Val Loss=0.4205, Val Acc=0.7999\n",
      "Epoch 79: Train Loss=0.4269, Train Acc=0.7905 ||| Val Loss=0.4267, Val Acc=0.7953\n",
      "Epoch 80: Train Loss=0.4223, Train Acc=0.7923 ||| Val Loss=0.4162, Val Acc=0.8010\n",
      "Epoch 81: Train Loss=0.4200, Train Acc=0.7913 ||| Val Loss=0.4324, Val Acc=0.7982\n",
      "Epoch 82: Train Loss=0.4273, Train Acc=0.7899 ||| Val Loss=0.4228, Val Acc=0.7970\n",
      "Epoch 83: Train Loss=0.4266, Train Acc=0.7906 ||| Val Loss=0.4217, Val Acc=0.7993\n",
      "Epoch 84: Train Loss=0.4229, Train Acc=0.7903 ||| Val Loss=0.4164, Val Acc=0.8005\n",
      "Epoch 85: Train Loss=0.4202, Train Acc=0.7882 ||| Val Loss=0.4181, Val Acc=0.7913\n",
      "Epoch 86: Train Loss=0.4221, Train Acc=0.7908 ||| Val Loss=0.4166, Val Acc=0.7976\n",
      "Epoch 87: Train Loss=0.4183, Train Acc=0.7931 ||| Val Loss=0.4223, Val Acc=0.7936\n",
      "Epoch 88: Train Loss=0.4275, Train Acc=0.7888 ||| Val Loss=0.4198, Val Acc=0.8005\n",
      "Epoch 89: Train Loss=0.4242, Train Acc=0.7939 ||| Val Loss=0.4136, Val Acc=0.8005\n",
      "Epoch 90: Train Loss=0.4263, Train Acc=0.7875 ||| Val Loss=0.4702, Val Acc=0.7987\n",
      "Epoch 91: Train Loss=0.4297, Train Acc=0.7929 ||| Val Loss=0.4237, Val Acc=0.7982\n",
      "Epoch 92: Train Loss=0.4191, Train Acc=0.7919 ||| Val Loss=0.4153, Val Acc=0.7953\n",
      "Epoch 93: Train Loss=0.4183, Train Acc=0.7941 ||| Val Loss=0.4208, Val Acc=0.7993\n",
      "Epoch 94: Train Loss=0.4152, Train Acc=0.7941 ||| Val Loss=0.4210, Val Acc=0.7959\n",
      "Epoch 95: Train Loss=0.4176, Train Acc=0.7909 ||| Val Loss=0.4793, Val Acc=0.7815\n",
      "Epoch 96: Train Loss=0.4262, Train Acc=0.7945 ||| Val Loss=0.4183, Val Acc=0.7987\n",
      "Epoch 97: Train Loss=0.4211, Train Acc=0.7962 ||| Val Loss=0.4186, Val Acc=0.8016\n",
      "Epoch 98: Train Loss=0.4159, Train Acc=0.7951 ||| Val Loss=0.4177, Val Acc=0.8022\n",
      "Epoch 99: Train Loss=0.4223, Train Acc=0.7932 ||| Val Loss=0.4169, Val Acc=0.7993\n",
      "Epoch 100: Train Loss=0.4166, Train Acc=0.7962 ||| Val Loss=0.4207, Val Acc=0.7901\n",
      "Epoch 101: Train Loss=0.4190, Train Acc=0.7947 ||| Val Loss=0.4175, Val Acc=0.8045\n",
      "Epoch 102: Train Loss=0.4187, Train Acc=0.7938 ||| Val Loss=0.4463, Val Acc=0.7936\n",
      "Epoch 103: Train Loss=0.4179, Train Acc=0.7957 ||| Val Loss=0.4358, Val Acc=0.7970\n",
      "Epoch 104: Train Loss=0.4163, Train Acc=0.7961 ||| Val Loss=0.4141, Val Acc=0.8039\n",
      "Epoch 105: Train Loss=0.4191, Train Acc=0.7965 ||| Val Loss=0.4115, Val Acc=0.7964\n",
      "Epoch 106: Train Loss=0.4223, Train Acc=0.7957 ||| Val Loss=0.4159, Val Acc=0.8079\n",
      "Epoch 107: Train Loss=0.4198, Train Acc=0.7935 ||| Val Loss=0.4135, Val Acc=0.8010\n",
      "Epoch 108: Train Loss=0.4240, Train Acc=0.7959 ||| Val Loss=0.4119, Val Acc=0.8062\n",
      "Epoch 109: Train Loss=0.4185, Train Acc=0.7955 ||| Val Loss=0.4128, Val Acc=0.8045\n",
      "Epoch 110: Train Loss=0.4214, Train Acc=0.7934 ||| Val Loss=0.4168, Val Acc=0.7959\n",
      "Epoch 111: Train Loss=0.4217, Train Acc=0.7941 ||| Val Loss=0.4144, Val Acc=0.7924\n",
      "Epoch 112: Train Loss=0.4156, Train Acc=0.7928 ||| Val Loss=0.4270, Val Acc=0.7907\n",
      "Epoch 113: Train Loss=0.4196, Train Acc=0.7951 ||| Val Loss=0.4114, Val Acc=0.8091\n",
      "Epoch 114: Train Loss=0.4198, Train Acc=0.7970 ||| Val Loss=0.4145, Val Acc=0.8051\n",
      "Epoch 115: Train Loss=0.4229, Train Acc=0.7961 ||| Val Loss=0.4243, Val Acc=0.7947\n",
      "Epoch 116: Train Loss=0.4183, Train Acc=0.8005 ||| Val Loss=0.4117, Val Acc=0.7993\n",
      "Epoch 117: Train Loss=0.4246, Train Acc=0.7978 ||| Val Loss=0.4081, Val Acc=0.8068\n",
      "Epoch 118: Train Loss=0.4159, Train Acc=0.8007 ||| Val Loss=0.4065, Val Acc=0.8091\n",
      "Epoch 119: Train Loss=0.4147, Train Acc=0.8007 ||| Val Loss=0.4127, Val Acc=0.8091\n",
      "Epoch 120: Train Loss=0.4150, Train Acc=0.7965 ||| Val Loss=0.4153, Val Acc=0.7970\n",
      "Epoch 121: Train Loss=0.4188, Train Acc=0.7958 ||| Val Loss=0.4133, Val Acc=0.8005\n",
      "Epoch 122: Train Loss=0.4130, Train Acc=0.7994 ||| Val Loss=0.4258, Val Acc=0.8016\n",
      "Epoch 123: Train Loss=0.4158, Train Acc=0.7978 ||| Val Loss=0.4238, Val Acc=0.7964\n",
      "Epoch 124: Train Loss=0.4157, Train Acc=0.7990 ||| Val Loss=0.4141, Val Acc=0.8079\n",
      "Epoch 125: Train Loss=0.4118, Train Acc=0.8031 ||| Val Loss=0.4122, Val Acc=0.8005\n",
      "Epoch 126: Train Loss=0.4159, Train Acc=0.8013 ||| Val Loss=0.4149, Val Acc=0.8005\n",
      "Epoch 127: Train Loss=0.4142, Train Acc=0.7997 ||| Val Loss=0.4102, Val Acc=0.8022\n",
      "Epoch 128: Train Loss=0.4176, Train Acc=0.7987 ||| Val Loss=0.4182, Val Acc=0.7941\n",
      "Epoch 129: Train Loss=0.4152, Train Acc=0.8013 ||| Val Loss=0.4117, Val Acc=0.7982\n",
      "Epoch 130: Train Loss=0.4140, Train Acc=0.7981 ||| Val Loss=0.4086, Val Acc=0.8079\n",
      "Epoch 131: Train Loss=0.4300, Train Acc=0.7939 ||| Val Loss=0.4170, Val Acc=0.8079\n",
      "Epoch 132: Train Loss=0.4228, Train Acc=0.7967 ||| Val Loss=0.4133, Val Acc=0.8056\n",
      "Epoch 133: Train Loss=0.4157, Train Acc=0.8010 ||| Val Loss=0.4177, Val Acc=0.8039\n",
      "Epoch 134: Train Loss=0.4171, Train Acc=0.7962 ||| Val Loss=0.4254, Val Acc=0.7982\n",
      "Epoch 135: Train Loss=0.4148, Train Acc=0.8007 ||| Val Loss=0.4214, Val Acc=0.8062\n",
      "Epoch 136: Train Loss=0.4151, Train Acc=0.8004 ||| Val Loss=0.4091, Val Acc=0.7959\n",
      "Epoch 137: Train Loss=0.4165, Train Acc=0.7957 ||| Val Loss=0.4124, Val Acc=0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:08:38,469] Trial 15 finished with value: 0.8056354226566993 and parameters: {'n_blocks': 5, 'd_block': 256, 'k': 12, 'dropout': 0.22021430390146038, 'activation': 'ReLU', 'lr': 0.006096229836076245, 'weight_decay': 3.400438765809951e-05}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: Train Loss=0.4082, Train Acc=0.8007 ||| Val Loss=0.4186, Val Acc=0.8056\n",
      "Early stopping triggered at epoch 138\n",
      "Validation Accuracy: 0.8056\n",
      "\n",
      " Trial 17 with params: {'n_blocks': 5, 'd_block': 256, 'k': 12, 'dropout': 0.1868444115130066, 'activation': 'ReLU', 'lr': 0.012090580233799669, 'weight_decay': 3.050559349806885e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=9.6492, Train Acc=0.6585 ||| Val Loss=0.5177, Val Acc=0.7826\n",
      "Epoch 2: Train Loss=0.5437, Train Acc=0.7558 ||| Val Loss=0.5087, Val Acc=0.7849\n",
      "Epoch 3: Train Loss=0.5276, Train Acc=0.7696 ||| Val Loss=0.5030, Val Acc=0.7890\n",
      "Epoch 4: Train Loss=0.5310, Train Acc=0.7680 ||| Val Loss=0.5104, Val Acc=0.7665\n",
      "Epoch 5: Train Loss=0.5093, Train Acc=0.7773 ||| Val Loss=0.4768, Val Acc=0.7976\n",
      "Epoch 6: Train Loss=0.5091, Train Acc=0.7778 ||| Val Loss=0.6848, Val Acc=0.7890\n",
      "Epoch 7: Train Loss=0.5056, Train Acc=0.7758 ||| Val Loss=0.4809, Val Acc=0.7953\n",
      "Epoch 8: Train Loss=0.5038, Train Acc=0.7777 ||| Val Loss=0.5173, Val Acc=0.7844\n",
      "Epoch 9: Train Loss=0.5014, Train Acc=0.7747 ||| Val Loss=0.4677, Val Acc=0.7890\n",
      "Epoch 10: Train Loss=0.4903, Train Acc=0.7867 ||| Val Loss=0.4868, Val Acc=0.7970\n",
      "Epoch 11: Train Loss=0.5009, Train Acc=0.7817 ||| Val Loss=0.4742, Val Acc=0.7953\n",
      "Epoch 12: Train Loss=0.4882, Train Acc=0.7849 ||| Val Loss=0.4685, Val Acc=0.7901\n",
      "Epoch 13: Train Loss=0.4885, Train Acc=0.7840 ||| Val Loss=0.4729, Val Acc=0.8005\n",
      "Epoch 14: Train Loss=0.4798, Train Acc=0.7807 ||| Val Loss=0.4650, Val Acc=0.7913\n",
      "Epoch 15: Train Loss=0.4750, Train Acc=0.7840 ||| Val Loss=0.4585, Val Acc=0.7947\n",
      "Epoch 16: Train Loss=0.4792, Train Acc=0.7867 ||| Val Loss=0.4571, Val Acc=0.7936\n",
      "Epoch 17: Train Loss=0.4682, Train Acc=0.7846 ||| Val Loss=0.4497, Val Acc=0.7936\n",
      "Epoch 18: Train Loss=0.4676, Train Acc=0.7859 ||| Val Loss=0.4442, Val Acc=0.7895\n",
      "Epoch 19: Train Loss=0.4674, Train Acc=0.7806 ||| Val Loss=0.4506, Val Acc=0.7959\n",
      "Epoch 20: Train Loss=0.4631, Train Acc=0.7853 ||| Val Loss=0.4606, Val Acc=0.7959\n",
      "Epoch 21: Train Loss=0.4661, Train Acc=0.7854 ||| Val Loss=0.4578, Val Acc=0.7918\n",
      "Epoch 22: Train Loss=0.4690, Train Acc=0.7827 ||| Val Loss=0.4359, Val Acc=0.7982\n",
      "Epoch 23: Train Loss=0.4572, Train Acc=0.7916 ||| Val Loss=0.4567, Val Acc=0.7867\n",
      "Epoch 24: Train Loss=0.4784, Train Acc=0.7837 ||| Val Loss=0.4618, Val Acc=0.7930\n",
      "Epoch 25: Train Loss=0.4861, Train Acc=0.7780 ||| Val Loss=0.4640, Val Acc=0.7895\n",
      "Epoch 26: Train Loss=0.4840, Train Acc=0.7829 ||| Val Loss=0.4613, Val Acc=0.7832\n",
      "Epoch 27: Train Loss=0.4739, Train Acc=0.7827 ||| Val Loss=0.4491, Val Acc=0.7918\n",
      "Epoch 28: Train Loss=0.4668, Train Acc=0.7817 ||| Val Loss=0.4501, Val Acc=0.7867\n",
      "Epoch 29: Train Loss=0.4719, Train Acc=0.7820 ||| Val Loss=0.4429, Val Acc=0.7953\n",
      "Epoch 30: Train Loss=0.4582, Train Acc=0.7843 ||| Val Loss=0.4302, Val Acc=0.7936\n",
      "Epoch 31: Train Loss=0.4578, Train Acc=0.7816 ||| Val Loss=0.4302, Val Acc=0.7970\n",
      "Epoch 32: Train Loss=0.4566, Train Acc=0.7866 ||| Val Loss=0.4410, Val Acc=0.7941\n",
      "Epoch 33: Train Loss=0.4518, Train Acc=0.7879 ||| Val Loss=0.4263, Val Acc=0.7924\n",
      "Epoch 34: Train Loss=0.4534, Train Acc=0.7846 ||| Val Loss=0.4264, Val Acc=0.7924\n",
      "Epoch 35: Train Loss=0.4422, Train Acc=0.7903 ||| Val Loss=0.4254, Val Acc=0.7970\n",
      "Epoch 36: Train Loss=0.4416, Train Acc=0.7867 ||| Val Loss=0.4294, Val Acc=0.7803\n",
      "Epoch 37: Train Loss=0.4420, Train Acc=0.7913 ||| Val Loss=0.4328, Val Acc=0.7941\n",
      "Epoch 38: Train Loss=0.4382, Train Acc=0.7890 ||| Val Loss=0.4164, Val Acc=0.7936\n",
      "Epoch 39: Train Loss=0.4390, Train Acc=0.7837 ||| Val Loss=0.4419, Val Acc=0.7809\n",
      "Epoch 40: Train Loss=0.4370, Train Acc=0.7842 ||| Val Loss=0.4263, Val Acc=0.7941\n",
      "Epoch 41: Train Loss=0.4339, Train Acc=0.7865 ||| Val Loss=0.4269, Val Acc=0.7936\n",
      "Epoch 42: Train Loss=0.4412, Train Acc=0.7849 ||| Val Loss=0.4195, Val Acc=0.7970\n",
      "Epoch 43: Train Loss=0.4322, Train Acc=0.7882 ||| Val Loss=0.4196, Val Acc=0.7941\n",
      "Epoch 44: Train Loss=0.4350, Train Acc=0.7866 ||| Val Loss=0.4167, Val Acc=0.7993\n",
      "Epoch 45: Train Loss=0.4255, Train Acc=0.7908 ||| Val Loss=0.4253, Val Acc=0.7947\n",
      "Epoch 46: Train Loss=0.4282, Train Acc=0.7873 ||| Val Loss=0.4242, Val Acc=0.7936\n",
      "Epoch 47: Train Loss=0.4310, Train Acc=0.7876 ||| Val Loss=0.4217, Val Acc=0.7987\n",
      "Epoch 48: Train Loss=0.4388, Train Acc=0.7839 ||| Val Loss=0.4204, Val Acc=0.7918\n",
      "Epoch 49: Train Loss=0.4405, Train Acc=0.7869 ||| Val Loss=0.4242, Val Acc=0.7798\n",
      "Epoch 50: Train Loss=0.4368, Train Acc=0.7880 ||| Val Loss=0.4179, Val Acc=0.7953\n",
      "Epoch 51: Train Loss=0.4287, Train Acc=0.7928 ||| Val Loss=0.4183, Val Acc=0.7918\n",
      "Epoch 52: Train Loss=0.4297, Train Acc=0.7928 ||| Val Loss=0.4164, Val Acc=0.7930\n",
      "Epoch 53: Train Loss=0.4291, Train Acc=0.7898 ||| Val Loss=0.4155, Val Acc=0.7947\n",
      "Epoch 54: Train Loss=0.4281, Train Acc=0.7932 ||| Val Loss=0.4141, Val Acc=0.7953\n",
      "Epoch 55: Train Loss=0.4262, Train Acc=0.7954 ||| Val Loss=0.4122, Val Acc=0.7982\n",
      "Epoch 56: Train Loss=0.4303, Train Acc=0.7919 ||| Val Loss=0.4264, Val Acc=0.7993\n",
      "Epoch 57: Train Loss=0.4299, Train Acc=0.7911 ||| Val Loss=0.4164, Val Acc=0.8102\n",
      "Epoch 58: Train Loss=0.4272, Train Acc=0.7948 ||| Val Loss=0.4262, Val Acc=0.7757\n",
      "Epoch 59: Train Loss=0.4397, Train Acc=0.7898 ||| Val Loss=0.4208, Val Acc=0.7918\n",
      "Epoch 60: Train Loss=0.4259, Train Acc=0.7954 ||| Val Loss=0.4240, Val Acc=0.7867\n",
      "Epoch 61: Train Loss=0.4261, Train Acc=0.7990 ||| Val Loss=0.4110, Val Acc=0.8033\n",
      "Epoch 62: Train Loss=0.4283, Train Acc=0.7923 ||| Val Loss=0.4311, Val Acc=0.7729\n",
      "Epoch 63: Train Loss=0.4292, Train Acc=0.7889 ||| Val Loss=0.4278, Val Acc=0.7982\n",
      "Epoch 64: Train Loss=0.4328, Train Acc=0.7870 ||| Val Loss=0.4125, Val Acc=0.8022\n",
      "Epoch 65: Train Loss=0.4247, Train Acc=0.7980 ||| Val Loss=0.4199, Val Acc=0.7907\n",
      "Epoch 66: Train Loss=0.4287, Train Acc=0.7860 ||| Val Loss=0.4315, Val Acc=0.7821\n",
      "Epoch 67: Train Loss=0.4231, Train Acc=0.7995 ||| Val Loss=0.4372, Val Acc=0.7953\n",
      "Epoch 68: Train Loss=0.4267, Train Acc=0.7928 ||| Val Loss=0.4180, Val Acc=0.7941\n",
      "Epoch 69: Train Loss=0.4254, Train Acc=0.7968 ||| Val Loss=0.4158, Val Acc=0.7918\n",
      "Epoch 70: Train Loss=0.4252, Train Acc=0.7951 ||| Val Loss=0.4073, Val Acc=0.7976\n",
      "Epoch 71: Train Loss=0.4222, Train Acc=0.7961 ||| Val Loss=0.4156, Val Acc=0.7924\n",
      "Epoch 72: Train Loss=0.4280, Train Acc=0.7947 ||| Val Loss=0.4116, Val Acc=0.8010\n",
      "Epoch 73: Train Loss=0.4389, Train Acc=0.7888 ||| Val Loss=0.4160, Val Acc=0.7959\n",
      "Epoch 74: Train Loss=0.4292, Train Acc=0.7942 ||| Val Loss=0.4234, Val Acc=0.7993\n",
      "Epoch 75: Train Loss=0.4295, Train Acc=0.7932 ||| Val Loss=0.4158, Val Acc=0.8005\n",
      "Epoch 76: Train Loss=0.4247, Train Acc=0.7980 ||| Val Loss=0.4201, Val Acc=0.7970\n",
      "Epoch 77: Train Loss=0.4366, Train Acc=0.7906 ||| Val Loss=0.4167, Val Acc=0.7941\n",
      "Epoch 78: Train Loss=0.4325, Train Acc=0.7945 ||| Val Loss=0.4319, Val Acc=0.7700\n",
      "Epoch 79: Train Loss=0.4296, Train Acc=0.7846 ||| Val Loss=0.4188, Val Acc=0.7878\n",
      "Epoch 80: Train Loss=0.4284, Train Acc=0.7932 ||| Val Loss=0.5089, Val Acc=0.7930\n",
      "Epoch 81: Train Loss=0.4323, Train Acc=0.7936 ||| Val Loss=0.4376, Val Acc=0.7717\n",
      "Epoch 82: Train Loss=0.4262, Train Acc=0.7928 ||| Val Loss=0.4179, Val Acc=0.8022\n",
      "Epoch 83: Train Loss=0.4420, Train Acc=0.7965 ||| Val Loss=0.4761, Val Acc=0.7867\n",
      "Epoch 84: Train Loss=0.4346, Train Acc=0.7951 ||| Val Loss=0.4276, Val Acc=0.7901\n",
      "Epoch 85: Train Loss=0.4385, Train Acc=0.7886 ||| Val Loss=0.4169, Val Acc=0.7895\n",
      "Epoch 86: Train Loss=0.4242, Train Acc=0.7945 ||| Val Loss=0.4125, Val Acc=0.7976\n",
      "Epoch 87: Train Loss=0.4326, Train Acc=0.7932 ||| Val Loss=0.4434, Val Acc=0.7947\n",
      "Epoch 88: Train Loss=0.4291, Train Acc=0.7962 ||| Val Loss=0.4446, Val Acc=0.7941\n",
      "Epoch 89: Train Loss=0.4330, Train Acc=0.7925 ||| Val Loss=0.4146, Val Acc=0.8022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:09:46,294] Trial 16 finished with value: 0.7929844738355377 and parameters: {'n_blocks': 5, 'd_block': 256, 'k': 12, 'dropout': 0.1868444115130066, 'activation': 'ReLU', 'lr': 0.012090580233799669, 'weight_decay': 3.050559349806885e-05}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss=0.4221, Train Acc=0.8000 ||| Val Loss=0.4320, Val Acc=0.7930\n",
      "Early stopping triggered at epoch 90\n",
      "Validation Accuracy: 0.7930\n",
      "\n",
      " Trial 18 with params: {'n_blocks': 5, 'd_block': 256, 'k': 12, 'dropout': 0.10894027041076242, 'activation': 'ReLU', 'lr': 0.04453125047086107, 'weight_decay': 0.00014842485660468803}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2649.6408, Train Acc=0.5469 ||| Val Loss=4.5939, Val Acc=0.5118\n",
      "Epoch 2: Train Loss=7.3541, Train Acc=0.5286 ||| Val Loss=39.4635, Val Acc=0.4963\n",
      "Epoch 3: Train Loss=38.6607, Train Acc=0.5559 ||| Val Loss=122.3272, Val Acc=0.4756\n",
      "Epoch 4: Train Loss=8631.8872, Train Acc=0.5729 ||| Val Loss=26746.2861, Val Acc=0.5589\n",
      "Epoch 5: Train Loss=462417.0091, Train Acc=0.6053 ||| Val Loss=99051.6953, Val Acc=0.5405\n",
      "Epoch 6: Train Loss=35625.0086, Train Acc=0.6488 ||| Val Loss=1392.1430, Val Acc=0.7332\n",
      "Epoch 7: Train Loss=972.1766, Train Acc=0.6789 ||| Val Loss=158.5144, Val Acc=0.7688\n",
      "Epoch 8: Train Loss=256.8901, Train Acc=0.6963 ||| Val Loss=82.6899, Val Acc=0.7476\n",
      "Epoch 9: Train Loss=168.4584, Train Acc=0.6923 ||| Val Loss=99.8561, Val Acc=0.7424\n",
      "Epoch 10: Train Loss=125.9350, Train Acc=0.6892 ||| Val Loss=34.4805, Val Acc=0.7826\n",
      "Epoch 11: Train Loss=102.7964, Train Acc=0.6918 ||| Val Loss=31.0049, Val Acc=0.7717\n",
      "Epoch 12: Train Loss=71.3434, Train Acc=0.6941 ||| Val Loss=22.7888, Val Acc=0.7694\n",
      "Epoch 13: Train Loss=57.4255, Train Acc=0.6990 ||| Val Loss=18.5846, Val Acc=0.7717\n",
      "Epoch 14: Train Loss=60.1291, Train Acc=0.6877 ||| Val Loss=19.3528, Val Acc=0.7694\n",
      "Epoch 15: Train Loss=37.2178, Train Acc=0.6977 ||| Val Loss=13.2062, Val Acc=0.7769\n",
      "Epoch 16: Train Loss=33.0767, Train Acc=0.6915 ||| Val Loss=8.3270, Val Acc=0.7844\n",
      "Epoch 17: Train Loss=30.7586, Train Acc=0.6875 ||| Val Loss=8.4886, Val Acc=0.7729\n",
      "Epoch 18: Train Loss=24.0008, Train Acc=0.6934 ||| Val Loss=7.8699, Val Acc=0.7625\n",
      "Epoch 19: Train Loss=25.2895, Train Acc=0.6956 ||| Val Loss=6.4746, Val Acc=0.7660\n",
      "Epoch 20: Train Loss=20.7069, Train Acc=0.6923 ||| Val Loss=10.7333, Val Acc=0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:10:02,238] Trial 17 finished with value: 0.7849338700402531 and parameters: {'n_blocks': 5, 'd_block': 256, 'k': 12, 'dropout': 0.10894027041076242, 'activation': 'ReLU', 'lr': 0.04453125047086107, 'weight_decay': 0.00014842485660468803}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=31.6281, Train Acc=0.6743 ||| Val Loss=5.8952, Val Acc=0.7849\n",
      "Early stopping triggered at epoch 21\n",
      "Validation Accuracy: 0.7849\n",
      "\n",
      " Trial 19 with params: {'n_blocks': 3, 'd_block': 256, 'k': 10, 'dropout': 0.2796146010934679, 'activation': 'LeakyReLU', 'lr': 0.007503253150104942, 'weight_decay': 2.193829486700668e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=6.0478, Train Acc=0.6629 ||| Val Loss=0.5516, Val Acc=0.7677\n",
      "Epoch 2: Train Loss=0.5478, Train Acc=0.7515 ||| Val Loss=0.5046, Val Acc=0.7815\n",
      "Epoch 3: Train Loss=0.5340, Train Acc=0.7591 ||| Val Loss=0.5955, Val Acc=0.6763\n",
      "Epoch 4: Train Loss=0.5236, Train Acc=0.7721 ||| Val Loss=0.5061, Val Acc=0.7976\n",
      "Epoch 5: Train Loss=0.5179, Train Acc=0.7725 ||| Val Loss=0.4920, Val Acc=0.7936\n",
      "Epoch 6: Train Loss=0.5114, Train Acc=0.7714 ||| Val Loss=0.5021, Val Acc=0.7844\n",
      "Epoch 7: Train Loss=0.5162, Train Acc=0.7706 ||| Val Loss=0.4957, Val Acc=0.7970\n",
      "Epoch 8: Train Loss=0.5041, Train Acc=0.7811 ||| Val Loss=0.4865, Val Acc=0.7924\n",
      "Epoch 9: Train Loss=0.5053, Train Acc=0.7752 ||| Val Loss=0.5035, Val Acc=0.7832\n",
      "Epoch 10: Train Loss=0.4990, Train Acc=0.7768 ||| Val Loss=0.4785, Val Acc=0.7901\n",
      "Epoch 11: Train Loss=0.4918, Train Acc=0.7820 ||| Val Loss=0.4698, Val Acc=0.7941\n",
      "Epoch 12: Train Loss=0.4804, Train Acc=0.7827 ||| Val Loss=0.4755, Val Acc=0.7867\n",
      "Epoch 13: Train Loss=0.4772, Train Acc=0.7846 ||| Val Loss=0.4642, Val Acc=0.7953\n",
      "Epoch 14: Train Loss=0.4731, Train Acc=0.7873 ||| Val Loss=0.4645, Val Acc=0.7947\n",
      "Epoch 15: Train Loss=0.4759, Train Acc=0.7852 ||| Val Loss=0.4532, Val Acc=0.7901\n",
      "Epoch 16: Train Loss=0.4654, Train Acc=0.7875 ||| Val Loss=0.4509, Val Acc=0.7832\n",
      "Epoch 17: Train Loss=0.4601, Train Acc=0.7860 ||| Val Loss=0.4340, Val Acc=0.7953\n",
      "Epoch 18: Train Loss=0.4596, Train Acc=0.7862 ||| Val Loss=0.4328, Val Acc=0.7941\n",
      "Epoch 19: Train Loss=0.4536, Train Acc=0.7852 ||| Val Loss=0.4309, Val Acc=0.7953\n",
      "Epoch 20: Train Loss=0.4564, Train Acc=0.7863 ||| Val Loss=0.4365, Val Acc=0.7895\n",
      "Epoch 21: Train Loss=0.4482, Train Acc=0.7839 ||| Val Loss=0.4297, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4484, Train Acc=0.7895 ||| Val Loss=0.4417, Val Acc=0.7941\n",
      "Epoch 23: Train Loss=0.4460, Train Acc=0.7908 ||| Val Loss=0.4318, Val Acc=0.7924\n",
      "Epoch 24: Train Loss=0.4459, Train Acc=0.7883 ||| Val Loss=0.4269, Val Acc=0.7901\n",
      "Epoch 25: Train Loss=0.4397, Train Acc=0.7892 ||| Val Loss=0.4217, Val Acc=0.8010\n",
      "Epoch 26: Train Loss=0.4389, Train Acc=0.7890 ||| Val Loss=0.4281, Val Acc=0.7987\n",
      "Epoch 27: Train Loss=0.4454, Train Acc=0.7893 ||| Val Loss=0.4334, Val Acc=0.7970\n",
      "Epoch 28: Train Loss=0.4364, Train Acc=0.7915 ||| Val Loss=0.4273, Val Acc=0.7987\n",
      "Epoch 29: Train Loss=0.4354, Train Acc=0.7932 ||| Val Loss=0.4222, Val Acc=0.7976\n",
      "Epoch 30: Train Loss=0.4369, Train Acc=0.7952 ||| Val Loss=0.4305, Val Acc=0.7826\n",
      "Epoch 31: Train Loss=0.4293, Train Acc=0.7949 ||| Val Loss=0.4214, Val Acc=0.7964\n",
      "Epoch 32: Train Loss=0.4336, Train Acc=0.7925 ||| Val Loss=0.4184, Val Acc=0.8010\n",
      "Epoch 33: Train Loss=0.4346, Train Acc=0.7896 ||| Val Loss=0.4330, Val Acc=0.7918\n",
      "Epoch 34: Train Loss=0.4327, Train Acc=0.7888 ||| Val Loss=0.4218, Val Acc=0.7936\n",
      "Epoch 35: Train Loss=0.4268, Train Acc=0.7911 ||| Val Loss=0.4272, Val Acc=0.7964\n",
      "Epoch 36: Train Loss=0.4240, Train Acc=0.7958 ||| Val Loss=0.4179, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4240, Train Acc=0.7936 ||| Val Loss=0.4190, Val Acc=0.7970\n",
      "Epoch 38: Train Loss=0.4213, Train Acc=0.7968 ||| Val Loss=0.4166, Val Acc=0.7964\n",
      "Epoch 39: Train Loss=0.4203, Train Acc=0.7987 ||| Val Loss=0.4179, Val Acc=0.7964\n",
      "Epoch 40: Train Loss=0.4227, Train Acc=0.7942 ||| Val Loss=0.4137, Val Acc=0.7964\n",
      "Epoch 41: Train Loss=0.4225, Train Acc=0.7942 ||| Val Loss=0.4176, Val Acc=0.7936\n",
      "Epoch 42: Train Loss=0.4202, Train Acc=0.7981 ||| Val Loss=0.4331, Val Acc=0.7913\n",
      "Epoch 43: Train Loss=0.4193, Train Acc=0.7982 ||| Val Loss=0.4627, Val Acc=0.7999\n",
      "Epoch 44: Train Loss=0.4282, Train Acc=0.7926 ||| Val Loss=0.4157, Val Acc=0.7930\n",
      "Epoch 45: Train Loss=0.4214, Train Acc=0.7988 ||| Val Loss=0.4296, Val Acc=0.7987\n",
      "Epoch 46: Train Loss=0.4169, Train Acc=0.8005 ||| Val Loss=0.4156, Val Acc=0.7976\n",
      "Epoch 47: Train Loss=0.4200, Train Acc=0.8000 ||| Val Loss=0.4200, Val Acc=0.7964\n",
      "Epoch 48: Train Loss=0.4172, Train Acc=0.8001 ||| Val Loss=0.4067, Val Acc=0.7993\n",
      "Epoch 49: Train Loss=0.4168, Train Acc=0.7978 ||| Val Loss=0.4136, Val Acc=0.7982\n",
      "Epoch 50: Train Loss=0.4202, Train Acc=0.7995 ||| Val Loss=0.4104, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4190, Train Acc=0.7988 ||| Val Loss=0.4124, Val Acc=0.7993\n",
      "Epoch 52: Train Loss=0.4187, Train Acc=0.8024 ||| Val Loss=0.4148, Val Acc=0.8005\n",
      "Epoch 53: Train Loss=0.4174, Train Acc=0.8020 ||| Val Loss=0.4178, Val Acc=0.7987\n",
      "Epoch 54: Train Loss=0.4175, Train Acc=0.7998 ||| Val Loss=0.4081, Val Acc=0.7976\n",
      "Epoch 55: Train Loss=0.4171, Train Acc=0.8007 ||| Val Loss=0.4143, Val Acc=0.7947\n",
      "Epoch 56: Train Loss=0.4187, Train Acc=0.7991 ||| Val Loss=0.4124, Val Acc=0.7947\n",
      "Epoch 57: Train Loss=0.4147, Train Acc=0.8024 ||| Val Loss=0.4124, Val Acc=0.7987\n",
      "Epoch 58: Train Loss=0.4181, Train Acc=0.8024 ||| Val Loss=0.4088, Val Acc=0.7976\n",
      "Epoch 59: Train Loss=0.4158, Train Acc=0.8000 ||| Val Loss=0.4179, Val Acc=0.7982\n",
      "Epoch 60: Train Loss=0.4119, Train Acc=0.8004 ||| Val Loss=0.4109, Val Acc=0.7982\n",
      "Epoch 61: Train Loss=0.4130, Train Acc=0.8008 ||| Val Loss=0.4174, Val Acc=0.7999\n",
      "Epoch 62: Train Loss=0.4166, Train Acc=0.8013 ||| Val Loss=0.4097, Val Acc=0.7982\n",
      "Epoch 63: Train Loss=0.4154, Train Acc=0.8010 ||| Val Loss=0.4136, Val Acc=0.7953\n",
      "Epoch 64: Train Loss=0.4138, Train Acc=0.8016 ||| Val Loss=0.4148, Val Acc=0.8005\n",
      "Epoch 65: Train Loss=0.4207, Train Acc=0.8044 ||| Val Loss=0.4129, Val Acc=0.7918\n",
      "Epoch 66: Train Loss=0.4239, Train Acc=0.7990 ||| Val Loss=0.4287, Val Acc=0.7970\n",
      "Epoch 67: Train Loss=0.4203, Train Acc=0.8007 ||| Val Loss=0.4119, Val Acc=0.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:10:32,705] Trial 18 finished with value: 0.8010350776308223 and parameters: {'n_blocks': 3, 'd_block': 256, 'k': 10, 'dropout': 0.2796146010934679, 'activation': 'LeakyReLU', 'lr': 0.007503253150104942, 'weight_decay': 2.193829486700668e-05}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Train Loss=0.4135, Train Acc=0.8043 ||| Val Loss=0.4171, Val Acc=0.8010\n",
      "Early stopping triggered at epoch 68\n",
      "Validation Accuracy: 0.8010\n",
      "\n",
      " Trial 20 with params: {'n_blocks': 6, 'd_block': 256, 'k': 11, 'dropout': 0.2000376712509801, 'activation': 'ReLU', 'lr': 0.002510177980904529, 'weight_decay': 1.0351607224212033e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.6480, Train Acc=0.6970 ||| Val Loss=0.5319, Val Acc=0.7752\n",
      "Epoch 2: Train Loss=0.5198, Train Acc=0.7767 ||| Val Loss=0.5052, Val Acc=0.7849\n",
      "Epoch 3: Train Loss=0.5110, Train Acc=0.7780 ||| Val Loss=0.4767, Val Acc=0.7987\n",
      "Epoch 4: Train Loss=0.5045, Train Acc=0.7827 ||| Val Loss=0.4775, Val Acc=0.7976\n",
      "Epoch 5: Train Loss=0.4955, Train Acc=0.7844 ||| Val Loss=0.4858, Val Acc=0.7987\n",
      "Epoch 6: Train Loss=0.4900, Train Acc=0.7846 ||| Val Loss=0.4598, Val Acc=0.7924\n",
      "Epoch 7: Train Loss=0.4752, Train Acc=0.7885 ||| Val Loss=0.4516, Val Acc=0.7953\n",
      "Epoch 8: Train Loss=0.4681, Train Acc=0.7892 ||| Val Loss=0.4496, Val Acc=0.8028\n",
      "Epoch 9: Train Loss=0.4612, Train Acc=0.7922 ||| Val Loss=0.4245, Val Acc=0.8005\n",
      "Epoch 10: Train Loss=0.4567, Train Acc=0.7827 ||| Val Loss=0.4366, Val Acc=0.7976\n",
      "Epoch 11: Train Loss=0.4460, Train Acc=0.7896 ||| Val Loss=0.4261, Val Acc=0.7947\n",
      "Epoch 12: Train Loss=0.4433, Train Acc=0.7912 ||| Val Loss=0.4247, Val Acc=0.7953\n",
      "Epoch 13: Train Loss=0.4394, Train Acc=0.7942 ||| Val Loss=0.4227, Val Acc=0.7964\n",
      "Epoch 14: Train Loss=0.4298, Train Acc=0.7951 ||| Val Loss=0.4223, Val Acc=0.7970\n",
      "Epoch 15: Train Loss=0.4268, Train Acc=0.7938 ||| Val Loss=0.4184, Val Acc=0.7953\n",
      "Epoch 16: Train Loss=0.4269, Train Acc=0.7949 ||| Val Loss=0.4261, Val Acc=0.7913\n",
      "Epoch 17: Train Loss=0.4290, Train Acc=0.7905 ||| Val Loss=0.4198, Val Acc=0.7936\n",
      "Epoch 18: Train Loss=0.4288, Train Acc=0.7935 ||| Val Loss=0.4212, Val Acc=0.7930\n",
      "Epoch 19: Train Loss=0.4253, Train Acc=0.7935 ||| Val Loss=0.4311, Val Acc=0.7999\n",
      "Epoch 20: Train Loss=0.4244, Train Acc=0.7975 ||| Val Loss=0.4192, Val Acc=0.7999\n",
      "Epoch 21: Train Loss=0.4202, Train Acc=0.7957 ||| Val Loss=0.4177, Val Acc=0.8010\n",
      "Epoch 22: Train Loss=0.4237, Train Acc=0.7962 ||| Val Loss=0.4145, Val Acc=0.7970\n",
      "Epoch 23: Train Loss=0.4202, Train Acc=0.7972 ||| Val Loss=0.4196, Val Acc=0.7976\n",
      "Epoch 24: Train Loss=0.4218, Train Acc=0.7955 ||| Val Loss=0.4079, Val Acc=0.8016\n",
      "Epoch 25: Train Loss=0.4160, Train Acc=0.7957 ||| Val Loss=0.4148, Val Acc=0.8056\n",
      "Epoch 26: Train Loss=0.4182, Train Acc=0.7971 ||| Val Loss=0.4147, Val Acc=0.7982\n",
      "Epoch 27: Train Loss=0.4212, Train Acc=0.8007 ||| Val Loss=0.4177, Val Acc=0.7976\n",
      "Epoch 28: Train Loss=0.4183, Train Acc=0.7967 ||| Val Loss=0.4084, Val Acc=0.7999\n",
      "Epoch 29: Train Loss=0.4209, Train Acc=0.7934 ||| Val Loss=0.4113, Val Acc=0.7976\n",
      "Epoch 30: Train Loss=0.4132, Train Acc=0.7957 ||| Val Loss=0.4143, Val Acc=0.7999\n",
      "Epoch 31: Train Loss=0.4235, Train Acc=0.7985 ||| Val Loss=0.4092, Val Acc=0.8045\n",
      "Epoch 32: Train Loss=0.4163, Train Acc=0.7980 ||| Val Loss=0.4152, Val Acc=0.7970\n",
      "Epoch 33: Train Loss=0.4130, Train Acc=0.7988 ||| Val Loss=0.4156, Val Acc=0.7982\n",
      "Epoch 34: Train Loss=0.4153, Train Acc=0.7998 ||| Val Loss=0.4139, Val Acc=0.7936\n",
      "Epoch 35: Train Loss=0.4139, Train Acc=0.7968 ||| Val Loss=0.4076, Val Acc=0.8010\n",
      "Epoch 36: Train Loss=0.4129, Train Acc=0.7988 ||| Val Loss=0.4198, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4115, Train Acc=0.8004 ||| Val Loss=0.4157, Val Acc=0.7964\n",
      "Epoch 38: Train Loss=0.4140, Train Acc=0.8003 ||| Val Loss=0.4090, Val Acc=0.8016\n",
      "Epoch 39: Train Loss=0.4083, Train Acc=0.8021 ||| Val Loss=0.4041, Val Acc=0.8016\n",
      "Epoch 40: Train Loss=0.4100, Train Acc=0.7947 ||| Val Loss=0.4128, Val Acc=0.8085\n",
      "Epoch 41: Train Loss=0.4097, Train Acc=0.8024 ||| Val Loss=0.4084, Val Acc=0.7999\n",
      "Epoch 42: Train Loss=0.4058, Train Acc=0.8041 ||| Val Loss=0.4103, Val Acc=0.8016\n",
      "Epoch 43: Train Loss=0.4071, Train Acc=0.8017 ||| Val Loss=0.4114, Val Acc=0.7924\n",
      "Epoch 44: Train Loss=0.4106, Train Acc=0.8008 ||| Val Loss=0.4083, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4096, Train Acc=0.8008 ||| Val Loss=0.3988, Val Acc=0.8056\n",
      "Epoch 46: Train Loss=0.4093, Train Acc=0.8024 ||| Val Loss=0.4066, Val Acc=0.7947\n",
      "Epoch 47: Train Loss=0.4063, Train Acc=0.8008 ||| Val Loss=0.4026, Val Acc=0.8074\n",
      "Epoch 48: Train Loss=0.4073, Train Acc=0.7981 ||| Val Loss=0.4069, Val Acc=0.7970\n",
      "Epoch 49: Train Loss=0.4071, Train Acc=0.8044 ||| Val Loss=0.4014, Val Acc=0.8079\n",
      "Epoch 50: Train Loss=0.4053, Train Acc=0.7984 ||| Val Loss=0.4049, Val Acc=0.8056\n",
      "Epoch 51: Train Loss=0.3970, Train Acc=0.8063 ||| Val Loss=0.4065, Val Acc=0.8068\n",
      "Epoch 52: Train Loss=0.4026, Train Acc=0.8034 ||| Val Loss=0.4049, Val Acc=0.8051\n",
      "Epoch 53: Train Loss=0.4039, Train Acc=0.8067 ||| Val Loss=0.4185, Val Acc=0.8005\n",
      "Epoch 54: Train Loss=0.4053, Train Acc=0.8016 ||| Val Loss=0.4133, Val Acc=0.8039\n",
      "Epoch 55: Train Loss=0.4021, Train Acc=0.8073 ||| Val Loss=0.4089, Val Acc=0.7999\n",
      "Epoch 56: Train Loss=0.4029, Train Acc=0.8041 ||| Val Loss=0.4101, Val Acc=0.8074\n",
      "Epoch 57: Train Loss=0.4003, Train Acc=0.8050 ||| Val Loss=0.4109, Val Acc=0.8056\n",
      "Epoch 58: Train Loss=0.4004, Train Acc=0.8073 ||| Val Loss=0.4106, Val Acc=0.8022\n",
      "Epoch 59: Train Loss=0.3985, Train Acc=0.8047 ||| Val Loss=0.4120, Val Acc=0.8045\n",
      "Epoch 60: Train Loss=0.3947, Train Acc=0.8074 ||| Val Loss=0.4172, Val Acc=0.8010\n",
      "Epoch 61: Train Loss=0.4003, Train Acc=0.8092 ||| Val Loss=0.4121, Val Acc=0.8005\n",
      "Epoch 62: Train Loss=0.4022, Train Acc=0.8062 ||| Val Loss=0.4128, Val Acc=0.8062\n",
      "Epoch 63: Train Loss=0.3985, Train Acc=0.8041 ||| Val Loss=0.4063, Val Acc=0.8039\n",
      "Epoch 64: Train Loss=0.3944, Train Acc=0.8097 ||| Val Loss=0.4120, Val Acc=0.8016\n",
      "Epoch 65: Train Loss=0.3986, Train Acc=0.8039 ||| Val Loss=0.3988, Val Acc=0.8039\n",
      "Epoch 66: Train Loss=0.3998, Train Acc=0.8077 ||| Val Loss=0.4049, Val Acc=0.8051\n",
      "Epoch 67: Train Loss=0.3928, Train Acc=0.8095 ||| Val Loss=0.4062, Val Acc=0.8010\n",
      "Epoch 68: Train Loss=0.3925, Train Acc=0.8049 ||| Val Loss=0.4097, Val Acc=0.8102\n",
      "Epoch 69: Train Loss=0.3943, Train Acc=0.8102 ||| Val Loss=0.4089, Val Acc=0.8079\n",
      "Epoch 70: Train Loss=0.3949, Train Acc=0.8062 ||| Val Loss=0.4029, Val Acc=0.8056\n",
      "Epoch 71: Train Loss=0.3955, Train Acc=0.8062 ||| Val Loss=0.4063, Val Acc=0.8028\n",
      "Epoch 72: Train Loss=0.3971, Train Acc=0.8064 ||| Val Loss=0.4104, Val Acc=0.8051\n",
      "Epoch 73: Train Loss=0.3968, Train Acc=0.8113 ||| Val Loss=0.4085, Val Acc=0.8028\n",
      "Epoch 74: Train Loss=0.3945, Train Acc=0.8136 ||| Val Loss=0.4215, Val Acc=0.8062\n",
      "Epoch 75: Train Loss=0.3965, Train Acc=0.8087 ||| Val Loss=0.4106, Val Acc=0.8016\n",
      "Epoch 76: Train Loss=0.3904, Train Acc=0.8164 ||| Val Loss=0.4073, Val Acc=0.8114\n",
      "Epoch 77: Train Loss=0.3936, Train Acc=0.8086 ||| Val Loss=0.4101, Val Acc=0.8045\n",
      "Epoch 78: Train Loss=0.3904, Train Acc=0.8138 ||| Val Loss=0.4050, Val Acc=0.8068\n",
      "Epoch 79: Train Loss=0.3899, Train Acc=0.8106 ||| Val Loss=0.4117, Val Acc=0.8062\n",
      "Epoch 80: Train Loss=0.3905, Train Acc=0.8090 ||| Val Loss=0.4011, Val Acc=0.8062\n",
      "Epoch 81: Train Loss=0.3887, Train Acc=0.8187 ||| Val Loss=0.4182, Val Acc=0.8062\n",
      "Epoch 82: Train Loss=0.3865, Train Acc=0.8133 ||| Val Loss=0.4318, Val Acc=0.8114\n",
      "Epoch 83: Train Loss=0.3900, Train Acc=0.8105 ||| Val Loss=0.4069, Val Acc=0.8079\n",
      "Epoch 84: Train Loss=0.3927, Train Acc=0.8086 ||| Val Loss=0.4201, Val Acc=0.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:11:31,853] Trial 19 finished with value: 0.8039102932719954 and parameters: {'n_blocks': 6, 'd_block': 256, 'k': 11, 'dropout': 0.2000376712509801, 'activation': 'ReLU', 'lr': 0.002510177980904529, 'weight_decay': 1.0351607224212033e-06}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Train Loss=0.3876, Train Acc=0.8097 ||| Val Loss=0.4114, Val Acc=0.8039\n",
      "Early stopping triggered at epoch 85\n",
      "Validation Accuracy: 0.8039\n",
      "\n",
      " Trial 21 with params: {'n_blocks': 5, 'd_block': 256, 'k': 7, 'dropout': 0.2825841632112342, 'activation': 'ReLU', 'lr': 0.008173394292636528, 'weight_decay': 6.528443999332398e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.2770, Train Acc=0.6119 ||| Val Loss=0.5733, Val Acc=0.7648\n",
      "Epoch 2: Train Loss=0.5634, Train Acc=0.7394 ||| Val Loss=0.5303, Val Acc=0.7838\n",
      "Epoch 3: Train Loss=0.5371, Train Acc=0.7575 ||| Val Loss=0.5338, Val Acc=0.7700\n",
      "Epoch 4: Train Loss=0.5403, Train Acc=0.7643 ||| Val Loss=0.5463, Val Acc=0.7303\n",
      "Epoch 5: Train Loss=0.5313, Train Acc=0.7657 ||| Val Loss=0.5145, Val Acc=0.7694\n",
      "Epoch 6: Train Loss=0.5175, Train Acc=0.7773 ||| Val Loss=0.4928, Val Acc=0.7953\n",
      "Epoch 7: Train Loss=0.5065, Train Acc=0.7821 ||| Val Loss=0.4816, Val Acc=0.7964\n",
      "Epoch 8: Train Loss=0.4958, Train Acc=0.7816 ||| Val Loss=0.4836, Val Acc=0.7924\n",
      "Epoch 9: Train Loss=0.5037, Train Acc=0.7764 ||| Val Loss=0.4778, Val Acc=0.7936\n",
      "Epoch 10: Train Loss=0.4917, Train Acc=0.7817 ||| Val Loss=0.4913, Val Acc=0.7775\n",
      "Epoch 11: Train Loss=0.5042, Train Acc=0.7739 ||| Val Loss=0.4839, Val Acc=0.7936\n",
      "Epoch 12: Train Loss=0.4949, Train Acc=0.7801 ||| Val Loss=0.4753, Val Acc=0.7844\n",
      "Epoch 13: Train Loss=0.4968, Train Acc=0.7791 ||| Val Loss=0.4721, Val Acc=0.7930\n",
      "Epoch 14: Train Loss=0.4875, Train Acc=0.7853 ||| Val Loss=0.4707, Val Acc=0.7987\n",
      "Epoch 15: Train Loss=0.4901, Train Acc=0.7866 ||| Val Loss=0.4702, Val Acc=0.7941\n",
      "Epoch 16: Train Loss=0.4888, Train Acc=0.7837 ||| Val Loss=0.4587, Val Acc=0.7947\n",
      "Epoch 17: Train Loss=0.4880, Train Acc=0.7872 ||| Val Loss=0.4676, Val Acc=0.7964\n",
      "Epoch 18: Train Loss=0.4790, Train Acc=0.7869 ||| Val Loss=0.4684, Val Acc=0.7959\n",
      "Epoch 19: Train Loss=0.4811, Train Acc=0.7877 ||| Val Loss=0.4703, Val Acc=0.7867\n",
      "Epoch 20: Train Loss=0.4795, Train Acc=0.7854 ||| Val Loss=0.4671, Val Acc=0.7947\n",
      "Epoch 21: Train Loss=0.4805, Train Acc=0.7852 ||| Val Loss=0.4757, Val Acc=0.7930\n",
      "Epoch 22: Train Loss=0.4870, Train Acc=0.7840 ||| Val Loss=0.4718, Val Acc=0.7913\n",
      "Epoch 23: Train Loss=0.4827, Train Acc=0.7877 ||| Val Loss=0.4669, Val Acc=0.7953\n",
      "Epoch 24: Train Loss=0.4835, Train Acc=0.7888 ||| Val Loss=0.4666, Val Acc=0.7959\n",
      "Epoch 25: Train Loss=0.4819, Train Acc=0.7867 ||| Val Loss=0.4653, Val Acc=0.7918\n",
      "Epoch 26: Train Loss=0.4760, Train Acc=0.7893 ||| Val Loss=0.4839, Val Acc=0.7976\n",
      "Epoch 27: Train Loss=0.4789, Train Acc=0.7867 ||| Val Loss=0.4612, Val Acc=0.7976\n",
      "Epoch 28: Train Loss=0.4876, Train Acc=0.7778 ||| Val Loss=0.4761, Val Acc=0.7924\n",
      "Epoch 29: Train Loss=0.4785, Train Acc=0.7895 ||| Val Loss=0.4575, Val Acc=0.7953\n",
      "Epoch 30: Train Loss=0.4773, Train Acc=0.7854 ||| Val Loss=0.4588, Val Acc=0.7987\n",
      "Epoch 31: Train Loss=0.4791, Train Acc=0.7869 ||| Val Loss=0.4785, Val Acc=0.7809\n",
      "Epoch 32: Train Loss=0.4783, Train Acc=0.7890 ||| Val Loss=0.4582, Val Acc=0.7953\n",
      "Epoch 33: Train Loss=0.4673, Train Acc=0.7898 ||| Val Loss=0.4679, Val Acc=0.7993\n",
      "Epoch 34: Train Loss=0.4777, Train Acc=0.7829 ||| Val Loss=0.4599, Val Acc=0.7976\n",
      "Epoch 35: Train Loss=0.4689, Train Acc=0.7867 ||| Val Loss=0.4601, Val Acc=0.7959\n",
      "Epoch 36: Train Loss=0.4774, Train Acc=0.7873 ||| Val Loss=0.4525, Val Acc=0.7993\n",
      "Epoch 37: Train Loss=0.4705, Train Acc=0.7853 ||| Val Loss=0.4437, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4747, Train Acc=0.7854 ||| Val Loss=0.4745, Val Acc=0.7930\n",
      "Epoch 39: Train Loss=0.4744, Train Acc=0.7877 ||| Val Loss=0.4604, Val Acc=0.7999\n",
      "Epoch 40: Train Loss=0.4721, Train Acc=0.7882 ||| Val Loss=0.4769, Val Acc=0.7924\n",
      "Epoch 41: Train Loss=0.4801, Train Acc=0.7862 ||| Val Loss=0.4674, Val Acc=0.7976\n",
      "Epoch 42: Train Loss=0.4777, Train Acc=0.7849 ||| Val Loss=0.4645, Val Acc=0.7964\n",
      "Epoch 43: Train Loss=0.4721, Train Acc=0.7911 ||| Val Loss=0.4533, Val Acc=0.8005\n",
      "Epoch 44: Train Loss=0.4740, Train Acc=0.7893 ||| Val Loss=0.4623, Val Acc=0.7964\n",
      "Epoch 45: Train Loss=0.4747, Train Acc=0.7880 ||| Val Loss=0.4926, Val Acc=0.7878\n",
      "Epoch 46: Train Loss=0.4727, Train Acc=0.7883 ||| Val Loss=0.4481, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.4725, Train Acc=0.7857 ||| Val Loss=0.4598, Val Acc=0.7936\n",
      "Epoch 48: Train Loss=0.4733, Train Acc=0.7886 ||| Val Loss=0.4693, Val Acc=0.7924\n",
      "Epoch 49: Train Loss=0.4733, Train Acc=0.7913 ||| Val Loss=0.4565, Val Acc=0.7982\n",
      "Epoch 50: Train Loss=0.4736, Train Acc=0.7883 ||| Val Loss=0.4675, Val Acc=0.7970\n",
      "Epoch 51: Train Loss=0.4725, Train Acc=0.7885 ||| Val Loss=0.4732, Val Acc=0.7798\n",
      "Epoch 52: Train Loss=0.4761, Train Acc=0.7900 ||| Val Loss=0.4704, Val Acc=0.7987\n",
      "Epoch 53: Train Loss=0.4743, Train Acc=0.7880 ||| Val Loss=0.4851, Val Acc=0.8005\n",
      "Epoch 54: Train Loss=0.4812, Train Acc=0.7863 ||| Val Loss=0.4640, Val Acc=0.7913\n",
      "Epoch 55: Train Loss=0.4671, Train Acc=0.7912 ||| Val Loss=0.4515, Val Acc=0.7924\n",
      "Epoch 56: Train Loss=0.4743, Train Acc=0.7893 ||| Val Loss=0.4615, Val Acc=0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:11:58,381] Trial 20 finished with value: 0.79700977573318 and parameters: {'n_blocks': 5, 'd_block': 256, 'k': 7, 'dropout': 0.2825841632112342, 'activation': 'ReLU', 'lr': 0.008173394292636528, 'weight_decay': 6.528443999332398e-05}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss=0.4689, Train Acc=0.7900 ||| Val Loss=0.4591, Val Acc=0.7970\n",
      "Early stopping triggered at epoch 57\n",
      "Validation Accuracy: 0.7970\n",
      "\n",
      " Trial 22 with params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.2256010105258364, 'activation': 'ReLU', 'lr': 0.003487671318826522, 'weight_decay': 6.9982025049786245e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7483, Train Acc=0.6634 ||| Val Loss=0.5201, Val Acc=0.7878\n",
      "Epoch 2: Train Loss=0.5248, Train Acc=0.7714 ||| Val Loss=0.4977, Val Acc=0.7844\n",
      "Epoch 3: Train Loss=0.5236, Train Acc=0.7757 ||| Val Loss=0.5050, Val Acc=0.7913\n",
      "Epoch 4: Train Loss=0.5079, Train Acc=0.7794 ||| Val Loss=0.4845, Val Acc=0.7964\n",
      "Epoch 5: Train Loss=0.4891, Train Acc=0.7810 ||| Val Loss=0.4719, Val Acc=0.7976\n",
      "Epoch 6: Train Loss=0.4857, Train Acc=0.7816 ||| Val Loss=0.4804, Val Acc=0.7987\n",
      "Epoch 7: Train Loss=0.4786, Train Acc=0.7820 ||| Val Loss=0.4590, Val Acc=0.7964\n",
      "Epoch 8: Train Loss=0.4617, Train Acc=0.7886 ||| Val Loss=0.4520, Val Acc=0.7947\n",
      "Epoch 9: Train Loss=0.4561, Train Acc=0.7890 ||| Val Loss=0.4405, Val Acc=0.7941\n",
      "Epoch 10: Train Loss=0.4490, Train Acc=0.7906 ||| Val Loss=0.4398, Val Acc=0.7936\n",
      "Epoch 11: Train Loss=0.4381, Train Acc=0.7883 ||| Val Loss=0.4339, Val Acc=0.7930\n",
      "Epoch 12: Train Loss=0.4375, Train Acc=0.7908 ||| Val Loss=0.4245, Val Acc=0.7924\n",
      "Epoch 13: Train Loss=0.4329, Train Acc=0.7902 ||| Val Loss=0.4182, Val Acc=0.7918\n",
      "Epoch 14: Train Loss=0.4330, Train Acc=0.7909 ||| Val Loss=0.4175, Val Acc=0.7993\n",
      "Epoch 15: Train Loss=0.4284, Train Acc=0.7931 ||| Val Loss=0.4259, Val Acc=0.7895\n",
      "Epoch 16: Train Loss=0.4260, Train Acc=0.7935 ||| Val Loss=0.4162, Val Acc=0.7993\n",
      "Epoch 17: Train Loss=0.4288, Train Acc=0.7923 ||| Val Loss=0.4200, Val Acc=0.7890\n",
      "Epoch 18: Train Loss=0.4244, Train Acc=0.7944 ||| Val Loss=0.4164, Val Acc=0.7999\n",
      "Epoch 19: Train Loss=0.4264, Train Acc=0.7949 ||| Val Loss=0.4176, Val Acc=0.7924\n",
      "Epoch 20: Train Loss=0.4217, Train Acc=0.7984 ||| Val Loss=0.4144, Val Acc=0.7953\n",
      "Epoch 21: Train Loss=0.4226, Train Acc=0.7949 ||| Val Loss=0.4171, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4226, Train Acc=0.7965 ||| Val Loss=0.4100, Val Acc=0.7993\n",
      "Epoch 23: Train Loss=0.4238, Train Acc=0.7944 ||| Val Loss=0.4113, Val Acc=0.7976\n",
      "Epoch 24: Train Loss=0.4218, Train Acc=0.7971 ||| Val Loss=0.4156, Val Acc=0.7976\n",
      "Epoch 25: Train Loss=0.4213, Train Acc=0.7949 ||| Val Loss=0.4167, Val Acc=0.7964\n",
      "Epoch 26: Train Loss=0.4206, Train Acc=0.7954 ||| Val Loss=0.4125, Val Acc=0.7987\n",
      "Epoch 27: Train Loss=0.4231, Train Acc=0.7974 ||| Val Loss=0.4125, Val Acc=0.7959\n",
      "Epoch 28: Train Loss=0.4212, Train Acc=0.7990 ||| Val Loss=0.4100, Val Acc=0.7976\n",
      "Epoch 29: Train Loss=0.4226, Train Acc=0.8001 ||| Val Loss=0.4151, Val Acc=0.7987\n",
      "Epoch 30: Train Loss=0.4203, Train Acc=0.7949 ||| Val Loss=0.4128, Val Acc=0.7941\n",
      "Epoch 31: Train Loss=0.4172, Train Acc=0.8011 ||| Val Loss=0.4155, Val Acc=0.7947\n",
      "Epoch 32: Train Loss=0.4178, Train Acc=0.7980 ||| Val Loss=0.4187, Val Acc=0.7964\n",
      "Epoch 33: Train Loss=0.4220, Train Acc=0.7978 ||| Val Loss=0.4289, Val Acc=0.8010\n",
      "Epoch 34: Train Loss=0.4158, Train Acc=0.8007 ||| Val Loss=0.4111, Val Acc=0.7976\n",
      "Epoch 35: Train Loss=0.4256, Train Acc=0.7959 ||| Val Loss=0.4115, Val Acc=0.7999\n",
      "Epoch 36: Train Loss=0.4196, Train Acc=0.7991 ||| Val Loss=0.4102, Val Acc=0.8028\n",
      "Epoch 37: Train Loss=0.4176, Train Acc=0.7974 ||| Val Loss=0.4131, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4167, Train Acc=0.8000 ||| Val Loss=0.4139, Val Acc=0.8005\n",
      "Epoch 39: Train Loss=0.4165, Train Acc=0.7990 ||| Val Loss=0.4142, Val Acc=0.7936\n",
      "Epoch 40: Train Loss=0.4145, Train Acc=0.7977 ||| Val Loss=0.4078, Val Acc=0.8039\n",
      "Epoch 41: Train Loss=0.4189, Train Acc=0.7982 ||| Val Loss=0.4082, Val Acc=0.7993\n",
      "Epoch 42: Train Loss=0.4146, Train Acc=0.8016 ||| Val Loss=0.4065, Val Acc=0.7993\n",
      "Epoch 43: Train Loss=0.4126, Train Acc=0.8036 ||| Val Loss=0.4077, Val Acc=0.7999\n",
      "Epoch 44: Train Loss=0.4122, Train Acc=0.8020 ||| Val Loss=0.4084, Val Acc=0.8005\n",
      "Epoch 45: Train Loss=0.4093, Train Acc=0.8050 ||| Val Loss=0.4102, Val Acc=0.8016\n",
      "Epoch 46: Train Loss=0.4177, Train Acc=0.7990 ||| Val Loss=0.4162, Val Acc=0.7959\n",
      "Epoch 47: Train Loss=0.4096, Train Acc=0.8041 ||| Val Loss=0.4116, Val Acc=0.8005\n",
      "Epoch 48: Train Loss=0.4127, Train Acc=0.8049 ||| Val Loss=0.4217, Val Acc=0.7930\n",
      "Epoch 49: Train Loss=0.4125, Train Acc=0.8028 ||| Val Loss=0.4121, Val Acc=0.7987\n",
      "Epoch 50: Train Loss=0.4113, Train Acc=0.8051 ||| Val Loss=0.4164, Val Acc=0.7999\n",
      "Epoch 51: Train Loss=0.4087, Train Acc=0.7995 ||| Val Loss=0.4071, Val Acc=0.8005\n",
      "Epoch 52: Train Loss=0.4129, Train Acc=0.8037 ||| Val Loss=0.4070, Val Acc=0.7999\n",
      "Epoch 53: Train Loss=0.4104, Train Acc=0.7990 ||| Val Loss=0.4079, Val Acc=0.7999\n",
      "Epoch 54: Train Loss=0.4069, Train Acc=0.8023 ||| Val Loss=0.4100, Val Acc=0.8010\n",
      "Epoch 55: Train Loss=0.4117, Train Acc=0.8034 ||| Val Loss=0.4170, Val Acc=0.7959\n",
      "Epoch 56: Train Loss=0.4094, Train Acc=0.8030 ||| Val Loss=0.4109, Val Acc=0.8056\n",
      "Epoch 57: Train Loss=0.4105, Train Acc=0.8053 ||| Val Loss=0.4171, Val Acc=0.7982\n",
      "Epoch 58: Train Loss=0.4095, Train Acc=0.8028 ||| Val Loss=0.4067, Val Acc=0.8016\n",
      "Epoch 59: Train Loss=0.4080, Train Acc=0.8067 ||| Val Loss=0.4062, Val Acc=0.8028\n",
      "Epoch 60: Train Loss=0.4038, Train Acc=0.8076 ||| Val Loss=0.4184, Val Acc=0.8016\n",
      "Epoch 61: Train Loss=0.4062, Train Acc=0.8066 ||| Val Loss=0.4070, Val Acc=0.8005\n",
      "Epoch 62: Train Loss=0.4056, Train Acc=0.8031 ||| Val Loss=0.4124, Val Acc=0.8010\n",
      "Epoch 63: Train Loss=0.4051, Train Acc=0.8067 ||| Val Loss=0.4128, Val Acc=0.8016\n",
      "Epoch 64: Train Loss=0.4035, Train Acc=0.8050 ||| Val Loss=0.4067, Val Acc=0.7993\n",
      "Epoch 65: Train Loss=0.4063, Train Acc=0.8043 ||| Val Loss=0.4105, Val Acc=0.8028\n",
      "Epoch 66: Train Loss=0.4048, Train Acc=0.8062 ||| Val Loss=0.4103, Val Acc=0.8022\n",
      "Epoch 67: Train Loss=0.4055, Train Acc=0.8060 ||| Val Loss=0.4067, Val Acc=0.8051\n",
      "Epoch 68: Train Loss=0.4009, Train Acc=0.8085 ||| Val Loss=0.4087, Val Acc=0.8022\n",
      "Epoch 69: Train Loss=0.4035, Train Acc=0.8050 ||| Val Loss=0.4166, Val Acc=0.7947\n",
      "Epoch 70: Train Loss=0.4013, Train Acc=0.8064 ||| Val Loss=0.4103, Val Acc=0.8056\n",
      "Epoch 71: Train Loss=0.4038, Train Acc=0.8069 ||| Val Loss=0.4086, Val Acc=0.8085\n",
      "Epoch 72: Train Loss=0.4007, Train Acc=0.8028 ||| Val Loss=0.4089, Val Acc=0.8085\n",
      "Epoch 73: Train Loss=0.4031, Train Acc=0.8082 ||| Val Loss=0.4138, Val Acc=0.8005\n",
      "Epoch 74: Train Loss=0.4015, Train Acc=0.8097 ||| Val Loss=0.4050, Val Acc=0.8045\n",
      "Epoch 75: Train Loss=0.3963, Train Acc=0.8041 ||| Val Loss=0.4086, Val Acc=0.8062\n",
      "Epoch 76: Train Loss=0.4034, Train Acc=0.8072 ||| Val Loss=0.4257, Val Acc=0.7953\n",
      "Epoch 77: Train Loss=0.4046, Train Acc=0.8067 ||| Val Loss=0.4187, Val Acc=0.7976\n",
      "Epoch 78: Train Loss=0.4027, Train Acc=0.8092 ||| Val Loss=0.4113, Val Acc=0.8016\n",
      "Epoch 79: Train Loss=0.3962, Train Acc=0.8123 ||| Val Loss=0.4192, Val Acc=0.7861\n",
      "Epoch 80: Train Loss=0.3991, Train Acc=0.8090 ||| Val Loss=0.4148, Val Acc=0.8010\n",
      "Epoch 81: Train Loss=0.4029, Train Acc=0.8097 ||| Val Loss=0.4074, Val Acc=0.8062\n",
      "Epoch 82: Train Loss=0.4029, Train Acc=0.8086 ||| Val Loss=0.4140, Val Acc=0.7982\n",
      "Epoch 83: Train Loss=0.4039, Train Acc=0.8082 ||| Val Loss=0.4115, Val Acc=0.8010\n",
      "Epoch 84: Train Loss=0.4007, Train Acc=0.8085 ||| Val Loss=0.4116, Val Acc=0.8051\n",
      "Epoch 85: Train Loss=0.3967, Train Acc=0.8079 ||| Val Loss=0.4105, Val Acc=0.8085\n",
      "Epoch 86: Train Loss=0.3987, Train Acc=0.8108 ||| Val Loss=0.4170, Val Acc=0.8028\n",
      "Epoch 87: Train Loss=0.4021, Train Acc=0.8083 ||| Val Loss=0.4174, Val Acc=0.7849\n",
      "Epoch 88: Train Loss=0.3983, Train Acc=0.8069 ||| Val Loss=0.4104, Val Acc=0.7953\n",
      "Epoch 89: Train Loss=0.3967, Train Acc=0.8128 ||| Val Loss=0.4121, Val Acc=0.8056\n",
      "Epoch 90: Train Loss=0.3963, Train Acc=0.8099 ||| Val Loss=0.4171, Val Acc=0.7982\n",
      "Epoch 91: Train Loss=0.3951, Train Acc=0.8093 ||| Val Loss=0.4151, Val Acc=0.8005\n",
      "Epoch 92: Train Loss=0.3977, Train Acc=0.8082 ||| Val Loss=0.4129, Val Acc=0.7936\n",
      "Epoch 93: Train Loss=0.3957, Train Acc=0.8118 ||| Val Loss=0.4087, Val Acc=0.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:12:31,699] Trial 21 finished with value: 0.8062104657849338 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.2256010105258364, 'activation': 'ReLU', 'lr': 0.003487671318826522, 'weight_decay': 6.9982025049786245e-06}. Best is trial 13 with value: 0.8067855089131685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss=0.3897, Train Acc=0.8181 ||| Val Loss=0.4062, Val Acc=0.8062\n",
      "Early stopping triggered at epoch 94\n",
      "Validation Accuracy: 0.8062\n",
      "\n",
      " Trial 23 with params: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.15984630203331762, 'activation': 'ReLU', 'lr': 0.0014769364639454208, 'weight_decay': 9.200748737757358e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.9108, Train Acc=0.6654 ||| Val Loss=0.5515, Val Acc=0.7752\n",
      "Epoch 2: Train Loss=0.5569, Train Acc=0.7345 ||| Val Loss=0.5341, Val Acc=0.7476\n",
      "Epoch 3: Train Loss=0.5385, Train Acc=0.7514 ||| Val Loss=0.5075, Val Acc=0.7936\n",
      "Epoch 4: Train Loss=0.5313, Train Acc=0.7606 ||| Val Loss=0.4972, Val Acc=0.7924\n",
      "Epoch 5: Train Loss=0.5150, Train Acc=0.7711 ||| Val Loss=0.5037, Val Acc=0.7890\n",
      "Epoch 6: Train Loss=0.5085, Train Acc=0.7768 ||| Val Loss=0.4930, Val Acc=0.7872\n",
      "Epoch 7: Train Loss=0.5035, Train Acc=0.7781 ||| Val Loss=0.4987, Val Acc=0.7849\n",
      "Epoch 8: Train Loss=0.4992, Train Acc=0.7816 ||| Val Loss=0.4902, Val Acc=0.7878\n",
      "Epoch 9: Train Loss=0.4908, Train Acc=0.7826 ||| Val Loss=0.4728, Val Acc=0.7987\n",
      "Epoch 10: Train Loss=0.4884, Train Acc=0.7807 ||| Val Loss=0.4810, Val Acc=0.7861\n",
      "Epoch 11: Train Loss=0.4798, Train Acc=0.7852 ||| Val Loss=0.4760, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.4726, Train Acc=0.7869 ||| Val Loss=0.4561, Val Acc=0.7982\n",
      "Epoch 13: Train Loss=0.4653, Train Acc=0.7893 ||| Val Loss=0.4513, Val Acc=0.7970\n",
      "Epoch 14: Train Loss=0.4543, Train Acc=0.7892 ||| Val Loss=0.4630, Val Acc=0.7953\n",
      "Epoch 15: Train Loss=0.4540, Train Acc=0.7885 ||| Val Loss=0.4453, Val Acc=0.7959\n",
      "Epoch 16: Train Loss=0.4535, Train Acc=0.7922 ||| Val Loss=0.4362, Val Acc=0.7890\n",
      "Epoch 17: Train Loss=0.4400, Train Acc=0.7877 ||| Val Loss=0.4387, Val Acc=0.7976\n",
      "Epoch 18: Train Loss=0.4368, Train Acc=0.7889 ||| Val Loss=0.4326, Val Acc=0.7953\n",
      "Epoch 19: Train Loss=0.4382, Train Acc=0.7929 ||| Val Loss=0.4376, Val Acc=0.7907\n",
      "Epoch 20: Train Loss=0.4286, Train Acc=0.7876 ||| Val Loss=0.4270, Val Acc=0.7930\n",
      "Epoch 21: Train Loss=0.4352, Train Acc=0.7921 ||| Val Loss=0.4322, Val Acc=0.7930\n",
      "Epoch 22: Train Loss=0.4272, Train Acc=0.7949 ||| Val Loss=0.4419, Val Acc=0.7918\n",
      "Epoch 23: Train Loss=0.4288, Train Acc=0.7947 ||| Val Loss=0.4278, Val Acc=0.7976\n",
      "Epoch 24: Train Loss=0.4255, Train Acc=0.7926 ||| Val Loss=0.4258, Val Acc=0.7964\n",
      "Epoch 25: Train Loss=0.4249, Train Acc=0.7951 ||| Val Loss=0.4293, Val Acc=0.7970\n",
      "Epoch 26: Train Loss=0.4224, Train Acc=0.7931 ||| Val Loss=0.4373, Val Acc=0.7959\n",
      "Epoch 27: Train Loss=0.4278, Train Acc=0.7912 ||| Val Loss=0.4275, Val Acc=0.7936\n",
      "Epoch 28: Train Loss=0.4293, Train Acc=0.7935 ||| Val Loss=0.4275, Val Acc=0.7970\n",
      "Epoch 29: Train Loss=0.4254, Train Acc=0.7929 ||| Val Loss=0.4310, Val Acc=0.7976\n",
      "Epoch 30: Train Loss=0.4210, Train Acc=0.7980 ||| Val Loss=0.4338, Val Acc=0.7941\n",
      "Epoch 31: Train Loss=0.4227, Train Acc=0.7997 ||| Val Loss=0.4299, Val Acc=0.7953\n",
      "Epoch 32: Train Loss=0.4206, Train Acc=0.7981 ||| Val Loss=0.4237, Val Acc=0.7936\n",
      "Epoch 33: Train Loss=0.4238, Train Acc=0.7929 ||| Val Loss=0.4270, Val Acc=0.7918\n",
      "Epoch 34: Train Loss=0.4225, Train Acc=0.7935 ||| Val Loss=0.4285, Val Acc=0.7964\n",
      "Epoch 35: Train Loss=0.4201, Train Acc=0.8000 ||| Val Loss=0.4174, Val Acc=0.7964\n",
      "Epoch 36: Train Loss=0.4173, Train Acc=0.7984 ||| Val Loss=0.4271, Val Acc=0.7993\n",
      "Epoch 37: Train Loss=0.4159, Train Acc=0.7944 ||| Val Loss=0.4362, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4169, Train Acc=0.7998 ||| Val Loss=0.4162, Val Acc=0.7987\n",
      "Epoch 39: Train Loss=0.4166, Train Acc=0.7935 ||| Val Loss=0.4238, Val Acc=0.7970\n",
      "Epoch 40: Train Loss=0.4160, Train Acc=0.7998 ||| Val Loss=0.4327, Val Acc=0.7999\n",
      "Epoch 41: Train Loss=0.4175, Train Acc=0.7981 ||| Val Loss=0.4269, Val Acc=0.7924\n",
      "Epoch 42: Train Loss=0.4168, Train Acc=0.7938 ||| Val Loss=0.4224, Val Acc=0.7907\n",
      "Epoch 43: Train Loss=0.4155, Train Acc=0.8005 ||| Val Loss=0.4229, Val Acc=0.7947\n",
      "Epoch 44: Train Loss=0.4136, Train Acc=0.7958 ||| Val Loss=0.4236, Val Acc=0.7924\n",
      "Epoch 45: Train Loss=0.4170, Train Acc=0.7982 ||| Val Loss=0.4345, Val Acc=0.7993\n",
      "Epoch 46: Train Loss=0.4177, Train Acc=0.7978 ||| Val Loss=0.4278, Val Acc=0.7959\n",
      "Epoch 47: Train Loss=0.4144, Train Acc=0.8039 ||| Val Loss=0.4314, Val Acc=0.7970\n",
      "Epoch 48: Train Loss=0.4145, Train Acc=0.7987 ||| Val Loss=0.4332, Val Acc=0.7964\n",
      "Epoch 49: Train Loss=0.4138, Train Acc=0.7993 ||| Val Loss=0.4236, Val Acc=0.7976\n",
      "Epoch 50: Train Loss=0.4099, Train Acc=0.8057 ||| Val Loss=0.4431, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4157, Train Acc=0.8013 ||| Val Loss=0.4166, Val Acc=0.7970\n",
      "Epoch 52: Train Loss=0.4078, Train Acc=0.8000 ||| Val Loss=0.4210, Val Acc=0.7970\n",
      "Epoch 53: Train Loss=0.4129, Train Acc=0.8000 ||| Val Loss=0.4203, Val Acc=0.7976\n",
      "Epoch 54: Train Loss=0.4113, Train Acc=0.8028 ||| Val Loss=0.4156, Val Acc=0.7999\n",
      "Epoch 55: Train Loss=0.4122, Train Acc=0.7994 ||| Val Loss=0.4192, Val Acc=0.7953\n",
      "Epoch 56: Train Loss=0.4096, Train Acc=0.8053 ||| Val Loss=0.4195, Val Acc=0.7970\n",
      "Epoch 57: Train Loss=0.4116, Train Acc=0.8007 ||| Val Loss=0.4199, Val Acc=0.7993\n",
      "Epoch 58: Train Loss=0.4083, Train Acc=0.8018 ||| Val Loss=0.4245, Val Acc=0.7999\n",
      "Epoch 59: Train Loss=0.4108, Train Acc=0.8041 ||| Val Loss=0.4139, Val Acc=0.7999\n",
      "Epoch 60: Train Loss=0.4035, Train Acc=0.8018 ||| Val Loss=0.4277, Val Acc=0.8016\n",
      "Epoch 61: Train Loss=0.4086, Train Acc=0.8014 ||| Val Loss=0.4217, Val Acc=0.7815\n",
      "Epoch 62: Train Loss=0.4079, Train Acc=0.8033 ||| Val Loss=0.4225, Val Acc=0.7999\n",
      "Epoch 63: Train Loss=0.4075, Train Acc=0.8023 ||| Val Loss=0.4217, Val Acc=0.7901\n",
      "Epoch 64: Train Loss=0.4103, Train Acc=0.8020 ||| Val Loss=0.4209, Val Acc=0.7993\n",
      "Epoch 65: Train Loss=0.4073, Train Acc=0.8004 ||| Val Loss=0.4172, Val Acc=0.8010\n",
      "Epoch 66: Train Loss=0.4056, Train Acc=0.8036 ||| Val Loss=0.4208, Val Acc=0.8005\n",
      "Epoch 67: Train Loss=0.4062, Train Acc=0.8021 ||| Val Loss=0.4146, Val Acc=0.8010\n",
      "Epoch 68: Train Loss=0.4052, Train Acc=0.8060 ||| Val Loss=0.4266, Val Acc=0.7993\n",
      "Epoch 69: Train Loss=0.4037, Train Acc=0.7991 ||| Val Loss=0.4173, Val Acc=0.7947\n",
      "Epoch 70: Train Loss=0.4049, Train Acc=0.8011 ||| Val Loss=0.4184, Val Acc=0.7924\n",
      "Epoch 71: Train Loss=0.4018, Train Acc=0.8049 ||| Val Loss=0.4097, Val Acc=0.8028\n",
      "Epoch 72: Train Loss=0.4034, Train Acc=0.8027 ||| Val Loss=0.4135, Val Acc=0.8033\n",
      "Epoch 73: Train Loss=0.4029, Train Acc=0.8056 ||| Val Loss=0.4141, Val Acc=0.8039\n",
      "Epoch 74: Train Loss=0.4002, Train Acc=0.8040 ||| Val Loss=0.4187, Val Acc=0.8045\n",
      "Epoch 75: Train Loss=0.4028, Train Acc=0.8000 ||| Val Loss=0.4247, Val Acc=0.7913\n",
      "Epoch 76: Train Loss=0.4040, Train Acc=0.8024 ||| Val Loss=0.4172, Val Acc=0.7970\n",
      "Epoch 77: Train Loss=0.4046, Train Acc=0.8039 ||| Val Loss=0.4180, Val Acc=0.7959\n",
      "Epoch 78: Train Loss=0.4018, Train Acc=0.8069 ||| Val Loss=0.4184, Val Acc=0.7993\n",
      "Epoch 79: Train Loss=0.4020, Train Acc=0.8069 ||| Val Loss=0.4194, Val Acc=0.8010\n",
      "Epoch 80: Train Loss=0.3975, Train Acc=0.8070 ||| Val Loss=0.4215, Val Acc=0.8010\n",
      "Epoch 81: Train Loss=0.3996, Train Acc=0.8080 ||| Val Loss=0.4156, Val Acc=0.8005\n",
      "Epoch 82: Train Loss=0.3981, Train Acc=0.8108 ||| Val Loss=0.4154, Val Acc=0.8005\n",
      "Epoch 83: Train Loss=0.3963, Train Acc=0.8034 ||| Val Loss=0.4166, Val Acc=0.7999\n",
      "Epoch 84: Train Loss=0.4042, Train Acc=0.8041 ||| Val Loss=0.4200, Val Acc=0.8033\n",
      "Epoch 85: Train Loss=0.4010, Train Acc=0.8059 ||| Val Loss=0.4194, Val Acc=0.7959\n",
      "Epoch 86: Train Loss=0.3968, Train Acc=0.8097 ||| Val Loss=0.4122, Val Acc=0.7964\n",
      "Epoch 87: Train Loss=0.3973, Train Acc=0.8064 ||| Val Loss=0.4149, Val Acc=0.7987\n",
      "Epoch 88: Train Loss=0.3954, Train Acc=0.8119 ||| Val Loss=0.4234, Val Acc=0.7987\n",
      "Epoch 89: Train Loss=0.3929, Train Acc=0.8109 ||| Val Loss=0.4121, Val Acc=0.7999\n",
      "Epoch 90: Train Loss=0.3953, Train Acc=0.8073 ||| Val Loss=0.4173, Val Acc=0.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:13:04,387] Trial 22 finished with value: 0.8096607245543416 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.15984630203331762, 'activation': 'ReLU', 'lr': 0.0014769364639454208, 'weight_decay': 9.200748737757358e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss=0.3919, Train Acc=0.8121 ||| Val Loss=0.4146, Val Acc=0.8097\n",
      "Early stopping triggered at epoch 91\n",
      "Validation Accuracy: 0.8097\n",
      "\n",
      " Trial 24 with params: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.1532506195603504, 'activation': 'ReLU', 'lr': 0.0016343055351461786, 'weight_decay': 2.9323631794337012e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.8443, Train Acc=0.6783 ||| Val Loss=0.5169, Val Acc=0.7780\n",
      "Epoch 2: Train Loss=0.5490, Train Acc=0.7463 ||| Val Loss=0.5121, Val Acc=0.7826\n",
      "Epoch 3: Train Loss=0.5309, Train Acc=0.7639 ||| Val Loss=0.4996, Val Acc=0.7959\n",
      "Epoch 4: Train Loss=0.5249, Train Acc=0.7683 ||| Val Loss=0.4901, Val Acc=0.7976\n",
      "Epoch 5: Train Loss=0.5037, Train Acc=0.7790 ||| Val Loss=0.5025, Val Acc=0.7953\n",
      "Epoch 6: Train Loss=0.5065, Train Acc=0.7800 ||| Val Loss=0.5112, Val Acc=0.7884\n",
      "Epoch 7: Train Loss=0.4996, Train Acc=0.7824 ||| Val Loss=0.4930, Val Acc=0.7976\n",
      "Epoch 8: Train Loss=0.4924, Train Acc=0.7843 ||| Val Loss=0.4747, Val Acc=0.8005\n",
      "Epoch 9: Train Loss=0.4825, Train Acc=0.7865 ||| Val Loss=0.4778, Val Acc=0.7924\n",
      "Epoch 10: Train Loss=0.4826, Train Acc=0.7876 ||| Val Loss=0.4712, Val Acc=0.7913\n",
      "Epoch 11: Train Loss=0.4790, Train Acc=0.7854 ||| Val Loss=0.4572, Val Acc=0.7941\n",
      "Epoch 12: Train Loss=0.4621, Train Acc=0.7879 ||| Val Loss=0.4597, Val Acc=0.7947\n",
      "Epoch 13: Train Loss=0.4551, Train Acc=0.7893 ||| Val Loss=0.4477, Val Acc=0.8005\n",
      "Epoch 14: Train Loss=0.4518, Train Acc=0.7895 ||| Val Loss=0.4437, Val Acc=0.7999\n",
      "Epoch 15: Train Loss=0.4485, Train Acc=0.7883 ||| Val Loss=0.4436, Val Acc=0.7941\n",
      "Epoch 16: Train Loss=0.4440, Train Acc=0.7939 ||| Val Loss=0.4364, Val Acc=0.7901\n",
      "Epoch 17: Train Loss=0.4399, Train Acc=0.7903 ||| Val Loss=0.4358, Val Acc=0.7993\n",
      "Epoch 18: Train Loss=0.4355, Train Acc=0.7885 ||| Val Loss=0.4320, Val Acc=0.7987\n",
      "Epoch 19: Train Loss=0.4374, Train Acc=0.7936 ||| Val Loss=0.4452, Val Acc=0.7982\n",
      "Epoch 20: Train Loss=0.4353, Train Acc=0.7935 ||| Val Loss=0.4206, Val Acc=0.7970\n",
      "Epoch 21: Train Loss=0.4291, Train Acc=0.7968 ||| Val Loss=0.4315, Val Acc=0.7953\n",
      "Epoch 22: Train Loss=0.4302, Train Acc=0.7931 ||| Val Loss=0.4237, Val Acc=0.8028\n",
      "Epoch 23: Train Loss=0.4270, Train Acc=0.7944 ||| Val Loss=0.4231, Val Acc=0.8005\n",
      "Epoch 24: Train Loss=0.4285, Train Acc=0.7934 ||| Val Loss=0.4212, Val Acc=0.7999\n",
      "Epoch 25: Train Loss=0.4255, Train Acc=0.7926 ||| Val Loss=0.4233, Val Acc=0.7959\n",
      "Epoch 26: Train Loss=0.4240, Train Acc=0.7968 ||| Val Loss=0.4242, Val Acc=0.7953\n",
      "Epoch 27: Train Loss=0.4217, Train Acc=0.7952 ||| Val Loss=0.4304, Val Acc=0.7936\n",
      "Epoch 28: Train Loss=0.4243, Train Acc=0.7954 ||| Val Loss=0.4192, Val Acc=0.7970\n",
      "Epoch 29: Train Loss=0.4222, Train Acc=0.7934 ||| Val Loss=0.4244, Val Acc=0.7987\n",
      "Epoch 30: Train Loss=0.4210, Train Acc=0.7948 ||| Val Loss=0.4181, Val Acc=0.7976\n",
      "Epoch 31: Train Loss=0.4177, Train Acc=0.7981 ||| Val Loss=0.4334, Val Acc=0.8005\n",
      "Epoch 32: Train Loss=0.4202, Train Acc=0.7944 ||| Val Loss=0.4238, Val Acc=0.7941\n",
      "Epoch 33: Train Loss=0.4202, Train Acc=0.7972 ||| Val Loss=0.4224, Val Acc=0.7993\n",
      "Epoch 34: Train Loss=0.4193, Train Acc=0.7970 ||| Val Loss=0.4146, Val Acc=0.7953\n",
      "Epoch 35: Train Loss=0.4148, Train Acc=0.7991 ||| Val Loss=0.4244, Val Acc=0.7999\n",
      "Epoch 36: Train Loss=0.4193, Train Acc=0.7974 ||| Val Loss=0.4251, Val Acc=0.7890\n",
      "Epoch 37: Train Loss=0.4181, Train Acc=0.7962 ||| Val Loss=0.4165, Val Acc=0.7924\n",
      "Epoch 38: Train Loss=0.4188, Train Acc=0.7955 ||| Val Loss=0.4166, Val Acc=0.7936\n",
      "Epoch 39: Train Loss=0.4138, Train Acc=0.7987 ||| Val Loss=0.4124, Val Acc=0.7987\n",
      "Epoch 40: Train Loss=0.4127, Train Acc=0.8020 ||| Val Loss=0.4191, Val Acc=0.7953\n",
      "Epoch 41: Train Loss=0.4163, Train Acc=0.7987 ||| Val Loss=0.4215, Val Acc=0.7976\n",
      "Epoch 42: Train Loss=0.4145, Train Acc=0.8014 ||| Val Loss=0.4165, Val Acc=0.7982\n",
      "Epoch 43: Train Loss=0.4127, Train Acc=0.8010 ||| Val Loss=0.4221, Val Acc=0.7872\n",
      "Epoch 44: Train Loss=0.4161, Train Acc=0.7980 ||| Val Loss=0.4277, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4109, Train Acc=0.8034 ||| Val Loss=0.4176, Val Acc=0.7924\n",
      "Epoch 46: Train Loss=0.4095, Train Acc=0.8010 ||| Val Loss=0.4255, Val Acc=0.7913\n",
      "Epoch 47: Train Loss=0.4107, Train Acc=0.8008 ||| Val Loss=0.4177, Val Acc=0.7970\n",
      "Epoch 48: Train Loss=0.4120, Train Acc=0.7982 ||| Val Loss=0.4147, Val Acc=0.7959\n",
      "Epoch 49: Train Loss=0.4115, Train Acc=0.7997 ||| Val Loss=0.4175, Val Acc=0.8010\n",
      "Epoch 50: Train Loss=0.4100, Train Acc=0.8021 ||| Val Loss=0.4192, Val Acc=0.7959\n",
      "Epoch 51: Train Loss=0.4074, Train Acc=0.7995 ||| Val Loss=0.4165, Val Acc=0.7918\n",
      "Epoch 52: Train Loss=0.4110, Train Acc=0.7987 ||| Val Loss=0.4213, Val Acc=0.7890\n",
      "Epoch 53: Train Loss=0.4066, Train Acc=0.8005 ||| Val Loss=0.4229, Val Acc=0.7970\n",
      "Epoch 54: Train Loss=0.4087, Train Acc=0.7998 ||| Val Loss=0.4123, Val Acc=0.7947\n",
      "Epoch 55: Train Loss=0.4074, Train Acc=0.8077 ||| Val Loss=0.4134, Val Acc=0.7987\n",
      "Epoch 56: Train Loss=0.4099, Train Acc=0.8016 ||| Val Loss=0.4142, Val Acc=0.8033\n",
      "Epoch 57: Train Loss=0.4060, Train Acc=0.8046 ||| Val Loss=0.4206, Val Acc=0.7913\n",
      "Epoch 58: Train Loss=0.4037, Train Acc=0.8049 ||| Val Loss=0.4277, Val Acc=0.7976\n",
      "Epoch 59: Train Loss=0.4046, Train Acc=0.8044 ||| Val Loss=0.4117, Val Acc=0.7982\n",
      "Epoch 60: Train Loss=0.4056, Train Acc=0.8018 ||| Val Loss=0.4143, Val Acc=0.7987\n",
      "Epoch 61: Train Loss=0.4079, Train Acc=0.8037 ||| Val Loss=0.4113, Val Acc=0.7976\n",
      "Epoch 62: Train Loss=0.4031, Train Acc=0.8051 ||| Val Loss=0.4214, Val Acc=0.7982\n",
      "Epoch 63: Train Loss=0.4033, Train Acc=0.8062 ||| Val Loss=0.4128, Val Acc=0.8005\n",
      "Epoch 64: Train Loss=0.4044, Train Acc=0.8047 ||| Val Loss=0.4111, Val Acc=0.7976\n",
      "Epoch 65: Train Loss=0.4021, Train Acc=0.8056 ||| Val Loss=0.4188, Val Acc=0.7993\n",
      "Epoch 66: Train Loss=0.4027, Train Acc=0.8040 ||| Val Loss=0.4202, Val Acc=0.7953\n",
      "Epoch 67: Train Loss=0.4007, Train Acc=0.8016 ||| Val Loss=0.4106, Val Acc=0.7982\n",
      "Epoch 68: Train Loss=0.4033, Train Acc=0.8090 ||| Val Loss=0.4140, Val Acc=0.8010\n",
      "Epoch 69: Train Loss=0.4022, Train Acc=0.8041 ||| Val Loss=0.4172, Val Acc=0.7970\n",
      "Epoch 70: Train Loss=0.4024, Train Acc=0.8062 ||| Val Loss=0.4193, Val Acc=0.7982\n",
      "Epoch 71: Train Loss=0.4010, Train Acc=0.8070 ||| Val Loss=0.4193, Val Acc=0.7970\n",
      "Epoch 72: Train Loss=0.4008, Train Acc=0.8047 ||| Val Loss=0.4206, Val Acc=0.7918\n",
      "Epoch 73: Train Loss=0.4019, Train Acc=0.8041 ||| Val Loss=0.4123, Val Acc=0.8016\n",
      "Epoch 74: Train Loss=0.4031, Train Acc=0.8110 ||| Val Loss=0.4242, Val Acc=0.7993\n",
      "Epoch 75: Train Loss=0.3988, Train Acc=0.8067 ||| Val Loss=0.4109, Val Acc=0.8033\n",
      "Epoch 76: Train Loss=0.3953, Train Acc=0.8095 ||| Val Loss=0.4204, Val Acc=0.7999\n",
      "Epoch 77: Train Loss=0.3943, Train Acc=0.8139 ||| Val Loss=0.4128, Val Acc=0.7970\n",
      "Epoch 78: Train Loss=0.3952, Train Acc=0.8062 ||| Val Loss=0.4212, Val Acc=0.7976\n",
      "Epoch 79: Train Loss=0.4017, Train Acc=0.8087 ||| Val Loss=0.4227, Val Acc=0.7970\n",
      "Epoch 80: Train Loss=0.3976, Train Acc=0.8076 ||| Val Loss=0.4154, Val Acc=0.8028\n",
      "Epoch 81: Train Loss=0.3928, Train Acc=0.8085 ||| Val Loss=0.4177, Val Acc=0.7970\n",
      "Epoch 82: Train Loss=0.3933, Train Acc=0.8139 ||| Val Loss=0.4152, Val Acc=0.8005\n",
      "Epoch 83: Train Loss=0.3941, Train Acc=0.8113 ||| Val Loss=0.4122, Val Acc=0.8051\n",
      "Epoch 84: Train Loss=0.3947, Train Acc=0.8131 ||| Val Loss=0.4188, Val Acc=0.8010\n",
      "Epoch 85: Train Loss=0.3922, Train Acc=0.8149 ||| Val Loss=0.4253, Val Acc=0.8022\n",
      "Epoch 86: Train Loss=0.3951, Train Acc=0.8092 ||| Val Loss=0.4211, Val Acc=0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:13:36,571] Trial 23 finished with value: 0.7993099482461185 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.1532506195603504, 'activation': 'ReLU', 'lr': 0.0016343055351461786, 'weight_decay': 2.9323631794337012e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train Loss=0.3907, Train Acc=0.8133 ||| Val Loss=0.4184, Val Acc=0.7993\n",
      "Early stopping triggered at epoch 87\n",
      "Validation Accuracy: 0.7993\n",
      "\n",
      " Trial 25 with params: {'n_blocks': 4, 'd_block': 128, 'k': 9, 'dropout': 0.17547440704922243, 'activation': 'ReLU', 'lr': 0.0032771537050493306, 'weight_decay': 7.983531635311177e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.8396, Train Acc=0.6845 ||| Val Loss=0.5044, Val Acc=0.7832\n",
      "Epoch 2: Train Loss=0.5370, Train Acc=0.7577 ||| Val Loss=0.5170, Val Acc=0.7700\n",
      "Epoch 3: Train Loss=0.5204, Train Acc=0.7701 ||| Val Loss=0.4927, Val Acc=0.7884\n",
      "Epoch 4: Train Loss=0.5121, Train Acc=0.7754 ||| Val Loss=0.5060, Val Acc=0.7999\n",
      "Epoch 5: Train Loss=0.5099, Train Acc=0.7739 ||| Val Loss=0.4773, Val Acc=0.7890\n",
      "Epoch 6: Train Loss=0.4912, Train Acc=0.7829 ||| Val Loss=0.4835, Val Acc=0.7970\n",
      "Epoch 7: Train Loss=0.4823, Train Acc=0.7833 ||| Val Loss=0.4528, Val Acc=0.7941\n",
      "Epoch 8: Train Loss=0.4794, Train Acc=0.7824 ||| Val Loss=0.4610, Val Acc=0.7924\n",
      "Epoch 9: Train Loss=0.4658, Train Acc=0.7860 ||| Val Loss=0.4493, Val Acc=0.7826\n",
      "Epoch 10: Train Loss=0.4690, Train Acc=0.7893 ||| Val Loss=0.4285, Val Acc=0.7918\n",
      "Epoch 11: Train Loss=0.4477, Train Acc=0.7875 ||| Val Loss=0.4267, Val Acc=0.7941\n",
      "Epoch 12: Train Loss=0.4390, Train Acc=0.7893 ||| Val Loss=0.4240, Val Acc=0.7976\n",
      "Epoch 13: Train Loss=0.4363, Train Acc=0.7925 ||| Val Loss=0.4227, Val Acc=0.7970\n",
      "Epoch 14: Train Loss=0.4298, Train Acc=0.7954 ||| Val Loss=0.4269, Val Acc=0.7999\n",
      "Epoch 15: Train Loss=0.4281, Train Acc=0.7836 ||| Val Loss=0.4256, Val Acc=0.7993\n",
      "Epoch 16: Train Loss=0.4322, Train Acc=0.7938 ||| Val Loss=0.4181, Val Acc=0.7976\n",
      "Epoch 17: Train Loss=0.4312, Train Acc=0.7922 ||| Val Loss=0.4241, Val Acc=0.7970\n",
      "Epoch 18: Train Loss=0.4258, Train Acc=0.7928 ||| Val Loss=0.4217, Val Acc=0.7959\n",
      "Epoch 19: Train Loss=0.4247, Train Acc=0.7955 ||| Val Loss=0.4202, Val Acc=0.7930\n",
      "Epoch 20: Train Loss=0.4257, Train Acc=0.7961 ||| Val Loss=0.4291, Val Acc=0.7964\n",
      "Epoch 21: Train Loss=0.4216, Train Acc=0.7968 ||| Val Loss=0.4222, Val Acc=0.7993\n",
      "Epoch 22: Train Loss=0.4221, Train Acc=0.7957 ||| Val Loss=0.4159, Val Acc=0.7907\n",
      "Epoch 23: Train Loss=0.4194, Train Acc=0.7964 ||| Val Loss=0.4113, Val Acc=0.7930\n",
      "Epoch 24: Train Loss=0.4229, Train Acc=0.7987 ||| Val Loss=0.4077, Val Acc=0.8010\n",
      "Epoch 25: Train Loss=0.4177, Train Acc=0.7959 ||| Val Loss=0.4136, Val Acc=0.7941\n",
      "Epoch 26: Train Loss=0.4167, Train Acc=0.8007 ||| Val Loss=0.4139, Val Acc=0.7982\n",
      "Epoch 27: Train Loss=0.4149, Train Acc=0.8010 ||| Val Loss=0.4117, Val Acc=0.7959\n",
      "Epoch 28: Train Loss=0.4169, Train Acc=0.7994 ||| Val Loss=0.4125, Val Acc=0.7993\n",
      "Epoch 29: Train Loss=0.4143, Train Acc=0.8005 ||| Val Loss=0.4121, Val Acc=0.7970\n",
      "Epoch 30: Train Loss=0.4185, Train Acc=0.7993 ||| Val Loss=0.4165, Val Acc=0.7959\n",
      "Epoch 31: Train Loss=0.4199, Train Acc=0.8008 ||| Val Loss=0.4145, Val Acc=0.7936\n",
      "Epoch 32: Train Loss=0.4211, Train Acc=0.8008 ||| Val Loss=0.4145, Val Acc=0.7930\n",
      "Epoch 33: Train Loss=0.4202, Train Acc=0.7964 ||| Val Loss=0.4222, Val Acc=0.7941\n",
      "Epoch 34: Train Loss=0.4187, Train Acc=0.8043 ||| Val Loss=0.4058, Val Acc=0.7964\n",
      "Epoch 35: Train Loss=0.4127, Train Acc=0.8026 ||| Val Loss=0.4112, Val Acc=0.7970\n",
      "Epoch 36: Train Loss=0.4104, Train Acc=0.7988 ||| Val Loss=0.4186, Val Acc=0.7947\n",
      "Epoch 37: Train Loss=0.4120, Train Acc=0.8007 ||| Val Loss=0.4136, Val Acc=0.7964\n",
      "Epoch 38: Train Loss=0.4107, Train Acc=0.8036 ||| Val Loss=0.4195, Val Acc=0.7999\n",
      "Epoch 39: Train Loss=0.4118, Train Acc=0.8014 ||| Val Loss=0.4221, Val Acc=0.7993\n",
      "Epoch 40: Train Loss=0.4050, Train Acc=0.8053 ||| Val Loss=0.4056, Val Acc=0.8022\n",
      "Epoch 41: Train Loss=0.4084, Train Acc=0.8043 ||| Val Loss=0.4177, Val Acc=0.7993\n",
      "Epoch 42: Train Loss=0.4095, Train Acc=0.8054 ||| Val Loss=0.4082, Val Acc=0.7982\n",
      "Epoch 43: Train Loss=0.4067, Train Acc=0.8069 ||| Val Loss=0.4090, Val Acc=0.8033\n",
      "Epoch 44: Train Loss=0.4092, Train Acc=0.8096 ||| Val Loss=0.4122, Val Acc=0.8039\n",
      "Epoch 45: Train Loss=0.4075, Train Acc=0.8080 ||| Val Loss=0.4134, Val Acc=0.7924\n",
      "Epoch 46: Train Loss=0.4077, Train Acc=0.8073 ||| Val Loss=0.4154, Val Acc=0.8039\n",
      "Epoch 47: Train Loss=0.4043, Train Acc=0.8099 ||| Val Loss=0.4155, Val Acc=0.8056\n",
      "Epoch 48: Train Loss=0.4042, Train Acc=0.8049 ||| Val Loss=0.4109, Val Acc=0.8005\n",
      "Epoch 49: Train Loss=0.4059, Train Acc=0.8062 ||| Val Loss=0.4049, Val Acc=0.8033\n",
      "Epoch 50: Train Loss=0.4055, Train Acc=0.8053 ||| Val Loss=0.4090, Val Acc=0.8028\n",
      "Epoch 51: Train Loss=0.4018, Train Acc=0.8070 ||| Val Loss=0.4038, Val Acc=0.8097\n",
      "Epoch 52: Train Loss=0.4010, Train Acc=0.8063 ||| Val Loss=0.4098, Val Acc=0.8085\n",
      "Epoch 53: Train Loss=0.4030, Train Acc=0.8051 ||| Val Loss=0.4153, Val Acc=0.8062\n",
      "Epoch 54: Train Loss=0.4002, Train Acc=0.8097 ||| Val Loss=0.4099, Val Acc=0.7987\n",
      "Epoch 55: Train Loss=0.4018, Train Acc=0.8077 ||| Val Loss=0.4149, Val Acc=0.8091\n",
      "Epoch 56: Train Loss=0.4022, Train Acc=0.8119 ||| Val Loss=0.4094, Val Acc=0.8079\n",
      "Epoch 57: Train Loss=0.4008, Train Acc=0.8079 ||| Val Loss=0.4094, Val Acc=0.8045\n",
      "Epoch 58: Train Loss=0.4057, Train Acc=0.8090 ||| Val Loss=0.4147, Val Acc=0.8056\n",
      "Epoch 59: Train Loss=0.4002, Train Acc=0.8105 ||| Val Loss=0.4141, Val Acc=0.8097\n",
      "Epoch 60: Train Loss=0.3997, Train Acc=0.8087 ||| Val Loss=0.4094, Val Acc=0.8108\n",
      "Epoch 61: Train Loss=0.3994, Train Acc=0.8079 ||| Val Loss=0.4077, Val Acc=0.8074\n",
      "Epoch 62: Train Loss=0.3971, Train Acc=0.8155 ||| Val Loss=0.4198, Val Acc=0.8039\n",
      "Epoch 63: Train Loss=0.3975, Train Acc=0.8125 ||| Val Loss=0.4133, Val Acc=0.8022\n",
      "Epoch 64: Train Loss=0.3978, Train Acc=0.8090 ||| Val Loss=0.4191, Val Acc=0.8137\n",
      "Epoch 65: Train Loss=0.3941, Train Acc=0.8148 ||| Val Loss=0.4205, Val Acc=0.8045\n",
      "Epoch 66: Train Loss=0.3937, Train Acc=0.8121 ||| Val Loss=0.4156, Val Acc=0.8074\n",
      "Epoch 67: Train Loss=0.3942, Train Acc=0.8133 ||| Val Loss=0.4133, Val Acc=0.8108\n",
      "Epoch 68: Train Loss=0.3938, Train Acc=0.8119 ||| Val Loss=0.4106, Val Acc=0.8097\n",
      "Epoch 69: Train Loss=0.3951, Train Acc=0.8118 ||| Val Loss=0.4071, Val Acc=0.8074\n",
      "Epoch 70: Train Loss=0.3903, Train Acc=0.8119 ||| Val Loss=0.4140, Val Acc=0.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:13:57,584] Trial 24 finished with value: 0.8062104657849338 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 9, 'dropout': 0.17547440704922243, 'activation': 'ReLU', 'lr': 0.0032771537050493306, 'weight_decay': 7.983531635311177e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train Loss=0.3919, Train Acc=0.8072 ||| Val Loss=0.4115, Val Acc=0.8062\n",
      "Early stopping triggered at epoch 71\n",
      "Validation Accuracy: 0.8062\n",
      "\n",
      " Trial 26 with params: {'n_blocks': 4, 'd_block': 128, 'k': 8, 'dropout': 0.11034959771817207, 'activation': 'LeakyReLU', 'lr': 0.002156236699487219, 'weight_decay': 2.605006821979682e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.8040, Train Acc=0.6980 ||| Val Loss=0.5074, Val Acc=0.7901\n",
      "Epoch 2: Train Loss=0.5335, Train Acc=0.7577 ||| Val Loss=0.4992, Val Acc=0.7959\n",
      "Epoch 3: Train Loss=0.5187, Train Acc=0.7683 ||| Val Loss=0.4884, Val Acc=0.7924\n",
      "Epoch 4: Train Loss=0.5081, Train Acc=0.7729 ||| Val Loss=0.4940, Val Acc=0.7907\n",
      "Epoch 5: Train Loss=0.5050, Train Acc=0.7771 ||| Val Loss=0.4910, Val Acc=0.7890\n",
      "Epoch 6: Train Loss=0.4983, Train Acc=0.7826 ||| Val Loss=0.4708, Val Acc=0.7999\n",
      "Epoch 7: Train Loss=0.4844, Train Acc=0.7839 ||| Val Loss=0.4758, Val Acc=0.7941\n",
      "Epoch 8: Train Loss=0.4802, Train Acc=0.7817 ||| Val Loss=0.4569, Val Acc=0.7913\n",
      "Epoch 9: Train Loss=0.4672, Train Acc=0.7824 ||| Val Loss=0.4620, Val Acc=0.7964\n",
      "Epoch 10: Train Loss=0.4609, Train Acc=0.7866 ||| Val Loss=0.4464, Val Acc=0.7959\n",
      "Epoch 11: Train Loss=0.4465, Train Acc=0.7854 ||| Val Loss=0.4396, Val Acc=0.7947\n",
      "Epoch 12: Train Loss=0.4552, Train Acc=0.7849 ||| Val Loss=0.4525, Val Acc=0.7740\n",
      "Epoch 13: Train Loss=0.4357, Train Acc=0.7865 ||| Val Loss=0.4429, Val Acc=0.7936\n",
      "Epoch 14: Train Loss=0.4430, Train Acc=0.7867 ||| Val Loss=0.4411, Val Acc=0.7947\n",
      "Epoch 15: Train Loss=0.4348, Train Acc=0.7895 ||| Val Loss=0.4378, Val Acc=0.7913\n",
      "Epoch 16: Train Loss=0.4292, Train Acc=0.7909 ||| Val Loss=0.4568, Val Acc=0.7941\n",
      "Epoch 17: Train Loss=0.4307, Train Acc=0.7944 ||| Val Loss=0.4227, Val Acc=0.7982\n",
      "Epoch 18: Train Loss=0.4275, Train Acc=0.7925 ||| Val Loss=0.4598, Val Acc=0.7936\n",
      "Epoch 19: Train Loss=0.4298, Train Acc=0.7913 ||| Val Loss=0.4316, Val Acc=0.7941\n",
      "Epoch 20: Train Loss=0.4225, Train Acc=0.7957 ||| Val Loss=0.4253, Val Acc=0.8039\n",
      "Epoch 21: Train Loss=0.4268, Train Acc=0.7912 ||| Val Loss=0.4211, Val Acc=0.7947\n",
      "Epoch 22: Train Loss=0.4208, Train Acc=0.7968 ||| Val Loss=0.4285, Val Acc=0.7970\n",
      "Epoch 23: Train Loss=0.4212, Train Acc=0.7968 ||| Val Loss=0.4257, Val Acc=0.7959\n",
      "Epoch 24: Train Loss=0.4255, Train Acc=0.7955 ||| Val Loss=0.4254, Val Acc=0.7976\n",
      "Epoch 25: Train Loss=0.4218, Train Acc=0.7939 ||| Val Loss=0.4208, Val Acc=0.7970\n",
      "Epoch 26: Train Loss=0.4185, Train Acc=0.7957 ||| Val Loss=0.4254, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4241, Train Acc=0.7954 ||| Val Loss=0.4161, Val Acc=0.7930\n",
      "Epoch 28: Train Loss=0.4181, Train Acc=0.7970 ||| Val Loss=0.4180, Val Acc=0.7987\n",
      "Epoch 29: Train Loss=0.4180, Train Acc=0.8014 ||| Val Loss=0.4260, Val Acc=0.7964\n",
      "Epoch 30: Train Loss=0.4200, Train Acc=0.7980 ||| Val Loss=0.4190, Val Acc=0.7947\n",
      "Epoch 31: Train Loss=0.4199, Train Acc=0.7938 ||| Val Loss=0.4139, Val Acc=0.7964\n",
      "Epoch 32: Train Loss=0.4174, Train Acc=0.7954 ||| Val Loss=0.4218, Val Acc=0.7959\n",
      "Epoch 33: Train Loss=0.4142, Train Acc=0.8008 ||| Val Loss=0.4179, Val Acc=0.7993\n",
      "Epoch 34: Train Loss=0.4172, Train Acc=0.7978 ||| Val Loss=0.4157, Val Acc=0.7976\n",
      "Epoch 35: Train Loss=0.4157, Train Acc=0.7962 ||| Val Loss=0.4117, Val Acc=0.7982\n",
      "Epoch 36: Train Loss=0.4129, Train Acc=0.8000 ||| Val Loss=0.4176, Val Acc=0.7941\n",
      "Epoch 37: Train Loss=0.4173, Train Acc=0.7990 ||| Val Loss=0.4257, Val Acc=0.7953\n",
      "Epoch 38: Train Loss=0.4162, Train Acc=0.7975 ||| Val Loss=0.4153, Val Acc=0.7953\n",
      "Epoch 39: Train Loss=0.4136, Train Acc=0.8031 ||| Val Loss=0.4134, Val Acc=0.7993\n",
      "Epoch 40: Train Loss=0.4126, Train Acc=0.8004 ||| Val Loss=0.4096, Val Acc=0.7976\n",
      "Epoch 41: Train Loss=0.4094, Train Acc=0.8017 ||| Val Loss=0.4204, Val Acc=0.7964\n",
      "Epoch 42: Train Loss=0.4121, Train Acc=0.7987 ||| Val Loss=0.4270, Val Acc=0.7941\n",
      "Epoch 43: Train Loss=0.4135, Train Acc=0.8001 ||| Val Loss=0.4109, Val Acc=0.7964\n",
      "Epoch 44: Train Loss=0.4131, Train Acc=0.7984 ||| Val Loss=0.4113, Val Acc=0.7993\n",
      "Epoch 45: Train Loss=0.4088, Train Acc=0.8005 ||| Val Loss=0.4155, Val Acc=0.8039\n",
      "Epoch 46: Train Loss=0.4088, Train Acc=0.8014 ||| Val Loss=0.4077, Val Acc=0.8022\n",
      "Epoch 47: Train Loss=0.4082, Train Acc=0.8008 ||| Val Loss=0.4132, Val Acc=0.7987\n",
      "Epoch 48: Train Loss=0.4073, Train Acc=0.8004 ||| Val Loss=0.4247, Val Acc=0.7970\n",
      "Epoch 49: Train Loss=0.4056, Train Acc=0.8017 ||| Val Loss=0.4241, Val Acc=0.7976\n",
      "Epoch 50: Train Loss=0.4045, Train Acc=0.8018 ||| Val Loss=0.4146, Val Acc=0.7999\n",
      "Epoch 51: Train Loss=0.4077, Train Acc=0.8043 ||| Val Loss=0.4093, Val Acc=0.7976\n",
      "Epoch 52: Train Loss=0.4043, Train Acc=0.8014 ||| Val Loss=0.4112, Val Acc=0.8005\n",
      "Epoch 53: Train Loss=0.4079, Train Acc=0.7985 ||| Val Loss=0.4084, Val Acc=0.8016\n",
      "Epoch 54: Train Loss=0.4054, Train Acc=0.8008 ||| Val Loss=0.4140, Val Acc=0.7987\n",
      "Epoch 55: Train Loss=0.4017, Train Acc=0.8047 ||| Val Loss=0.4390, Val Acc=0.7993\n",
      "Epoch 56: Train Loss=0.4044, Train Acc=0.8003 ||| Val Loss=0.4096, Val Acc=0.8010\n",
      "Epoch 57: Train Loss=0.4032, Train Acc=0.8017 ||| Val Loss=0.4107, Val Acc=0.8016\n",
      "Epoch 58: Train Loss=0.4010, Train Acc=0.8011 ||| Val Loss=0.4211, Val Acc=0.7947\n",
      "Epoch 59: Train Loss=0.4051, Train Acc=0.8024 ||| Val Loss=0.4157, Val Acc=0.8022\n",
      "Epoch 60: Train Loss=0.3967, Train Acc=0.8023 ||| Val Loss=0.4177, Val Acc=0.8028\n",
      "Epoch 61: Train Loss=0.4000, Train Acc=0.8026 ||| Val Loss=0.4133, Val Acc=0.7999\n",
      "Epoch 62: Train Loss=0.4007, Train Acc=0.8051 ||| Val Loss=0.4140, Val Acc=0.7987\n",
      "Epoch 63: Train Loss=0.4027, Train Acc=0.8027 ||| Val Loss=0.4380, Val Acc=0.8028\n",
      "Epoch 64: Train Loss=0.3989, Train Acc=0.7994 ||| Val Loss=0.4263, Val Acc=0.7907\n",
      "Epoch 65: Train Loss=0.3965, Train Acc=0.8044 ||| Val Loss=0.4219, Val Acc=0.8010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:14:16,190] Trial 25 finished with value: 0.79700977573318 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 8, 'dropout': 0.11034959771817207, 'activation': 'LeakyReLU', 'lr': 0.002156236699487219, 'weight_decay': 2.605006821979682e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train Loss=0.4031, Train Acc=0.8064 ||| Val Loss=0.4166, Val Acc=0.7970\n",
      "Early stopping triggered at epoch 66\n",
      "Validation Accuracy: 0.7970\n",
      "\n",
      " Trial 27 with params: {'n_blocks': 3, 'd_block': 128, 'k': 10, 'dropout': 0.2588240720542714, 'activation': 'ReLU', 'lr': 0.0006853961787791875, 'weight_decay': 9.177083287946332e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.6575, Train Acc=0.6309 ||| Val Loss=0.5671, Val Acc=0.7671\n",
      "Epoch 2: Train Loss=1.0008, Train Acc=0.6654 ||| Val Loss=0.5432, Val Acc=0.7711\n",
      "Epoch 3: Train Loss=0.7500, Train Acc=0.6674 ||| Val Loss=0.5661, Val Acc=0.7476\n",
      "Epoch 4: Train Loss=0.6539, Train Acc=0.6871 ||| Val Loss=0.5552, Val Acc=0.7355\n",
      "Epoch 5: Train Loss=0.6054, Train Acc=0.7137 ||| Val Loss=0.5469, Val Acc=0.7671\n",
      "Epoch 6: Train Loss=0.5820, Train Acc=0.7236 ||| Val Loss=0.5431, Val Acc=0.7717\n",
      "Epoch 7: Train Loss=0.5634, Train Acc=0.7274 ||| Val Loss=0.5258, Val Acc=0.7809\n",
      "Epoch 8: Train Loss=0.5422, Train Acc=0.7481 ||| Val Loss=0.5223, Val Acc=0.7849\n",
      "Epoch 9: Train Loss=0.5462, Train Acc=0.7494 ||| Val Loss=0.5189, Val Acc=0.7826\n",
      "Epoch 10: Train Loss=0.5364, Train Acc=0.7573 ||| Val Loss=0.5276, Val Acc=0.7913\n",
      "Epoch 11: Train Loss=0.5323, Train Acc=0.7567 ||| Val Loss=0.5085, Val Acc=0.7901\n",
      "Epoch 12: Train Loss=0.5203, Train Acc=0.7647 ||| Val Loss=0.5035, Val Acc=0.7890\n",
      "Epoch 13: Train Loss=0.5305, Train Acc=0.7630 ||| Val Loss=0.5095, Val Acc=0.7821\n",
      "Epoch 14: Train Loss=0.5180, Train Acc=0.7683 ||| Val Loss=0.4965, Val Acc=0.7913\n",
      "Epoch 15: Train Loss=0.5120, Train Acc=0.7706 ||| Val Loss=0.5032, Val Acc=0.7855\n",
      "Epoch 16: Train Loss=0.5168, Train Acc=0.7712 ||| Val Loss=0.4993, Val Acc=0.7849\n",
      "Epoch 17: Train Loss=0.5086, Train Acc=0.7755 ||| Val Loss=0.4889, Val Acc=0.7918\n",
      "Epoch 18: Train Loss=0.5067, Train Acc=0.7762 ||| Val Loss=0.4927, Val Acc=0.7884\n",
      "Epoch 19: Train Loss=0.5087, Train Acc=0.7725 ||| Val Loss=0.4937, Val Acc=0.7890\n",
      "Epoch 20: Train Loss=0.5049, Train Acc=0.7747 ||| Val Loss=0.4821, Val Acc=0.7901\n",
      "Epoch 21: Train Loss=0.5029, Train Acc=0.7783 ||| Val Loss=0.4909, Val Acc=0.7878\n",
      "Epoch 22: Train Loss=0.5004, Train Acc=0.7810 ||| Val Loss=0.4840, Val Acc=0.7907\n",
      "Epoch 23: Train Loss=0.4970, Train Acc=0.7808 ||| Val Loss=0.4821, Val Acc=0.7953\n",
      "Epoch 24: Train Loss=0.4970, Train Acc=0.7796 ||| Val Loss=0.4837, Val Acc=0.7855\n",
      "Epoch 25: Train Loss=0.4923, Train Acc=0.7823 ||| Val Loss=0.4812, Val Acc=0.7918\n",
      "Epoch 26: Train Loss=0.4939, Train Acc=0.7806 ||| Val Loss=0.4842, Val Acc=0.7924\n",
      "Epoch 27: Train Loss=0.4861, Train Acc=0.7830 ||| Val Loss=0.4769, Val Acc=0.7901\n",
      "Epoch 28: Train Loss=0.4877, Train Acc=0.7826 ||| Val Loss=0.4765, Val Acc=0.7953\n",
      "Epoch 29: Train Loss=0.4831, Train Acc=0.7834 ||| Val Loss=0.4727, Val Acc=0.7901\n",
      "Epoch 30: Train Loss=0.4825, Train Acc=0.7819 ||| Val Loss=0.4752, Val Acc=0.7895\n",
      "Epoch 31: Train Loss=0.4792, Train Acc=0.7836 ||| Val Loss=0.4706, Val Acc=0.7982\n",
      "Epoch 32: Train Loss=0.4765, Train Acc=0.7854 ||| Val Loss=0.4686, Val Acc=0.7924\n",
      "Epoch 33: Train Loss=0.4750, Train Acc=0.7875 ||| Val Loss=0.4603, Val Acc=0.7924\n",
      "Epoch 34: Train Loss=0.4722, Train Acc=0.7870 ||| Val Loss=0.4599, Val Acc=0.7970\n",
      "Epoch 35: Train Loss=0.4666, Train Acc=0.7843 ||| Val Loss=0.4540, Val Acc=0.7941\n",
      "Epoch 36: Train Loss=0.4679, Train Acc=0.7843 ||| Val Loss=0.4506, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4592, Train Acc=0.7862 ||| Val Loss=0.4438, Val Acc=0.7959\n",
      "Epoch 38: Train Loss=0.4546, Train Acc=0.7847 ||| Val Loss=0.4443, Val Acc=0.7924\n",
      "Epoch 39: Train Loss=0.4556, Train Acc=0.7854 ||| Val Loss=0.4444, Val Acc=0.7987\n",
      "Epoch 40: Train Loss=0.4518, Train Acc=0.7890 ||| Val Loss=0.4521, Val Acc=0.8005\n",
      "Epoch 41: Train Loss=0.4486, Train Acc=0.7873 ||| Val Loss=0.4387, Val Acc=0.7982\n",
      "Epoch 42: Train Loss=0.4472, Train Acc=0.7876 ||| Val Loss=0.4383, Val Acc=0.7987\n",
      "Epoch 43: Train Loss=0.4488, Train Acc=0.7875 ||| Val Loss=0.4363, Val Acc=0.7982\n",
      "Epoch 44: Train Loss=0.4399, Train Acc=0.7892 ||| Val Loss=0.4312, Val Acc=0.7987\n",
      "Epoch 45: Train Loss=0.4400, Train Acc=0.7929 ||| Val Loss=0.4343, Val Acc=0.7959\n",
      "Epoch 46: Train Loss=0.4415, Train Acc=0.7912 ||| Val Loss=0.4352, Val Acc=0.7999\n",
      "Epoch 47: Train Loss=0.4367, Train Acc=0.7931 ||| Val Loss=0.4319, Val Acc=0.7999\n",
      "Epoch 48: Train Loss=0.4317, Train Acc=0.7923 ||| Val Loss=0.4439, Val Acc=0.7976\n",
      "Epoch 49: Train Loss=0.4343, Train Acc=0.7909 ||| Val Loss=0.4330, Val Acc=0.7953\n",
      "Epoch 50: Train Loss=0.4346, Train Acc=0.7915 ||| Val Loss=0.4382, Val Acc=0.7953\n",
      "Epoch 51: Train Loss=0.4346, Train Acc=0.7938 ||| Val Loss=0.4292, Val Acc=0.7953\n",
      "Epoch 52: Train Loss=0.4337, Train Acc=0.7926 ||| Val Loss=0.4331, Val Acc=0.7976\n",
      "Epoch 53: Train Loss=0.4297, Train Acc=0.7967 ||| Val Loss=0.4281, Val Acc=0.7953\n",
      "Epoch 54: Train Loss=0.4317, Train Acc=0.7918 ||| Val Loss=0.4402, Val Acc=0.7901\n",
      "Epoch 55: Train Loss=0.4294, Train Acc=0.7911 ||| Val Loss=0.4290, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4270, Train Acc=0.7944 ||| Val Loss=0.4327, Val Acc=0.7987\n",
      "Epoch 57: Train Loss=0.4284, Train Acc=0.7934 ||| Val Loss=0.4257, Val Acc=0.7941\n",
      "Epoch 58: Train Loss=0.4265, Train Acc=0.7935 ||| Val Loss=0.4343, Val Acc=0.7976\n",
      "Epoch 59: Train Loss=0.4309, Train Acc=0.7944 ||| Val Loss=0.4314, Val Acc=0.7907\n",
      "Epoch 60: Train Loss=0.4256, Train Acc=0.7915 ||| Val Loss=0.4281, Val Acc=0.7976\n",
      "Epoch 61: Train Loss=0.4275, Train Acc=0.7944 ||| Val Loss=0.4269, Val Acc=0.7924\n",
      "Epoch 62: Train Loss=0.4295, Train Acc=0.7932 ||| Val Loss=0.4308, Val Acc=0.7959\n",
      "Epoch 63: Train Loss=0.4233, Train Acc=0.7955 ||| Val Loss=0.4248, Val Acc=0.7924\n",
      "Epoch 64: Train Loss=0.4250, Train Acc=0.7926 ||| Val Loss=0.4247, Val Acc=0.7970\n",
      "Epoch 65: Train Loss=0.4220, Train Acc=0.7964 ||| Val Loss=0.4263, Val Acc=0.7976\n",
      "Epoch 66: Train Loss=0.4228, Train Acc=0.7978 ||| Val Loss=0.4340, Val Acc=0.8033\n",
      "Epoch 67: Train Loss=0.4237, Train Acc=0.7936 ||| Val Loss=0.4259, Val Acc=0.8022\n",
      "Epoch 68: Train Loss=0.4199, Train Acc=0.8003 ||| Val Loss=0.4253, Val Acc=0.7947\n",
      "Epoch 69: Train Loss=0.4229, Train Acc=0.7925 ||| Val Loss=0.4235, Val Acc=0.7976\n",
      "Epoch 70: Train Loss=0.4197, Train Acc=0.7916 ||| Val Loss=0.4265, Val Acc=0.7924\n",
      "Epoch 71: Train Loss=0.4182, Train Acc=0.7988 ||| Val Loss=0.4254, Val Acc=0.8022\n",
      "Epoch 72: Train Loss=0.4201, Train Acc=0.7978 ||| Val Loss=0.4236, Val Acc=0.7970\n",
      "Epoch 73: Train Loss=0.4222, Train Acc=0.7998 ||| Val Loss=0.4224, Val Acc=0.8028\n",
      "Epoch 74: Train Loss=0.4200, Train Acc=0.7981 ||| Val Loss=0.4260, Val Acc=0.7941\n",
      "Epoch 75: Train Loss=0.4194, Train Acc=0.7965 ||| Val Loss=0.4268, Val Acc=0.7930\n",
      "Epoch 76: Train Loss=0.4180, Train Acc=0.7982 ||| Val Loss=0.4265, Val Acc=0.7895\n",
      "Epoch 77: Train Loss=0.4181, Train Acc=0.7926 ||| Val Loss=0.4204, Val Acc=0.7999\n",
      "Epoch 78: Train Loss=0.4174, Train Acc=0.7968 ||| Val Loss=0.4214, Val Acc=0.7999\n",
      "Epoch 79: Train Loss=0.4188, Train Acc=0.7981 ||| Val Loss=0.4268, Val Acc=0.7947\n",
      "Epoch 80: Train Loss=0.4186, Train Acc=0.7962 ||| Val Loss=0.4272, Val Acc=0.7953\n",
      "Epoch 81: Train Loss=0.4216, Train Acc=0.7944 ||| Val Loss=0.4256, Val Acc=0.7959\n",
      "Epoch 82: Train Loss=0.4182, Train Acc=0.7926 ||| Val Loss=0.4273, Val Acc=0.7976\n",
      "Epoch 83: Train Loss=0.4165, Train Acc=0.7958 ||| Val Loss=0.4250, Val Acc=0.7936\n",
      "Epoch 84: Train Loss=0.4173, Train Acc=0.8026 ||| Val Loss=0.4191, Val Acc=0.8010\n",
      "Epoch 85: Train Loss=0.4182, Train Acc=0.7971 ||| Val Loss=0.4211, Val Acc=0.7993\n",
      "Epoch 86: Train Loss=0.4140, Train Acc=0.7991 ||| Val Loss=0.4225, Val Acc=0.7982\n",
      "Epoch 87: Train Loss=0.4146, Train Acc=0.7990 ||| Val Loss=0.4264, Val Acc=0.7976\n",
      "Epoch 88: Train Loss=0.4172, Train Acc=0.7974 ||| Val Loss=0.4235, Val Acc=0.7964\n",
      "Epoch 89: Train Loss=0.4128, Train Acc=0.7948 ||| Val Loss=0.4215, Val Acc=0.7976\n",
      "Epoch 90: Train Loss=0.4150, Train Acc=0.8033 ||| Val Loss=0.4213, Val Acc=0.8022\n",
      "Epoch 91: Train Loss=0.4164, Train Acc=0.8007 ||| Val Loss=0.4248, Val Acc=0.7999\n",
      "Epoch 92: Train Loss=0.4164, Train Acc=0.8000 ||| Val Loss=0.4201, Val Acc=0.7970\n",
      "Epoch 93: Train Loss=0.4113, Train Acc=0.7972 ||| Val Loss=0.4207, Val Acc=0.8039\n",
      "Epoch 94: Train Loss=0.4140, Train Acc=0.7945 ||| Val Loss=0.4332, Val Acc=0.7941\n",
      "Epoch 95: Train Loss=0.4138, Train Acc=0.7975 ||| Val Loss=0.4247, Val Acc=0.7941\n",
      "Epoch 96: Train Loss=0.4180, Train Acc=0.8003 ||| Val Loss=0.4221, Val Acc=0.7936\n",
      "Epoch 97: Train Loss=0.4114, Train Acc=0.8003 ||| Val Loss=0.4241, Val Acc=0.7959\n",
      "Epoch 98: Train Loss=0.4158, Train Acc=0.7967 ||| Val Loss=0.4208, Val Acc=0.8062\n",
      "Epoch 99: Train Loss=0.4116, Train Acc=0.7978 ||| Val Loss=0.4212, Val Acc=0.7987\n",
      "Epoch 100: Train Loss=0.4088, Train Acc=0.8001 ||| Val Loss=0.4255, Val Acc=0.8016\n",
      "Epoch 101: Train Loss=0.4105, Train Acc=0.8010 ||| Val Loss=0.4224, Val Acc=0.7999\n",
      "Epoch 102: Train Loss=0.4117, Train Acc=0.8014 ||| Val Loss=0.4224, Val Acc=0.7953\n",
      "Epoch 103: Train Loss=0.4126, Train Acc=0.7995 ||| Val Loss=0.4219, Val Acc=0.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:14:42,191] Trial 26 finished with value: 0.7987349051178838 and parameters: {'n_blocks': 3, 'd_block': 128, 'k': 10, 'dropout': 0.2588240720542714, 'activation': 'ReLU', 'lr': 0.0006853961787791875, 'weight_decay': 9.177083287946332e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: Train Loss=0.4104, Train Acc=0.8013 ||| Val Loss=0.4198, Val Acc=0.7987\n",
      "Early stopping triggered at epoch 104\n",
      "Validation Accuracy: 0.7987\n",
      "\n",
      " Trial 28 with params: {'n_blocks': 5, 'd_block': 512, 'k': 9, 'dropout': 0.2078537782803282, 'activation': 'ReLU', 'lr': 0.0014908074450939784, 'weight_decay': 2.2289399936271573e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.1752, Train Acc=0.6828 ||| Val Loss=0.5301, Val Acc=0.7849\n",
      "Epoch 2: Train Loss=0.5413, Train Acc=0.7561 ||| Val Loss=0.5421, Val Acc=0.7953\n",
      "Epoch 3: Train Loss=0.5329, Train Acc=0.7696 ||| Val Loss=0.5197, Val Acc=0.7884\n",
      "Epoch 4: Train Loss=0.5176, Train Acc=0.7714 ||| Val Loss=0.5029, Val Acc=0.7890\n",
      "Epoch 5: Train Loss=0.5094, Train Acc=0.7813 ||| Val Loss=0.4931, Val Acc=0.7901\n",
      "Epoch 6: Train Loss=0.5004, Train Acc=0.7794 ||| Val Loss=0.4951, Val Acc=0.7907\n",
      "Epoch 7: Train Loss=0.5028, Train Acc=0.7780 ||| Val Loss=0.4878, Val Acc=0.7941\n",
      "Epoch 8: Train Loss=0.4923, Train Acc=0.7819 ||| Val Loss=0.4642, Val Acc=0.7953\n",
      "Epoch 9: Train Loss=0.4919, Train Acc=0.7824 ||| Val Loss=0.4905, Val Acc=0.7844\n",
      "Epoch 10: Train Loss=0.4829, Train Acc=0.7872 ||| Val Loss=0.4612, Val Acc=0.7947\n",
      "Epoch 11: Train Loss=0.4877, Train Acc=0.7880 ||| Val Loss=0.4526, Val Acc=0.7959\n",
      "Epoch 12: Train Loss=0.4700, Train Acc=0.7873 ||| Val Loss=0.4677, Val Acc=0.7959\n",
      "Epoch 13: Train Loss=0.4638, Train Acc=0.7873 ||| Val Loss=0.4468, Val Acc=0.8016\n",
      "Epoch 14: Train Loss=0.4642, Train Acc=0.7870 ||| Val Loss=0.4443, Val Acc=0.7936\n",
      "Epoch 15: Train Loss=0.4579, Train Acc=0.7905 ||| Val Loss=0.4374, Val Acc=0.7924\n",
      "Epoch 16: Train Loss=0.4610, Train Acc=0.7911 ||| Val Loss=0.4445, Val Acc=0.7941\n",
      "Epoch 17: Train Loss=0.4519, Train Acc=0.7880 ||| Val Loss=0.4452, Val Acc=0.7890\n",
      "Epoch 18: Train Loss=0.4577, Train Acc=0.7942 ||| Val Loss=0.4459, Val Acc=0.7982\n",
      "Epoch 19: Train Loss=0.4457, Train Acc=0.7913 ||| Val Loss=0.4457, Val Acc=0.7987\n",
      "Epoch 20: Train Loss=0.4421, Train Acc=0.7925 ||| Val Loss=0.4364, Val Acc=0.7941\n",
      "Epoch 21: Train Loss=0.4464, Train Acc=0.7945 ||| Val Loss=0.4332, Val Acc=0.7964\n",
      "Epoch 22: Train Loss=0.4327, Train Acc=0.7932 ||| Val Loss=0.4447, Val Acc=0.7970\n",
      "Epoch 23: Train Loss=0.4353, Train Acc=0.7942 ||| Val Loss=0.4294, Val Acc=0.7959\n",
      "Epoch 24: Train Loss=0.4339, Train Acc=0.7965 ||| Val Loss=0.4235, Val Acc=0.7953\n",
      "Epoch 25: Train Loss=0.4336, Train Acc=0.7908 ||| Val Loss=0.4363, Val Acc=0.7976\n",
      "Epoch 26: Train Loss=0.4332, Train Acc=0.7948 ||| Val Loss=0.4273, Val Acc=0.7941\n",
      "Epoch 27: Train Loss=0.4259, Train Acc=0.7987 ||| Val Loss=0.4170, Val Acc=0.7941\n",
      "Epoch 28: Train Loss=0.4292, Train Acc=0.7941 ||| Val Loss=0.4278, Val Acc=0.7999\n",
      "Epoch 29: Train Loss=0.4258, Train Acc=0.7938 ||| Val Loss=0.4242, Val Acc=0.7970\n",
      "Epoch 30: Train Loss=0.4275, Train Acc=0.7939 ||| Val Loss=0.4228, Val Acc=0.7970\n",
      "Epoch 31: Train Loss=0.4258, Train Acc=0.7923 ||| Val Loss=0.4270, Val Acc=0.7953\n",
      "Epoch 32: Train Loss=0.4287, Train Acc=0.7967 ||| Val Loss=0.4202, Val Acc=0.7970\n",
      "Epoch 33: Train Loss=0.4263, Train Acc=0.7932 ||| Val Loss=0.4218, Val Acc=0.8010\n",
      "Epoch 34: Train Loss=0.4248, Train Acc=0.7962 ||| Val Loss=0.4367, Val Acc=0.7976\n",
      "Epoch 35: Train Loss=0.4220, Train Acc=0.7974 ||| Val Loss=0.4210, Val Acc=0.7959\n",
      "Epoch 36: Train Loss=0.4180, Train Acc=0.7968 ||| Val Loss=0.4209, Val Acc=0.7999\n",
      "Epoch 37: Train Loss=0.4215, Train Acc=0.7974 ||| Val Loss=0.4165, Val Acc=0.7953\n",
      "Epoch 38: Train Loss=0.4243, Train Acc=0.7936 ||| Val Loss=0.4315, Val Acc=0.7976\n",
      "Epoch 39: Train Loss=0.4317, Train Acc=0.7965 ||| Val Loss=0.4215, Val Acc=0.7964\n",
      "Epoch 40: Train Loss=0.4212, Train Acc=0.7964 ||| Val Loss=0.4422, Val Acc=0.7964\n",
      "Epoch 41: Train Loss=0.4288, Train Acc=0.7941 ||| Val Loss=0.4271, Val Acc=0.7987\n",
      "Epoch 42: Train Loss=0.4243, Train Acc=0.7987 ||| Val Loss=0.4209, Val Acc=0.7970\n",
      "Epoch 43: Train Loss=0.4178, Train Acc=0.7977 ||| Val Loss=0.4251, Val Acc=0.8010\n",
      "Epoch 44: Train Loss=0.4150, Train Acc=0.8001 ||| Val Loss=0.4140, Val Acc=0.8016\n",
      "Epoch 45: Train Loss=0.4205, Train Acc=0.7954 ||| Val Loss=0.4363, Val Acc=0.7832\n",
      "Epoch 46: Train Loss=0.4185, Train Acc=0.7971 ||| Val Loss=0.4175, Val Acc=0.7982\n",
      "Epoch 47: Train Loss=0.4229, Train Acc=0.7995 ||| Val Loss=0.4160, Val Acc=0.7947\n",
      "Epoch 48: Train Loss=0.4176, Train Acc=0.7984 ||| Val Loss=0.4202, Val Acc=0.8022\n",
      "Epoch 49: Train Loss=0.4154, Train Acc=0.7974 ||| Val Loss=0.4118, Val Acc=0.7953\n",
      "Epoch 50: Train Loss=0.4118, Train Acc=0.8010 ||| Val Loss=0.4217, Val Acc=0.7953\n",
      "Epoch 51: Train Loss=0.4144, Train Acc=0.8017 ||| Val Loss=0.4137, Val Acc=0.7999\n",
      "Epoch 52: Train Loss=0.4144, Train Acc=0.8018 ||| Val Loss=0.4360, Val Acc=0.7930\n",
      "Epoch 53: Train Loss=0.4209, Train Acc=0.7977 ||| Val Loss=0.4143, Val Acc=0.8016\n",
      "Epoch 54: Train Loss=0.4177, Train Acc=0.7971 ||| Val Loss=0.4134, Val Acc=0.7930\n",
      "Epoch 55: Train Loss=0.4172, Train Acc=0.7988 ||| Val Loss=0.4155, Val Acc=0.7999\n",
      "Epoch 56: Train Loss=0.4145, Train Acc=0.8001 ||| Val Loss=0.4211, Val Acc=0.7964\n",
      "Epoch 57: Train Loss=0.4157, Train Acc=0.7998 ||| Val Loss=0.4217, Val Acc=0.8045\n",
      "Epoch 58: Train Loss=0.4175, Train Acc=0.7997 ||| Val Loss=0.4198, Val Acc=0.7959\n",
      "Epoch 59: Train Loss=0.4165, Train Acc=0.8027 ||| Val Loss=0.4203, Val Acc=0.7999\n",
      "Epoch 60: Train Loss=0.4148, Train Acc=0.7968 ||| Val Loss=0.4131, Val Acc=0.7941\n",
      "Epoch 61: Train Loss=0.4128, Train Acc=0.7995 ||| Val Loss=0.4183, Val Acc=0.7976\n",
      "Epoch 62: Train Loss=0.4158, Train Acc=0.8003 ||| Val Loss=0.4253, Val Acc=0.8051\n",
      "Epoch 63: Train Loss=0.4135, Train Acc=0.7998 ||| Val Loss=0.4118, Val Acc=0.7953\n",
      "Epoch 64: Train Loss=0.4141, Train Acc=0.7991 ||| Val Loss=0.4101, Val Acc=0.8039\n",
      "Epoch 65: Train Loss=0.4145, Train Acc=0.8027 ||| Val Loss=0.4207, Val Acc=0.8010\n",
      "Epoch 66: Train Loss=0.4173, Train Acc=0.8031 ||| Val Loss=0.4144, Val Acc=0.8005\n",
      "Epoch 67: Train Loss=0.4135, Train Acc=0.7991 ||| Val Loss=0.4214, Val Acc=0.7959\n",
      "Epoch 68: Train Loss=0.4126, Train Acc=0.7993 ||| Val Loss=0.4129, Val Acc=0.8005\n",
      "Epoch 69: Train Loss=0.4108, Train Acc=0.7987 ||| Val Loss=0.4143, Val Acc=0.7987\n",
      "Epoch 70: Train Loss=0.4090, Train Acc=0.8041 ||| Val Loss=0.4281, Val Acc=0.7964\n",
      "Epoch 71: Train Loss=0.4080, Train Acc=0.8039 ||| Val Loss=0.4129, Val Acc=0.8028\n",
      "Epoch 72: Train Loss=0.4109, Train Acc=0.8004 ||| Val Loss=0.4121, Val Acc=0.7964\n",
      "Epoch 73: Train Loss=0.4062, Train Acc=0.8011 ||| Val Loss=0.4197, Val Acc=0.8028\n",
      "Epoch 74: Train Loss=0.4074, Train Acc=0.8040 ||| Val Loss=0.4172, Val Acc=0.7964\n",
      "Epoch 75: Train Loss=0.4087, Train Acc=0.8017 ||| Val Loss=0.4106, Val Acc=0.7924\n",
      "Epoch 76: Train Loss=0.4068, Train Acc=0.8031 ||| Val Loss=0.4108, Val Acc=0.8016\n",
      "Epoch 77: Train Loss=0.4080, Train Acc=0.8046 ||| Val Loss=0.4173, Val Acc=0.7976\n",
      "Epoch 78: Train Loss=0.4088, Train Acc=0.8001 ||| Val Loss=0.4160, Val Acc=0.7993\n",
      "Epoch 79: Train Loss=0.4076, Train Acc=0.7998 ||| Val Loss=0.4163, Val Acc=0.7976\n",
      "Epoch 80: Train Loss=0.4082, Train Acc=0.8053 ||| Val Loss=0.4124, Val Acc=0.7976\n",
      "Epoch 81: Train Loss=0.4062, Train Acc=0.8036 ||| Val Loss=0.4170, Val Acc=0.8016\n",
      "Epoch 82: Train Loss=0.4081, Train Acc=0.8047 ||| Val Loss=0.4144, Val Acc=0.7964\n",
      "Epoch 83: Train Loss=0.4036, Train Acc=0.8067 ||| Val Loss=0.4212, Val Acc=0.7993\n",
      "Epoch 84: Train Loss=0.4083, Train Acc=0.8046 ||| Val Loss=0.4078, Val Acc=0.7976\n",
      "Epoch 85: Train Loss=0.4021, Train Acc=0.8026 ||| Val Loss=0.4129, Val Acc=0.8005\n",
      "Epoch 86: Train Loss=0.4045, Train Acc=0.8030 ||| Val Loss=0.4202, Val Acc=0.7982\n",
      "Epoch 87: Train Loss=0.4057, Train Acc=0.8041 ||| Val Loss=0.4097, Val Acc=0.7970\n",
      "Epoch 88: Train Loss=0.4058, Train Acc=0.8013 ||| Val Loss=0.4126, Val Acc=0.7941\n",
      "Epoch 89: Train Loss=0.4040, Train Acc=0.8011 ||| Val Loss=0.4146, Val Acc=0.8045\n",
      "Epoch 90: Train Loss=0.4021, Train Acc=0.8049 ||| Val Loss=0.4117, Val Acc=0.7976\n",
      "Epoch 91: Train Loss=0.4042, Train Acc=0.8000 ||| Val Loss=0.4120, Val Acc=0.7999\n",
      "Epoch 92: Train Loss=0.4041, Train Acc=0.8008 ||| Val Loss=0.4095, Val Acc=0.7953\n",
      "Epoch 93: Train Loss=0.4030, Train Acc=0.7997 ||| Val Loss=0.4059, Val Acc=0.7959\n",
      "Epoch 94: Train Loss=0.4034, Train Acc=0.8066 ||| Val Loss=0.4062, Val Acc=0.7999\n",
      "Epoch 95: Train Loss=0.4027, Train Acc=0.8076 ||| Val Loss=0.4242, Val Acc=0.7964\n",
      "Epoch 96: Train Loss=0.4049, Train Acc=0.8039 ||| Val Loss=0.4159, Val Acc=0.7953\n",
      "Epoch 97: Train Loss=0.3972, Train Acc=0.8077 ||| Val Loss=0.4142, Val Acc=0.8010\n",
      "Epoch 98: Train Loss=0.3989, Train Acc=0.8060 ||| Val Loss=0.4131, Val Acc=0.8005\n",
      "Epoch 99: Train Loss=0.4039, Train Acc=0.8031 ||| Val Loss=0.4192, Val Acc=0.8010\n",
      "Epoch 100: Train Loss=0.3977, Train Acc=0.8095 ||| Val Loss=0.4230, Val Acc=0.7953\n",
      "Epoch 101: Train Loss=0.3975, Train Acc=0.8063 ||| Val Loss=0.4463, Val Acc=0.8010\n",
      "Epoch 102: Train Loss=0.3971, Train Acc=0.8056 ||| Val Loss=0.4161, Val Acc=0.7941\n",
      "Epoch 103: Train Loss=0.3968, Train Acc=0.8133 ||| Val Loss=0.4185, Val Acc=0.8039\n",
      "Epoch 104: Train Loss=0.3964, Train Acc=0.8110 ||| Val Loss=0.4173, Val Acc=0.7993\n",
      "Epoch 105: Train Loss=0.3937, Train Acc=0.8110 ||| Val Loss=0.4177, Val Acc=0.7964\n",
      "Epoch 106: Train Loss=0.4013, Train Acc=0.8041 ||| Val Loss=0.4080, Val Acc=0.8022\n",
      "Epoch 107: Train Loss=0.3941, Train Acc=0.8056 ||| Val Loss=0.4148, Val Acc=0.7976\n",
      "Epoch 108: Train Loss=0.3932, Train Acc=0.8056 ||| Val Loss=0.4174, Val Acc=0.7999\n",
      "Epoch 109: Train Loss=0.3944, Train Acc=0.8070 ||| Val Loss=0.4081, Val Acc=0.8068\n",
      "Epoch 110: Train Loss=0.3927, Train Acc=0.8093 ||| Val Loss=0.4167, Val Acc=0.7930\n",
      "Epoch 111: Train Loss=0.3922, Train Acc=0.8095 ||| Val Loss=0.4254, Val Acc=0.8039\n",
      "Epoch 112: Train Loss=0.3935, Train Acc=0.8095 ||| Val Loss=0.4204, Val Acc=0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:16:48,665] Trial 27 finished with value: 0.8027602070155262 and parameters: {'n_blocks': 5, 'd_block': 512, 'k': 9, 'dropout': 0.2078537782803282, 'activation': 'ReLU', 'lr': 0.0014908074450939784, 'weight_decay': 2.2289399936271573e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: Train Loss=0.3937, Train Acc=0.8076 ||| Val Loss=0.4129, Val Acc=0.8028\n",
      "Early stopping triggered at epoch 113\n",
      "Validation Accuracy: 0.8028\n",
      "\n",
      " Trial 29 with params: {'n_blocks': 4, 'd_block': 128, 'k': 11, 'dropout': 0.1378665338462055, 'activation': 'ReLU', 'lr': 0.012078381069982127, 'weight_decay': 1.3158998363428355e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.4054, Train Acc=0.6681 ||| Val Loss=0.5432, Val Acc=0.7487\n",
      "Epoch 2: Train Loss=0.5287, Train Acc=0.7702 ||| Val Loss=0.4931, Val Acc=0.7970\n",
      "Epoch 3: Train Loss=0.5081, Train Acc=0.7729 ||| Val Loss=0.4839, Val Acc=0.7936\n",
      "Epoch 4: Train Loss=0.5002, Train Acc=0.7804 ||| Val Loss=0.4967, Val Acc=0.7849\n",
      "Epoch 5: Train Loss=0.4915, Train Acc=0.7821 ||| Val Loss=0.4636, Val Acc=0.7993\n",
      "Epoch 6: Train Loss=0.4834, Train Acc=0.7844 ||| Val Loss=0.4578, Val Acc=0.7913\n",
      "Epoch 7: Train Loss=0.4696, Train Acc=0.7820 ||| Val Loss=0.4618, Val Acc=0.7757\n",
      "Epoch 8: Train Loss=0.4738, Train Acc=0.7801 ||| Val Loss=0.4887, Val Acc=0.7706\n",
      "Epoch 9: Train Loss=0.4705, Train Acc=0.7791 ||| Val Loss=0.4422, Val Acc=0.7936\n",
      "Epoch 10: Train Loss=0.4493, Train Acc=0.7869 ||| Val Loss=0.4222, Val Acc=0.7849\n",
      "Epoch 11: Train Loss=0.4477, Train Acc=0.7886 ||| Val Loss=0.4234, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.4414, Train Acc=0.7833 ||| Val Loss=0.4488, Val Acc=0.7970\n",
      "Epoch 13: Train Loss=0.4418, Train Acc=0.7842 ||| Val Loss=0.4164, Val Acc=0.7987\n",
      "Epoch 14: Train Loss=0.4370, Train Acc=0.7906 ||| Val Loss=0.4145, Val Acc=0.7953\n",
      "Epoch 15: Train Loss=0.4431, Train Acc=0.7856 ||| Val Loss=0.4148, Val Acc=0.7959\n",
      "Epoch 16: Train Loss=0.4316, Train Acc=0.7947 ||| Val Loss=0.4169, Val Acc=0.7970\n",
      "Epoch 17: Train Loss=0.4347, Train Acc=0.7915 ||| Val Loss=0.4401, Val Acc=0.7907\n",
      "Epoch 18: Train Loss=0.4365, Train Acc=0.7902 ||| Val Loss=0.4158, Val Acc=0.8005\n",
      "Epoch 19: Train Loss=0.4304, Train Acc=0.7934 ||| Val Loss=0.4099, Val Acc=0.7918\n",
      "Epoch 20: Train Loss=0.4266, Train Acc=0.7994 ||| Val Loss=0.4156, Val Acc=0.8033\n",
      "Epoch 21: Train Loss=0.4265, Train Acc=0.7964 ||| Val Loss=0.4140, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4287, Train Acc=0.7955 ||| Val Loss=0.4238, Val Acc=0.7936\n",
      "Epoch 23: Train Loss=0.4411, Train Acc=0.7865 ||| Val Loss=0.4166, Val Acc=0.7964\n",
      "Epoch 24: Train Loss=0.4350, Train Acc=0.7959 ||| Val Loss=0.4079, Val Acc=0.7987\n",
      "Epoch 25: Train Loss=0.4248, Train Acc=0.7978 ||| Val Loss=0.4028, Val Acc=0.7993\n",
      "Epoch 26: Train Loss=0.4189, Train Acc=0.8017 ||| Val Loss=0.4069, Val Acc=0.7976\n",
      "Epoch 27: Train Loss=0.4255, Train Acc=0.7984 ||| Val Loss=0.4102, Val Acc=0.7987\n",
      "Epoch 28: Train Loss=0.4312, Train Acc=0.7964 ||| Val Loss=0.4040, Val Acc=0.8033\n",
      "Epoch 29: Train Loss=0.4256, Train Acc=0.7962 ||| Val Loss=0.4129, Val Acc=0.8033\n",
      "Epoch 30: Train Loss=0.4274, Train Acc=0.7984 ||| Val Loss=0.4129, Val Acc=0.7936\n",
      "Epoch 31: Train Loss=0.4271, Train Acc=0.7975 ||| Val Loss=0.4319, Val Acc=0.7832\n",
      "Epoch 32: Train Loss=0.4220, Train Acc=0.7993 ||| Val Loss=0.4069, Val Acc=0.7959\n",
      "Epoch 33: Train Loss=0.4204, Train Acc=0.8013 ||| Val Loss=0.4050, Val Acc=0.7987\n",
      "Epoch 34: Train Loss=0.4198, Train Acc=0.8011 ||| Val Loss=0.4124, Val Acc=0.7941\n",
      "Epoch 35: Train Loss=0.4202, Train Acc=0.8000 ||| Val Loss=0.4098, Val Acc=0.7924\n",
      "Epoch 36: Train Loss=0.4297, Train Acc=0.7959 ||| Val Loss=0.4188, Val Acc=0.7918\n",
      "Epoch 37: Train Loss=0.4234, Train Acc=0.7995 ||| Val Loss=0.4287, Val Acc=0.7987\n",
      "Epoch 38: Train Loss=0.4242, Train Acc=0.8021 ||| Val Loss=0.4272, Val Acc=0.7953\n",
      "Epoch 39: Train Loss=0.4204, Train Acc=0.7975 ||| Val Loss=0.4020, Val Acc=0.8039\n",
      "Epoch 40: Train Loss=0.4167, Train Acc=0.8077 ||| Val Loss=0.4317, Val Acc=0.7953\n",
      "Epoch 41: Train Loss=0.4191, Train Acc=0.7995 ||| Val Loss=0.4063, Val Acc=0.8005\n",
      "Epoch 42: Train Loss=0.4196, Train Acc=0.8017 ||| Val Loss=0.4090, Val Acc=0.7999\n",
      "Epoch 43: Train Loss=0.4190, Train Acc=0.7962 ||| Val Loss=0.4183, Val Acc=0.7982\n",
      "Epoch 44: Train Loss=0.4240, Train Acc=0.7978 ||| Val Loss=0.4058, Val Acc=0.7993\n",
      "Epoch 45: Train Loss=0.4172, Train Acc=0.8036 ||| Val Loss=0.4312, Val Acc=0.7959\n",
      "Epoch 46: Train Loss=0.4261, Train Acc=0.7987 ||| Val Loss=0.4505, Val Acc=0.7987\n",
      "Epoch 47: Train Loss=0.4178, Train Acc=0.7982 ||| Val Loss=0.4497, Val Acc=0.8005\n",
      "Epoch 48: Train Loss=0.4259, Train Acc=0.8017 ||| Val Loss=0.4079, Val Acc=0.8010\n",
      "Epoch 49: Train Loss=0.4170, Train Acc=0.8030 ||| Val Loss=0.4028, Val Acc=0.7970\n",
      "Epoch 50: Train Loss=0.4145, Train Acc=0.8080 ||| Val Loss=0.4128, Val Acc=0.8010\n",
      "Epoch 51: Train Loss=0.4172, Train Acc=0.8027 ||| Val Loss=0.4112, Val Acc=0.8022\n",
      "Epoch 52: Train Loss=0.4138, Train Acc=0.8049 ||| Val Loss=0.4192, Val Acc=0.7855\n",
      "Epoch 53: Train Loss=0.4156, Train Acc=0.8083 ||| Val Loss=0.4510, Val Acc=0.7729\n",
      "Epoch 54: Train Loss=0.4181, Train Acc=0.8014 ||| Val Loss=0.4083, Val Acc=0.8033\n",
      "Epoch 55: Train Loss=0.4288, Train Acc=0.7985 ||| Val Loss=0.4063, Val Acc=0.7993\n",
      "Epoch 56: Train Loss=0.4204, Train Acc=0.8014 ||| Val Loss=0.4157, Val Acc=0.8079\n",
      "Epoch 57: Train Loss=0.4241, Train Acc=0.8008 ||| Val Loss=0.4138, Val Acc=0.8079\n",
      "Epoch 58: Train Loss=0.4142, Train Acc=0.8013 ||| Val Loss=0.4175, Val Acc=0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:17:06,835] Trial 28 finished with value: 0.7935595169637722 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 11, 'dropout': 0.1378665338462055, 'activation': 'ReLU', 'lr': 0.012078381069982127, 'weight_decay': 1.3158998363428355e-05}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss=0.4156, Train Acc=0.8057 ||| Val Loss=0.4100, Val Acc=0.7936\n",
      "Early stopping triggered at epoch 59\n",
      "Validation Accuracy: 0.7936\n",
      "\n",
      " Trial 30 with params: {'n_blocks': 6, 'd_block': 128, 'k': 8, 'dropout': 0.32551897451828177, 'activation': 'LeakyReLU', 'lr': 0.004113579887730336, 'weight_decay': 5.063621078557173e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.6942, Train Acc=0.6372 ||| Val Loss=0.5515, Val Acc=0.7798\n",
      "Epoch 2: Train Loss=0.5458, Train Acc=0.7552 ||| Val Loss=0.5327, Val Acc=0.7861\n",
      "Epoch 3: Train Loss=0.5140, Train Acc=0.7791 ||| Val Loss=0.5042, Val Acc=0.7878\n",
      "Epoch 4: Train Loss=0.5162, Train Acc=0.7752 ||| Val Loss=0.4954, Val Acc=0.7803\n",
      "Epoch 5: Train Loss=0.5075, Train Acc=0.7777 ||| Val Loss=0.4759, Val Acc=0.7970\n",
      "Epoch 6: Train Loss=0.5029, Train Acc=0.7785 ||| Val Loss=0.5191, Val Acc=0.7884\n",
      "Epoch 7: Train Loss=0.4878, Train Acc=0.7854 ||| Val Loss=0.4668, Val Acc=0.7964\n",
      "Epoch 8: Train Loss=0.4820, Train Acc=0.7846 ||| Val Loss=0.4731, Val Acc=0.7700\n",
      "Epoch 9: Train Loss=0.4625, Train Acc=0.7827 ||| Val Loss=0.4378, Val Acc=0.7913\n",
      "Epoch 10: Train Loss=0.4562, Train Acc=0.7859 ||| Val Loss=0.4460, Val Acc=0.7867\n",
      "Epoch 11: Train Loss=0.4473, Train Acc=0.7888 ||| Val Loss=0.4555, Val Acc=0.7959\n",
      "Epoch 12: Train Loss=0.4514, Train Acc=0.7906 ||| Val Loss=0.4449, Val Acc=0.7976\n",
      "Epoch 13: Train Loss=0.4430, Train Acc=0.7923 ||| Val Loss=0.4220, Val Acc=0.7976\n",
      "Epoch 14: Train Loss=0.4386, Train Acc=0.7926 ||| Val Loss=0.4211, Val Acc=0.7999\n",
      "Epoch 15: Train Loss=0.4386, Train Acc=0.7919 ||| Val Loss=0.4183, Val Acc=0.7976\n",
      "Epoch 16: Train Loss=0.4258, Train Acc=0.7890 ||| Val Loss=0.4159, Val Acc=0.7936\n",
      "Epoch 17: Train Loss=0.4275, Train Acc=0.7926 ||| Val Loss=0.4274, Val Acc=0.7982\n",
      "Epoch 18: Train Loss=0.4254, Train Acc=0.7948 ||| Val Loss=0.4167, Val Acc=0.7936\n",
      "Epoch 19: Train Loss=0.4305, Train Acc=0.7938 ||| Val Loss=0.4142, Val Acc=0.7953\n",
      "Epoch 20: Train Loss=0.4272, Train Acc=0.7942 ||| Val Loss=0.4188, Val Acc=0.7924\n",
      "Epoch 21: Train Loss=0.4286, Train Acc=0.7964 ||| Val Loss=0.4198, Val Acc=0.7936\n",
      "Epoch 22: Train Loss=0.4220, Train Acc=0.7982 ||| Val Loss=0.4102, Val Acc=0.7987\n",
      "Epoch 23: Train Loss=0.4228, Train Acc=0.7945 ||| Val Loss=0.4112, Val Acc=0.7936\n",
      "Epoch 24: Train Loss=0.4230, Train Acc=0.7991 ||| Val Loss=0.4146, Val Acc=0.7976\n",
      "Epoch 25: Train Loss=0.4228, Train Acc=0.7994 ||| Val Loss=0.4105, Val Acc=0.7947\n",
      "Epoch 26: Train Loss=0.4275, Train Acc=0.7949 ||| Val Loss=0.4132, Val Acc=0.7993\n",
      "Epoch 27: Train Loss=0.4221, Train Acc=0.7967 ||| Val Loss=0.4214, Val Acc=0.7999\n",
      "Epoch 28: Train Loss=0.4167, Train Acc=0.8008 ||| Val Loss=0.4140, Val Acc=0.7999\n",
      "Epoch 29: Train Loss=0.4202, Train Acc=0.7978 ||| Val Loss=0.4131, Val Acc=0.8010\n",
      "Epoch 30: Train Loss=0.4173, Train Acc=0.7970 ||| Val Loss=0.4122, Val Acc=0.7982\n",
      "Epoch 31: Train Loss=0.4164, Train Acc=0.8050 ||| Val Loss=0.4143, Val Acc=0.8016\n",
      "Epoch 32: Train Loss=0.4209, Train Acc=0.7981 ||| Val Loss=0.4154, Val Acc=0.7953\n",
      "Epoch 33: Train Loss=0.4194, Train Acc=0.8000 ||| Val Loss=0.4154, Val Acc=0.7924\n",
      "Epoch 34: Train Loss=0.4180, Train Acc=0.8014 ||| Val Loss=0.4098, Val Acc=0.7999\n",
      "Epoch 35: Train Loss=0.4155, Train Acc=0.8008 ||| Val Loss=0.4184, Val Acc=0.7947\n",
      "Epoch 36: Train Loss=0.4154, Train Acc=0.8005 ||| Val Loss=0.4133, Val Acc=0.7964\n",
      "Epoch 37: Train Loss=0.4174, Train Acc=0.7964 ||| Val Loss=0.4135, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4122, Train Acc=0.8023 ||| Val Loss=0.4097, Val Acc=0.8033\n",
      "Epoch 39: Train Loss=0.4148, Train Acc=0.8017 ||| Val Loss=0.4090, Val Acc=0.7982\n",
      "Epoch 40: Train Loss=0.4118, Train Acc=0.8039 ||| Val Loss=0.4190, Val Acc=0.7918\n",
      "Epoch 41: Train Loss=0.4149, Train Acc=0.8007 ||| Val Loss=0.4090, Val Acc=0.7964\n",
      "Epoch 42: Train Loss=0.4110, Train Acc=0.8047 ||| Val Loss=0.4124, Val Acc=0.7947\n",
      "Epoch 43: Train Loss=0.4103, Train Acc=0.7991 ||| Val Loss=0.4068, Val Acc=0.7976\n",
      "Epoch 44: Train Loss=0.4072, Train Acc=0.8060 ||| Val Loss=0.4143, Val Acc=0.7964\n",
      "Epoch 45: Train Loss=0.4100, Train Acc=0.7994 ||| Val Loss=0.4169, Val Acc=0.7987\n",
      "Epoch 46: Train Loss=0.4184, Train Acc=0.8005 ||| Val Loss=0.4129, Val Acc=0.8010\n",
      "Epoch 47: Train Loss=0.4163, Train Acc=0.8050 ||| Val Loss=0.4094, Val Acc=0.7982\n",
      "Epoch 48: Train Loss=0.4073, Train Acc=0.8072 ||| Val Loss=0.4151, Val Acc=0.7936\n",
      "Epoch 49: Train Loss=0.4100, Train Acc=0.8036 ||| Val Loss=0.4101, Val Acc=0.7959\n",
      "Epoch 50: Train Loss=0.4109, Train Acc=0.7990 ||| Val Loss=0.4085, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4104, Train Acc=0.8016 ||| Val Loss=0.4105, Val Acc=0.7964\n",
      "Epoch 52: Train Loss=0.4078, Train Acc=0.8043 ||| Val Loss=0.4091, Val Acc=0.7953\n",
      "Epoch 53: Train Loss=0.4082, Train Acc=0.8017 ||| Val Loss=0.4088, Val Acc=0.7959\n",
      "Epoch 54: Train Loss=0.4098, Train Acc=0.8037 ||| Val Loss=0.4095, Val Acc=0.7976\n",
      "Epoch 55: Train Loss=0.4073, Train Acc=0.8043 ||| Val Loss=0.4073, Val Acc=0.7987\n",
      "Epoch 56: Train Loss=0.4085, Train Acc=0.7982 ||| Val Loss=0.4226, Val Acc=0.8022\n",
      "Epoch 57: Train Loss=0.4091, Train Acc=0.8023 ||| Val Loss=0.4101, Val Acc=0.7976\n",
      "Epoch 58: Train Loss=0.4080, Train Acc=0.8037 ||| Val Loss=0.4141, Val Acc=0.7964\n",
      "Epoch 59: Train Loss=0.4094, Train Acc=0.8066 ||| Val Loss=0.4151, Val Acc=0.7959\n",
      "Epoch 60: Train Loss=0.4130, Train Acc=0.8016 ||| Val Loss=0.4061, Val Acc=0.7987\n",
      "Epoch 61: Train Loss=0.4063, Train Acc=0.8076 ||| Val Loss=0.4093, Val Acc=0.7982\n",
      "Epoch 62: Train Loss=0.4070, Train Acc=0.8073 ||| Val Loss=0.4208, Val Acc=0.7970\n",
      "Epoch 63: Train Loss=0.4091, Train Acc=0.8046 ||| Val Loss=0.4183, Val Acc=0.7964\n",
      "Epoch 64: Train Loss=0.4075, Train Acc=0.8054 ||| Val Loss=0.4106, Val Acc=0.7976\n",
      "Epoch 65: Train Loss=0.4073, Train Acc=0.8074 ||| Val Loss=0.4114, Val Acc=0.7976\n",
      "Epoch 66: Train Loss=0.4066, Train Acc=0.8050 ||| Val Loss=0.4092, Val Acc=0.7964\n",
      "Epoch 67: Train Loss=0.4072, Train Acc=0.8053 ||| Val Loss=0.4103, Val Acc=0.7947\n",
      "Epoch 68: Train Loss=0.4048, Train Acc=0.8080 ||| Val Loss=0.4119, Val Acc=0.7895\n",
      "Epoch 69: Train Loss=0.4056, Train Acc=0.8064 ||| Val Loss=0.4159, Val Acc=0.7947\n",
      "Epoch 70: Train Loss=0.4115, Train Acc=0.8060 ||| Val Loss=0.4091, Val Acc=0.7936\n",
      "Epoch 71: Train Loss=0.4074, Train Acc=0.8010 ||| Val Loss=0.4097, Val Acc=0.7901\n",
      "Epoch 72: Train Loss=0.4038, Train Acc=0.8070 ||| Val Loss=0.4126, Val Acc=0.8074\n",
      "Epoch 73: Train Loss=0.4044, Train Acc=0.8069 ||| Val Loss=0.4098, Val Acc=0.7936\n",
      "Epoch 74: Train Loss=0.4029, Train Acc=0.8097 ||| Val Loss=0.4060, Val Acc=0.8016\n",
      "Epoch 75: Train Loss=0.4075, Train Acc=0.8064 ||| Val Loss=0.4048, Val Acc=0.8016\n",
      "Epoch 76: Train Loss=0.4031, Train Acc=0.8066 ||| Val Loss=0.4100, Val Acc=0.7867\n",
      "Epoch 77: Train Loss=0.4056, Train Acc=0.8085 ||| Val Loss=0.4163, Val Acc=0.7964\n",
      "Epoch 78: Train Loss=0.4036, Train Acc=0.8089 ||| Val Loss=0.4091, Val Acc=0.8005\n",
      "Epoch 79: Train Loss=0.4046, Train Acc=0.8076 ||| Val Loss=0.4035, Val Acc=0.8091\n",
      "Epoch 80: Train Loss=0.4050, Train Acc=0.8028 ||| Val Loss=0.4054, Val Acc=0.7976\n",
      "Epoch 81: Train Loss=0.4005, Train Acc=0.8095 ||| Val Loss=0.4167, Val Acc=0.8010\n",
      "Epoch 82: Train Loss=0.4028, Train Acc=0.8074 ||| Val Loss=0.4121, Val Acc=0.7913\n",
      "Epoch 83: Train Loss=0.3996, Train Acc=0.8099 ||| Val Loss=0.4102, Val Acc=0.8010\n",
      "Epoch 84: Train Loss=0.4030, Train Acc=0.8074 ||| Val Loss=0.4051, Val Acc=0.7947\n",
      "Epoch 85: Train Loss=0.4027, Train Acc=0.8093 ||| Val Loss=0.4149, Val Acc=0.7953\n",
      "Epoch 86: Train Loss=0.3985, Train Acc=0.8121 ||| Val Loss=0.4063, Val Acc=0.8005\n",
      "Epoch 87: Train Loss=0.4014, Train Acc=0.8063 ||| Val Loss=0.4086, Val Acc=0.7987\n",
      "Epoch 88: Train Loss=0.3964, Train Acc=0.8126 ||| Val Loss=0.4088, Val Acc=0.7982\n",
      "Epoch 89: Train Loss=0.4034, Train Acc=0.8066 ||| Val Loss=0.4036, Val Acc=0.8010\n",
      "Epoch 90: Train Loss=0.4026, Train Acc=0.8090 ||| Val Loss=0.4098, Val Acc=0.7913\n",
      "Epoch 91: Train Loss=0.4018, Train Acc=0.8128 ||| Val Loss=0.4100, Val Acc=0.7930\n",
      "Epoch 92: Train Loss=0.4011, Train Acc=0.8106 ||| Val Loss=0.4126, Val Acc=0.8028\n",
      "Epoch 93: Train Loss=0.3979, Train Acc=0.8109 ||| Val Loss=0.4089, Val Acc=0.8091\n",
      "Epoch 94: Train Loss=0.3999, Train Acc=0.8059 ||| Val Loss=0.4086, Val Acc=0.8074\n",
      "Epoch 95: Train Loss=0.3959, Train Acc=0.8105 ||| Val Loss=0.4126, Val Acc=0.8010\n",
      "Epoch 96: Train Loss=0.3991, Train Acc=0.8109 ||| Val Loss=0.4091, Val Acc=0.8062\n",
      "Epoch 97: Train Loss=0.4057, Train Acc=0.8082 ||| Val Loss=0.4084, Val Acc=0.7976\n",
      "Epoch 98: Train Loss=0.3940, Train Acc=0.8155 ||| Val Loss=0.4108, Val Acc=0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:17:44,272] Trial 29 finished with value: 0.7975848188614146 and parameters: {'n_blocks': 6, 'd_block': 128, 'k': 8, 'dropout': 0.32551897451828177, 'activation': 'LeakyReLU', 'lr': 0.004113579887730336, 'weight_decay': 5.063621078557173e-06}. Best is trial 22 with value: 0.8096607245543416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Train Loss=0.4018, Train Acc=0.8118 ||| Val Loss=0.4081, Val Acc=0.7976\n",
      "Early stopping triggered at epoch 99\n",
      "Validation Accuracy: 0.7976\n",
      "\n",
      " Trial 31 with params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.27284433651928997, 'activation': 'ReLU', 'lr': 0.002029456931526584, 'weight_decay': 3.9033694841500456e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7688, Train Acc=0.6383 ||| Val Loss=0.5483, Val Acc=0.7947\n",
      "Epoch 2: Train Loss=0.5522, Train Acc=0.7419 ||| Val Loss=0.5257, Val Acc=0.7734\n",
      "Epoch 3: Train Loss=0.5232, Train Acc=0.7719 ||| Val Loss=0.4997, Val Acc=0.7918\n",
      "Epoch 4: Train Loss=0.5193, Train Acc=0.7712 ||| Val Loss=0.4831, Val Acc=0.7953\n",
      "Epoch 5: Train Loss=0.5104, Train Acc=0.7784 ||| Val Loss=0.4877, Val Acc=0.7976\n",
      "Epoch 6: Train Loss=0.4969, Train Acc=0.7808 ||| Val Loss=0.4945, Val Acc=0.7993\n",
      "Epoch 7: Train Loss=0.4924, Train Acc=0.7831 ||| Val Loss=0.4699, Val Acc=0.7976\n",
      "Epoch 8: Train Loss=0.4845, Train Acc=0.7830 ||| Val Loss=0.4706, Val Acc=0.8005\n",
      "Epoch 9: Train Loss=0.4789, Train Acc=0.7850 ||| Val Loss=0.4514, Val Acc=0.7964\n",
      "Epoch 10: Train Loss=0.4743, Train Acc=0.7862 ||| Val Loss=0.4442, Val Acc=0.7964\n",
      "Epoch 11: Train Loss=0.4632, Train Acc=0.7869 ||| Val Loss=0.4498, Val Acc=0.7976\n",
      "Epoch 12: Train Loss=0.4541, Train Acc=0.7902 ||| Val Loss=0.4387, Val Acc=0.7982\n",
      "Epoch 13: Train Loss=0.4467, Train Acc=0.7911 ||| Val Loss=0.4300, Val Acc=0.7959\n",
      "Epoch 14: Train Loss=0.4402, Train Acc=0.7888 ||| Val Loss=0.4307, Val Acc=0.7918\n",
      "Epoch 15: Train Loss=0.4387, Train Acc=0.7922 ||| Val Loss=0.4248, Val Acc=0.7947\n",
      "Epoch 16: Train Loss=0.4346, Train Acc=0.7885 ||| Val Loss=0.4288, Val Acc=0.7907\n",
      "Epoch 17: Train Loss=0.4334, Train Acc=0.7926 ||| Val Loss=0.4194, Val Acc=0.7964\n",
      "Epoch 18: Train Loss=0.4319, Train Acc=0.7923 ||| Val Loss=0.4179, Val Acc=0.7953\n",
      "Epoch 19: Train Loss=0.4331, Train Acc=0.7905 ||| Val Loss=0.4172, Val Acc=0.7982\n",
      "Epoch 20: Train Loss=0.4278, Train Acc=0.7908 ||| Val Loss=0.4145, Val Acc=0.7941\n",
      "Epoch 21: Train Loss=0.4232, Train Acc=0.7974 ||| Val Loss=0.4199, Val Acc=0.7993\n",
      "Epoch 22: Train Loss=0.4318, Train Acc=0.7919 ||| Val Loss=0.4238, Val Acc=0.7918\n",
      "Epoch 23: Train Loss=0.4263, Train Acc=0.7939 ||| Val Loss=0.4205, Val Acc=0.7872\n",
      "Epoch 24: Train Loss=0.4248, Train Acc=0.7843 ||| Val Loss=0.4195, Val Acc=0.7959\n",
      "Epoch 25: Train Loss=0.4248, Train Acc=0.7945 ||| Val Loss=0.4173, Val Acc=0.7999\n",
      "Epoch 26: Train Loss=0.4220, Train Acc=0.7938 ||| Val Loss=0.4173, Val Acc=0.7936\n",
      "Epoch 27: Train Loss=0.4198, Train Acc=0.7997 ||| Val Loss=0.4127, Val Acc=0.7964\n",
      "Epoch 28: Train Loss=0.4248, Train Acc=0.7944 ||| Val Loss=0.4152, Val Acc=0.7918\n",
      "Epoch 29: Train Loss=0.4198, Train Acc=0.7980 ||| Val Loss=0.4131, Val Acc=0.7993\n",
      "Epoch 30: Train Loss=0.4223, Train Acc=0.7971 ||| Val Loss=0.4119, Val Acc=0.8010\n",
      "Epoch 31: Train Loss=0.4213, Train Acc=0.7985 ||| Val Loss=0.4190, Val Acc=0.7959\n",
      "Epoch 32: Train Loss=0.4200, Train Acc=0.7974 ||| Val Loss=0.4144, Val Acc=0.7976\n",
      "Epoch 33: Train Loss=0.4220, Train Acc=0.7975 ||| Val Loss=0.4141, Val Acc=0.7970\n",
      "Epoch 34: Train Loss=0.4198, Train Acc=0.7947 ||| Val Loss=0.4110, Val Acc=0.7987\n",
      "Epoch 35: Train Loss=0.4165, Train Acc=0.7970 ||| Val Loss=0.4147, Val Acc=0.7959\n",
      "Epoch 36: Train Loss=0.4173, Train Acc=0.7968 ||| Val Loss=0.4088, Val Acc=0.7964\n",
      "Epoch 37: Train Loss=0.4159, Train Acc=0.7967 ||| Val Loss=0.4166, Val Acc=0.7959\n",
      "Epoch 38: Train Loss=0.4189, Train Acc=0.7974 ||| Val Loss=0.4137, Val Acc=0.7959\n",
      "Epoch 39: Train Loss=0.4156, Train Acc=0.8028 ||| Val Loss=0.4121, Val Acc=0.8005\n",
      "Epoch 40: Train Loss=0.4141, Train Acc=0.8011 ||| Val Loss=0.4056, Val Acc=0.7987\n",
      "Epoch 41: Train Loss=0.4157, Train Acc=0.7965 ||| Val Loss=0.4074, Val Acc=0.7982\n",
      "Epoch 42: Train Loss=0.4149, Train Acc=0.7952 ||| Val Loss=0.4132, Val Acc=0.7861\n",
      "Epoch 43: Train Loss=0.4182, Train Acc=0.7968 ||| Val Loss=0.4103, Val Acc=0.7964\n",
      "Epoch 44: Train Loss=0.4150, Train Acc=0.7997 ||| Val Loss=0.4128, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4154, Train Acc=0.8004 ||| Val Loss=0.4105, Val Acc=0.7982\n",
      "Epoch 46: Train Loss=0.4134, Train Acc=0.7975 ||| Val Loss=0.4046, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.4136, Train Acc=0.7988 ||| Val Loss=0.4065, Val Acc=0.7953\n",
      "Epoch 48: Train Loss=0.4113, Train Acc=0.7985 ||| Val Loss=0.4129, Val Acc=0.7959\n",
      "Epoch 49: Train Loss=0.4096, Train Acc=0.8003 ||| Val Loss=0.4040, Val Acc=0.8010\n",
      "Epoch 50: Train Loss=0.4113, Train Acc=0.7991 ||| Val Loss=0.4020, Val Acc=0.7987\n",
      "Epoch 51: Train Loss=0.4132, Train Acc=0.7974 ||| Val Loss=0.4002, Val Acc=0.7999\n",
      "Epoch 52: Train Loss=0.4096, Train Acc=0.8013 ||| Val Loss=0.4031, Val Acc=0.8028\n",
      "Epoch 53: Train Loss=0.4104, Train Acc=0.7997 ||| Val Loss=0.4090, Val Acc=0.8056\n",
      "Epoch 54: Train Loss=0.4086, Train Acc=0.8041 ||| Val Loss=0.4092, Val Acc=0.7982\n",
      "Epoch 55: Train Loss=0.4069, Train Acc=0.8017 ||| Val Loss=0.4039, Val Acc=0.8102\n",
      "Epoch 56: Train Loss=0.4061, Train Acc=0.8050 ||| Val Loss=0.4062, Val Acc=0.7976\n",
      "Epoch 57: Train Loss=0.4072, Train Acc=0.7993 ||| Val Loss=0.4025, Val Acc=0.8079\n",
      "Epoch 58: Train Loss=0.4119, Train Acc=0.7968 ||| Val Loss=0.4059, Val Acc=0.8051\n",
      "Epoch 59: Train Loss=0.4042, Train Acc=0.8082 ||| Val Loss=0.4027, Val Acc=0.8068\n",
      "Epoch 60: Train Loss=0.4059, Train Acc=0.8004 ||| Val Loss=0.4084, Val Acc=0.7953\n",
      "Epoch 61: Train Loss=0.4029, Train Acc=0.8021 ||| Val Loss=0.4070, Val Acc=0.8062\n",
      "Epoch 62: Train Loss=0.4118, Train Acc=0.8021 ||| Val Loss=0.4050, Val Acc=0.8068\n",
      "Epoch 63: Train Loss=0.4058, Train Acc=0.8041 ||| Val Loss=0.4090, Val Acc=0.7976\n",
      "Epoch 64: Train Loss=0.4057, Train Acc=0.8073 ||| Val Loss=0.4022, Val Acc=0.8068\n",
      "Epoch 65: Train Loss=0.4005, Train Acc=0.8050 ||| Val Loss=0.4035, Val Acc=0.8079\n",
      "Epoch 66: Train Loss=0.4050, Train Acc=0.8060 ||| Val Loss=0.4131, Val Acc=0.7959\n",
      "Epoch 67: Train Loss=0.4046, Train Acc=0.8054 ||| Val Loss=0.4064, Val Acc=0.8125\n",
      "Epoch 68: Train Loss=0.4071, Train Acc=0.8050 ||| Val Loss=0.4069, Val Acc=0.8051\n",
      "Epoch 69: Train Loss=0.4035, Train Acc=0.8079 ||| Val Loss=0.4121, Val Acc=0.8005\n",
      "Epoch 70: Train Loss=0.4041, Train Acc=0.8073 ||| Val Loss=0.4037, Val Acc=0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:18:09,071] Trial 30 finished with value: 0.8125359401955147 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.27284433651928997, 'activation': 'ReLU', 'lr': 0.002029456931526584, 'weight_decay': 3.9033694841500456e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train Loss=0.4030, Train Acc=0.8047 ||| Val Loss=0.4024, Val Acc=0.8125\n",
      "Early stopping triggered at epoch 71\n",
      "Validation Accuracy: 0.8125\n",
      "\n",
      " Trial 32 with params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.2636809099799959, 'activation': 'ReLU', 'lr': 0.0016600543074176363, 'weight_decay': 4.116320746842263e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7521, Train Acc=0.6179 ||| Val Loss=0.5466, Val Acc=0.7527\n",
      "Epoch 2: Train Loss=0.5624, Train Acc=0.7271 ||| Val Loss=0.5349, Val Acc=0.7631\n",
      "Epoch 3: Train Loss=0.5373, Train Acc=0.7597 ||| Val Loss=0.5057, Val Acc=0.7907\n",
      "Epoch 4: Train Loss=0.5256, Train Acc=0.7685 ||| Val Loss=0.4918, Val Acc=0.7907\n",
      "Epoch 5: Train Loss=0.5149, Train Acc=0.7765 ||| Val Loss=0.4907, Val Acc=0.7924\n",
      "Epoch 6: Train Loss=0.5055, Train Acc=0.7798 ||| Val Loss=0.4856, Val Acc=0.7924\n",
      "Epoch 7: Train Loss=0.4989, Train Acc=0.7814 ||| Val Loss=0.4832, Val Acc=0.7964\n",
      "Epoch 8: Train Loss=0.4952, Train Acc=0.7830 ||| Val Loss=0.4716, Val Acc=0.7970\n",
      "Epoch 9: Train Loss=0.4848, Train Acc=0.7865 ||| Val Loss=0.4656, Val Acc=0.7976\n",
      "Epoch 10: Train Loss=0.4789, Train Acc=0.7840 ||| Val Loss=0.4551, Val Acc=0.7987\n",
      "Epoch 11: Train Loss=0.4851, Train Acc=0.7880 ||| Val Loss=0.4693, Val Acc=0.8010\n",
      "Epoch 12: Train Loss=0.4748, Train Acc=0.7862 ||| Val Loss=0.4671, Val Acc=0.7982\n",
      "Epoch 13: Train Loss=0.4700, Train Acc=0.7890 ||| Val Loss=0.4472, Val Acc=0.8028\n",
      "Epoch 14: Train Loss=0.4670, Train Acc=0.7899 ||| Val Loss=0.4483, Val Acc=0.8010\n",
      "Epoch 15: Train Loss=0.4535, Train Acc=0.7931 ||| Val Loss=0.4463, Val Acc=0.7982\n",
      "Epoch 16: Train Loss=0.4517, Train Acc=0.7909 ||| Val Loss=0.4371, Val Acc=0.7964\n",
      "Epoch 17: Train Loss=0.4552, Train Acc=0.7939 ||| Val Loss=0.4472, Val Acc=0.7855\n",
      "Epoch 18: Train Loss=0.4407, Train Acc=0.7883 ||| Val Loss=0.4328, Val Acc=0.7947\n",
      "Epoch 19: Train Loss=0.4429, Train Acc=0.7929 ||| Val Loss=0.4248, Val Acc=0.7987\n",
      "Epoch 20: Train Loss=0.4343, Train Acc=0.7895 ||| Val Loss=0.4348, Val Acc=0.7964\n",
      "Epoch 21: Train Loss=0.4389, Train Acc=0.7886 ||| Val Loss=0.4286, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4305, Train Acc=0.7923 ||| Val Loss=0.4251, Val Acc=0.7941\n",
      "Epoch 23: Train Loss=0.4287, Train Acc=0.7977 ||| Val Loss=0.4292, Val Acc=0.7924\n",
      "Epoch 24: Train Loss=0.4286, Train Acc=0.7915 ||| Val Loss=0.4199, Val Acc=0.7970\n",
      "Epoch 25: Train Loss=0.4256, Train Acc=0.7945 ||| Val Loss=0.4211, Val Acc=0.7918\n",
      "Epoch 26: Train Loss=0.4291, Train Acc=0.7934 ||| Val Loss=0.4270, Val Acc=0.7890\n",
      "Epoch 27: Train Loss=0.4259, Train Acc=0.7957 ||| Val Loss=0.4199, Val Acc=0.7993\n",
      "Epoch 28: Train Loss=0.4274, Train Acc=0.7918 ||| Val Loss=0.4205, Val Acc=0.7930\n",
      "Epoch 29: Train Loss=0.4227, Train Acc=0.7964 ||| Val Loss=0.4404, Val Acc=0.8016\n",
      "Epoch 30: Train Loss=0.4232, Train Acc=0.7968 ||| Val Loss=0.4186, Val Acc=0.7982\n",
      "Epoch 31: Train Loss=0.4190, Train Acc=0.7980 ||| Val Loss=0.4181, Val Acc=0.7936\n",
      "Epoch 32: Train Loss=0.4254, Train Acc=0.7916 ||| Val Loss=0.4208, Val Acc=0.7953\n",
      "Epoch 33: Train Loss=0.4213, Train Acc=0.7959 ||| Val Loss=0.4160, Val Acc=0.7970\n",
      "Epoch 34: Train Loss=0.4210, Train Acc=0.7990 ||| Val Loss=0.4211, Val Acc=0.7987\n",
      "Epoch 35: Train Loss=0.4196, Train Acc=0.7968 ||| Val Loss=0.4164, Val Acc=0.7884\n",
      "Epoch 36: Train Loss=0.4191, Train Acc=0.7962 ||| Val Loss=0.4285, Val Acc=0.7993\n",
      "Epoch 37: Train Loss=0.4182, Train Acc=0.7974 ||| Val Loss=0.4180, Val Acc=0.7941\n",
      "Epoch 38: Train Loss=0.4179, Train Acc=0.7982 ||| Val Loss=0.4163, Val Acc=0.7964\n",
      "Epoch 39: Train Loss=0.4147, Train Acc=0.7962 ||| Val Loss=0.4241, Val Acc=0.8005\n",
      "Epoch 40: Train Loss=0.4185, Train Acc=0.7974 ||| Val Loss=0.4140, Val Acc=0.7959\n",
      "Epoch 41: Train Loss=0.4154, Train Acc=0.8005 ||| Val Loss=0.4155, Val Acc=0.7982\n",
      "Epoch 42: Train Loss=0.4173, Train Acc=0.7971 ||| Val Loss=0.4178, Val Acc=0.7947\n",
      "Epoch 43: Train Loss=0.4163, Train Acc=0.7965 ||| Val Loss=0.4135, Val Acc=0.7970\n",
      "Epoch 44: Train Loss=0.4187, Train Acc=0.7991 ||| Val Loss=0.4119, Val Acc=0.7982\n",
      "Epoch 45: Train Loss=0.4154, Train Acc=0.8004 ||| Val Loss=0.4116, Val Acc=0.7976\n",
      "Epoch 46: Train Loss=0.4165, Train Acc=0.7982 ||| Val Loss=0.4126, Val Acc=0.7970\n",
      "Epoch 47: Train Loss=0.4146, Train Acc=0.8034 ||| Val Loss=0.4086, Val Acc=0.7970\n",
      "Epoch 48: Train Loss=0.4144, Train Acc=0.8021 ||| Val Loss=0.4131, Val Acc=0.7982\n",
      "Epoch 49: Train Loss=0.4165, Train Acc=0.7998 ||| Val Loss=0.4093, Val Acc=0.7987\n",
      "Epoch 50: Train Loss=0.4111, Train Acc=0.7987 ||| Val Loss=0.4161, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4116, Train Acc=0.7993 ||| Val Loss=0.4084, Val Acc=0.7959\n",
      "Epoch 52: Train Loss=0.4124, Train Acc=0.8023 ||| Val Loss=0.4086, Val Acc=0.7941\n",
      "Epoch 53: Train Loss=0.4129, Train Acc=0.7993 ||| Val Loss=0.4086, Val Acc=0.7970\n",
      "Epoch 54: Train Loss=0.4125, Train Acc=0.7994 ||| Val Loss=0.4097, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4095, Train Acc=0.7995 ||| Val Loss=0.4174, Val Acc=0.7930\n",
      "Epoch 56: Train Loss=0.4114, Train Acc=0.7978 ||| Val Loss=0.4098, Val Acc=0.7987\n",
      "Epoch 57: Train Loss=0.4089, Train Acc=0.8033 ||| Val Loss=0.4088, Val Acc=0.7895\n",
      "Epoch 58: Train Loss=0.4101, Train Acc=0.8007 ||| Val Loss=0.4072, Val Acc=0.7976\n",
      "Epoch 59: Train Loss=0.4095, Train Acc=0.8033 ||| Val Loss=0.4119, Val Acc=0.7987\n",
      "Epoch 60: Train Loss=0.4073, Train Acc=0.8018 ||| Val Loss=0.4153, Val Acc=0.7947\n",
      "Epoch 61: Train Loss=0.4088, Train Acc=0.8018 ||| Val Loss=0.4082, Val Acc=0.7987\n",
      "Epoch 62: Train Loss=0.4104, Train Acc=0.7987 ||| Val Loss=0.4123, Val Acc=0.7913\n",
      "Epoch 63: Train Loss=0.4083, Train Acc=0.8036 ||| Val Loss=0.4102, Val Acc=0.7953\n",
      "Epoch 64: Train Loss=0.4078, Train Acc=0.8028 ||| Val Loss=0.4088, Val Acc=0.7982\n",
      "Epoch 65: Train Loss=0.4064, Train Acc=0.8026 ||| Val Loss=0.4125, Val Acc=0.7878\n",
      "Epoch 66: Train Loss=0.4081, Train Acc=0.8013 ||| Val Loss=0.4127, Val Acc=0.7855\n",
      "Epoch 67: Train Loss=0.4027, Train Acc=0.8073 ||| Val Loss=0.4093, Val Acc=0.7970\n",
      "Epoch 68: Train Loss=0.4048, Train Acc=0.8060 ||| Val Loss=0.4098, Val Acc=0.7941\n",
      "Epoch 69: Train Loss=0.4063, Train Acc=0.8033 ||| Val Loss=0.4077, Val Acc=0.7987\n",
      "Epoch 70: Train Loss=0.4079, Train Acc=0.8039 ||| Val Loss=0.4056, Val Acc=0.8016\n",
      "Epoch 71: Train Loss=0.4089, Train Acc=0.8043 ||| Val Loss=0.4091, Val Acc=0.7930\n",
      "Epoch 72: Train Loss=0.4049, Train Acc=0.8041 ||| Val Loss=0.4070, Val Acc=0.8033\n",
      "Epoch 73: Train Loss=0.4077, Train Acc=0.8050 ||| Val Loss=0.4173, Val Acc=0.7941\n",
      "Epoch 74: Train Loss=0.4028, Train Acc=0.8040 ||| Val Loss=0.4158, Val Acc=0.8022\n",
      "Epoch 75: Train Loss=0.4055, Train Acc=0.8023 ||| Val Loss=0.4085, Val Acc=0.7999\n",
      "Epoch 76: Train Loss=0.4028, Train Acc=0.8040 ||| Val Loss=0.4117, Val Acc=0.7993\n",
      "Epoch 77: Train Loss=0.4003, Train Acc=0.8031 ||| Val Loss=0.4091, Val Acc=0.7987\n",
      "Epoch 78: Train Loss=0.4011, Train Acc=0.8066 ||| Val Loss=0.4128, Val Acc=0.7976\n",
      "Epoch 79: Train Loss=0.4012, Train Acc=0.8076 ||| Val Loss=0.4125, Val Acc=0.7941\n",
      "Epoch 80: Train Loss=0.4033, Train Acc=0.8030 ||| Val Loss=0.4076, Val Acc=0.7959\n",
      "Epoch 81: Train Loss=0.4035, Train Acc=0.8041 ||| Val Loss=0.4072, Val Acc=0.7947\n",
      "Epoch 82: Train Loss=0.4040, Train Acc=0.8033 ||| Val Loss=0.4082, Val Acc=0.7976\n",
      "Epoch 83: Train Loss=0.4011, Train Acc=0.8036 ||| Val Loss=0.4108, Val Acc=0.7959\n",
      "Epoch 84: Train Loss=0.4011, Train Acc=0.8089 ||| Val Loss=0.4072, Val Acc=0.7970\n",
      "Epoch 85: Train Loss=0.4021, Train Acc=0.8060 ||| Val Loss=0.4095, Val Acc=0.7970\n",
      "Epoch 86: Train Loss=0.4009, Train Acc=0.8044 ||| Val Loss=0.4108, Val Acc=0.7964\n",
      "Epoch 87: Train Loss=0.4017, Train Acc=0.8074 ||| Val Loss=0.4084, Val Acc=0.7987\n",
      "Epoch 88: Train Loss=0.4005, Train Acc=0.8090 ||| Val Loss=0.4190, Val Acc=0.7884\n",
      "Epoch 89: Train Loss=0.4019, Train Acc=0.8069 ||| Val Loss=0.4103, Val Acc=0.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:18:40,463] Trial 31 finished with value: 0.7947096032202415 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.2636809099799959, 'activation': 'ReLU', 'lr': 0.0016600543074176363, 'weight_decay': 4.116320746842263e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss=0.3993, Train Acc=0.8105 ||| Val Loss=0.4124, Val Acc=0.7947\n",
      "Early stopping triggered at epoch 90\n",
      "Validation Accuracy: 0.7947\n",
      "\n",
      " Trial 33 with params: {'n_blocks': 6, 'd_block': 128, 'k': 9, 'dropout': 0.3579712838405346, 'activation': 'ReLU', 'lr': 0.0009008772942833015, 'weight_decay': 1.5734642077417547e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7773, Train Acc=0.5449 ||| Val Loss=0.6395, Val Acc=0.6843\n",
      "Epoch 2: Train Loss=0.6157, Train Acc=0.6746 ||| Val Loss=0.5392, Val Acc=0.7809\n",
      "Epoch 3: Train Loss=0.5626, Train Acc=0.7440 ||| Val Loss=0.5239, Val Acc=0.7838\n",
      "Epoch 4: Train Loss=0.5371, Train Acc=0.7624 ||| Val Loss=0.5107, Val Acc=0.7895\n",
      "Epoch 5: Train Loss=0.5337, Train Acc=0.7672 ||| Val Loss=0.5112, Val Acc=0.7970\n",
      "Epoch 6: Train Loss=0.5153, Train Acc=0.7768 ||| Val Loss=0.5110, Val Acc=0.7878\n",
      "Epoch 7: Train Loss=0.5173, Train Acc=0.7793 ||| Val Loss=0.5042, Val Acc=0.7964\n",
      "Epoch 8: Train Loss=0.5084, Train Acc=0.7784 ||| Val Loss=0.4865, Val Acc=0.7976\n",
      "Epoch 9: Train Loss=0.5058, Train Acc=0.7794 ||| Val Loss=0.4893, Val Acc=0.7930\n",
      "Epoch 10: Train Loss=0.4986, Train Acc=0.7790 ||| Val Loss=0.4849, Val Acc=0.7964\n",
      "Epoch 11: Train Loss=0.4959, Train Acc=0.7847 ||| Val Loss=0.4856, Val Acc=0.7953\n",
      "Epoch 12: Train Loss=0.4911, Train Acc=0.7827 ||| Val Loss=0.4851, Val Acc=0.7982\n",
      "Epoch 13: Train Loss=0.4903, Train Acc=0.7813 ||| Val Loss=0.4863, Val Acc=0.7930\n",
      "Epoch 14: Train Loss=0.4795, Train Acc=0.7849 ||| Val Loss=0.4729, Val Acc=0.7976\n",
      "Epoch 15: Train Loss=0.4739, Train Acc=0.7852 ||| Val Loss=0.4786, Val Acc=0.8022\n",
      "Epoch 16: Train Loss=0.4675, Train Acc=0.7863 ||| Val Loss=0.4755, Val Acc=0.7970\n",
      "Epoch 17: Train Loss=0.4619, Train Acc=0.7865 ||| Val Loss=0.4631, Val Acc=0.7999\n",
      "Epoch 18: Train Loss=0.4543, Train Acc=0.7908 ||| Val Loss=0.4529, Val Acc=0.7976\n",
      "Epoch 19: Train Loss=0.4546, Train Acc=0.7895 ||| Val Loss=0.4501, Val Acc=0.7999\n",
      "Epoch 20: Train Loss=0.4566, Train Acc=0.7900 ||| Val Loss=0.4715, Val Acc=0.7924\n",
      "Epoch 21: Train Loss=0.4509, Train Acc=0.7893 ||| Val Loss=0.4364, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4467, Train Acc=0.7880 ||| Val Loss=0.4304, Val Acc=0.7982\n",
      "Epoch 23: Train Loss=0.4413, Train Acc=0.7892 ||| Val Loss=0.4390, Val Acc=0.7941\n",
      "Epoch 24: Train Loss=0.4493, Train Acc=0.7918 ||| Val Loss=0.4517, Val Acc=0.7964\n",
      "Epoch 25: Train Loss=0.4407, Train Acc=0.7906 ||| Val Loss=0.4344, Val Acc=0.7947\n",
      "Epoch 26: Train Loss=0.4364, Train Acc=0.7918 ||| Val Loss=0.4286, Val Acc=0.7999\n",
      "Epoch 27: Train Loss=0.4390, Train Acc=0.7932 ||| Val Loss=0.4431, Val Acc=0.8005\n",
      "Epoch 28: Train Loss=0.4315, Train Acc=0.7977 ||| Val Loss=0.4317, Val Acc=0.7993\n",
      "Epoch 29: Train Loss=0.4377, Train Acc=0.7923 ||| Val Loss=0.4461, Val Acc=0.7930\n",
      "Epoch 30: Train Loss=0.4370, Train Acc=0.7903 ||| Val Loss=0.4281, Val Acc=0.7970\n",
      "Epoch 31: Train Loss=0.4355, Train Acc=0.7944 ||| Val Loss=0.4333, Val Acc=0.7936\n",
      "Epoch 32: Train Loss=0.4336, Train Acc=0.7970 ||| Val Loss=0.4249, Val Acc=0.8010\n",
      "Epoch 33: Train Loss=0.4357, Train Acc=0.7952 ||| Val Loss=0.4285, Val Acc=0.8005\n",
      "Epoch 34: Train Loss=0.4361, Train Acc=0.7964 ||| Val Loss=0.4224, Val Acc=0.8005\n",
      "Epoch 35: Train Loss=0.4332, Train Acc=0.7934 ||| Val Loss=0.4248, Val Acc=0.7993\n",
      "Epoch 36: Train Loss=0.4345, Train Acc=0.7926 ||| Val Loss=0.4358, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4322, Train Acc=0.7972 ||| Val Loss=0.4260, Val Acc=0.7964\n",
      "Epoch 38: Train Loss=0.4327, Train Acc=0.7932 ||| Val Loss=0.4254, Val Acc=0.8005\n",
      "Epoch 39: Train Loss=0.4317, Train Acc=0.7941 ||| Val Loss=0.4339, Val Acc=0.7953\n",
      "Epoch 40: Train Loss=0.4293, Train Acc=0.7981 ||| Val Loss=0.4219, Val Acc=0.7930\n",
      "Epoch 41: Train Loss=0.4255, Train Acc=0.7941 ||| Val Loss=0.4277, Val Acc=0.7982\n",
      "Epoch 42: Train Loss=0.4285, Train Acc=0.7981 ||| Val Loss=0.4264, Val Acc=0.7947\n",
      "Epoch 43: Train Loss=0.4276, Train Acc=0.7970 ||| Val Loss=0.4250, Val Acc=0.8005\n",
      "Epoch 44: Train Loss=0.4273, Train Acc=0.7942 ||| Val Loss=0.4219, Val Acc=0.7982\n",
      "Epoch 45: Train Loss=0.4311, Train Acc=0.7942 ||| Val Loss=0.4261, Val Acc=0.7936\n",
      "Epoch 46: Train Loss=0.4276, Train Acc=0.7987 ||| Val Loss=0.4256, Val Acc=0.7987\n",
      "Epoch 47: Train Loss=0.4243, Train Acc=0.7967 ||| Val Loss=0.4230, Val Acc=0.7930\n",
      "Epoch 48: Train Loss=0.4268, Train Acc=0.7941 ||| Val Loss=0.4268, Val Acc=0.7861\n",
      "Epoch 49: Train Loss=0.4256, Train Acc=0.7975 ||| Val Loss=0.4246, Val Acc=0.7999\n",
      "Epoch 50: Train Loss=0.4244, Train Acc=0.7984 ||| Val Loss=0.4200, Val Acc=0.7987\n",
      "Epoch 51: Train Loss=0.4262, Train Acc=0.7995 ||| Val Loss=0.4244, Val Acc=0.7982\n",
      "Epoch 52: Train Loss=0.4229, Train Acc=0.7967 ||| Val Loss=0.4191, Val Acc=0.8005\n",
      "Epoch 53: Train Loss=0.4244, Train Acc=0.7970 ||| Val Loss=0.4239, Val Acc=0.7947\n",
      "Epoch 54: Train Loss=0.4219, Train Acc=0.7981 ||| Val Loss=0.4227, Val Acc=0.7976\n",
      "Epoch 55: Train Loss=0.4247, Train Acc=0.7984 ||| Val Loss=0.4198, Val Acc=0.7959\n",
      "Epoch 56: Train Loss=0.4239, Train Acc=0.7944 ||| Val Loss=0.4236, Val Acc=0.7976\n",
      "Epoch 57: Train Loss=0.4214, Train Acc=0.7982 ||| Val Loss=0.4277, Val Acc=0.8010\n",
      "Epoch 58: Train Loss=0.4202, Train Acc=0.7938 ||| Val Loss=0.4194, Val Acc=0.7970\n",
      "Epoch 59: Train Loss=0.4203, Train Acc=0.7961 ||| Val Loss=0.4357, Val Acc=0.7976\n",
      "Epoch 60: Train Loss=0.4256, Train Acc=0.7957 ||| Val Loss=0.4328, Val Acc=0.7976\n",
      "Epoch 61: Train Loss=0.4243, Train Acc=0.8003 ||| Val Loss=0.4373, Val Acc=0.8005\n",
      "Epoch 62: Train Loss=0.4244, Train Acc=0.7918 ||| Val Loss=0.4251, Val Acc=0.7901\n",
      "Epoch 63: Train Loss=0.4230, Train Acc=0.7965 ||| Val Loss=0.4278, Val Acc=0.7913\n",
      "Epoch 64: Train Loss=0.4211, Train Acc=0.7980 ||| Val Loss=0.4153, Val Acc=0.8028\n",
      "Epoch 65: Train Loss=0.4225, Train Acc=0.7982 ||| Val Loss=0.4211, Val Acc=0.7993\n",
      "Epoch 66: Train Loss=0.4184, Train Acc=0.7967 ||| Val Loss=0.4303, Val Acc=0.7953\n",
      "Epoch 67: Train Loss=0.4238, Train Acc=0.7967 ||| Val Loss=0.4158, Val Acc=0.7982\n",
      "Epoch 68: Train Loss=0.4212, Train Acc=0.7985 ||| Val Loss=0.4308, Val Acc=0.7964\n",
      "Epoch 69: Train Loss=0.4161, Train Acc=0.7995 ||| Val Loss=0.4287, Val Acc=0.7884\n",
      "Epoch 70: Train Loss=0.4191, Train Acc=0.8021 ||| Val Loss=0.4272, Val Acc=0.7924\n",
      "Epoch 71: Train Loss=0.4201, Train Acc=0.7957 ||| Val Loss=0.4297, Val Acc=0.7918\n",
      "Epoch 72: Train Loss=0.4180, Train Acc=0.7958 ||| Val Loss=0.4243, Val Acc=0.7982\n",
      "Epoch 73: Train Loss=0.4159, Train Acc=0.7970 ||| Val Loss=0.4241, Val Acc=0.7970\n",
      "Epoch 74: Train Loss=0.4187, Train Acc=0.7970 ||| Val Loss=0.4293, Val Acc=0.7999\n",
      "Epoch 75: Train Loss=0.4193, Train Acc=0.7977 ||| Val Loss=0.4203, Val Acc=0.8022\n",
      "Epoch 76: Train Loss=0.4199, Train Acc=0.7962 ||| Val Loss=0.4173, Val Acc=0.8068\n",
      "Epoch 77: Train Loss=0.4182, Train Acc=0.7982 ||| Val Loss=0.4166, Val Acc=0.7941\n",
      "Epoch 78: Train Loss=0.4189, Train Acc=0.7967 ||| Val Loss=0.4169, Val Acc=0.7976\n",
      "Epoch 79: Train Loss=0.4197, Train Acc=0.7987 ||| Val Loss=0.4319, Val Acc=0.7953\n",
      "Epoch 80: Train Loss=0.4186, Train Acc=0.7980 ||| Val Loss=0.4124, Val Acc=0.8033\n",
      "Epoch 81: Train Loss=0.4184, Train Acc=0.7984 ||| Val Loss=0.4182, Val Acc=0.7964\n",
      "Epoch 82: Train Loss=0.4200, Train Acc=0.7985 ||| Val Loss=0.4286, Val Acc=0.7976\n",
      "Epoch 83: Train Loss=0.4195, Train Acc=0.7972 ||| Val Loss=0.4242, Val Acc=0.8005\n",
      "Epoch 84: Train Loss=0.4149, Train Acc=0.8005 ||| Val Loss=0.4185, Val Acc=0.8028\n",
      "Epoch 85: Train Loss=0.4175, Train Acc=0.7972 ||| Val Loss=0.4200, Val Acc=0.7918\n",
      "Epoch 86: Train Loss=0.4149, Train Acc=0.8005 ||| Val Loss=0.4226, Val Acc=0.8039\n",
      "Epoch 87: Train Loss=0.4172, Train Acc=0.8034 ||| Val Loss=0.4184, Val Acc=0.7970\n",
      "Epoch 88: Train Loss=0.4132, Train Acc=0.7982 ||| Val Loss=0.4146, Val Acc=0.8005\n",
      "Epoch 89: Train Loss=0.4166, Train Acc=0.8013 ||| Val Loss=0.4148, Val Acc=0.7964\n",
      "Epoch 90: Train Loss=0.4143, Train Acc=0.8003 ||| Val Loss=0.4187, Val Acc=0.7936\n",
      "Epoch 91: Train Loss=0.4151, Train Acc=0.7978 ||| Val Loss=0.4224, Val Acc=0.7941\n",
      "Epoch 92: Train Loss=0.4163, Train Acc=0.7995 ||| Val Loss=0.4227, Val Acc=0.8010\n",
      "Epoch 93: Train Loss=0.4113, Train Acc=0.7982 ||| Val Loss=0.4206, Val Acc=0.8039\n",
      "Epoch 94: Train Loss=0.4138, Train Acc=0.8024 ||| Val Loss=0.4185, Val Acc=0.8010\n",
      "Epoch 95: Train Loss=0.4196, Train Acc=0.7968 ||| Val Loss=0.4167, Val Acc=0.8016\n",
      "Epoch 96: Train Loss=0.4186, Train Acc=0.8000 ||| Val Loss=0.4210, Val Acc=0.7970\n",
      "Epoch 97: Train Loss=0.4155, Train Acc=0.8031 ||| Val Loss=0.4237, Val Acc=0.8022\n",
      "Epoch 98: Train Loss=0.4132, Train Acc=0.7987 ||| Val Loss=0.4160, Val Acc=0.7959\n",
      "Epoch 99: Train Loss=0.4137, Train Acc=0.8024 ||| Val Loss=0.4157, Val Acc=0.7976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:19:19,095] Trial 32 finished with value: 0.7912593444508338 and parameters: {'n_blocks': 6, 'd_block': 128, 'k': 9, 'dropout': 0.3579712838405346, 'activation': 'ReLU', 'lr': 0.0009008772942833015, 'weight_decay': 1.5734642077417547e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss=0.4143, Train Acc=0.7990 ||| Val Loss=0.4336, Val Acc=0.7913\n",
      "Early stopping triggered at epoch 100\n",
      "Validation Accuracy: 0.7913\n",
      "\n",
      " Trial 34 with params: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.23106814668354772, 'activation': 'ReLU', 'lr': 0.0020532734451836642, 'weight_decay': 9.746529460798676e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.8408, Train Acc=0.6452 ||| Val Loss=0.5263, Val Acc=0.7533\n",
      "Epoch 2: Train Loss=0.5647, Train Acc=0.7322 ||| Val Loss=0.5413, Val Acc=0.7746\n",
      "Epoch 3: Train Loss=0.5315, Train Acc=0.7633 ||| Val Loss=0.5031, Val Acc=0.7867\n",
      "Epoch 4: Train Loss=0.5211, Train Acc=0.7691 ||| Val Loss=0.4939, Val Acc=0.7890\n",
      "Epoch 5: Train Loss=0.5157, Train Acc=0.7751 ||| Val Loss=0.5017, Val Acc=0.7959\n",
      "Epoch 6: Train Loss=0.5089, Train Acc=0.7762 ||| Val Loss=0.4814, Val Acc=0.7936\n",
      "Epoch 7: Train Loss=0.5030, Train Acc=0.7767 ||| Val Loss=0.4894, Val Acc=0.7907\n",
      "Epoch 8: Train Loss=0.4979, Train Acc=0.7830 ||| Val Loss=0.4777, Val Acc=0.7930\n",
      "Epoch 9: Train Loss=0.4953, Train Acc=0.7798 ||| Val Loss=0.4844, Val Acc=0.7895\n",
      "Epoch 10: Train Loss=0.4875, Train Acc=0.7859 ||| Val Loss=0.4746, Val Acc=0.7970\n",
      "Epoch 11: Train Loss=0.4812, Train Acc=0.7846 ||| Val Loss=0.4734, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.4822, Train Acc=0.7840 ||| Val Loss=0.4670, Val Acc=0.7947\n",
      "Epoch 13: Train Loss=0.4716, Train Acc=0.7873 ||| Val Loss=0.4715, Val Acc=0.7982\n",
      "Epoch 14: Train Loss=0.4677, Train Acc=0.7834 ||| Val Loss=0.4418, Val Acc=0.7993\n",
      "Epoch 15: Train Loss=0.4625, Train Acc=0.7852 ||| Val Loss=0.4527, Val Acc=0.7993\n",
      "Epoch 16: Train Loss=0.4545, Train Acc=0.7865 ||| Val Loss=0.4350, Val Acc=0.7970\n",
      "Epoch 17: Train Loss=0.4492, Train Acc=0.7879 ||| Val Loss=0.4411, Val Acc=0.7970\n",
      "Epoch 18: Train Loss=0.4487, Train Acc=0.7876 ||| Val Loss=0.4413, Val Acc=0.7936\n",
      "Epoch 19: Train Loss=0.4443, Train Acc=0.7866 ||| Val Loss=0.4338, Val Acc=0.7895\n",
      "Epoch 20: Train Loss=0.4419, Train Acc=0.7895 ||| Val Loss=0.4324, Val Acc=0.7959\n",
      "Epoch 21: Train Loss=0.4373, Train Acc=0.7939 ||| Val Loss=0.4275, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4372, Train Acc=0.7883 ||| Val Loss=0.4274, Val Acc=0.8005\n",
      "Epoch 23: Train Loss=0.4318, Train Acc=0.7951 ||| Val Loss=0.4250, Val Acc=0.7924\n",
      "Epoch 24: Train Loss=0.4286, Train Acc=0.7905 ||| Val Loss=0.4307, Val Acc=0.7941\n",
      "Epoch 25: Train Loss=0.4308, Train Acc=0.7935 ||| Val Loss=0.4229, Val Acc=0.7976\n",
      "Epoch 26: Train Loss=0.4286, Train Acc=0.7949 ||| Val Loss=0.4227, Val Acc=0.7953\n",
      "Epoch 27: Train Loss=0.4280, Train Acc=0.7980 ||| Val Loss=0.4208, Val Acc=0.7924\n",
      "Epoch 28: Train Loss=0.4250, Train Acc=0.7985 ||| Val Loss=0.4260, Val Acc=0.7953\n",
      "Epoch 29: Train Loss=0.4251, Train Acc=0.7974 ||| Val Loss=0.4251, Val Acc=0.7976\n",
      "Epoch 30: Train Loss=0.4231, Train Acc=0.7972 ||| Val Loss=0.4199, Val Acc=0.7907\n",
      "Epoch 31: Train Loss=0.4236, Train Acc=0.7980 ||| Val Loss=0.4232, Val Acc=0.7976\n",
      "Epoch 32: Train Loss=0.4216, Train Acc=0.7980 ||| Val Loss=0.4228, Val Acc=0.7913\n",
      "Epoch 33: Train Loss=0.4238, Train Acc=0.7948 ||| Val Loss=0.4244, Val Acc=0.7970\n",
      "Epoch 34: Train Loss=0.4199, Train Acc=0.7959 ||| Val Loss=0.4120, Val Acc=0.7982\n",
      "Epoch 35: Train Loss=0.4209, Train Acc=0.7959 ||| Val Loss=0.4224, Val Acc=0.7941\n",
      "Epoch 36: Train Loss=0.4231, Train Acc=0.7971 ||| Val Loss=0.4230, Val Acc=0.7838\n",
      "Epoch 37: Train Loss=0.4208, Train Acc=0.7995 ||| Val Loss=0.4244, Val Acc=0.7947\n",
      "Epoch 38: Train Loss=0.4189, Train Acc=0.7981 ||| Val Loss=0.4243, Val Acc=0.7809\n",
      "Epoch 39: Train Loss=0.4184, Train Acc=0.7985 ||| Val Loss=0.4127, Val Acc=0.8022\n",
      "Epoch 40: Train Loss=0.4170, Train Acc=0.7988 ||| Val Loss=0.4206, Val Acc=0.8010\n",
      "Epoch 41: Train Loss=0.4155, Train Acc=0.7984 ||| Val Loss=0.4151, Val Acc=0.8005\n",
      "Epoch 42: Train Loss=0.4154, Train Acc=0.8013 ||| Val Loss=0.4195, Val Acc=0.7953\n",
      "Epoch 43: Train Loss=0.4223, Train Acc=0.8005 ||| Val Loss=0.4139, Val Acc=0.7861\n",
      "Epoch 44: Train Loss=0.4148, Train Acc=0.7985 ||| Val Loss=0.4141, Val Acc=0.7964\n",
      "Epoch 45: Train Loss=0.4151, Train Acc=0.8001 ||| Val Loss=0.4164, Val Acc=0.7964\n",
      "Epoch 46: Train Loss=0.4149, Train Acc=0.8005 ||| Val Loss=0.4186, Val Acc=0.7987\n",
      "Epoch 47: Train Loss=0.4155, Train Acc=0.7997 ||| Val Loss=0.4161, Val Acc=0.7907\n",
      "Epoch 48: Train Loss=0.4145, Train Acc=0.7997 ||| Val Loss=0.4070, Val Acc=0.7959\n",
      "Epoch 49: Train Loss=0.4157, Train Acc=0.7974 ||| Val Loss=0.4116, Val Acc=0.7884\n",
      "Epoch 50: Train Loss=0.4158, Train Acc=0.8005 ||| Val Loss=0.4081, Val Acc=0.8039\n",
      "Epoch 51: Train Loss=0.4083, Train Acc=0.8010 ||| Val Loss=0.4142, Val Acc=0.8016\n",
      "Epoch 52: Train Loss=0.4145, Train Acc=0.7993 ||| Val Loss=0.4127, Val Acc=0.7959\n",
      "Epoch 53: Train Loss=0.4116, Train Acc=0.8000 ||| Val Loss=0.4087, Val Acc=0.8016\n",
      "Epoch 54: Train Loss=0.4098, Train Acc=0.8000 ||| Val Loss=0.4085, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4147, Train Acc=0.8007 ||| Val Loss=0.4162, Val Acc=0.7982\n",
      "Epoch 56: Train Loss=0.4100, Train Acc=0.8014 ||| Val Loss=0.4109, Val Acc=0.7953\n",
      "Epoch 57: Train Loss=0.4096, Train Acc=0.8020 ||| Val Loss=0.4090, Val Acc=0.7953\n",
      "Epoch 58: Train Loss=0.4100, Train Acc=0.7981 ||| Val Loss=0.4049, Val Acc=0.7959\n",
      "Epoch 59: Train Loss=0.4064, Train Acc=0.8040 ||| Val Loss=0.4195, Val Acc=0.7815\n",
      "Epoch 60: Train Loss=0.4053, Train Acc=0.8027 ||| Val Loss=0.4037, Val Acc=0.7987\n",
      "Epoch 61: Train Loss=0.4108, Train Acc=0.8034 ||| Val Loss=0.4111, Val Acc=0.7976\n",
      "Epoch 62: Train Loss=0.4080, Train Acc=0.8059 ||| Val Loss=0.4087, Val Acc=0.7959\n",
      "Epoch 63: Train Loss=0.4060, Train Acc=0.8010 ||| Val Loss=0.4209, Val Acc=0.7924\n",
      "Epoch 64: Train Loss=0.4076, Train Acc=0.8030 ||| Val Loss=0.4165, Val Acc=0.8022\n",
      "Epoch 65: Train Loss=0.4063, Train Acc=0.8051 ||| Val Loss=0.4078, Val Acc=0.8005\n",
      "Epoch 66: Train Loss=0.4055, Train Acc=0.8053 ||| Val Loss=0.4061, Val Acc=0.8068\n",
      "Epoch 67: Train Loss=0.4061, Train Acc=0.8039 ||| Val Loss=0.4065, Val Acc=0.8005\n",
      "Epoch 68: Train Loss=0.4070, Train Acc=0.8041 ||| Val Loss=0.4136, Val Acc=0.7849\n",
      "Epoch 69: Train Loss=0.4044, Train Acc=0.8050 ||| Val Loss=0.4047, Val Acc=0.8016\n",
      "Epoch 70: Train Loss=0.4073, Train Acc=0.8054 ||| Val Loss=0.4118, Val Acc=0.8005\n",
      "Epoch 71: Train Loss=0.4068, Train Acc=0.8020 ||| Val Loss=0.4092, Val Acc=0.8010\n",
      "Epoch 72: Train Loss=0.4040, Train Acc=0.8083 ||| Val Loss=0.4086, Val Acc=0.8039\n",
      "Epoch 73: Train Loss=0.4042, Train Acc=0.8066 ||| Val Loss=0.4076, Val Acc=0.8005\n",
      "Epoch 74: Train Loss=0.4048, Train Acc=0.8053 ||| Val Loss=0.4122, Val Acc=0.7970\n",
      "Epoch 75: Train Loss=0.4052, Train Acc=0.8106 ||| Val Loss=0.4076, Val Acc=0.8010\n",
      "Epoch 76: Train Loss=0.4039, Train Acc=0.8041 ||| Val Loss=0.4048, Val Acc=0.7913\n",
      "Epoch 77: Train Loss=0.4029, Train Acc=0.8067 ||| Val Loss=0.4105, Val Acc=0.8039\n",
      "Epoch 78: Train Loss=0.4014, Train Acc=0.8063 ||| Val Loss=0.4060, Val Acc=0.7993\n",
      "Epoch 79: Train Loss=0.3961, Train Acc=0.8070 ||| Val Loss=0.4041, Val Acc=0.7982\n",
      "Epoch 80: Train Loss=0.4016, Train Acc=0.8074 ||| Val Loss=0.4011, Val Acc=0.8051\n",
      "Epoch 81: Train Loss=0.3995, Train Acc=0.8066 ||| Val Loss=0.4069, Val Acc=0.8010\n",
      "Epoch 82: Train Loss=0.4026, Train Acc=0.8083 ||| Val Loss=0.4072, Val Acc=0.7999\n",
      "Epoch 83: Train Loss=0.3955, Train Acc=0.8113 ||| Val Loss=0.4024, Val Acc=0.8079\n",
      "Epoch 84: Train Loss=0.3972, Train Acc=0.8115 ||| Val Loss=0.4163, Val Acc=0.7993\n",
      "Epoch 85: Train Loss=0.3930, Train Acc=0.8113 ||| Val Loss=0.4091, Val Acc=0.8010\n",
      "Epoch 86: Train Loss=0.4020, Train Acc=0.8072 ||| Val Loss=0.4034, Val Acc=0.7999\n",
      "Epoch 87: Train Loss=0.3968, Train Acc=0.8112 ||| Val Loss=0.4162, Val Acc=0.8005\n",
      "Epoch 88: Train Loss=0.3979, Train Acc=0.8072 ||| Val Loss=0.4113, Val Acc=0.7941\n",
      "Epoch 89: Train Loss=0.3955, Train Acc=0.8085 ||| Val Loss=0.4137, Val Acc=0.8045\n",
      "Epoch 90: Train Loss=0.3980, Train Acc=0.8121 ||| Val Loss=0.4035, Val Acc=0.7964\n",
      "Epoch 91: Train Loss=0.3987, Train Acc=0.8102 ||| Val Loss=0.4069, Val Acc=0.7970\n",
      "Epoch 92: Train Loss=0.3986, Train Acc=0.8082 ||| Val Loss=0.4092, Val Acc=0.7936\n",
      "Epoch 93: Train Loss=0.3959, Train Acc=0.8132 ||| Val Loss=0.4039, Val Acc=0.8028\n",
      "Epoch 94: Train Loss=0.3927, Train Acc=0.8109 ||| Val Loss=0.4061, Val Acc=0.8079\n",
      "Epoch 95: Train Loss=0.3933, Train Acc=0.8105 ||| Val Loss=0.4111, Val Acc=0.7987\n",
      "Epoch 96: Train Loss=0.3934, Train Acc=0.8158 ||| Val Loss=0.4029, Val Acc=0.8022\n",
      "Epoch 97: Train Loss=0.3937, Train Acc=0.8126 ||| Val Loss=0.4093, Val Acc=0.8039\n",
      "Epoch 98: Train Loss=0.3918, Train Acc=0.8087 ||| Val Loss=0.4084, Val Acc=0.7993\n",
      "Epoch 99: Train Loss=0.3910, Train Acc=0.8083 ||| Val Loss=0.4045, Val Acc=0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:19:49,149] Trial 33 finished with value: 0.8027602070155262 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.23106814668354772, 'activation': 'ReLU', 'lr': 0.0020532734451836642, 'weight_decay': 9.746529460798676e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss=0.3882, Train Acc=0.8168 ||| Val Loss=0.4046, Val Acc=0.8028\n",
      "Early stopping triggered at epoch 100\n",
      "Validation Accuracy: 0.8028\n",
      "\n",
      " Trial 35 with params: {'n_blocks': 5, 'd_block': 128, 'k': 11, 'dropout': 0.18721197844802795, 'activation': 'ReLU', 'lr': 0.003798950203094358, 'weight_decay': 1.4278012196222145e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7500, Train Acc=0.6799 ||| Val Loss=0.5219, Val Acc=0.7918\n",
      "Epoch 2: Train Loss=0.5298, Train Acc=0.7673 ||| Val Loss=0.4964, Val Acc=0.7913\n",
      "Epoch 3: Train Loss=0.5153, Train Acc=0.7783 ||| Val Loss=0.5299, Val Acc=0.7711\n",
      "Epoch 4: Train Loss=0.5046, Train Acc=0.7784 ||| Val Loss=0.4678, Val Acc=0.7941\n",
      "Epoch 5: Train Loss=0.5014, Train Acc=0.7800 ||| Val Loss=0.4631, Val Acc=0.7953\n",
      "Epoch 6: Train Loss=0.4762, Train Acc=0.7888 ||| Val Loss=0.4630, Val Acc=0.7976\n",
      "Epoch 7: Train Loss=0.4866, Train Acc=0.7831 ||| Val Loss=0.4676, Val Acc=0.7930\n",
      "Epoch 8: Train Loss=0.4648, Train Acc=0.7834 ||| Val Loss=0.4437, Val Acc=0.7941\n",
      "Epoch 9: Train Loss=0.4569, Train Acc=0.7886 ||| Val Loss=0.4509, Val Acc=0.7901\n",
      "Epoch 10: Train Loss=0.4432, Train Acc=0.7926 ||| Val Loss=0.4316, Val Acc=0.7936\n",
      "Epoch 11: Train Loss=0.4471, Train Acc=0.7895 ||| Val Loss=0.4312, Val Acc=0.7970\n",
      "Epoch 12: Train Loss=0.4429, Train Acc=0.7900 ||| Val Loss=0.4262, Val Acc=0.7872\n",
      "Epoch 13: Train Loss=0.4488, Train Acc=0.7846 ||| Val Loss=0.4278, Val Acc=0.7964\n",
      "Epoch 14: Train Loss=0.4328, Train Acc=0.7890 ||| Val Loss=0.4491, Val Acc=0.7976\n",
      "Epoch 15: Train Loss=0.4356, Train Acc=0.7867 ||| Val Loss=0.4407, Val Acc=0.7832\n",
      "Epoch 16: Train Loss=0.4298, Train Acc=0.7921 ||| Val Loss=0.4422, Val Acc=0.7936\n",
      "Epoch 17: Train Loss=0.4331, Train Acc=0.7954 ||| Val Loss=0.4179, Val Acc=0.7941\n",
      "Epoch 18: Train Loss=0.4287, Train Acc=0.7928 ||| Val Loss=0.4276, Val Acc=0.7890\n",
      "Epoch 19: Train Loss=0.4256, Train Acc=0.7931 ||| Val Loss=0.4318, Val Acc=0.7941\n",
      "Epoch 20: Train Loss=0.4301, Train Acc=0.7896 ||| Val Loss=0.4162, Val Acc=0.7941\n",
      "Epoch 21: Train Loss=0.4275, Train Acc=0.7931 ||| Val Loss=0.4124, Val Acc=0.7941\n",
      "Epoch 22: Train Loss=0.4208, Train Acc=0.7955 ||| Val Loss=0.4210, Val Acc=0.7924\n",
      "Epoch 23: Train Loss=0.4218, Train Acc=0.7965 ||| Val Loss=0.4118, Val Acc=0.7976\n",
      "Epoch 24: Train Loss=0.4254, Train Acc=0.7957 ||| Val Loss=0.4229, Val Acc=0.7936\n",
      "Epoch 25: Train Loss=0.4189, Train Acc=0.8023 ||| Val Loss=0.4239, Val Acc=0.7941\n",
      "Epoch 26: Train Loss=0.4271, Train Acc=0.7955 ||| Val Loss=0.4140, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4176, Train Acc=0.7981 ||| Val Loss=0.4133, Val Acc=0.8010\n",
      "Epoch 28: Train Loss=0.4190, Train Acc=0.7974 ||| Val Loss=0.4212, Val Acc=0.7941\n",
      "Epoch 29: Train Loss=0.4213, Train Acc=0.7944 ||| Val Loss=0.4173, Val Acc=0.7918\n",
      "Epoch 30: Train Loss=0.4184, Train Acc=0.7961 ||| Val Loss=0.4095, Val Acc=0.7976\n",
      "Epoch 31: Train Loss=0.4208, Train Acc=0.7970 ||| Val Loss=0.4077, Val Acc=0.7993\n",
      "Epoch 32: Train Loss=0.4157, Train Acc=0.7980 ||| Val Loss=0.4108, Val Acc=0.8039\n",
      "Epoch 33: Train Loss=0.4130, Train Acc=0.7990 ||| Val Loss=0.4085, Val Acc=0.7953\n",
      "Epoch 34: Train Loss=0.4199, Train Acc=0.7961 ||| Val Loss=0.4135, Val Acc=0.7913\n",
      "Epoch 35: Train Loss=0.4136, Train Acc=0.7995 ||| Val Loss=0.4130, Val Acc=0.7993\n",
      "Epoch 36: Train Loss=0.4135, Train Acc=0.7995 ||| Val Loss=0.4128, Val Acc=0.7895\n",
      "Epoch 37: Train Loss=0.4123, Train Acc=0.8033 ||| Val Loss=0.4119, Val Acc=0.7970\n",
      "Epoch 38: Train Loss=0.4140, Train Acc=0.7998 ||| Val Loss=0.4054, Val Acc=0.7976\n",
      "Epoch 39: Train Loss=0.4168, Train Acc=0.7987 ||| Val Loss=0.4216, Val Acc=0.7999\n",
      "Epoch 40: Train Loss=0.4143, Train Acc=0.8026 ||| Val Loss=0.4133, Val Acc=0.8005\n",
      "Epoch 41: Train Loss=0.4114, Train Acc=0.8053 ||| Val Loss=0.4136, Val Acc=0.7982\n",
      "Epoch 42: Train Loss=0.4155, Train Acc=0.7988 ||| Val Loss=0.4090, Val Acc=0.8033\n",
      "Epoch 43: Train Loss=0.4118, Train Acc=0.8001 ||| Val Loss=0.4045, Val Acc=0.7970\n",
      "Epoch 44: Train Loss=0.4135, Train Acc=0.8046 ||| Val Loss=0.4100, Val Acc=0.7941\n",
      "Epoch 45: Train Loss=0.4124, Train Acc=0.8041 ||| Val Loss=0.4039, Val Acc=0.7999\n",
      "Epoch 46: Train Loss=0.4109, Train Acc=0.8074 ||| Val Loss=0.4038, Val Acc=0.8010\n",
      "Epoch 47: Train Loss=0.4117, Train Acc=0.8037 ||| Val Loss=0.4091, Val Acc=0.7982\n",
      "Epoch 48: Train Loss=0.4077, Train Acc=0.8051 ||| Val Loss=0.4076, Val Acc=0.8016\n",
      "Epoch 49: Train Loss=0.4082, Train Acc=0.8062 ||| Val Loss=0.4112, Val Acc=0.8010\n",
      "Epoch 50: Train Loss=0.4107, Train Acc=0.8039 ||| Val Loss=0.4062, Val Acc=0.7970\n",
      "Epoch 51: Train Loss=0.4132, Train Acc=0.8056 ||| Val Loss=0.4169, Val Acc=0.8028\n",
      "Epoch 52: Train Loss=0.4111, Train Acc=0.8067 ||| Val Loss=0.4149, Val Acc=0.8022\n",
      "Epoch 53: Train Loss=0.4093, Train Acc=0.8074 ||| Val Loss=0.4080, Val Acc=0.7976\n",
      "Epoch 54: Train Loss=0.4063, Train Acc=0.8074 ||| Val Loss=0.4112, Val Acc=0.7936\n",
      "Epoch 55: Train Loss=0.4140, Train Acc=0.8003 ||| Val Loss=0.4233, Val Acc=0.8028\n",
      "Epoch 56: Train Loss=0.4075, Train Acc=0.8086 ||| Val Loss=0.4044, Val Acc=0.8051\n",
      "Epoch 57: Train Loss=0.4079, Train Acc=0.8073 ||| Val Loss=0.4089, Val Acc=0.8005\n",
      "Epoch 58: Train Loss=0.4052, Train Acc=0.8034 ||| Val Loss=0.4099, Val Acc=0.8010\n",
      "Epoch 59: Train Loss=0.4074, Train Acc=0.8099 ||| Val Loss=0.4058, Val Acc=0.8022\n",
      "Epoch 60: Train Loss=0.4054, Train Acc=0.8060 ||| Val Loss=0.4088, Val Acc=0.8022\n",
      "Epoch 61: Train Loss=0.4058, Train Acc=0.8072 ||| Val Loss=0.4116, Val Acc=0.7964\n",
      "Epoch 62: Train Loss=0.4089, Train Acc=0.8034 ||| Val Loss=0.4118, Val Acc=0.7959\n",
      "Epoch 63: Train Loss=0.4056, Train Acc=0.8087 ||| Val Loss=0.4082, Val Acc=0.7993\n",
      "Epoch 64: Train Loss=0.4051, Train Acc=0.8064 ||| Val Loss=0.4055, Val Acc=0.7987\n",
      "Epoch 65: Train Loss=0.4052, Train Acc=0.8080 ||| Val Loss=0.4074, Val Acc=0.7993\n",
      "Epoch 66: Train Loss=0.4036, Train Acc=0.8040 ||| Val Loss=0.4037, Val Acc=0.7982\n",
      "Epoch 67: Train Loss=0.4030, Train Acc=0.8083 ||| Val Loss=0.4092, Val Acc=0.8005\n",
      "Epoch 68: Train Loss=0.4056, Train Acc=0.8039 ||| Val Loss=0.4089, Val Acc=0.8028\n",
      "Epoch 69: Train Loss=0.4017, Train Acc=0.8076 ||| Val Loss=0.4051, Val Acc=0.8005\n",
      "Epoch 70: Train Loss=0.4033, Train Acc=0.8085 ||| Val Loss=0.4033, Val Acc=0.8022\n",
      "Epoch 71: Train Loss=0.4042, Train Acc=0.8099 ||| Val Loss=0.4072, Val Acc=0.7884\n",
      "Epoch 72: Train Loss=0.4005, Train Acc=0.8102 ||| Val Loss=0.4105, Val Acc=0.8039\n",
      "Epoch 73: Train Loss=0.4014, Train Acc=0.8063 ||| Val Loss=0.4083, Val Acc=0.7982\n",
      "Epoch 74: Train Loss=0.3992, Train Acc=0.8141 ||| Val Loss=0.4077, Val Acc=0.7982\n",
      "Epoch 75: Train Loss=0.4020, Train Acc=0.8128 ||| Val Loss=0.4013, Val Acc=0.8045\n",
      "Epoch 76: Train Loss=0.4021, Train Acc=0.8074 ||| Val Loss=0.4100, Val Acc=0.7999\n",
      "Epoch 77: Train Loss=0.4017, Train Acc=0.8067 ||| Val Loss=0.4063, Val Acc=0.8028\n",
      "Epoch 78: Train Loss=0.3969, Train Acc=0.8079 ||| Val Loss=0.4062, Val Acc=0.8062\n",
      "Epoch 79: Train Loss=0.3985, Train Acc=0.8121 ||| Val Loss=0.4018, Val Acc=0.8039\n",
      "Epoch 80: Train Loss=0.3951, Train Acc=0.8126 ||| Val Loss=0.4140, Val Acc=0.8068\n",
      "Epoch 81: Train Loss=0.4002, Train Acc=0.8106 ||| Val Loss=0.4090, Val Acc=0.7918\n",
      "Epoch 82: Train Loss=0.4005, Train Acc=0.8105 ||| Val Loss=0.4171, Val Acc=0.7959\n",
      "Epoch 83: Train Loss=0.4012, Train Acc=0.8099 ||| Val Loss=0.4063, Val Acc=0.8051\n",
      "Epoch 84: Train Loss=0.3971, Train Acc=0.8097 ||| Val Loss=0.4079, Val Acc=0.8022\n",
      "Epoch 85: Train Loss=0.4015, Train Acc=0.8128 ||| Val Loss=0.4065, Val Acc=0.7999\n",
      "Epoch 86: Train Loss=0.3963, Train Acc=0.8123 ||| Val Loss=0.4082, Val Acc=0.7964\n",
      "Epoch 87: Train Loss=0.3980, Train Acc=0.8089 ||| Val Loss=0.4059, Val Acc=0.7964\n",
      "Epoch 88: Train Loss=0.3935, Train Acc=0.8142 ||| Val Loss=0.4090, Val Acc=0.8010\n",
      "Epoch 89: Train Loss=0.3957, Train Acc=0.8100 ||| Val Loss=0.4110, Val Acc=0.7999\n",
      "Epoch 90: Train Loss=0.3951, Train Acc=0.8136 ||| Val Loss=0.4017, Val Acc=0.8010\n",
      "Epoch 91: Train Loss=0.3952, Train Acc=0.8096 ||| Val Loss=0.4068, Val Acc=0.8016\n",
      "Epoch 92: Train Loss=0.3960, Train Acc=0.8148 ||| Val Loss=0.4130, Val Acc=0.7872\n",
      "Epoch 93: Train Loss=0.3958, Train Acc=0.8119 ||| Val Loss=0.4210, Val Acc=0.7815\n",
      "Epoch 94: Train Loss=0.3930, Train Acc=0.8167 ||| Val Loss=0.4040, Val Acc=0.8022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:20:23,173] Trial 34 finished with value: 0.8021851638872916 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 11, 'dropout': 0.18721197844802795, 'activation': 'ReLU', 'lr': 0.003798950203094358, 'weight_decay': 1.4278012196222145e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Train Loss=0.3920, Train Acc=0.8106 ||| Val Loss=0.4140, Val Acc=0.8022\n",
      "Early stopping triggered at epoch 95\n",
      "Validation Accuracy: 0.8022\n",
      "\n",
      " Trial 36 with params: {'n_blocks': 4, 'd_block': 512, 'k': 9, 'dropout': 0.2931050500937418, 'activation': 'GELU', 'lr': 0.0009119021657581938, 'weight_decay': 3.5193322723725726e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.4273, Train Acc=0.6411 ||| Val Loss=0.5365, Val Acc=0.7930\n",
      "Epoch 2: Train Loss=0.6125, Train Acc=0.7028 ||| Val Loss=0.5537, Val Acc=0.7838\n",
      "Epoch 3: Train Loss=0.5651, Train Acc=0.7317 ||| Val Loss=0.5418, Val Acc=0.7499\n",
      "Epoch 4: Train Loss=0.5574, Train Acc=0.7386 ||| Val Loss=0.5429, Val Acc=0.7108\n",
      "Epoch 5: Train Loss=0.5407, Train Acc=0.7537 ||| Val Loss=0.5230, Val Acc=0.7890\n",
      "Epoch 6: Train Loss=0.5300, Train Acc=0.7614 ||| Val Loss=0.5059, Val Acc=0.7959\n",
      "Epoch 7: Train Loss=0.5215, Train Acc=0.7706 ||| Val Loss=0.4990, Val Acc=0.7872\n",
      "Epoch 8: Train Loss=0.5245, Train Acc=0.7676 ||| Val Loss=0.4953, Val Acc=0.7872\n",
      "Epoch 9: Train Loss=0.5192, Train Acc=0.7718 ||| Val Loss=0.4987, Val Acc=0.7936\n",
      "Epoch 10: Train Loss=0.5109, Train Acc=0.7758 ||| Val Loss=0.5116, Val Acc=0.7803\n",
      "Epoch 11: Train Loss=0.5102, Train Acc=0.7749 ||| Val Loss=0.4952, Val Acc=0.7815\n",
      "Epoch 12: Train Loss=0.5047, Train Acc=0.7748 ||| Val Loss=0.4881, Val Acc=0.7901\n",
      "Epoch 13: Train Loss=0.5081, Train Acc=0.7757 ||| Val Loss=0.5014, Val Acc=0.7941\n",
      "Epoch 14: Train Loss=0.5060, Train Acc=0.7773 ||| Val Loss=0.5001, Val Acc=0.7878\n",
      "Epoch 15: Train Loss=0.4990, Train Acc=0.7788 ||| Val Loss=0.4891, Val Acc=0.7907\n",
      "Epoch 16: Train Loss=0.4977, Train Acc=0.7803 ||| Val Loss=0.4855, Val Acc=0.7826\n",
      "Epoch 17: Train Loss=0.4959, Train Acc=0.7804 ||| Val Loss=0.4690, Val Acc=0.7913\n",
      "Epoch 18: Train Loss=0.4936, Train Acc=0.7808 ||| Val Loss=0.4836, Val Acc=0.7953\n",
      "Epoch 19: Train Loss=0.4860, Train Acc=0.7803 ||| Val Loss=0.4778, Val Acc=0.7930\n",
      "Epoch 20: Train Loss=0.4820, Train Acc=0.7823 ||| Val Loss=0.4724, Val Acc=0.7918\n",
      "Epoch 21: Train Loss=0.4835, Train Acc=0.7783 ||| Val Loss=0.4692, Val Acc=0.7913\n",
      "Epoch 22: Train Loss=0.4769, Train Acc=0.7819 ||| Val Loss=0.4593, Val Acc=0.7913\n",
      "Epoch 23: Train Loss=0.4724, Train Acc=0.7783 ||| Val Loss=0.4814, Val Acc=0.7982\n",
      "Epoch 24: Train Loss=0.4784, Train Acc=0.7823 ||| Val Loss=0.4475, Val Acc=0.7953\n",
      "Epoch 25: Train Loss=0.4586, Train Acc=0.7856 ||| Val Loss=0.4456, Val Acc=0.7993\n",
      "Epoch 26: Train Loss=0.4571, Train Acc=0.7853 ||| Val Loss=0.4449, Val Acc=0.7982\n",
      "Epoch 27: Train Loss=0.4609, Train Acc=0.7854 ||| Val Loss=0.4500, Val Acc=0.7964\n",
      "Epoch 28: Train Loss=0.4544, Train Acc=0.7850 ||| Val Loss=0.4568, Val Acc=0.7970\n",
      "Epoch 29: Train Loss=0.4505, Train Acc=0.7872 ||| Val Loss=0.4433, Val Acc=0.8022\n",
      "Epoch 30: Train Loss=0.4515, Train Acc=0.7877 ||| Val Loss=0.4431, Val Acc=0.7941\n",
      "Epoch 31: Train Loss=0.4501, Train Acc=0.7893 ||| Val Loss=0.4473, Val Acc=0.7959\n",
      "Epoch 32: Train Loss=0.4517, Train Acc=0.7908 ||| Val Loss=0.4394, Val Acc=0.7964\n",
      "Epoch 33: Train Loss=0.4435, Train Acc=0.7892 ||| Val Loss=0.4379, Val Acc=0.7976\n",
      "Epoch 34: Train Loss=0.4462, Train Acc=0.7898 ||| Val Loss=0.4396, Val Acc=0.7947\n",
      "Epoch 35: Train Loss=0.4384, Train Acc=0.7902 ||| Val Loss=0.4383, Val Acc=0.7941\n",
      "Epoch 36: Train Loss=0.4463, Train Acc=0.7903 ||| Val Loss=0.4342, Val Acc=0.7941\n",
      "Epoch 37: Train Loss=0.4385, Train Acc=0.7919 ||| Val Loss=0.4414, Val Acc=0.7941\n",
      "Epoch 38: Train Loss=0.4364, Train Acc=0.7922 ||| Val Loss=0.4365, Val Acc=0.7901\n",
      "Epoch 39: Train Loss=0.4350, Train Acc=0.7921 ||| Val Loss=0.4372, Val Acc=0.7970\n",
      "Epoch 40: Train Loss=0.4377, Train Acc=0.7890 ||| Val Loss=0.4349, Val Acc=0.7999\n",
      "Epoch 41: Train Loss=0.4332, Train Acc=0.7928 ||| Val Loss=0.4262, Val Acc=0.7936\n",
      "Epoch 42: Train Loss=0.4285, Train Acc=0.7911 ||| Val Loss=0.4340, Val Acc=0.7982\n",
      "Epoch 43: Train Loss=0.4371, Train Acc=0.7934 ||| Val Loss=0.4430, Val Acc=0.7930\n",
      "Epoch 44: Train Loss=0.4298, Train Acc=0.7955 ||| Val Loss=0.4331, Val Acc=0.7953\n",
      "Epoch 45: Train Loss=0.4297, Train Acc=0.7958 ||| Val Loss=0.4374, Val Acc=0.7901\n",
      "Epoch 46: Train Loss=0.4224, Train Acc=0.7970 ||| Val Loss=0.4308, Val Acc=0.7993\n",
      "Epoch 47: Train Loss=0.4309, Train Acc=0.7922 ||| Val Loss=0.4326, Val Acc=0.7987\n",
      "Epoch 48: Train Loss=0.4333, Train Acc=0.7919 ||| Val Loss=0.4199, Val Acc=0.7993\n",
      "Epoch 49: Train Loss=0.4271, Train Acc=0.7916 ||| Val Loss=0.4282, Val Acc=0.7982\n",
      "Epoch 50: Train Loss=0.4311, Train Acc=0.7913 ||| Val Loss=0.4303, Val Acc=0.7970\n",
      "Epoch 51: Train Loss=0.4282, Train Acc=0.7993 ||| Val Loss=0.4332, Val Acc=0.7976\n",
      "Epoch 52: Train Loss=0.4274, Train Acc=0.7947 ||| Val Loss=0.4279, Val Acc=0.7964\n",
      "Epoch 53: Train Loss=0.4238, Train Acc=0.7972 ||| Val Loss=0.4280, Val Acc=0.7924\n",
      "Epoch 54: Train Loss=0.4265, Train Acc=0.7972 ||| Val Loss=0.4338, Val Acc=0.7918\n",
      "Epoch 55: Train Loss=0.4278, Train Acc=0.7957 ||| Val Loss=0.4278, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4221, Train Acc=0.7921 ||| Val Loss=0.4242, Val Acc=0.7907\n",
      "Epoch 57: Train Loss=0.4205, Train Acc=0.7970 ||| Val Loss=0.4387, Val Acc=0.7987\n",
      "Epoch 58: Train Loss=0.4248, Train Acc=0.7929 ||| Val Loss=0.4221, Val Acc=0.7959\n",
      "Epoch 59: Train Loss=0.4258, Train Acc=0.7912 ||| Val Loss=0.4289, Val Acc=0.7930\n",
      "Epoch 60: Train Loss=0.4220, Train Acc=0.8004 ||| Val Loss=0.4173, Val Acc=0.7976\n",
      "Epoch 61: Train Loss=0.4195, Train Acc=0.7965 ||| Val Loss=0.4227, Val Acc=0.7953\n",
      "Epoch 62: Train Loss=0.4237, Train Acc=0.7939 ||| Val Loss=0.4184, Val Acc=0.7941\n",
      "Epoch 63: Train Loss=0.4167, Train Acc=0.7968 ||| Val Loss=0.4405, Val Acc=0.7941\n",
      "Epoch 64: Train Loss=0.4223, Train Acc=0.7968 ||| Val Loss=0.4244, Val Acc=0.8028\n",
      "Epoch 65: Train Loss=0.4147, Train Acc=0.7995 ||| Val Loss=0.4173, Val Acc=0.7987\n",
      "Epoch 66: Train Loss=0.4189, Train Acc=0.7947 ||| Val Loss=0.4240, Val Acc=0.7918\n",
      "Epoch 67: Train Loss=0.4201, Train Acc=0.7980 ||| Val Loss=0.4288, Val Acc=0.7947\n",
      "Epoch 68: Train Loss=0.4175, Train Acc=0.7962 ||| Val Loss=0.4139, Val Acc=0.7959\n",
      "Epoch 69: Train Loss=0.4201, Train Acc=0.7981 ||| Val Loss=0.4287, Val Acc=0.7993\n",
      "Epoch 70: Train Loss=0.4181, Train Acc=0.7955 ||| Val Loss=0.4233, Val Acc=0.7924\n",
      "Epoch 71: Train Loss=0.4183, Train Acc=0.7991 ||| Val Loss=0.4296, Val Acc=0.7913\n",
      "Epoch 72: Train Loss=0.4155, Train Acc=0.7975 ||| Val Loss=0.4198, Val Acc=0.7959\n",
      "Epoch 73: Train Loss=0.4176, Train Acc=0.8007 ||| Val Loss=0.4317, Val Acc=0.7959\n",
      "Epoch 74: Train Loss=0.4116, Train Acc=0.8027 ||| Val Loss=0.4113, Val Acc=0.7947\n",
      "Epoch 75: Train Loss=0.4192, Train Acc=0.7980 ||| Val Loss=0.4259, Val Acc=0.7878\n",
      "Epoch 76: Train Loss=0.4116, Train Acc=0.7998 ||| Val Loss=0.4199, Val Acc=0.7970\n",
      "Epoch 77: Train Loss=0.4132, Train Acc=0.7982 ||| Val Loss=0.4169, Val Acc=0.7947\n",
      "Epoch 78: Train Loss=0.4161, Train Acc=0.7997 ||| Val Loss=0.4149, Val Acc=0.8022\n",
      "Epoch 79: Train Loss=0.4098, Train Acc=0.8017 ||| Val Loss=0.4226, Val Acc=0.7947\n",
      "Epoch 80: Train Loss=0.4102, Train Acc=0.7990 ||| Val Loss=0.4260, Val Acc=0.7918\n",
      "Epoch 81: Train Loss=0.4138, Train Acc=0.8046 ||| Val Loss=0.4257, Val Acc=0.7901\n",
      "Epoch 82: Train Loss=0.4134, Train Acc=0.8051 ||| Val Loss=0.4279, Val Acc=0.7890\n",
      "Epoch 83: Train Loss=0.4101, Train Acc=0.8008 ||| Val Loss=0.4216, Val Acc=0.7884\n",
      "Epoch 84: Train Loss=0.4142, Train Acc=0.7957 ||| Val Loss=0.4212, Val Acc=0.7941\n",
      "Epoch 85: Train Loss=0.4092, Train Acc=0.8007 ||| Val Loss=0.4237, Val Acc=0.7895\n",
      "Epoch 86: Train Loss=0.4060, Train Acc=0.8033 ||| Val Loss=0.4299, Val Acc=0.7976\n",
      "Epoch 87: Train Loss=0.4099, Train Acc=0.7972 ||| Val Loss=0.4230, Val Acc=0.7987\n",
      "Epoch 88: Train Loss=0.4079, Train Acc=0.8024 ||| Val Loss=0.4234, Val Acc=0.7936\n",
      "Epoch 89: Train Loss=0.4088, Train Acc=0.8072 ||| Val Loss=0.4297, Val Acc=0.7884\n",
      "Epoch 90: Train Loss=0.4101, Train Acc=0.8040 ||| Val Loss=0.4278, Val Acc=0.7918\n",
      "Epoch 91: Train Loss=0.4040, Train Acc=0.8036 ||| Val Loss=0.4300, Val Acc=0.7947\n",
      "Epoch 92: Train Loss=0.4096, Train Acc=0.8008 ||| Val Loss=0.4275, Val Acc=0.7947\n",
      "Epoch 93: Train Loss=0.4108, Train Acc=0.8027 ||| Val Loss=0.4233, Val Acc=0.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:21:47,646] Trial 35 finished with value: 0.7906843013225991 and parameters: {'n_blocks': 4, 'd_block': 512, 'k': 9, 'dropout': 0.2931050500937418, 'activation': 'GELU', 'lr': 0.0009119021657581938, 'weight_decay': 3.5193322723725726e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss=0.4067, Train Acc=0.7998 ||| Val Loss=0.4280, Val Acc=0.7907\n",
      "Early stopping triggered at epoch 94\n",
      "Validation Accuracy: 0.7907\n",
      "\n",
      " Trial 37 with params: {'n_blocks': 6, 'd_block': 128, 'k': 11, 'dropout': 0.15881191148404622, 'activation': 'ReLU', 'lr': 0.0012993999845610782, 'weight_decay': 8.80397444867152e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.6233, Train Acc=0.6746 ||| Val Loss=0.5401, Val Acc=0.7637\n",
      "Epoch 2: Train Loss=0.5281, Train Acc=0.7650 ||| Val Loss=0.5048, Val Acc=0.7982\n",
      "Epoch 3: Train Loss=0.5136, Train Acc=0.7757 ||| Val Loss=0.4887, Val Acc=0.7907\n",
      "Epoch 4: Train Loss=0.5090, Train Acc=0.7781 ||| Val Loss=0.4835, Val Acc=0.7936\n",
      "Epoch 5: Train Loss=0.5028, Train Acc=0.7796 ||| Val Loss=0.4851, Val Acc=0.7924\n",
      "Epoch 6: Train Loss=0.4975, Train Acc=0.7847 ||| Val Loss=0.4836, Val Acc=0.7895\n",
      "Epoch 7: Train Loss=0.4905, Train Acc=0.7869 ||| Val Loss=0.4759, Val Acc=0.7947\n",
      "Epoch 8: Train Loss=0.4874, Train Acc=0.7873 ||| Val Loss=0.4683, Val Acc=0.7970\n",
      "Epoch 9: Train Loss=0.4828, Train Acc=0.7847 ||| Val Loss=0.4688, Val Acc=0.7947\n",
      "Epoch 10: Train Loss=0.4794, Train Acc=0.7882 ||| Val Loss=0.4675, Val Acc=0.7953\n",
      "Epoch 11: Train Loss=0.4771, Train Acc=0.7903 ||| Val Loss=0.4589, Val Acc=0.8005\n",
      "Epoch 12: Train Loss=0.4746, Train Acc=0.7898 ||| Val Loss=0.4587, Val Acc=0.7964\n",
      "Epoch 13: Train Loss=0.4617, Train Acc=0.7912 ||| Val Loss=0.4646, Val Acc=0.7964\n",
      "Epoch 14: Train Loss=0.4646, Train Acc=0.7888 ||| Val Loss=0.4497, Val Acc=0.7982\n",
      "Epoch 15: Train Loss=0.4529, Train Acc=0.7892 ||| Val Loss=0.4353, Val Acc=0.7941\n",
      "Epoch 16: Train Loss=0.4474, Train Acc=0.7893 ||| Val Loss=0.4462, Val Acc=0.7964\n",
      "Epoch 17: Train Loss=0.4454, Train Acc=0.7922 ||| Val Loss=0.4370, Val Acc=0.7936\n",
      "Epoch 18: Train Loss=0.4393, Train Acc=0.7923 ||| Val Loss=0.4276, Val Acc=0.7941\n",
      "Epoch 19: Train Loss=0.4426, Train Acc=0.7905 ||| Val Loss=0.4417, Val Acc=0.7970\n",
      "Epoch 20: Train Loss=0.4342, Train Acc=0.7931 ||| Val Loss=0.4378, Val Acc=0.7918\n",
      "Epoch 21: Train Loss=0.4302, Train Acc=0.7941 ||| Val Loss=0.4311, Val Acc=0.7890\n",
      "Epoch 22: Train Loss=0.4326, Train Acc=0.7942 ||| Val Loss=0.4273, Val Acc=0.7941\n",
      "Epoch 23: Train Loss=0.4290, Train Acc=0.7949 ||| Val Loss=0.4306, Val Acc=0.7918\n",
      "Epoch 24: Train Loss=0.4274, Train Acc=0.7957 ||| Val Loss=0.4324, Val Acc=0.7924\n",
      "Epoch 25: Train Loss=0.4260, Train Acc=0.7938 ||| Val Loss=0.4284, Val Acc=0.7941\n",
      "Epoch 26: Train Loss=0.4252, Train Acc=0.7972 ||| Val Loss=0.4288, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4235, Train Acc=0.7964 ||| Val Loss=0.4280, Val Acc=0.7959\n",
      "Epoch 28: Train Loss=0.4222, Train Acc=0.7971 ||| Val Loss=0.4282, Val Acc=0.7878\n",
      "Epoch 29: Train Loss=0.4199, Train Acc=0.7982 ||| Val Loss=0.4319, Val Acc=0.7826\n",
      "Epoch 30: Train Loss=0.4194, Train Acc=0.7967 ||| Val Loss=0.4270, Val Acc=0.7947\n",
      "Epoch 31: Train Loss=0.4202, Train Acc=0.8008 ||| Val Loss=0.4196, Val Acc=0.8028\n",
      "Epoch 32: Train Loss=0.4182, Train Acc=0.7957 ||| Val Loss=0.4184, Val Acc=0.7976\n",
      "Epoch 33: Train Loss=0.4226, Train Acc=0.7990 ||| Val Loss=0.4200, Val Acc=0.7987\n",
      "Epoch 34: Train Loss=0.4204, Train Acc=0.7939 ||| Val Loss=0.4269, Val Acc=0.8010\n",
      "Epoch 35: Train Loss=0.4176, Train Acc=0.7978 ||| Val Loss=0.4194, Val Acc=0.7959\n",
      "Epoch 36: Train Loss=0.4199, Train Acc=0.7955 ||| Val Loss=0.4187, Val Acc=0.8005\n",
      "Epoch 37: Train Loss=0.4145, Train Acc=0.7987 ||| Val Loss=0.4222, Val Acc=0.7964\n",
      "Epoch 38: Train Loss=0.4181, Train Acc=0.7978 ||| Val Loss=0.4205, Val Acc=0.7913\n",
      "Epoch 39: Train Loss=0.4140, Train Acc=0.7975 ||| Val Loss=0.4131, Val Acc=0.7993\n",
      "Epoch 40: Train Loss=0.4123, Train Acc=0.7988 ||| Val Loss=0.4161, Val Acc=0.7947\n",
      "Epoch 41: Train Loss=0.4142, Train Acc=0.7990 ||| Val Loss=0.4144, Val Acc=0.7976\n",
      "Epoch 42: Train Loss=0.4132, Train Acc=0.8020 ||| Val Loss=0.4282, Val Acc=0.7867\n",
      "Epoch 43: Train Loss=0.4152, Train Acc=0.7997 ||| Val Loss=0.4127, Val Acc=0.7976\n",
      "Epoch 44: Train Loss=0.4126, Train Acc=0.8001 ||| Val Loss=0.4146, Val Acc=0.7959\n",
      "Epoch 45: Train Loss=0.4124, Train Acc=0.8001 ||| Val Loss=0.4162, Val Acc=0.7884\n",
      "Epoch 46: Train Loss=0.4120, Train Acc=0.8007 ||| Val Loss=0.4192, Val Acc=0.7930\n",
      "Epoch 47: Train Loss=0.4110, Train Acc=0.8044 ||| Val Loss=0.4227, Val Acc=0.7901\n",
      "Epoch 48: Train Loss=0.4137, Train Acc=0.8020 ||| Val Loss=0.4180, Val Acc=0.7907\n",
      "Epoch 49: Train Loss=0.4088, Train Acc=0.8024 ||| Val Loss=0.4145, Val Acc=0.8022\n",
      "Epoch 50: Train Loss=0.4089, Train Acc=0.7965 ||| Val Loss=0.4142, Val Acc=0.7982\n",
      "Epoch 51: Train Loss=0.4111, Train Acc=0.8004 ||| Val Loss=0.4202, Val Acc=0.8022\n",
      "Epoch 52: Train Loss=0.4096, Train Acc=0.8001 ||| Val Loss=0.4142, Val Acc=0.7982\n",
      "Epoch 53: Train Loss=0.4092, Train Acc=0.7974 ||| Val Loss=0.4127, Val Acc=0.7999\n",
      "Epoch 54: Train Loss=0.4057, Train Acc=0.8005 ||| Val Loss=0.4184, Val Acc=0.8016\n",
      "Epoch 55: Train Loss=0.4055, Train Acc=0.8017 ||| Val Loss=0.4137, Val Acc=0.8022\n",
      "Epoch 56: Train Loss=0.4058, Train Acc=0.8017 ||| Val Loss=0.4111, Val Acc=0.7953\n",
      "Epoch 57: Train Loss=0.4081, Train Acc=0.8007 ||| Val Loss=0.4083, Val Acc=0.8005\n",
      "Epoch 58: Train Loss=0.4063, Train Acc=0.8028 ||| Val Loss=0.4220, Val Acc=0.7947\n",
      "Epoch 59: Train Loss=0.4074, Train Acc=0.8026 ||| Val Loss=0.4139, Val Acc=0.8005\n",
      "Epoch 60: Train Loss=0.4054, Train Acc=0.8040 ||| Val Loss=0.4146, Val Acc=0.8005\n",
      "Epoch 61: Train Loss=0.4064, Train Acc=0.7995 ||| Val Loss=0.4124, Val Acc=0.7964\n",
      "Epoch 62: Train Loss=0.4044, Train Acc=0.8028 ||| Val Loss=0.4117, Val Acc=0.7930\n",
      "Epoch 63: Train Loss=0.4014, Train Acc=0.8040 ||| Val Loss=0.4116, Val Acc=0.8045\n",
      "Epoch 64: Train Loss=0.4044, Train Acc=0.7998 ||| Val Loss=0.4168, Val Acc=0.8016\n",
      "Epoch 65: Train Loss=0.4010, Train Acc=0.8073 ||| Val Loss=0.4153, Val Acc=0.7959\n",
      "Epoch 66: Train Loss=0.4024, Train Acc=0.8027 ||| Val Loss=0.4128, Val Acc=0.8062\n",
      "Epoch 67: Train Loss=0.4039, Train Acc=0.8020 ||| Val Loss=0.4181, Val Acc=0.8016\n",
      "Epoch 68: Train Loss=0.4065, Train Acc=0.8046 ||| Val Loss=0.4135, Val Acc=0.7941\n",
      "Epoch 69: Train Loss=0.3990, Train Acc=0.8034 ||| Val Loss=0.4113, Val Acc=0.8028\n",
      "Epoch 70: Train Loss=0.3990, Train Acc=0.8054 ||| Val Loss=0.4112, Val Acc=0.8028\n",
      "Epoch 71: Train Loss=0.3999, Train Acc=0.8087 ||| Val Loss=0.4159, Val Acc=0.7999\n",
      "Epoch 72: Train Loss=0.3985, Train Acc=0.8076 ||| Val Loss=0.4170, Val Acc=0.7918\n",
      "Epoch 73: Train Loss=0.3964, Train Acc=0.8080 ||| Val Loss=0.4198, Val Acc=0.8033\n",
      "Epoch 74: Train Loss=0.3972, Train Acc=0.8018 ||| Val Loss=0.4186, Val Acc=0.7901\n",
      "Epoch 75: Train Loss=0.3983, Train Acc=0.8053 ||| Val Loss=0.4164, Val Acc=0.7959\n",
      "Epoch 76: Train Loss=0.4009, Train Acc=0.8069 ||| Val Loss=0.4158, Val Acc=0.8016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:22:20,095] Trial 36 finished with value: 0.8010350776308223 and parameters: {'n_blocks': 6, 'd_block': 128, 'k': 11, 'dropout': 0.15881191148404622, 'activation': 'ReLU', 'lr': 0.0012993999845610782, 'weight_decay': 8.80397444867152e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train Loss=0.4013, Train Acc=0.8043 ||| Val Loss=0.4125, Val Acc=0.8010\n",
      "Early stopping triggered at epoch 77\n",
      "Validation Accuracy: 0.8010\n",
      "\n",
      " Trial 38 with params: {'n_blocks': 5, 'd_block': 128, 'k': 8, 'dropout': 0.2593541836743758, 'activation': 'GELU', 'lr': 0.00037684303782844916, 'weight_decay': 2.1963319714100293e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.9892, Train Acc=0.5677 ||| Val Loss=0.5782, Val Acc=0.7453\n",
      "Epoch 2: Train Loss=0.6676, Train Acc=0.6349 ||| Val Loss=0.5522, Val Acc=0.7424\n",
      "Epoch 3: Train Loss=0.6148, Train Acc=0.6776 ||| Val Loss=0.5354, Val Acc=0.7464\n",
      "Epoch 4: Train Loss=0.5921, Train Acc=0.6967 ||| Val Loss=0.5298, Val Acc=0.7769\n",
      "Epoch 5: Train Loss=0.5613, Train Acc=0.7265 ||| Val Loss=0.5244, Val Acc=0.7654\n",
      "Epoch 6: Train Loss=0.5577, Train Acc=0.7383 ||| Val Loss=0.5136, Val Acc=0.7832\n",
      "Epoch 7: Train Loss=0.5501, Train Acc=0.7419 ||| Val Loss=0.5100, Val Acc=0.7895\n",
      "Epoch 8: Train Loss=0.5429, Train Acc=0.7524 ||| Val Loss=0.5143, Val Acc=0.7895\n",
      "Epoch 9: Train Loss=0.5341, Train Acc=0.7548 ||| Val Loss=0.5017, Val Acc=0.7936\n",
      "Epoch 10: Train Loss=0.5261, Train Acc=0.7611 ||| Val Loss=0.5016, Val Acc=0.7895\n",
      "Epoch 11: Train Loss=0.5226, Train Acc=0.7657 ||| Val Loss=0.5047, Val Acc=0.7924\n",
      "Epoch 12: Train Loss=0.5235, Train Acc=0.7663 ||| Val Loss=0.4990, Val Acc=0.7872\n",
      "Epoch 13: Train Loss=0.5182, Train Acc=0.7701 ||| Val Loss=0.4983, Val Acc=0.7930\n",
      "Epoch 14: Train Loss=0.5136, Train Acc=0.7725 ||| Val Loss=0.4955, Val Acc=0.7884\n",
      "Epoch 15: Train Loss=0.5065, Train Acc=0.7770 ||| Val Loss=0.4902, Val Acc=0.7941\n",
      "Epoch 16: Train Loss=0.5069, Train Acc=0.7735 ||| Val Loss=0.4906, Val Acc=0.7890\n",
      "Epoch 17: Train Loss=0.5089, Train Acc=0.7783 ||| Val Loss=0.4981, Val Acc=0.7924\n",
      "Epoch 18: Train Loss=0.5086, Train Acc=0.7755 ||| Val Loss=0.4895, Val Acc=0.7895\n",
      "Epoch 19: Train Loss=0.5026, Train Acc=0.7801 ||| Val Loss=0.4892, Val Acc=0.7941\n",
      "Epoch 20: Train Loss=0.4970, Train Acc=0.7798 ||| Val Loss=0.4961, Val Acc=0.7941\n",
      "Epoch 21: Train Loss=0.5006, Train Acc=0.7785 ||| Val Loss=0.4868, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4933, Train Acc=0.7821 ||| Val Loss=0.4844, Val Acc=0.7993\n",
      "Epoch 23: Train Loss=0.4991, Train Acc=0.7821 ||| Val Loss=0.4905, Val Acc=0.7987\n",
      "Epoch 24: Train Loss=0.4953, Train Acc=0.7839 ||| Val Loss=0.4775, Val Acc=0.7959\n",
      "Epoch 25: Train Loss=0.4933, Train Acc=0.7831 ||| Val Loss=0.4816, Val Acc=0.7987\n",
      "Epoch 26: Train Loss=0.4924, Train Acc=0.7837 ||| Val Loss=0.4771, Val Acc=0.7953\n",
      "Epoch 27: Train Loss=0.4909, Train Acc=0.7834 ||| Val Loss=0.4779, Val Acc=0.7941\n",
      "Epoch 28: Train Loss=0.4836, Train Acc=0.7840 ||| Val Loss=0.4688, Val Acc=0.7976\n",
      "Epoch 29: Train Loss=0.4832, Train Acc=0.7875 ||| Val Loss=0.4704, Val Acc=0.7970\n",
      "Epoch 30: Train Loss=0.4851, Train Acc=0.7831 ||| Val Loss=0.4637, Val Acc=0.7947\n",
      "Epoch 31: Train Loss=0.4840, Train Acc=0.7879 ||| Val Loss=0.4657, Val Acc=0.7959\n",
      "Epoch 32: Train Loss=0.4820, Train Acc=0.7852 ||| Val Loss=0.4640, Val Acc=0.7953\n",
      "Epoch 33: Train Loss=0.4754, Train Acc=0.7877 ||| Val Loss=0.4646, Val Acc=0.7976\n",
      "Epoch 34: Train Loss=0.4748, Train Acc=0.7857 ||| Val Loss=0.4605, Val Acc=0.7930\n",
      "Epoch 35: Train Loss=0.4750, Train Acc=0.7842 ||| Val Loss=0.4553, Val Acc=0.7930\n",
      "Epoch 36: Train Loss=0.4720, Train Acc=0.7883 ||| Val Loss=0.4602, Val Acc=0.7964\n",
      "Epoch 37: Train Loss=0.4707, Train Acc=0.7873 ||| Val Loss=0.4572, Val Acc=0.7947\n",
      "Epoch 38: Train Loss=0.4666, Train Acc=0.7876 ||| Val Loss=0.4479, Val Acc=0.7976\n",
      "Epoch 39: Train Loss=0.4633, Train Acc=0.7908 ||| Val Loss=0.4473, Val Acc=0.7970\n",
      "Epoch 40: Train Loss=0.4603, Train Acc=0.7877 ||| Val Loss=0.4449, Val Acc=0.7976\n",
      "Epoch 41: Train Loss=0.4551, Train Acc=0.7869 ||| Val Loss=0.4470, Val Acc=0.7976\n",
      "Epoch 42: Train Loss=0.4549, Train Acc=0.7875 ||| Val Loss=0.4448, Val Acc=0.7999\n",
      "Epoch 43: Train Loss=0.4512, Train Acc=0.7893 ||| Val Loss=0.4504, Val Acc=0.8005\n",
      "Epoch 44: Train Loss=0.4510, Train Acc=0.7929 ||| Val Loss=0.4452, Val Acc=0.7964\n",
      "Epoch 45: Train Loss=0.4492, Train Acc=0.7913 ||| Val Loss=0.4466, Val Acc=0.7999\n",
      "Epoch 46: Train Loss=0.4512, Train Acc=0.7900 ||| Val Loss=0.4402, Val Acc=0.7987\n",
      "Epoch 47: Train Loss=0.4465, Train Acc=0.7905 ||| Val Loss=0.4493, Val Acc=0.7982\n",
      "Epoch 48: Train Loss=0.4481, Train Acc=0.7886 ||| Val Loss=0.4450, Val Acc=0.7982\n",
      "Epoch 49: Train Loss=0.4445, Train Acc=0.7932 ||| Val Loss=0.4441, Val Acc=0.7964\n",
      "Epoch 50: Train Loss=0.4426, Train Acc=0.7926 ||| Val Loss=0.4406, Val Acc=0.7987\n",
      "Epoch 51: Train Loss=0.4412, Train Acc=0.7918 ||| Val Loss=0.4396, Val Acc=0.7999\n",
      "Epoch 52: Train Loss=0.4387, Train Acc=0.7938 ||| Val Loss=0.4413, Val Acc=0.7999\n",
      "Epoch 53: Train Loss=0.4416, Train Acc=0.7912 ||| Val Loss=0.4401, Val Acc=0.7959\n",
      "Epoch 54: Train Loss=0.4391, Train Acc=0.7896 ||| Val Loss=0.4416, Val Acc=0.7941\n",
      "Epoch 55: Train Loss=0.4322, Train Acc=0.7905 ||| Val Loss=0.4363, Val Acc=0.7947\n",
      "Epoch 56: Train Loss=0.4344, Train Acc=0.7941 ||| Val Loss=0.4384, Val Acc=0.7936\n",
      "Epoch 57: Train Loss=0.4327, Train Acc=0.7948 ||| Val Loss=0.4418, Val Acc=0.7941\n",
      "Epoch 58: Train Loss=0.4321, Train Acc=0.7939 ||| Val Loss=0.4290, Val Acc=0.7918\n",
      "Epoch 59: Train Loss=0.4333, Train Acc=0.7957 ||| Val Loss=0.4347, Val Acc=0.7930\n",
      "Epoch 60: Train Loss=0.4302, Train Acc=0.7967 ||| Val Loss=0.4375, Val Acc=0.7884\n",
      "Epoch 61: Train Loss=0.4325, Train Acc=0.7958 ||| Val Loss=0.4304, Val Acc=0.7907\n",
      "Epoch 62: Train Loss=0.4319, Train Acc=0.7945 ||| Val Loss=0.4299, Val Acc=0.7930\n",
      "Epoch 63: Train Loss=0.4309, Train Acc=0.7949 ||| Val Loss=0.4305, Val Acc=0.7947\n",
      "Epoch 64: Train Loss=0.4271, Train Acc=0.7944 ||| Val Loss=0.4306, Val Acc=0.7924\n",
      "Epoch 65: Train Loss=0.4233, Train Acc=0.7964 ||| Val Loss=0.4332, Val Acc=0.7918\n",
      "Epoch 66: Train Loss=0.4252, Train Acc=0.7906 ||| Val Loss=0.4370, Val Acc=0.7855\n",
      "Epoch 67: Train Loss=0.4265, Train Acc=0.7982 ||| Val Loss=0.4310, Val Acc=0.7924\n",
      "Epoch 68: Train Loss=0.4294, Train Acc=0.7972 ||| Val Loss=0.4268, Val Acc=0.7895\n",
      "Epoch 69: Train Loss=0.4242, Train Acc=0.7952 ||| Val Loss=0.4472, Val Acc=0.7918\n",
      "Epoch 70: Train Loss=0.4291, Train Acc=0.7911 ||| Val Loss=0.4305, Val Acc=0.7855\n",
      "Epoch 71: Train Loss=0.4227, Train Acc=0.7932 ||| Val Loss=0.4270, Val Acc=0.7907\n",
      "Epoch 72: Train Loss=0.4244, Train Acc=0.7928 ||| Val Loss=0.4326, Val Acc=0.7844\n",
      "Epoch 73: Train Loss=0.4250, Train Acc=0.7974 ||| Val Loss=0.4349, Val Acc=0.7884\n",
      "Epoch 74: Train Loss=0.4251, Train Acc=0.7974 ||| Val Loss=0.4329, Val Acc=0.7884\n",
      "Epoch 75: Train Loss=0.4228, Train Acc=0.7942 ||| Val Loss=0.4273, Val Acc=0.7895\n",
      "Epoch 76: Train Loss=0.4222, Train Acc=0.7965 ||| Val Loss=0.4252, Val Acc=0.7878\n",
      "Epoch 77: Train Loss=0.4218, Train Acc=0.7982 ||| Val Loss=0.4266, Val Acc=0.7936\n",
      "Epoch 78: Train Loss=0.4216, Train Acc=0.7945 ||| Val Loss=0.4276, Val Acc=0.7815\n",
      "Epoch 79: Train Loss=0.4223, Train Acc=0.7952 ||| Val Loss=0.4306, Val Acc=0.7838\n",
      "Epoch 80: Train Loss=0.4217, Train Acc=0.7944 ||| Val Loss=0.4356, Val Acc=0.7878\n",
      "Epoch 81: Train Loss=0.4233, Train Acc=0.7955 ||| Val Loss=0.4250, Val Acc=0.7930\n",
      "Epoch 82: Train Loss=0.4209, Train Acc=0.7970 ||| Val Loss=0.4274, Val Acc=0.7867\n",
      "Epoch 83: Train Loss=0.4187, Train Acc=0.8001 ||| Val Loss=0.4266, Val Acc=0.7913\n",
      "Epoch 84: Train Loss=0.4202, Train Acc=0.7967 ||| Val Loss=0.4296, Val Acc=0.7930\n",
      "Epoch 85: Train Loss=0.4185, Train Acc=0.7959 ||| Val Loss=0.4473, Val Acc=0.7936\n",
      "Epoch 86: Train Loss=0.4228, Train Acc=0.7951 ||| Val Loss=0.4303, Val Acc=0.7918\n",
      "Epoch 87: Train Loss=0.4169, Train Acc=0.8016 ||| Val Loss=0.4251, Val Acc=0.7947\n",
      "Epoch 88: Train Loss=0.4187, Train Acc=0.7972 ||| Val Loss=0.4282, Val Acc=0.7982\n",
      "Epoch 89: Train Loss=0.4170, Train Acc=0.7954 ||| Val Loss=0.4210, Val Acc=0.7884\n",
      "Epoch 90: Train Loss=0.4174, Train Acc=0.7993 ||| Val Loss=0.4315, Val Acc=0.7872\n",
      "Epoch 91: Train Loss=0.4135, Train Acc=0.7944 ||| Val Loss=0.4273, Val Acc=0.7964\n",
      "Epoch 92: Train Loss=0.4186, Train Acc=0.7928 ||| Val Loss=0.4194, Val Acc=0.8005\n",
      "Epoch 93: Train Loss=0.4182, Train Acc=0.7971 ||| Val Loss=0.4193, Val Acc=0.7941\n",
      "Epoch 94: Train Loss=0.4154, Train Acc=0.8010 ||| Val Loss=0.4245, Val Acc=0.7913\n",
      "Epoch 95: Train Loss=0.4132, Train Acc=0.7993 ||| Val Loss=0.4192, Val Acc=0.7930\n",
      "Epoch 96: Train Loss=0.4153, Train Acc=0.7958 ||| Val Loss=0.4187, Val Acc=0.7890\n",
      "Epoch 97: Train Loss=0.4122, Train Acc=0.7957 ||| Val Loss=0.4230, Val Acc=0.7953\n",
      "Epoch 98: Train Loss=0.4212, Train Acc=0.7925 ||| Val Loss=0.4218, Val Acc=0.7959\n",
      "Epoch 99: Train Loss=0.4151, Train Acc=0.7977 ||| Val Loss=0.4264, Val Acc=0.8028\n",
      "Epoch 100: Train Loss=0.4124, Train Acc=0.7970 ||| Val Loss=0.4264, Val Acc=0.7901\n",
      "Epoch 101: Train Loss=0.4147, Train Acc=0.7970 ||| Val Loss=0.4306, Val Acc=0.7941\n",
      "Epoch 102: Train Loss=0.4124, Train Acc=0.7965 ||| Val Loss=0.4181, Val Acc=0.7895\n",
      "Epoch 103: Train Loss=0.4132, Train Acc=0.8000 ||| Val Loss=0.4199, Val Acc=0.7947\n",
      "Epoch 104: Train Loss=0.4092, Train Acc=0.8001 ||| Val Loss=0.4247, Val Acc=0.7890\n",
      "Epoch 105: Train Loss=0.4120, Train Acc=0.7998 ||| Val Loss=0.4211, Val Acc=0.7964\n",
      "Epoch 106: Train Loss=0.4110, Train Acc=0.7991 ||| Val Loss=0.4330, Val Acc=0.7907\n",
      "Epoch 107: Train Loss=0.4114, Train Acc=0.8011 ||| Val Loss=0.4259, Val Acc=0.7953\n",
      "Epoch 108: Train Loss=0.4105, Train Acc=0.8014 ||| Val Loss=0.4208, Val Acc=0.7959\n",
      "Epoch 109: Train Loss=0.4118, Train Acc=0.7985 ||| Val Loss=0.4306, Val Acc=0.7930\n",
      "Epoch 110: Train Loss=0.4118, Train Acc=0.7988 ||| Val Loss=0.4212, Val Acc=0.7844\n",
      "Epoch 111: Train Loss=0.4122, Train Acc=0.7997 ||| Val Loss=0.4189, Val Acc=0.7982\n",
      "Epoch 112: Train Loss=0.4123, Train Acc=0.7957 ||| Val Loss=0.4295, Val Acc=0.7872\n",
      "Epoch 113: Train Loss=0.4099, Train Acc=0.7961 ||| Val Loss=0.4272, Val Acc=0.7924\n",
      "Epoch 114: Train Loss=0.4095, Train Acc=0.8005 ||| Val Loss=0.4226, Val Acc=0.7941\n",
      "Epoch 115: Train Loss=0.4075, Train Acc=0.7993 ||| Val Loss=0.4350, Val Acc=0.7982\n",
      "Epoch 116: Train Loss=0.4115, Train Acc=0.7977 ||| Val Loss=0.4299, Val Acc=0.7855\n",
      "Epoch 117: Train Loss=0.4090, Train Acc=0.7984 ||| Val Loss=0.4268, Val Acc=0.7924\n",
      "Epoch 118: Train Loss=0.4099, Train Acc=0.7975 ||| Val Loss=0.4250, Val Acc=0.7895\n",
      "Epoch 119: Train Loss=0.4095, Train Acc=0.8004 ||| Val Loss=0.4265, Val Acc=0.7930\n",
      "Epoch 120: Train Loss=0.4069, Train Acc=0.7998 ||| Val Loss=0.4216, Val Acc=0.7901\n",
      "Epoch 121: Train Loss=0.4067, Train Acc=0.7995 ||| Val Loss=0.4275, Val Acc=0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:23:05,443] Trial 37 finished with value: 0.7924094307073031 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 8, 'dropout': 0.2593541836743758, 'activation': 'GELU', 'lr': 0.00037684303782844916, 'weight_decay': 2.1963319714100293e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Train Loss=0.4054, Train Acc=0.8005 ||| Val Loss=0.4283, Val Acc=0.7924\n",
      "Early stopping triggered at epoch 122\n",
      "Validation Accuracy: 0.7924\n",
      "\n",
      " Trial 39 with params: {'n_blocks': 4, 'd_block': 128, 'k': 6, 'dropout': 0.2050635318633716, 'activation': 'ReLU', 'lr': 0.008554855242641284, 'weight_decay': 1.8983572014132025e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.7192, Train Acc=0.6734 ||| Val Loss=0.5116, Val Acc=0.7780\n",
      "Epoch 2: Train Loss=0.5370, Train Acc=0.7610 ||| Val Loss=0.5140, Val Acc=0.7901\n",
      "Epoch 3: Train Loss=0.5296, Train Acc=0.7660 ||| Val Loss=0.5206, Val Acc=0.7752\n",
      "Epoch 4: Train Loss=0.5118, Train Acc=0.7744 ||| Val Loss=0.4988, Val Acc=0.7867\n",
      "Epoch 5: Train Loss=0.4954, Train Acc=0.7807 ||| Val Loss=0.4656, Val Acc=0.8016\n",
      "Epoch 6: Train Loss=0.4848, Train Acc=0.7803 ||| Val Loss=0.4648, Val Acc=0.7959\n",
      "Epoch 7: Train Loss=0.4699, Train Acc=0.7816 ||| Val Loss=0.4343, Val Acc=0.7918\n",
      "Epoch 8: Train Loss=0.4554, Train Acc=0.7873 ||| Val Loss=0.4616, Val Acc=0.7947\n",
      "Epoch 9: Train Loss=0.4586, Train Acc=0.7834 ||| Val Loss=0.4420, Val Acc=0.7947\n",
      "Epoch 10: Train Loss=0.4577, Train Acc=0.7867 ||| Val Loss=0.4373, Val Acc=0.7953\n",
      "Epoch 11: Train Loss=0.4483, Train Acc=0.7931 ||| Val Loss=0.4419, Val Acc=0.7890\n",
      "Epoch 12: Train Loss=0.4466, Train Acc=0.7883 ||| Val Loss=0.4186, Val Acc=0.7959\n",
      "Epoch 13: Train Loss=0.4410, Train Acc=0.7853 ||| Val Loss=0.4245, Val Acc=0.8005\n",
      "Epoch 14: Train Loss=0.4379, Train Acc=0.7875 ||| Val Loss=0.4180, Val Acc=0.7987\n",
      "Epoch 15: Train Loss=0.4347, Train Acc=0.7896 ||| Val Loss=0.4613, Val Acc=0.7970\n",
      "Epoch 16: Train Loss=0.4398, Train Acc=0.7877 ||| Val Loss=0.4178, Val Acc=0.7982\n",
      "Epoch 17: Train Loss=0.4286, Train Acc=0.7899 ||| Val Loss=0.4132, Val Acc=0.7947\n",
      "Epoch 18: Train Loss=0.4359, Train Acc=0.7926 ||| Val Loss=0.4176, Val Acc=0.7964\n",
      "Epoch 19: Train Loss=0.4308, Train Acc=0.7886 ||| Val Loss=0.4142, Val Acc=0.7895\n",
      "Epoch 20: Train Loss=0.4296, Train Acc=0.7882 ||| Val Loss=0.4114, Val Acc=0.7941\n",
      "Epoch 21: Train Loss=0.4273, Train Acc=0.7908 ||| Val Loss=0.4139, Val Acc=0.8039\n",
      "Epoch 22: Train Loss=0.4281, Train Acc=0.7921 ||| Val Loss=0.4144, Val Acc=0.8022\n",
      "Epoch 23: Train Loss=0.4226, Train Acc=0.7934 ||| Val Loss=0.4146, Val Acc=0.7970\n",
      "Epoch 24: Train Loss=0.4258, Train Acc=0.7918 ||| Val Loss=0.4151, Val Acc=0.8005\n",
      "Epoch 25: Train Loss=0.4228, Train Acc=0.7926 ||| Val Loss=0.4122, Val Acc=0.7936\n",
      "Epoch 26: Train Loss=0.4238, Train Acc=0.7993 ||| Val Loss=0.4189, Val Acc=0.7826\n",
      "Epoch 27: Train Loss=0.4300, Train Acc=0.7945 ||| Val Loss=0.4286, Val Acc=0.7999\n",
      "Epoch 28: Train Loss=0.4187, Train Acc=0.7948 ||| Val Loss=0.4097, Val Acc=0.7993\n",
      "Epoch 29: Train Loss=0.4231, Train Acc=0.7955 ||| Val Loss=0.4189, Val Acc=0.7924\n",
      "Epoch 30: Train Loss=0.4224, Train Acc=0.7945 ||| Val Loss=0.4045, Val Acc=0.8005\n",
      "Epoch 31: Train Loss=0.4268, Train Acc=0.7942 ||| Val Loss=0.4122, Val Acc=0.7964\n",
      "Epoch 32: Train Loss=0.4227, Train Acc=0.7988 ||| Val Loss=0.4074, Val Acc=0.8010\n",
      "Epoch 33: Train Loss=0.4162, Train Acc=0.7991 ||| Val Loss=0.4067, Val Acc=0.7999\n",
      "Epoch 34: Train Loss=0.4194, Train Acc=0.7985 ||| Val Loss=0.4135, Val Acc=0.8005\n",
      "Epoch 35: Train Loss=0.4242, Train Acc=0.7972 ||| Val Loss=0.4272, Val Acc=0.7982\n",
      "Epoch 36: Train Loss=0.4208, Train Acc=0.7972 ||| Val Loss=0.4069, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4259, Train Acc=0.7972 ||| Val Loss=0.4099, Val Acc=0.7987\n",
      "Epoch 38: Train Loss=0.4196, Train Acc=0.7981 ||| Val Loss=0.4259, Val Acc=0.7924\n",
      "Epoch 39: Train Loss=0.4182, Train Acc=0.8000 ||| Val Loss=0.4102, Val Acc=0.7987\n",
      "Epoch 40: Train Loss=0.4301, Train Acc=0.7911 ||| Val Loss=0.4114, Val Acc=0.7953\n",
      "Epoch 41: Train Loss=0.4226, Train Acc=0.8004 ||| Val Loss=0.4024, Val Acc=0.7970\n",
      "Epoch 42: Train Loss=0.4156, Train Acc=0.8004 ||| Val Loss=0.4051, Val Acc=0.8056\n",
      "Epoch 43: Train Loss=0.4157, Train Acc=0.8018 ||| Val Loss=0.4022, Val Acc=0.7959\n",
      "Epoch 44: Train Loss=0.4203, Train Acc=0.7978 ||| Val Loss=0.4141, Val Acc=0.7976\n",
      "Epoch 45: Train Loss=0.4184, Train Acc=0.8018 ||| Val Loss=0.4139, Val Acc=0.7884\n",
      "Epoch 46: Train Loss=0.4270, Train Acc=0.7952 ||| Val Loss=0.4100, Val Acc=0.7987\n",
      "Epoch 47: Train Loss=0.4173, Train Acc=0.8017 ||| Val Loss=0.4033, Val Acc=0.7993\n",
      "Epoch 48: Train Loss=0.4157, Train Acc=0.8036 ||| Val Loss=0.4049, Val Acc=0.7999\n",
      "Epoch 49: Train Loss=0.4153, Train Acc=0.7991 ||| Val Loss=0.3999, Val Acc=0.8039\n",
      "Epoch 50: Train Loss=0.4146, Train Acc=0.8003 ||| Val Loss=0.4048, Val Acc=0.8051\n",
      "Epoch 51: Train Loss=0.4130, Train Acc=0.8066 ||| Val Loss=0.4043, Val Acc=0.8010\n",
      "Epoch 52: Train Loss=0.4192, Train Acc=0.8040 ||| Val Loss=0.4148, Val Acc=0.7913\n",
      "Epoch 53: Train Loss=0.4255, Train Acc=0.7949 ||| Val Loss=0.4038, Val Acc=0.8016\n",
      "Epoch 54: Train Loss=0.4104, Train Acc=0.7995 ||| Val Loss=0.4218, Val Acc=0.7953\n",
      "Epoch 55: Train Loss=0.4204, Train Acc=0.7974 ||| Val Loss=0.4092, Val Acc=0.7999\n",
      "Epoch 56: Train Loss=0.4180, Train Acc=0.8039 ||| Val Loss=0.4052, Val Acc=0.8005\n",
      "Epoch 57: Train Loss=0.4127, Train Acc=0.7971 ||| Val Loss=0.4122, Val Acc=0.7907\n",
      "Epoch 58: Train Loss=0.4211, Train Acc=0.7997 ||| Val Loss=0.4124, Val Acc=0.8022\n",
      "Epoch 59: Train Loss=0.4139, Train Acc=0.8021 ||| Val Loss=0.4054, Val Acc=0.7999\n",
      "Epoch 60: Train Loss=0.4101, Train Acc=0.8003 ||| Val Loss=0.4155, Val Acc=0.7907\n",
      "Epoch 61: Train Loss=0.4121, Train Acc=0.8007 ||| Val Loss=0.4031, Val Acc=0.8056\n",
      "Epoch 62: Train Loss=0.4177, Train Acc=0.8013 ||| Val Loss=0.4057, Val Acc=0.8005\n",
      "Epoch 63: Train Loss=0.4130, Train Acc=0.8030 ||| Val Loss=0.4170, Val Acc=0.7987\n",
      "Epoch 64: Train Loss=0.4142, Train Acc=0.8000 ||| Val Loss=0.4128, Val Acc=0.8005\n",
      "Epoch 65: Train Loss=0.4063, Train Acc=0.8034 ||| Val Loss=0.4102, Val Acc=0.8010\n",
      "Epoch 66: Train Loss=0.4158, Train Acc=0.8037 ||| Val Loss=0.4043, Val Acc=0.7953\n",
      "Epoch 67: Train Loss=0.4127, Train Acc=0.8017 ||| Val Loss=0.4026, Val Acc=0.7964\n",
      "Epoch 68: Train Loss=0.4123, Train Acc=0.8073 ||| Val Loss=0.4046, Val Acc=0.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:23:23,766] Trial 38 finished with value: 0.8016101207590569 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 6, 'dropout': 0.2050635318633716, 'activation': 'ReLU', 'lr': 0.008554855242641284, 'weight_decay': 1.8983572014132025e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Train Loss=0.4137, Train Acc=0.8037 ||| Val Loss=0.4171, Val Acc=0.8016\n",
      "Early stopping triggered at epoch 69\n",
      "Validation Accuracy: 0.8016\n",
      "\n",
      " Trial 40 with params: {'n_blocks': 3, 'd_block': 512, 'k': 10, 'dropout': 0.31642719264252867, 'activation': 'LeakyReLU', 'lr': 0.0031445137761433057, 'weight_decay': 6.361729222149192e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=3.6438, Train Acc=0.6677 ||| Val Loss=0.5723, Val Acc=0.7085\n",
      "Epoch 2: Train Loss=0.5745, Train Acc=0.7315 ||| Val Loss=0.5160, Val Acc=0.7786\n",
      "Epoch 3: Train Loss=0.5542, Train Acc=0.7496 ||| Val Loss=0.5096, Val Acc=0.7723\n",
      "Epoch 4: Train Loss=0.5532, Train Acc=0.7541 ||| Val Loss=0.4999, Val Acc=0.7849\n",
      "Epoch 5: Train Loss=0.5455, Train Acc=0.7545 ||| Val Loss=0.4987, Val Acc=0.7809\n",
      "Epoch 6: Train Loss=0.5301, Train Acc=0.7624 ||| Val Loss=0.4965, Val Acc=0.7838\n",
      "Epoch 7: Train Loss=0.5231, Train Acc=0.7673 ||| Val Loss=0.4909, Val Acc=0.7872\n",
      "Epoch 8: Train Loss=0.5191, Train Acc=0.7722 ||| Val Loss=0.4822, Val Acc=0.7913\n",
      "Epoch 9: Train Loss=0.5171, Train Acc=0.7686 ||| Val Loss=0.4850, Val Acc=0.8010\n",
      "Epoch 10: Train Loss=0.5147, Train Acc=0.7696 ||| Val Loss=0.4870, Val Acc=0.7803\n",
      "Epoch 11: Train Loss=0.5020, Train Acc=0.7739 ||| Val Loss=0.4649, Val Acc=0.7947\n",
      "Epoch 12: Train Loss=0.4953, Train Acc=0.7758 ||| Val Loss=0.4546, Val Acc=0.7993\n",
      "Epoch 13: Train Loss=0.4808, Train Acc=0.7758 ||| Val Loss=0.4841, Val Acc=0.7723\n",
      "Epoch 14: Train Loss=0.4783, Train Acc=0.7854 ||| Val Loss=0.4522, Val Acc=0.7976\n",
      "Epoch 15: Train Loss=0.4584, Train Acc=0.7813 ||| Val Loss=0.4348, Val Acc=0.7999\n",
      "Epoch 16: Train Loss=0.4586, Train Acc=0.7826 ||| Val Loss=0.4545, Val Acc=0.7976\n",
      "Epoch 17: Train Loss=0.4560, Train Acc=0.7900 ||| Val Loss=0.4396, Val Acc=0.7964\n",
      "Epoch 18: Train Loss=0.4520, Train Acc=0.7869 ||| Val Loss=0.4245, Val Acc=0.7999\n",
      "Epoch 19: Train Loss=0.4541, Train Acc=0.7876 ||| Val Loss=0.4345, Val Acc=0.8005\n",
      "Epoch 20: Train Loss=0.4482, Train Acc=0.7892 ||| Val Loss=0.4270, Val Acc=0.7993\n",
      "Epoch 21: Train Loss=0.4585, Train Acc=0.7865 ||| Val Loss=0.4314, Val Acc=0.7970\n",
      "Epoch 22: Train Loss=0.4435, Train Acc=0.7892 ||| Val Loss=0.4209, Val Acc=0.7987\n",
      "Epoch 23: Train Loss=0.4432, Train Acc=0.7916 ||| Val Loss=0.4443, Val Acc=0.7970\n",
      "Epoch 24: Train Loss=0.4496, Train Acc=0.7850 ||| Val Loss=0.4194, Val Acc=0.7964\n",
      "Epoch 25: Train Loss=0.4414, Train Acc=0.7850 ||| Val Loss=0.4251, Val Acc=0.7953\n",
      "Epoch 26: Train Loss=0.4454, Train Acc=0.7857 ||| Val Loss=0.4658, Val Acc=0.7763\n",
      "Epoch 27: Train Loss=0.4523, Train Acc=0.7834 ||| Val Loss=0.4181, Val Acc=0.7976\n",
      "Epoch 28: Train Loss=0.4398, Train Acc=0.7876 ||| Val Loss=0.4346, Val Acc=0.7993\n",
      "Epoch 29: Train Loss=0.4315, Train Acc=0.7934 ||| Val Loss=0.4225, Val Acc=0.7999\n",
      "Epoch 30: Train Loss=0.4334, Train Acc=0.7898 ||| Val Loss=0.4110, Val Acc=0.7999\n",
      "Epoch 31: Train Loss=0.4342, Train Acc=0.7890 ||| Val Loss=0.4147, Val Acc=0.8010\n",
      "Epoch 32: Train Loss=0.4324, Train Acc=0.7919 ||| Val Loss=0.4220, Val Acc=0.7976\n",
      "Epoch 33: Train Loss=0.4307, Train Acc=0.7916 ||| Val Loss=0.4361, Val Acc=0.7913\n",
      "Epoch 34: Train Loss=0.4394, Train Acc=0.7895 ||| Val Loss=0.4190, Val Acc=0.7999\n",
      "Epoch 35: Train Loss=0.4312, Train Acc=0.7977 ||| Val Loss=0.4246, Val Acc=0.7993\n",
      "Epoch 36: Train Loss=0.4298, Train Acc=0.7882 ||| Val Loss=0.4163, Val Acc=0.7947\n",
      "Epoch 37: Train Loss=0.4289, Train Acc=0.7942 ||| Val Loss=0.4196, Val Acc=0.7987\n",
      "Epoch 38: Train Loss=0.4306, Train Acc=0.7957 ||| Val Loss=0.4163, Val Acc=0.7970\n",
      "Epoch 39: Train Loss=0.4265, Train Acc=0.7926 ||| Val Loss=0.4157, Val Acc=0.8022\n",
      "Epoch 40: Train Loss=0.4218, Train Acc=0.7954 ||| Val Loss=0.4125, Val Acc=0.8028\n",
      "Epoch 41: Train Loss=0.4251, Train Acc=0.7970 ||| Val Loss=0.4207, Val Acc=0.7999\n",
      "Epoch 42: Train Loss=0.4253, Train Acc=0.7964 ||| Val Loss=0.4284, Val Acc=0.8010\n",
      "Epoch 43: Train Loss=0.4240, Train Acc=0.7972 ||| Val Loss=0.4126, Val Acc=0.8045\n",
      "Epoch 44: Train Loss=0.4217, Train Acc=0.7928 ||| Val Loss=0.4195, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4216, Train Acc=0.7962 ||| Val Loss=0.4166, Val Acc=0.8033\n",
      "Epoch 46: Train Loss=0.4196, Train Acc=0.7984 ||| Val Loss=0.4201, Val Acc=0.8028\n",
      "Epoch 47: Train Loss=0.4190, Train Acc=0.8018 ||| Val Loss=0.4277, Val Acc=0.7884\n",
      "Epoch 48: Train Loss=0.4242, Train Acc=0.7970 ||| Val Loss=0.4186, Val Acc=0.7993\n",
      "Epoch 49: Train Loss=0.4200, Train Acc=0.7975 ||| Val Loss=0.4143, Val Acc=0.8005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:23:58,908] Trial 39 finished with value: 0.7987349051178838 and parameters: {'n_blocks': 3, 'd_block': 512, 'k': 10, 'dropout': 0.31642719264252867, 'activation': 'LeakyReLU', 'lr': 0.0031445137761433057, 'weight_decay': 6.361729222149192e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss=0.4191, Train Acc=0.7970 ||| Val Loss=0.4146, Val Acc=0.7987\n",
      "Early stopping triggered at epoch 50\n",
      "Validation Accuracy: 0.7987\n",
      "\n",
      " Trial 41 with params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.1345066994362784, 'activation': 'GELU', 'lr': 0.02433477950478476, 'weight_decay': 0.00018530246895455223}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=3.7900, Train Acc=0.5453 ||| Val Loss=0.6344, Val Acc=0.6147\n",
      "Epoch 2: Train Loss=0.6608, Train Acc=0.6478 ||| Val Loss=0.5443, Val Acc=0.7389\n",
      "Epoch 3: Train Loss=0.5700, Train Acc=0.7309 ||| Val Loss=0.5240, Val Acc=0.7763\n",
      "Epoch 4: Train Loss=0.5467, Train Acc=0.7440 ||| Val Loss=0.5059, Val Acc=0.7941\n",
      "Epoch 5: Train Loss=0.5259, Train Acc=0.7696 ||| Val Loss=0.4952, Val Acc=0.7849\n",
      "Epoch 6: Train Loss=0.5092, Train Acc=0.7777 ||| Val Loss=0.4889, Val Acc=0.7832\n",
      "Epoch 7: Train Loss=0.4985, Train Acc=0.7827 ||| Val Loss=0.4793, Val Acc=0.7907\n",
      "Epoch 8: Train Loss=0.4986, Train Acc=0.7846 ||| Val Loss=0.4638, Val Acc=0.7907\n",
      "Epoch 9: Train Loss=0.4891, Train Acc=0.7854 ||| Val Loss=0.4758, Val Acc=0.7901\n",
      "Epoch 10: Train Loss=0.4912, Train Acc=0.7831 ||| Val Loss=0.4891, Val Acc=0.7878\n",
      "Epoch 11: Train Loss=0.4965, Train Acc=0.7856 ||| Val Loss=0.4744, Val Acc=0.7953\n",
      "Epoch 12: Train Loss=0.4944, Train Acc=0.7859 ||| Val Loss=0.4751, Val Acc=0.7987\n",
      "Epoch 13: Train Loss=0.4940, Train Acc=0.7853 ||| Val Loss=0.4713, Val Acc=0.7964\n",
      "Epoch 14: Train Loss=0.4852, Train Acc=0.7888 ||| Val Loss=0.4856, Val Acc=0.7798\n",
      "Epoch 15: Train Loss=0.4812, Train Acc=0.7892 ||| Val Loss=0.4644, Val Acc=0.7964\n",
      "Epoch 16: Train Loss=0.4769, Train Acc=0.7896 ||| Val Loss=0.4571, Val Acc=0.7987\n",
      "Epoch 17: Train Loss=0.4774, Train Acc=0.7916 ||| Val Loss=0.4719, Val Acc=0.7924\n",
      "Epoch 18: Train Loss=0.4786, Train Acc=0.7902 ||| Val Loss=0.4616, Val Acc=0.8005\n",
      "Epoch 19: Train Loss=0.4770, Train Acc=0.7906 ||| Val Loss=0.4733, Val Acc=0.7982\n",
      "Epoch 20: Train Loss=0.4836, Train Acc=0.7895 ||| Val Loss=0.4680, Val Acc=0.7959\n",
      "Epoch 21: Train Loss=0.4854, Train Acc=0.7879 ||| Val Loss=0.4747, Val Acc=0.7964\n",
      "Epoch 22: Train Loss=0.4848, Train Acc=0.7931 ||| Val Loss=0.4707, Val Acc=0.7964\n",
      "Epoch 23: Train Loss=0.4815, Train Acc=0.7911 ||| Val Loss=0.4732, Val Acc=0.7901\n",
      "Epoch 24: Train Loss=0.4846, Train Acc=0.7880 ||| Val Loss=0.4639, Val Acc=0.7964\n",
      "Epoch 25: Train Loss=0.4825, Train Acc=0.7900 ||| Val Loss=0.4660, Val Acc=0.7947\n",
      "Epoch 26: Train Loss=0.4859, Train Acc=0.7879 ||| Val Loss=0.4718, Val Acc=0.7884\n",
      "Epoch 27: Train Loss=0.4784, Train Acc=0.7902 ||| Val Loss=0.4683, Val Acc=0.7947\n",
      "Epoch 28: Train Loss=0.4839, Train Acc=0.7886 ||| Val Loss=0.4695, Val Acc=0.7918\n",
      "Epoch 29: Train Loss=0.4907, Train Acc=0.7872 ||| Val Loss=0.4934, Val Acc=0.7878\n",
      "Epoch 30: Train Loss=0.4896, Train Acc=0.7869 ||| Val Loss=0.4741, Val Acc=0.7872\n",
      "Epoch 31: Train Loss=0.4912, Train Acc=0.7870 ||| Val Loss=0.4781, Val Acc=0.7947\n",
      "Epoch 32: Train Loss=0.4880, Train Acc=0.7898 ||| Val Loss=0.4884, Val Acc=0.7936\n",
      "Epoch 33: Train Loss=0.4954, Train Acc=0.7886 ||| Val Loss=0.5077, Val Acc=0.7918\n",
      "Epoch 34: Train Loss=0.4900, Train Acc=0.7882 ||| Val Loss=0.4722, Val Acc=0.7924\n",
      "Epoch 35: Train Loss=0.4871, Train Acc=0.7873 ||| Val Loss=0.4861, Val Acc=0.7815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:24:12,568] Trial 40 finished with value: 0.7929844738355377 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.1345066994362784, 'activation': 'GELU', 'lr': 0.02433477950478476, 'weight_decay': 0.00018530246895455223}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=0.4815, Train Acc=0.7895 ||| Val Loss=0.4741, Val Acc=0.7930\n",
      "Early stopping triggered at epoch 36\n",
      "Validation Accuracy: 0.7930\n",
      "\n",
      " Trial 42 with params: {'n_blocks': 4, 'd_block': 128, 'k': 9, 'dropout': 0.17206160024841372, 'activation': 'ReLU', 'lr': 0.00508239905977638, 'weight_decay': 7.436342540113737e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.0352, Train Acc=0.6726 ||| Val Loss=0.5231, Val Acc=0.7884\n",
      "Epoch 2: Train Loss=0.5394, Train Acc=0.7636 ||| Val Loss=0.5198, Val Acc=0.7884\n",
      "Epoch 3: Train Loss=0.5148, Train Acc=0.7754 ||| Val Loss=0.4968, Val Acc=0.7855\n",
      "Epoch 4: Train Loss=0.5150, Train Acc=0.7783 ||| Val Loss=0.4955, Val Acc=0.7815\n",
      "Epoch 5: Train Loss=0.4910, Train Acc=0.7819 ||| Val Loss=0.4741, Val Acc=0.7993\n",
      "Epoch 6: Train Loss=0.4909, Train Acc=0.7842 ||| Val Loss=0.4650, Val Acc=0.7947\n",
      "Epoch 7: Train Loss=0.4662, Train Acc=0.7913 ||| Val Loss=0.4518, Val Acc=0.7918\n",
      "Epoch 8: Train Loss=0.4670, Train Acc=0.7902 ||| Val Loss=0.4396, Val Acc=0.7953\n",
      "Epoch 9: Train Loss=0.4537, Train Acc=0.7865 ||| Val Loss=0.4276, Val Acc=0.7953\n",
      "Epoch 10: Train Loss=0.4514, Train Acc=0.7890 ||| Val Loss=0.4284, Val Acc=0.7936\n",
      "Epoch 11: Train Loss=0.4411, Train Acc=0.7900 ||| Val Loss=0.4442, Val Acc=0.7976\n",
      "Epoch 12: Train Loss=0.4462, Train Acc=0.7831 ||| Val Loss=0.4264, Val Acc=0.7964\n",
      "Epoch 13: Train Loss=0.4395, Train Acc=0.7883 ||| Val Loss=0.4230, Val Acc=0.7976\n",
      "Epoch 14: Train Loss=0.4293, Train Acc=0.7915 ||| Val Loss=0.4250, Val Acc=0.7832\n",
      "Epoch 15: Train Loss=0.4323, Train Acc=0.7948 ||| Val Loss=0.4197, Val Acc=0.7976\n",
      "Epoch 16: Train Loss=0.4266, Train Acc=0.7935 ||| Val Loss=0.4230, Val Acc=0.7976\n",
      "Epoch 17: Train Loss=0.4297, Train Acc=0.7998 ||| Val Loss=0.4291, Val Acc=0.7884\n",
      "Epoch 18: Train Loss=0.4248, Train Acc=0.7941 ||| Val Loss=0.4094, Val Acc=0.7987\n",
      "Epoch 19: Train Loss=0.4225, Train Acc=0.7965 ||| Val Loss=0.4108, Val Acc=0.7999\n",
      "Epoch 20: Train Loss=0.4223, Train Acc=0.7964 ||| Val Loss=0.4118, Val Acc=0.7976\n",
      "Epoch 21: Train Loss=0.4231, Train Acc=0.7962 ||| Val Loss=0.4112, Val Acc=0.7947\n",
      "Epoch 22: Train Loss=0.4201, Train Acc=0.7982 ||| Val Loss=0.4225, Val Acc=0.7930\n",
      "Epoch 23: Train Loss=0.4190, Train Acc=0.7991 ||| Val Loss=0.4133, Val Acc=0.7964\n",
      "Epoch 24: Train Loss=0.4217, Train Acc=0.8007 ||| Val Loss=0.4089, Val Acc=0.7999\n",
      "Epoch 25: Train Loss=0.4202, Train Acc=0.7975 ||| Val Loss=0.4140, Val Acc=0.7959\n",
      "Epoch 26: Train Loss=0.4216, Train Acc=0.7974 ||| Val Loss=0.4157, Val Acc=0.7999\n",
      "Epoch 27: Train Loss=0.4166, Train Acc=0.7995 ||| Val Loss=0.4083, Val Acc=0.7976\n",
      "Epoch 28: Train Loss=0.4165, Train Acc=0.7991 ||| Val Loss=0.4188, Val Acc=0.7993\n",
      "Epoch 29: Train Loss=0.4253, Train Acc=0.7984 ||| Val Loss=0.4174, Val Acc=0.7913\n",
      "Epoch 30: Train Loss=0.4184, Train Acc=0.8011 ||| Val Loss=0.4073, Val Acc=0.8028\n",
      "Epoch 31: Train Loss=0.4165, Train Acc=0.7980 ||| Val Loss=0.4100, Val Acc=0.8045\n",
      "Epoch 32: Train Loss=0.4100, Train Acc=0.8021 ||| Val Loss=0.4117, Val Acc=0.8022\n",
      "Epoch 33: Train Loss=0.4168, Train Acc=0.8013 ||| Val Loss=0.4130, Val Acc=0.8010\n",
      "Epoch 34: Train Loss=0.4151, Train Acc=0.8005 ||| Val Loss=0.4077, Val Acc=0.8010\n",
      "Epoch 35: Train Loss=0.4131, Train Acc=0.8043 ||| Val Loss=0.4090, Val Acc=0.8022\n",
      "Epoch 36: Train Loss=0.4133, Train Acc=0.8066 ||| Val Loss=0.4146, Val Acc=0.8074\n",
      "Epoch 37: Train Loss=0.4101, Train Acc=0.8024 ||| Val Loss=0.4086, Val Acc=0.7999\n",
      "Epoch 38: Train Loss=0.4075, Train Acc=0.8039 ||| Val Loss=0.4069, Val Acc=0.8051\n",
      "Epoch 39: Train Loss=0.4115, Train Acc=0.8046 ||| Val Loss=0.4076, Val Acc=0.8039\n",
      "Epoch 40: Train Loss=0.4065, Train Acc=0.8066 ||| Val Loss=0.4108, Val Acc=0.7999\n",
      "Epoch 41: Train Loss=0.4101, Train Acc=0.8041 ||| Val Loss=0.4085, Val Acc=0.7959\n",
      "Epoch 42: Train Loss=0.4084, Train Acc=0.8085 ||| Val Loss=0.4050, Val Acc=0.7982\n",
      "Epoch 43: Train Loss=0.4090, Train Acc=0.8083 ||| Val Loss=0.4093, Val Acc=0.8033\n",
      "Epoch 44: Train Loss=0.4109, Train Acc=0.8031 ||| Val Loss=0.4120, Val Acc=0.8010\n",
      "Epoch 45: Train Loss=0.4089, Train Acc=0.8070 ||| Val Loss=0.4097, Val Acc=0.8022\n",
      "Epoch 46: Train Loss=0.4089, Train Acc=0.8064 ||| Val Loss=0.4051, Val Acc=0.8022\n",
      "Epoch 47: Train Loss=0.4060, Train Acc=0.8056 ||| Val Loss=0.4102, Val Acc=0.8039\n",
      "Epoch 48: Train Loss=0.4117, Train Acc=0.8034 ||| Val Loss=0.4122, Val Acc=0.8028\n",
      "Epoch 49: Train Loss=0.4049, Train Acc=0.8108 ||| Val Loss=0.4048, Val Acc=0.8028\n",
      "Epoch 50: Train Loss=0.4037, Train Acc=0.8126 ||| Val Loss=0.4085, Val Acc=0.8056\n",
      "Epoch 51: Train Loss=0.4046, Train Acc=0.8036 ||| Val Loss=0.4072, Val Acc=0.8010\n",
      "Epoch 52: Train Loss=0.4094, Train Acc=0.8082 ||| Val Loss=0.4122, Val Acc=0.8062\n",
      "Epoch 53: Train Loss=0.4008, Train Acc=0.8121 ||| Val Loss=0.4196, Val Acc=0.8039\n",
      "Epoch 54: Train Loss=0.4034, Train Acc=0.8073 ||| Val Loss=0.4084, Val Acc=0.8010\n",
      "Epoch 55: Train Loss=0.4036, Train Acc=0.8113 ||| Val Loss=0.4057, Val Acc=0.8056\n",
      "Epoch 56: Train Loss=0.4006, Train Acc=0.8090 ||| Val Loss=0.4066, Val Acc=0.7987\n",
      "Epoch 57: Train Loss=0.4018, Train Acc=0.8059 ||| Val Loss=0.4029, Val Acc=0.8039\n",
      "Epoch 58: Train Loss=0.4084, Train Acc=0.8066 ||| Val Loss=0.4085, Val Acc=0.7982\n",
      "Epoch 59: Train Loss=0.4070, Train Acc=0.8067 ||| Val Loss=0.4186, Val Acc=0.7999\n",
      "Epoch 60: Train Loss=0.4032, Train Acc=0.8059 ||| Val Loss=0.4055, Val Acc=0.8051\n",
      "Epoch 61: Train Loss=0.4007, Train Acc=0.8083 ||| Val Loss=0.4106, Val Acc=0.8062\n",
      "Epoch 62: Train Loss=0.3966, Train Acc=0.8154 ||| Val Loss=0.4143, Val Acc=0.7964\n",
      "Epoch 63: Train Loss=0.4043, Train Acc=0.8080 ||| Val Loss=0.4122, Val Acc=0.7959\n",
      "Epoch 64: Train Loss=0.3975, Train Acc=0.8100 ||| Val Loss=0.4182, Val Acc=0.7976\n",
      "Epoch 65: Train Loss=0.3978, Train Acc=0.8062 ||| Val Loss=0.4078, Val Acc=0.8045\n",
      "Epoch 66: Train Loss=0.3974, Train Acc=0.8110 ||| Val Loss=0.4137, Val Acc=0.8039\n",
      "Epoch 67: Train Loss=0.3969, Train Acc=0.8126 ||| Val Loss=0.4255, Val Acc=0.8022\n",
      "Epoch 68: Train Loss=0.3993, Train Acc=0.8096 ||| Val Loss=0.4167, Val Acc=0.7953\n",
      "Epoch 69: Train Loss=0.3985, Train Acc=0.8093 ||| Val Loss=0.4116, Val Acc=0.8045\n",
      "Epoch 70: Train Loss=0.3941, Train Acc=0.8108 ||| Val Loss=0.4157, Val Acc=0.8056\n",
      "Epoch 71: Train Loss=0.3959, Train Acc=0.8136 ||| Val Loss=0.4091, Val Acc=0.8045\n",
      "Epoch 72: Train Loss=0.3994, Train Acc=0.8076 ||| Val Loss=0.4129, Val Acc=0.8022\n",
      "Epoch 73: Train Loss=0.3959, Train Acc=0.8156 ||| Val Loss=0.4157, Val Acc=0.7959\n",
      "Epoch 74: Train Loss=0.3915, Train Acc=0.8167 ||| Val Loss=0.4085, Val Acc=0.8033\n",
      "Epoch 75: Train Loss=0.3967, Train Acc=0.8106 ||| Val Loss=0.4099, Val Acc=0.8033\n",
      "Epoch 76: Train Loss=0.3931, Train Acc=0.8115 ||| Val Loss=0.4161, Val Acc=0.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:24:34,840] Trial 41 finished with value: 0.8021851638872916 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 9, 'dropout': 0.17206160024841372, 'activation': 'ReLU', 'lr': 0.00508239905977638, 'weight_decay': 7.436342540113737e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train Loss=0.3963, Train Acc=0.8135 ||| Val Loss=0.4115, Val Acc=0.8022\n",
      "Early stopping triggered at epoch 77\n",
      "Validation Accuracy: 0.8022\n",
      "\n",
      " Trial 43 with params: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.1762118093370013, 'activation': 'ReLU', 'lr': 0.002904932626054875, 'weight_decay': 1.650298134436485e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.8907, Train Acc=0.6816 ||| Val Loss=0.5306, Val Acc=0.7918\n",
      "Epoch 2: Train Loss=0.5367, Train Acc=0.7577 ||| Val Loss=0.5130, Val Acc=0.7815\n",
      "Epoch 3: Train Loss=0.5265, Train Acc=0.7686 ||| Val Loss=0.5052, Val Acc=0.7913\n",
      "Epoch 4: Train Loss=0.5159, Train Acc=0.7695 ||| Val Loss=0.4948, Val Acc=0.7924\n",
      "Epoch 5: Train Loss=0.5109, Train Acc=0.7767 ||| Val Loss=0.5036, Val Acc=0.7947\n",
      "Epoch 6: Train Loss=0.5013, Train Acc=0.7783 ||| Val Loss=0.4817, Val Acc=0.7941\n",
      "Epoch 7: Train Loss=0.4958, Train Acc=0.7840 ||| Val Loss=0.4765, Val Acc=0.7936\n",
      "Epoch 8: Train Loss=0.4878, Train Acc=0.7839 ||| Val Loss=0.4809, Val Acc=0.7924\n",
      "Epoch 9: Train Loss=0.4859, Train Acc=0.7827 ||| Val Loss=0.4797, Val Acc=0.7884\n",
      "Epoch 10: Train Loss=0.4819, Train Acc=0.7824 ||| Val Loss=0.4710, Val Acc=0.7901\n",
      "Epoch 11: Train Loss=0.4782, Train Acc=0.7857 ||| Val Loss=0.4551, Val Acc=0.7976\n",
      "Epoch 12: Train Loss=0.4775, Train Acc=0.7839 ||| Val Loss=0.4714, Val Acc=0.7987\n",
      "Epoch 13: Train Loss=0.4669, Train Acc=0.7888 ||| Val Loss=0.4496, Val Acc=0.7964\n",
      "Epoch 14: Train Loss=0.4613, Train Acc=0.7926 ||| Val Loss=0.4537, Val Acc=0.8005\n",
      "Epoch 15: Train Loss=0.4501, Train Acc=0.7912 ||| Val Loss=0.4613, Val Acc=0.7867\n",
      "Epoch 16: Train Loss=0.4425, Train Acc=0.7923 ||| Val Loss=0.4392, Val Acc=0.7895\n",
      "Epoch 17: Train Loss=0.4371, Train Acc=0.7915 ||| Val Loss=0.4504, Val Acc=0.7999\n",
      "Epoch 18: Train Loss=0.4343, Train Acc=0.7915 ||| Val Loss=0.4272, Val Acc=0.7913\n",
      "Epoch 19: Train Loss=0.4294, Train Acc=0.7935 ||| Val Loss=0.4214, Val Acc=0.7947\n",
      "Epoch 20: Train Loss=0.4322, Train Acc=0.7938 ||| Val Loss=0.4211, Val Acc=0.7976\n",
      "Epoch 21: Train Loss=0.4262, Train Acc=0.7932 ||| Val Loss=0.4346, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4269, Train Acc=0.7941 ||| Val Loss=0.4218, Val Acc=0.7953\n",
      "Epoch 23: Train Loss=0.4224, Train Acc=0.7970 ||| Val Loss=0.4291, Val Acc=0.7947\n",
      "Epoch 24: Train Loss=0.4221, Train Acc=0.7962 ||| Val Loss=0.4230, Val Acc=0.7970\n",
      "Epoch 25: Train Loss=0.4247, Train Acc=0.7916 ||| Val Loss=0.4225, Val Acc=0.7895\n",
      "Epoch 26: Train Loss=0.4227, Train Acc=0.7949 ||| Val Loss=0.4176, Val Acc=0.7970\n",
      "Epoch 27: Train Loss=0.4230, Train Acc=0.7978 ||| Val Loss=0.4161, Val Acc=0.7987\n",
      "Epoch 28: Train Loss=0.4208, Train Acc=0.7977 ||| Val Loss=0.4202, Val Acc=0.7809\n",
      "Epoch 29: Train Loss=0.4184, Train Acc=0.7947 ||| Val Loss=0.4247, Val Acc=0.7832\n",
      "Epoch 30: Train Loss=0.4173, Train Acc=0.7975 ||| Val Loss=0.4171, Val Acc=0.7913\n",
      "Epoch 31: Train Loss=0.4210, Train Acc=0.7926 ||| Val Loss=0.4236, Val Acc=0.7890\n",
      "Epoch 32: Train Loss=0.4180, Train Acc=0.8023 ||| Val Loss=0.4249, Val Acc=0.7976\n",
      "Epoch 33: Train Loss=0.4171, Train Acc=0.7980 ||| Val Loss=0.4232, Val Acc=0.7895\n",
      "Epoch 34: Train Loss=0.4205, Train Acc=0.8008 ||| Val Loss=0.4151, Val Acc=0.7872\n",
      "Epoch 35: Train Loss=0.4189, Train Acc=0.7964 ||| Val Loss=0.4197, Val Acc=0.7953\n",
      "Epoch 36: Train Loss=0.4172, Train Acc=0.7970 ||| Val Loss=0.4132, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4164, Train Acc=0.7990 ||| Val Loss=0.4185, Val Acc=0.7959\n",
      "Epoch 38: Train Loss=0.4180, Train Acc=0.8013 ||| Val Loss=0.4083, Val Acc=0.7953\n",
      "Epoch 39: Train Loss=0.4121, Train Acc=0.8005 ||| Val Loss=0.4174, Val Acc=0.7959\n",
      "Epoch 40: Train Loss=0.4129, Train Acc=0.8011 ||| Val Loss=0.4182, Val Acc=0.7999\n",
      "Epoch 41: Train Loss=0.4180, Train Acc=0.7991 ||| Val Loss=0.4164, Val Acc=0.7999\n",
      "Epoch 42: Train Loss=0.4130, Train Acc=0.8020 ||| Val Loss=0.4165, Val Acc=0.8033\n",
      "Epoch 43: Train Loss=0.4171, Train Acc=0.7978 ||| Val Loss=0.4176, Val Acc=0.7918\n",
      "Epoch 44: Train Loss=0.4108, Train Acc=0.7984 ||| Val Loss=0.4236, Val Acc=0.7924\n",
      "Epoch 45: Train Loss=0.4104, Train Acc=0.8007 ||| Val Loss=0.4101, Val Acc=0.8016\n",
      "Epoch 46: Train Loss=0.4111, Train Acc=0.7995 ||| Val Loss=0.4182, Val Acc=0.7970\n",
      "Epoch 47: Train Loss=0.4117, Train Acc=0.8017 ||| Val Loss=0.4271, Val Acc=0.7976\n",
      "Epoch 48: Train Loss=0.4099, Train Acc=0.8007 ||| Val Loss=0.4169, Val Acc=0.7982\n",
      "Epoch 49: Train Loss=0.4113, Train Acc=0.8021 ||| Val Loss=0.4138, Val Acc=0.7999\n",
      "Epoch 50: Train Loss=0.4114, Train Acc=0.8040 ||| Val Loss=0.4191, Val Acc=0.7964\n",
      "Epoch 51: Train Loss=0.4090, Train Acc=0.8030 ||| Val Loss=0.4155, Val Acc=0.7976\n",
      "Epoch 52: Train Loss=0.4109, Train Acc=0.7993 ||| Val Loss=0.4153, Val Acc=0.8016\n",
      "Epoch 53: Train Loss=0.4094, Train Acc=0.8028 ||| Val Loss=0.4152, Val Acc=0.7976\n",
      "Epoch 54: Train Loss=0.4071, Train Acc=0.8070 ||| Val Loss=0.4112, Val Acc=0.7941\n",
      "Epoch 55: Train Loss=0.4104, Train Acc=0.7978 ||| Val Loss=0.4174, Val Acc=0.7878\n",
      "Epoch 56: Train Loss=0.4064, Train Acc=0.8077 ||| Val Loss=0.4165, Val Acc=0.7982\n",
      "Epoch 57: Train Loss=0.4060, Train Acc=0.8070 ||| Val Loss=0.4148, Val Acc=0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:24:52,194] Trial 42 finished with value: 0.7998849913743531 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.1762118093370013, 'activation': 'ReLU', 'lr': 0.002904932626054875, 'weight_decay': 1.650298134436485e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss=0.4094, Train Acc=0.8018 ||| Val Loss=0.4175, Val Acc=0.7999\n",
      "Early stopping triggered at epoch 58\n",
      "Validation Accuracy: 0.7999\n",
      "\n",
      " Trial 44 with params: {'n_blocks': 4, 'd_block': 128, 'k': 8, 'dropout': 0.23337714009542354, 'activation': 'ReLU', 'lr': 0.0010609206170323917, 'weight_decay': 3.2282782714111487e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.9321, Train Acc=0.6401 ||| Val Loss=0.5506, Val Acc=0.7188\n",
      "Epoch 2: Train Loss=0.5858, Train Acc=0.7131 ||| Val Loss=0.5199, Val Acc=0.7832\n",
      "Epoch 3: Train Loss=0.5566, Train Acc=0.7412 ||| Val Loss=0.5200, Val Acc=0.7930\n",
      "Epoch 4: Train Loss=0.5380, Train Acc=0.7535 ||| Val Loss=0.5097, Val Acc=0.7913\n",
      "Epoch 5: Train Loss=0.5209, Train Acc=0.7688 ||| Val Loss=0.4952, Val Acc=0.7970\n",
      "Epoch 6: Train Loss=0.5186, Train Acc=0.7702 ||| Val Loss=0.4944, Val Acc=0.7941\n",
      "Epoch 7: Train Loss=0.5065, Train Acc=0.7774 ||| Val Loss=0.4920, Val Acc=0.7941\n",
      "Epoch 8: Train Loss=0.5097, Train Acc=0.7771 ||| Val Loss=0.4864, Val Acc=0.7941\n",
      "Epoch 9: Train Loss=0.5039, Train Acc=0.7794 ||| Val Loss=0.4826, Val Acc=0.7947\n",
      "Epoch 10: Train Loss=0.4949, Train Acc=0.7806 ||| Val Loss=0.4906, Val Acc=0.7890\n",
      "Epoch 11: Train Loss=0.4904, Train Acc=0.7831 ||| Val Loss=0.4719, Val Acc=0.7964\n",
      "Epoch 12: Train Loss=0.4876, Train Acc=0.7847 ||| Val Loss=0.4645, Val Acc=0.8005\n",
      "Epoch 13: Train Loss=0.4790, Train Acc=0.7850 ||| Val Loss=0.4639, Val Acc=0.7959\n",
      "Epoch 14: Train Loss=0.4753, Train Acc=0.7826 ||| Val Loss=0.4533, Val Acc=0.8010\n",
      "Epoch 15: Train Loss=0.4655, Train Acc=0.7876 ||| Val Loss=0.4455, Val Acc=0.8022\n",
      "Epoch 16: Train Loss=0.4588, Train Acc=0.7870 ||| Val Loss=0.4519, Val Acc=0.7947\n",
      "Epoch 17: Train Loss=0.4554, Train Acc=0.7856 ||| Val Loss=0.4423, Val Acc=0.7987\n",
      "Epoch 18: Train Loss=0.4478, Train Acc=0.7879 ||| Val Loss=0.4465, Val Acc=0.8022\n",
      "Epoch 19: Train Loss=0.4477, Train Acc=0.7865 ||| Val Loss=0.4352, Val Acc=0.7959\n",
      "Epoch 20: Train Loss=0.4436, Train Acc=0.7863 ||| Val Loss=0.4326, Val Acc=0.7953\n",
      "Epoch 21: Train Loss=0.4397, Train Acc=0.7921 ||| Val Loss=0.4314, Val Acc=0.7936\n",
      "Epoch 22: Train Loss=0.4390, Train Acc=0.7939 ||| Val Loss=0.4328, Val Acc=0.7884\n",
      "Epoch 23: Train Loss=0.4384, Train Acc=0.7908 ||| Val Loss=0.4312, Val Acc=0.7947\n",
      "Epoch 24: Train Loss=0.4340, Train Acc=0.7898 ||| Val Loss=0.4318, Val Acc=0.7913\n",
      "Epoch 25: Train Loss=0.4345, Train Acc=0.7929 ||| Val Loss=0.4319, Val Acc=0.8005\n",
      "Epoch 26: Train Loss=0.4322, Train Acc=0.7922 ||| Val Loss=0.4263, Val Acc=0.7918\n",
      "Epoch 27: Train Loss=0.4387, Train Acc=0.7873 ||| Val Loss=0.4323, Val Acc=0.7936\n",
      "Epoch 28: Train Loss=0.4315, Train Acc=0.7918 ||| Val Loss=0.4312, Val Acc=0.7953\n",
      "Epoch 29: Train Loss=0.4254, Train Acc=0.7955 ||| Val Loss=0.4289, Val Acc=0.7993\n",
      "Epoch 30: Train Loss=0.4336, Train Acc=0.7938 ||| Val Loss=0.4250, Val Acc=0.7918\n",
      "Epoch 31: Train Loss=0.4274, Train Acc=0.7959 ||| Val Loss=0.4234, Val Acc=0.7999\n",
      "Epoch 32: Train Loss=0.4245, Train Acc=0.7947 ||| Val Loss=0.4174, Val Acc=0.7993\n",
      "Epoch 33: Train Loss=0.4270, Train Acc=0.7949 ||| Val Loss=0.4246, Val Acc=0.8016\n",
      "Epoch 34: Train Loss=0.4239, Train Acc=0.7929 ||| Val Loss=0.4229, Val Acc=0.7964\n",
      "Epoch 35: Train Loss=0.4233, Train Acc=0.7955 ||| Val Loss=0.4264, Val Acc=0.7993\n",
      "Epoch 36: Train Loss=0.4276, Train Acc=0.7923 ||| Val Loss=0.4261, Val Acc=0.7964\n",
      "Epoch 37: Train Loss=0.4245, Train Acc=0.7959 ||| Val Loss=0.4166, Val Acc=0.8016\n",
      "Epoch 38: Train Loss=0.4243, Train Acc=0.7934 ||| Val Loss=0.4266, Val Acc=0.7993\n",
      "Epoch 39: Train Loss=0.4198, Train Acc=0.7975 ||| Val Loss=0.4328, Val Acc=0.7959\n",
      "Epoch 40: Train Loss=0.4240, Train Acc=0.7972 ||| Val Loss=0.4193, Val Acc=0.7959\n",
      "Epoch 41: Train Loss=0.4223, Train Acc=0.7949 ||| Val Loss=0.4217, Val Acc=0.7953\n",
      "Epoch 42: Train Loss=0.4208, Train Acc=0.7965 ||| Val Loss=0.4194, Val Acc=0.7987\n",
      "Epoch 43: Train Loss=0.4188, Train Acc=0.7970 ||| Val Loss=0.4220, Val Acc=0.8010\n",
      "Epoch 44: Train Loss=0.4183, Train Acc=0.7994 ||| Val Loss=0.4164, Val Acc=0.8005\n",
      "Epoch 45: Train Loss=0.4181, Train Acc=0.7955 ||| Val Loss=0.4180, Val Acc=0.7987\n",
      "Epoch 46: Train Loss=0.4168, Train Acc=0.7985 ||| Val Loss=0.4209, Val Acc=0.7970\n",
      "Epoch 47: Train Loss=0.4162, Train Acc=0.7997 ||| Val Loss=0.4163, Val Acc=0.7982\n",
      "Epoch 48: Train Loss=0.4147, Train Acc=0.7968 ||| Val Loss=0.4304, Val Acc=0.7987\n",
      "Epoch 49: Train Loss=0.4193, Train Acc=0.8010 ||| Val Loss=0.4259, Val Acc=0.7884\n",
      "Epoch 50: Train Loss=0.4192, Train Acc=0.7942 ||| Val Loss=0.4172, Val Acc=0.7947\n",
      "Epoch 51: Train Loss=0.4150, Train Acc=0.8008 ||| Val Loss=0.4189, Val Acc=0.8010\n",
      "Epoch 52: Train Loss=0.4195, Train Acc=0.7965 ||| Val Loss=0.4209, Val Acc=0.7964\n",
      "Epoch 53: Train Loss=0.4176, Train Acc=0.7965 ||| Val Loss=0.4193, Val Acc=0.8016\n",
      "Epoch 54: Train Loss=0.4190, Train Acc=0.7971 ||| Val Loss=0.4153, Val Acc=0.7941\n",
      "Epoch 55: Train Loss=0.4177, Train Acc=0.7949 ||| Val Loss=0.4155, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4202, Train Acc=0.7984 ||| Val Loss=0.4182, Val Acc=0.7976\n",
      "Epoch 57: Train Loss=0.4156, Train Acc=0.7980 ||| Val Loss=0.4158, Val Acc=0.7987\n",
      "Epoch 58: Train Loss=0.4139, Train Acc=0.7982 ||| Val Loss=0.4125, Val Acc=0.8005\n",
      "Epoch 59: Train Loss=0.4137, Train Acc=0.8000 ||| Val Loss=0.4213, Val Acc=0.7895\n",
      "Epoch 60: Train Loss=0.4130, Train Acc=0.8013 ||| Val Loss=0.4141, Val Acc=0.8028\n",
      "Epoch 61: Train Loss=0.4125, Train Acc=0.7985 ||| Val Loss=0.4170, Val Acc=0.7947\n",
      "Epoch 62: Train Loss=0.4170, Train Acc=0.7975 ||| Val Loss=0.4228, Val Acc=0.7982\n",
      "Epoch 63: Train Loss=0.4148, Train Acc=0.8010 ||| Val Loss=0.4164, Val Acc=0.7970\n",
      "Epoch 64: Train Loss=0.4120, Train Acc=0.7990 ||| Val Loss=0.4151, Val Acc=0.7976\n",
      "Epoch 65: Train Loss=0.4096, Train Acc=0.8004 ||| Val Loss=0.4172, Val Acc=0.7976\n",
      "Epoch 66: Train Loss=0.4145, Train Acc=0.7993 ||| Val Loss=0.4123, Val Acc=0.7987\n",
      "Epoch 67: Train Loss=0.4114, Train Acc=0.8013 ||| Val Loss=0.4138, Val Acc=0.7964\n",
      "Epoch 68: Train Loss=0.4157, Train Acc=0.8026 ||| Val Loss=0.4244, Val Acc=0.7936\n",
      "Epoch 69: Train Loss=0.4118, Train Acc=0.8033 ||| Val Loss=0.4131, Val Acc=0.7947\n",
      "Epoch 70: Train Loss=0.4087, Train Acc=0.8034 ||| Val Loss=0.4136, Val Acc=0.7964\n",
      "Epoch 71: Train Loss=0.4101, Train Acc=0.8037 ||| Val Loss=0.4183, Val Acc=0.7953\n",
      "Epoch 72: Train Loss=0.4130, Train Acc=0.8000 ||| Val Loss=0.4280, Val Acc=0.7947\n",
      "Epoch 73: Train Loss=0.4097, Train Acc=0.7995 ||| Val Loss=0.4209, Val Acc=0.7924\n",
      "Epoch 74: Train Loss=0.4062, Train Acc=0.8044 ||| Val Loss=0.4182, Val Acc=0.7976\n",
      "Epoch 75: Train Loss=0.4087, Train Acc=0.8016 ||| Val Loss=0.4135, Val Acc=0.8022\n",
      "Epoch 76: Train Loss=0.4072, Train Acc=0.8016 ||| Val Loss=0.4191, Val Acc=0.7930\n",
      "Epoch 77: Train Loss=0.4107, Train Acc=0.8008 ||| Val Loss=0.4122, Val Acc=0.7999\n",
      "Epoch 78: Train Loss=0.4047, Train Acc=0.8021 ||| Val Loss=0.4249, Val Acc=0.7993\n",
      "Epoch 79: Train Loss=0.4100, Train Acc=0.8011 ||| Val Loss=0.4137, Val Acc=0.7930\n",
      "Epoch 80: Train Loss=0.4112, Train Acc=0.8046 ||| Val Loss=0.4146, Val Acc=0.7936\n",
      "Epoch 81: Train Loss=0.4065, Train Acc=0.8050 ||| Val Loss=0.4148, Val Acc=0.8010\n",
      "Epoch 82: Train Loss=0.4050, Train Acc=0.8028 ||| Val Loss=0.4203, Val Acc=0.7936\n",
      "Epoch 83: Train Loss=0.4065, Train Acc=0.8069 ||| Val Loss=0.4131, Val Acc=0.8010\n",
      "Epoch 84: Train Loss=0.4057, Train Acc=0.8037 ||| Val Loss=0.4123, Val Acc=0.7982\n",
      "Epoch 85: Train Loss=0.4066, Train Acc=0.8031 ||| Val Loss=0.4132, Val Acc=0.7924\n",
      "Epoch 86: Train Loss=0.4069, Train Acc=0.8039 ||| Val Loss=0.4214, Val Acc=0.7930\n",
      "Epoch 87: Train Loss=0.4067, Train Acc=0.8027 ||| Val Loss=0.4199, Val Acc=0.7872\n",
      "Epoch 88: Train Loss=0.4043, Train Acc=0.8053 ||| Val Loss=0.4198, Val Acc=0.7970\n",
      "Epoch 89: Train Loss=0.4038, Train Acc=0.8060 ||| Val Loss=0.4178, Val Acc=0.7976\n",
      "Epoch 90: Train Loss=0.4028, Train Acc=0.8046 ||| Val Loss=0.4168, Val Acc=0.8039\n",
      "Epoch 91: Train Loss=0.4008, Train Acc=0.8046 ||| Val Loss=0.4156, Val Acc=0.8022\n",
      "Epoch 92: Train Loss=0.4068, Train Acc=0.8026 ||| Val Loss=0.4175, Val Acc=0.7976\n",
      "Epoch 93: Train Loss=0.4045, Train Acc=0.8034 ||| Val Loss=0.4180, Val Acc=0.8028\n",
      "Epoch 94: Train Loss=0.4011, Train Acc=0.8030 ||| Val Loss=0.4210, Val Acc=0.7924\n",
      "Epoch 95: Train Loss=0.4011, Train Acc=0.8074 ||| Val Loss=0.4136, Val Acc=0.7953\n",
      "Epoch 96: Train Loss=0.4037, Train Acc=0.8073 ||| Val Loss=0.4138, Val Acc=0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:25:19,887] Trial 43 finished with value: 0.7993099482461185 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 8, 'dropout': 0.23337714009542354, 'activation': 'ReLU', 'lr': 0.0010609206170323917, 'weight_decay': 3.2282782714111487e-06}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss=0.4052, Train Acc=0.8026 ||| Val Loss=0.4123, Val Acc=0.7993\n",
      "Early stopping triggered at epoch 97\n",
      "Validation Accuracy: 0.7993\n",
      "\n",
      " Trial 45 with params: {'n_blocks': 3, 'd_block': 128, 'k': 7, 'dropout': 0.14698338733891037, 'activation': 'ReLU', 'lr': 0.0020416279301639826, 'weight_decay': 5.4653696621886695e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.2274, Train Acc=0.6639 ||| Val Loss=0.5437, Val Acc=0.7487\n",
      "Epoch 2: Train Loss=0.5985, Train Acc=0.7212 ||| Val Loss=0.5296, Val Acc=0.7861\n",
      "Epoch 3: Train Loss=0.5532, Train Acc=0.7459 ||| Val Loss=0.5162, Val Acc=0.7838\n",
      "Epoch 4: Train Loss=0.5278, Train Acc=0.7639 ||| Val Loss=0.5099, Val Acc=0.7930\n",
      "Epoch 5: Train Loss=0.5237, Train Acc=0.7683 ||| Val Loss=0.4954, Val Acc=0.7901\n",
      "Epoch 6: Train Loss=0.5090, Train Acc=0.7764 ||| Val Loss=0.4965, Val Acc=0.7907\n",
      "Epoch 7: Train Loss=0.5022, Train Acc=0.7778 ||| Val Loss=0.5013, Val Acc=0.7913\n",
      "Epoch 8: Train Loss=0.5053, Train Acc=0.7797 ||| Val Loss=0.4901, Val Acc=0.7907\n",
      "Epoch 9: Train Loss=0.4983, Train Acc=0.7816 ||| Val Loss=0.4899, Val Acc=0.7941\n",
      "Epoch 10: Train Loss=0.5010, Train Acc=0.7843 ||| Val Loss=0.4951, Val Acc=0.7838\n",
      "Epoch 11: Train Loss=0.4949, Train Acc=0.7826 ||| Val Loss=0.4771, Val Acc=0.7907\n",
      "Epoch 12: Train Loss=0.4920, Train Acc=0.7837 ||| Val Loss=0.4764, Val Acc=0.7867\n",
      "Epoch 13: Train Loss=0.4901, Train Acc=0.7850 ||| Val Loss=0.4967, Val Acc=0.7959\n",
      "Epoch 14: Train Loss=0.4891, Train Acc=0.7847 ||| Val Loss=0.4808, Val Acc=0.7947\n",
      "Epoch 15: Train Loss=0.4877, Train Acc=0.7873 ||| Val Loss=0.4924, Val Acc=0.7809\n",
      "Epoch 16: Train Loss=0.4845, Train Acc=0.7866 ||| Val Loss=0.4754, Val Acc=0.7930\n",
      "Epoch 17: Train Loss=0.4823, Train Acc=0.7869 ||| Val Loss=0.4796, Val Acc=0.7907\n",
      "Epoch 18: Train Loss=0.4814, Train Acc=0.7866 ||| Val Loss=0.4744, Val Acc=0.7924\n",
      "Epoch 19: Train Loss=0.4789, Train Acc=0.7853 ||| Val Loss=0.4720, Val Acc=0.7930\n",
      "Epoch 20: Train Loss=0.4790, Train Acc=0.7844 ||| Val Loss=0.4800, Val Acc=0.7987\n",
      "Epoch 21: Train Loss=0.4825, Train Acc=0.7867 ||| Val Loss=0.4724, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4761, Train Acc=0.7889 ||| Val Loss=0.4683, Val Acc=0.7999\n",
      "Epoch 23: Train Loss=0.4781, Train Acc=0.7846 ||| Val Loss=0.4715, Val Acc=0.7930\n",
      "Epoch 24: Train Loss=0.4703, Train Acc=0.7899 ||| Val Loss=0.4669, Val Acc=0.7918\n",
      "Epoch 25: Train Loss=0.4647, Train Acc=0.7879 ||| Val Loss=0.4920, Val Acc=0.7987\n",
      "Epoch 26: Train Loss=0.4668, Train Acc=0.7876 ||| Val Loss=0.4599, Val Acc=0.7953\n",
      "Epoch 27: Train Loss=0.4630, Train Acc=0.7859 ||| Val Loss=0.4515, Val Acc=0.7959\n",
      "Epoch 28: Train Loss=0.4645, Train Acc=0.7889 ||| Val Loss=0.4546, Val Acc=0.7918\n",
      "Epoch 29: Train Loss=0.4624, Train Acc=0.7908 ||| Val Loss=0.4597, Val Acc=0.7953\n",
      "Epoch 30: Train Loss=0.4704, Train Acc=0.7880 ||| Val Loss=0.4511, Val Acc=0.7970\n",
      "Epoch 31: Train Loss=0.4564, Train Acc=0.7882 ||| Val Loss=0.4589, Val Acc=0.7982\n",
      "Epoch 32: Train Loss=0.4598, Train Acc=0.7903 ||| Val Loss=0.4449, Val Acc=0.7959\n",
      "Epoch 33: Train Loss=0.4586, Train Acc=0.7908 ||| Val Loss=0.4569, Val Acc=0.7936\n",
      "Epoch 34: Train Loss=0.4593, Train Acc=0.7860 ||| Val Loss=0.4505, Val Acc=0.7993\n",
      "Epoch 35: Train Loss=0.4485, Train Acc=0.7900 ||| Val Loss=0.4499, Val Acc=0.8010\n",
      "Epoch 36: Train Loss=0.4477, Train Acc=0.7911 ||| Val Loss=0.4337, Val Acc=0.7959\n",
      "Epoch 37: Train Loss=0.4495, Train Acc=0.7905 ||| Val Loss=0.4394, Val Acc=0.7999\n",
      "Epoch 38: Train Loss=0.4459, Train Acc=0.7923 ||| Val Loss=0.4354, Val Acc=0.7993\n",
      "Epoch 39: Train Loss=0.4404, Train Acc=0.7942 ||| Val Loss=0.4384, Val Acc=0.7982\n",
      "Epoch 40: Train Loss=0.4409, Train Acc=0.7925 ||| Val Loss=0.4390, Val Acc=0.7953\n",
      "Epoch 41: Train Loss=0.4444, Train Acc=0.7873 ||| Val Loss=0.4335, Val Acc=0.7947\n",
      "Epoch 42: Train Loss=0.4452, Train Acc=0.7915 ||| Val Loss=0.4453, Val Acc=0.7895\n",
      "Epoch 43: Train Loss=0.4421, Train Acc=0.7932 ||| Val Loss=0.4398, Val Acc=0.7936\n",
      "Epoch 44: Train Loss=0.4363, Train Acc=0.7938 ||| Val Loss=0.4325, Val Acc=0.7964\n",
      "Epoch 45: Train Loss=0.4384, Train Acc=0.7925 ||| Val Loss=0.4346, Val Acc=0.7976\n",
      "Epoch 46: Train Loss=0.4344, Train Acc=0.7889 ||| Val Loss=0.4323, Val Acc=0.7964\n",
      "Epoch 47: Train Loss=0.4318, Train Acc=0.7911 ||| Val Loss=0.4277, Val Acc=0.7959\n",
      "Epoch 48: Train Loss=0.4295, Train Acc=0.7942 ||| Val Loss=0.4387, Val Acc=0.7867\n",
      "Epoch 49: Train Loss=0.4302, Train Acc=0.7909 ||| Val Loss=0.4337, Val Acc=0.7890\n",
      "Epoch 50: Train Loss=0.4326, Train Acc=0.7923 ||| Val Loss=0.4311, Val Acc=0.7982\n",
      "Epoch 51: Train Loss=0.4321, Train Acc=0.7926 ||| Val Loss=0.4302, Val Acc=0.7953\n",
      "Epoch 52: Train Loss=0.4364, Train Acc=0.7941 ||| Val Loss=0.4324, Val Acc=0.7982\n",
      "Epoch 53: Train Loss=0.4292, Train Acc=0.7949 ||| Val Loss=0.4279, Val Acc=0.7964\n",
      "Epoch 54: Train Loss=0.4296, Train Acc=0.7922 ||| Val Loss=0.4318, Val Acc=0.7999\n",
      "Epoch 55: Train Loss=0.4284, Train Acc=0.7947 ||| Val Loss=0.4252, Val Acc=0.7964\n",
      "Epoch 56: Train Loss=0.4277, Train Acc=0.7925 ||| Val Loss=0.4295, Val Acc=0.7930\n",
      "Epoch 57: Train Loss=0.4293, Train Acc=0.7912 ||| Val Loss=0.4289, Val Acc=0.7936\n",
      "Epoch 58: Train Loss=0.4261, Train Acc=0.7958 ||| Val Loss=0.4147, Val Acc=0.7947\n",
      "Epoch 59: Train Loss=0.4265, Train Acc=0.7961 ||| Val Loss=0.4243, Val Acc=0.7930\n",
      "Epoch 60: Train Loss=0.4235, Train Acc=0.7955 ||| Val Loss=0.4216, Val Acc=0.7959\n",
      "Epoch 61: Train Loss=0.4260, Train Acc=0.7928 ||| Val Loss=0.4235, Val Acc=0.7918\n",
      "Epoch 62: Train Loss=0.4232, Train Acc=0.7991 ||| Val Loss=0.4261, Val Acc=0.7901\n",
      "Epoch 63: Train Loss=0.4239, Train Acc=0.7929 ||| Val Loss=0.4292, Val Acc=0.7964\n",
      "Epoch 64: Train Loss=0.4215, Train Acc=0.7961 ||| Val Loss=0.4224, Val Acc=0.7895\n",
      "Epoch 65: Train Loss=0.4217, Train Acc=0.7948 ||| Val Loss=0.4279, Val Acc=0.7930\n",
      "Epoch 66: Train Loss=0.4181, Train Acc=0.7967 ||| Val Loss=0.4211, Val Acc=0.7947\n",
      "Epoch 67: Train Loss=0.4190, Train Acc=0.7971 ||| Val Loss=0.4201, Val Acc=0.7918\n",
      "Epoch 68: Train Loss=0.4183, Train Acc=0.7928 ||| Val Loss=0.4255, Val Acc=0.7901\n",
      "Epoch 69: Train Loss=0.4186, Train Acc=0.7971 ||| Val Loss=0.4167, Val Acc=0.7930\n",
      "Epoch 70: Train Loss=0.4191, Train Acc=0.7981 ||| Val Loss=0.4252, Val Acc=0.7861\n",
      "Epoch 71: Train Loss=0.4178, Train Acc=0.7935 ||| Val Loss=0.4185, Val Acc=0.7959\n",
      "Epoch 72: Train Loss=0.4197, Train Acc=0.7962 ||| Val Loss=0.4212, Val Acc=0.7982\n",
      "Epoch 73: Train Loss=0.4196, Train Acc=0.7954 ||| Val Loss=0.4217, Val Acc=0.7855\n",
      "Epoch 74: Train Loss=0.4153, Train Acc=0.7967 ||| Val Loss=0.4159, Val Acc=0.7890\n",
      "Epoch 75: Train Loss=0.4132, Train Acc=0.7948 ||| Val Loss=0.4209, Val Acc=0.7930\n",
      "Epoch 76: Train Loss=0.4158, Train Acc=0.7941 ||| Val Loss=0.4193, Val Acc=0.7878\n",
      "Epoch 77: Train Loss=0.4168, Train Acc=0.7958 ||| Val Loss=0.4136, Val Acc=0.7901\n",
      "Epoch 78: Train Loss=0.4134, Train Acc=0.8000 ||| Val Loss=0.4226, Val Acc=0.7982\n",
      "Epoch 79: Train Loss=0.4121, Train Acc=0.7997 ||| Val Loss=0.4103, Val Acc=0.7970\n",
      "Epoch 80: Train Loss=0.4135, Train Acc=0.7977 ||| Val Loss=0.4164, Val Acc=0.7964\n",
      "Epoch 81: Train Loss=0.4096, Train Acc=0.7964 ||| Val Loss=0.4175, Val Acc=0.7901\n",
      "Epoch 82: Train Loss=0.4089, Train Acc=0.8007 ||| Val Loss=0.4136, Val Acc=0.7964\n",
      "Epoch 83: Train Loss=0.4128, Train Acc=0.7962 ||| Val Loss=0.4191, Val Acc=0.7947\n",
      "Epoch 84: Train Loss=0.4117, Train Acc=0.8008 ||| Val Loss=0.4139, Val Acc=0.7907\n",
      "Epoch 85: Train Loss=0.4107, Train Acc=0.7967 ||| Val Loss=0.4154, Val Acc=0.7936\n",
      "Epoch 86: Train Loss=0.4160, Train Acc=0.7962 ||| Val Loss=0.4192, Val Acc=0.7953\n",
      "Epoch 87: Train Loss=0.4074, Train Acc=0.8001 ||| Val Loss=0.4158, Val Acc=0.7941\n",
      "Epoch 88: Train Loss=0.4086, Train Acc=0.8028 ||| Val Loss=0.4155, Val Acc=0.7936\n",
      "Epoch 89: Train Loss=0.4070, Train Acc=0.8011 ||| Val Loss=0.4106, Val Acc=0.7936\n",
      "Epoch 90: Train Loss=0.4105, Train Acc=0.8004 ||| Val Loss=0.4099, Val Acc=0.7930\n",
      "Epoch 91: Train Loss=0.4081, Train Acc=0.7987 ||| Val Loss=0.4175, Val Acc=0.7947\n",
      "Epoch 92: Train Loss=0.4076, Train Acc=0.7980 ||| Val Loss=0.4079, Val Acc=0.7930\n",
      "Epoch 93: Train Loss=0.4077, Train Acc=0.8004 ||| Val Loss=0.4125, Val Acc=0.7970\n",
      "Epoch 94: Train Loss=0.4086, Train Acc=0.8037 ||| Val Loss=0.4164, Val Acc=0.7890\n",
      "Epoch 95: Train Loss=0.4073, Train Acc=0.8041 ||| Val Loss=0.4166, Val Acc=0.7959\n",
      "Epoch 96: Train Loss=0.4086, Train Acc=0.7994 ||| Val Loss=0.4114, Val Acc=0.7924\n",
      "Epoch 97: Train Loss=0.4067, Train Acc=0.7995 ||| Val Loss=0.4124, Val Acc=0.8039\n",
      "Epoch 98: Train Loss=0.4083, Train Acc=0.8004 ||| Val Loss=0.4118, Val Acc=0.7907\n",
      "Epoch 99: Train Loss=0.4087, Train Acc=0.7970 ||| Val Loss=0.4164, Val Acc=0.7913\n",
      "Epoch 100: Train Loss=0.4033, Train Acc=0.8020 ||| Val Loss=0.4097, Val Acc=0.7918\n",
      "Epoch 101: Train Loss=0.4085, Train Acc=0.7991 ||| Val Loss=0.4096, Val Acc=0.7976\n",
      "Epoch 102: Train Loss=0.4070, Train Acc=0.8013 ||| Val Loss=0.4108, Val Acc=0.7993\n",
      "Epoch 103: Train Loss=0.4035, Train Acc=0.8021 ||| Val Loss=0.4098, Val Acc=0.7941\n",
      "Epoch 104: Train Loss=0.4057, Train Acc=0.7997 ||| Val Loss=0.4145, Val Acc=0.7976\n",
      "Epoch 105: Train Loss=0.4072, Train Acc=0.8027 ||| Val Loss=0.4153, Val Acc=0.7918\n",
      "Epoch 106: Train Loss=0.4036, Train Acc=0.8005 ||| Val Loss=0.4089, Val Acc=0.7901\n",
      "Epoch 107: Train Loss=0.4049, Train Acc=0.8020 ||| Val Loss=0.4138, Val Acc=0.7987\n",
      "Epoch 108: Train Loss=0.4027, Train Acc=0.8049 ||| Val Loss=0.4158, Val Acc=0.7970\n",
      "Epoch 109: Train Loss=0.4026, Train Acc=0.8014 ||| Val Loss=0.4095, Val Acc=0.8016\n",
      "Epoch 110: Train Loss=0.4028, Train Acc=0.8039 ||| Val Loss=0.4112, Val Acc=0.7987\n",
      "Epoch 111: Train Loss=0.4039, Train Acc=0.8003 ||| Val Loss=0.4110, Val Acc=0.7941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:25:45,540] Trial 44 finished with value: 0.7952846463484762 and parameters: {'n_blocks': 3, 'd_block': 128, 'k': 7, 'dropout': 0.14698338733891037, 'activation': 'ReLU', 'lr': 0.0020416279301639826, 'weight_decay': 5.4653696621886695e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: Train Loss=0.4033, Train Acc=0.8017 ||| Val Loss=0.4087, Val Acc=0.7953\n",
      "Early stopping triggered at epoch 112\n",
      "Validation Accuracy: 0.7953\n",
      "\n",
      " Trial 46 with params: {'n_blocks': 4, 'd_block': 128, 'k': 9, 'dropout': 0.19903942029752023, 'activation': 'ReLU', 'lr': 0.003389970772327613, 'weight_decay': 1.2052973692351311e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.9801, Train Acc=0.6763 ||| Val Loss=0.5230, Val Acc=0.7936\n",
      "Epoch 2: Train Loss=0.5403, Train Acc=0.7580 ||| Val Loss=0.4905, Val Acc=0.7930\n",
      "Epoch 3: Train Loss=0.5186, Train Acc=0.7729 ||| Val Loss=0.4998, Val Acc=0.7982\n",
      "Epoch 4: Train Loss=0.5105, Train Acc=0.7752 ||| Val Loss=0.5062, Val Acc=0.7895\n",
      "Epoch 5: Train Loss=0.4990, Train Acc=0.7826 ||| Val Loss=0.5023, Val Acc=0.7803\n",
      "Epoch 6: Train Loss=0.4908, Train Acc=0.7837 ||| Val Loss=0.4642, Val Acc=0.7936\n",
      "Epoch 7: Train Loss=0.4797, Train Acc=0.7846 ||| Val Loss=0.4523, Val Acc=0.7999\n",
      "Epoch 8: Train Loss=0.4680, Train Acc=0.7896 ||| Val Loss=0.4434, Val Acc=0.8016\n",
      "Epoch 9: Train Loss=0.4623, Train Acc=0.7888 ||| Val Loss=0.4425, Val Acc=0.7953\n",
      "Epoch 10: Train Loss=0.4567, Train Acc=0.7886 ||| Val Loss=0.4577, Val Acc=0.7878\n",
      "Epoch 11: Train Loss=0.4517, Train Acc=0.7872 ||| Val Loss=0.4524, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.4448, Train Acc=0.7873 ||| Val Loss=0.4397, Val Acc=0.7947\n",
      "Epoch 13: Train Loss=0.4424, Train Acc=0.7900 ||| Val Loss=0.4553, Val Acc=0.7826\n",
      "Epoch 14: Train Loss=0.4336, Train Acc=0.7921 ||| Val Loss=0.4285, Val Acc=0.7890\n",
      "Epoch 15: Train Loss=0.4295, Train Acc=0.7926 ||| Val Loss=0.4239, Val Acc=0.7930\n",
      "Epoch 16: Train Loss=0.4307, Train Acc=0.7934 ||| Val Loss=0.4189, Val Acc=0.7987\n",
      "Epoch 17: Train Loss=0.4293, Train Acc=0.7931 ||| Val Loss=0.4179, Val Acc=0.7982\n",
      "Epoch 18: Train Loss=0.4267, Train Acc=0.7892 ||| Val Loss=0.4289, Val Acc=0.7947\n",
      "Epoch 19: Train Loss=0.4245, Train Acc=0.7923 ||| Val Loss=0.4153, Val Acc=0.7930\n",
      "Epoch 20: Train Loss=0.4248, Train Acc=0.7932 ||| Val Loss=0.4139, Val Acc=0.7941\n",
      "Epoch 21: Train Loss=0.4258, Train Acc=0.7923 ||| Val Loss=0.4181, Val Acc=0.8022\n",
      "Epoch 22: Train Loss=0.4215, Train Acc=0.7905 ||| Val Loss=0.4174, Val Acc=0.7964\n",
      "Epoch 23: Train Loss=0.4226, Train Acc=0.7975 ||| Val Loss=0.4182, Val Acc=0.7964\n",
      "Epoch 24: Train Loss=0.4232, Train Acc=0.7962 ||| Val Loss=0.4137, Val Acc=0.7936\n",
      "Epoch 25: Train Loss=0.4207, Train Acc=0.7958 ||| Val Loss=0.4126, Val Acc=0.7964\n",
      "Epoch 26: Train Loss=0.4185, Train Acc=0.8008 ||| Val Loss=0.4199, Val Acc=0.7947\n",
      "Epoch 27: Train Loss=0.4185, Train Acc=0.7970 ||| Val Loss=0.4143, Val Acc=0.8005\n",
      "Epoch 28: Train Loss=0.4174, Train Acc=0.7968 ||| Val Loss=0.4161, Val Acc=0.8033\n",
      "Epoch 29: Train Loss=0.4204, Train Acc=0.7959 ||| Val Loss=0.4158, Val Acc=0.7941\n",
      "Epoch 30: Train Loss=0.4156, Train Acc=0.7981 ||| Val Loss=0.4127, Val Acc=0.8016\n",
      "Epoch 31: Train Loss=0.4190, Train Acc=0.7967 ||| Val Loss=0.4071, Val Acc=0.7976\n",
      "Epoch 32: Train Loss=0.4191, Train Acc=0.8010 ||| Val Loss=0.4113, Val Acc=0.7913\n",
      "Epoch 33: Train Loss=0.4182, Train Acc=0.7987 ||| Val Loss=0.4110, Val Acc=0.7993\n",
      "Epoch 34: Train Loss=0.4149, Train Acc=0.8013 ||| Val Loss=0.4095, Val Acc=0.8016\n",
      "Epoch 35: Train Loss=0.4158, Train Acc=0.7985 ||| Val Loss=0.4156, Val Acc=0.7987\n",
      "Epoch 36: Train Loss=0.4168, Train Acc=0.7988 ||| Val Loss=0.4124, Val Acc=0.7913\n",
      "Epoch 37: Train Loss=0.4158, Train Acc=0.7990 ||| Val Loss=0.4153, Val Acc=0.8051\n",
      "Epoch 38: Train Loss=0.4147, Train Acc=0.7978 ||| Val Loss=0.4078, Val Acc=0.7976\n",
      "Epoch 39: Train Loss=0.4132, Train Acc=0.8001 ||| Val Loss=0.4151, Val Acc=0.7878\n",
      "Epoch 40: Train Loss=0.4142, Train Acc=0.7997 ||| Val Loss=0.4081, Val Acc=0.8033\n",
      "Epoch 41: Train Loss=0.4131, Train Acc=0.8027 ||| Val Loss=0.4080, Val Acc=0.7913\n",
      "Epoch 42: Train Loss=0.4124, Train Acc=0.8000 ||| Val Loss=0.4069, Val Acc=0.7964\n",
      "Epoch 43: Train Loss=0.4123, Train Acc=0.7987 ||| Val Loss=0.4103, Val Acc=0.7959\n",
      "Epoch 44: Train Loss=0.4113, Train Acc=0.7988 ||| Val Loss=0.4103, Val Acc=0.7964\n",
      "Epoch 45: Train Loss=0.4132, Train Acc=0.8020 ||| Val Loss=0.4111, Val Acc=0.7901\n",
      "Epoch 46: Train Loss=0.4131, Train Acc=0.7985 ||| Val Loss=0.4144, Val Acc=0.7941\n",
      "Epoch 47: Train Loss=0.4102, Train Acc=0.8014 ||| Val Loss=0.4086, Val Acc=0.7976\n",
      "Epoch 48: Train Loss=0.4094, Train Acc=0.8041 ||| Val Loss=0.4127, Val Acc=0.7982\n",
      "Epoch 49: Train Loss=0.4099, Train Acc=0.8054 ||| Val Loss=0.4095, Val Acc=0.7987\n",
      "Epoch 50: Train Loss=0.4105, Train Acc=0.8060 ||| Val Loss=0.4076, Val Acc=0.7982\n",
      "Epoch 51: Train Loss=0.4089, Train Acc=0.8053 ||| Val Loss=0.4053, Val Acc=0.7970\n",
      "Epoch 52: Train Loss=0.4086, Train Acc=0.8074 ||| Val Loss=0.4108, Val Acc=0.7907\n",
      "Epoch 53: Train Loss=0.4048, Train Acc=0.8070 ||| Val Loss=0.4080, Val Acc=0.8028\n",
      "Epoch 54: Train Loss=0.4051, Train Acc=0.8076 ||| Val Loss=0.4124, Val Acc=0.8010\n",
      "Epoch 55: Train Loss=0.4071, Train Acc=0.8027 ||| Val Loss=0.4075, Val Acc=0.7999\n",
      "Epoch 56: Train Loss=0.4043, Train Acc=0.8041 ||| Val Loss=0.4168, Val Acc=0.7999\n",
      "Epoch 57: Train Loss=0.4056, Train Acc=0.8069 ||| Val Loss=0.4062, Val Acc=0.7999\n",
      "Epoch 58: Train Loss=0.4051, Train Acc=0.8069 ||| Val Loss=0.4137, Val Acc=0.7953\n",
      "Epoch 59: Train Loss=0.4090, Train Acc=0.8069 ||| Val Loss=0.4056, Val Acc=0.7999\n",
      "Epoch 60: Train Loss=0.4033, Train Acc=0.8070 ||| Val Loss=0.4134, Val Acc=0.8022\n",
      "Epoch 61: Train Loss=0.4075, Train Acc=0.8033 ||| Val Loss=0.4052, Val Acc=0.7976\n",
      "Epoch 62: Train Loss=0.4071, Train Acc=0.8043 ||| Val Loss=0.4063, Val Acc=0.8010\n",
      "Epoch 63: Train Loss=0.4020, Train Acc=0.8043 ||| Val Loss=0.4089, Val Acc=0.8056\n",
      "Epoch 64: Train Loss=0.4015, Train Acc=0.8112 ||| Val Loss=0.4079, Val Acc=0.7970\n",
      "Epoch 65: Train Loss=0.4031, Train Acc=0.8090 ||| Val Loss=0.4092, Val Acc=0.7993\n",
      "Epoch 66: Train Loss=0.4021, Train Acc=0.8096 ||| Val Loss=0.4165, Val Acc=0.7907\n",
      "Epoch 67: Train Loss=0.4017, Train Acc=0.8103 ||| Val Loss=0.4056, Val Acc=0.7982\n",
      "Epoch 68: Train Loss=0.4032, Train Acc=0.8087 ||| Val Loss=0.4181, Val Acc=0.8028\n",
      "Epoch 69: Train Loss=0.3999, Train Acc=0.8083 ||| Val Loss=0.4090, Val Acc=0.7901\n",
      "Epoch 70: Train Loss=0.4027, Train Acc=0.8086 ||| Val Loss=0.4086, Val Acc=0.8039\n",
      "Epoch 71: Train Loss=0.4020, Train Acc=0.8105 ||| Val Loss=0.4113, Val Acc=0.8085\n",
      "Epoch 72: Train Loss=0.3988, Train Acc=0.8106 ||| Val Loss=0.4177, Val Acc=0.7964\n",
      "Epoch 73: Train Loss=0.3998, Train Acc=0.8063 ||| Val Loss=0.4088, Val Acc=0.8010\n",
      "Epoch 74: Train Loss=0.4005, Train Acc=0.8063 ||| Val Loss=0.4062, Val Acc=0.7976\n",
      "Epoch 75: Train Loss=0.3966, Train Acc=0.8132 ||| Val Loss=0.4200, Val Acc=0.7987\n",
      "Epoch 76: Train Loss=0.3981, Train Acc=0.8133 ||| Val Loss=0.4116, Val Acc=0.7964\n",
      "Epoch 77: Train Loss=0.3993, Train Acc=0.8106 ||| Val Loss=0.4160, Val Acc=0.7999\n",
      "Epoch 78: Train Loss=0.3977, Train Acc=0.8125 ||| Val Loss=0.4136, Val Acc=0.7999\n",
      "Epoch 79: Train Loss=0.4007, Train Acc=0.8135 ||| Val Loss=0.4138, Val Acc=0.7970\n",
      "Epoch 80: Train Loss=0.3972, Train Acc=0.8099 ||| Val Loss=0.4149, Val Acc=0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:26:09,025] Trial 45 finished with value: 0.8050603795284647 and parameters: {'n_blocks': 4, 'd_block': 128, 'k': 9, 'dropout': 0.19903942029752023, 'activation': 'ReLU', 'lr': 0.003389970772327613, 'weight_decay': 1.2052973692351311e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train Loss=0.4007, Train Acc=0.8085 ||| Val Loss=0.4102, Val Acc=0.8051\n",
      "Early stopping triggered at epoch 81\n",
      "Validation Accuracy: 0.8051\n",
      "\n",
      " Trial 47 with params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.24359651545595912, 'activation': 'ReLU', 'lr': 0.005323721854063274, 'weight_decay': 3.296597682039308e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7175, Train Acc=0.6944 ||| Val Loss=0.5583, Val Acc=0.6929\n",
      "Epoch 2: Train Loss=0.5412, Train Acc=0.7573 ||| Val Loss=0.5082, Val Acc=0.7872\n",
      "Epoch 3: Train Loss=0.5206, Train Acc=0.7725 ||| Val Loss=0.5023, Val Acc=0.7844\n",
      "Epoch 4: Train Loss=0.5221, Train Acc=0.7738 ||| Val Loss=0.4895, Val Acc=0.7861\n",
      "Epoch 5: Train Loss=0.5046, Train Acc=0.7807 ||| Val Loss=0.5049, Val Acc=0.7895\n",
      "Epoch 6: Train Loss=0.5063, Train Acc=0.7790 ||| Val Loss=0.4690, Val Acc=0.7970\n",
      "Epoch 7: Train Loss=0.4952, Train Acc=0.7842 ||| Val Loss=0.4681, Val Acc=0.7947\n",
      "Epoch 8: Train Loss=0.4938, Train Acc=0.7839 ||| Val Loss=0.4791, Val Acc=0.7901\n",
      "Epoch 9: Train Loss=0.4828, Train Acc=0.7859 ||| Val Loss=0.4595, Val Acc=0.7953\n",
      "Epoch 10: Train Loss=0.4855, Train Acc=0.7879 ||| Val Loss=0.4689, Val Acc=0.7987\n",
      "Epoch 11: Train Loss=0.4773, Train Acc=0.7899 ||| Val Loss=0.4536, Val Acc=0.7976\n",
      "Epoch 12: Train Loss=0.4734, Train Acc=0.7875 ||| Val Loss=0.4709, Val Acc=0.7918\n",
      "Epoch 13: Train Loss=0.4724, Train Acc=0.7876 ||| Val Loss=0.4540, Val Acc=0.7976\n",
      "Epoch 14: Train Loss=0.4665, Train Acc=0.7892 ||| Val Loss=0.4477, Val Acc=0.7982\n",
      "Epoch 15: Train Loss=0.4709, Train Acc=0.7869 ||| Val Loss=0.4525, Val Acc=0.7913\n",
      "Epoch 16: Train Loss=0.4676, Train Acc=0.7853 ||| Val Loss=0.4447, Val Acc=0.7936\n",
      "Epoch 17: Train Loss=0.4576, Train Acc=0.7867 ||| Val Loss=0.4416, Val Acc=0.7993\n",
      "Epoch 18: Train Loss=0.4564, Train Acc=0.7921 ||| Val Loss=0.4493, Val Acc=0.8010\n",
      "Epoch 19: Train Loss=0.4506, Train Acc=0.7875 ||| Val Loss=0.4447, Val Acc=0.7941\n",
      "Epoch 20: Train Loss=0.4490, Train Acc=0.7919 ||| Val Loss=0.4321, Val Acc=0.7844\n",
      "Epoch 21: Train Loss=0.4485, Train Acc=0.7919 ||| Val Loss=0.4444, Val Acc=0.7821\n",
      "Epoch 22: Train Loss=0.4421, Train Acc=0.7889 ||| Val Loss=0.4225, Val Acc=0.7964\n",
      "Epoch 23: Train Loss=0.4447, Train Acc=0.7918 ||| Val Loss=0.4309, Val Acc=0.7970\n",
      "Epoch 24: Train Loss=0.4396, Train Acc=0.7869 ||| Val Loss=0.4239, Val Acc=0.7936\n",
      "Epoch 25: Train Loss=0.4396, Train Acc=0.7923 ||| Val Loss=0.4185, Val Acc=0.7976\n",
      "Epoch 26: Train Loss=0.4389, Train Acc=0.7913 ||| Val Loss=0.4229, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4381, Train Acc=0.7899 ||| Val Loss=0.4204, Val Acc=0.7976\n",
      "Epoch 28: Train Loss=0.4348, Train Acc=0.7926 ||| Val Loss=0.4223, Val Acc=0.7970\n",
      "Epoch 29: Train Loss=0.4276, Train Acc=0.7941 ||| Val Loss=0.4207, Val Acc=0.7993\n",
      "Epoch 30: Train Loss=0.4341, Train Acc=0.7934 ||| Val Loss=0.4209, Val Acc=0.7964\n",
      "Epoch 31: Train Loss=0.4299, Train Acc=0.7886 ||| Val Loss=0.4117, Val Acc=0.7907\n",
      "Epoch 32: Train Loss=0.4330, Train Acc=0.7949 ||| Val Loss=0.4145, Val Acc=0.7959\n",
      "Epoch 33: Train Loss=0.4245, Train Acc=0.7926 ||| Val Loss=0.4108, Val Acc=0.7953\n",
      "Epoch 34: Train Loss=0.4286, Train Acc=0.7926 ||| Val Loss=0.4098, Val Acc=0.7970\n",
      "Epoch 35: Train Loss=0.4269, Train Acc=0.7902 ||| Val Loss=0.4076, Val Acc=0.7964\n",
      "Epoch 36: Train Loss=0.4249, Train Acc=0.7951 ||| Val Loss=0.4127, Val Acc=0.7936\n",
      "Epoch 37: Train Loss=0.4271, Train Acc=0.7925 ||| Val Loss=0.4097, Val Acc=0.8010\n",
      "Epoch 38: Train Loss=0.4223, Train Acc=0.7938 ||| Val Loss=0.4063, Val Acc=0.8033\n",
      "Epoch 39: Train Loss=0.4227, Train Acc=0.7938 ||| Val Loss=0.4165, Val Acc=0.7964\n",
      "Epoch 40: Train Loss=0.4209, Train Acc=0.7936 ||| Val Loss=0.4128, Val Acc=0.7976\n",
      "Epoch 41: Train Loss=0.4223, Train Acc=0.7935 ||| Val Loss=0.4084, Val Acc=0.7982\n",
      "Epoch 42: Train Loss=0.4242, Train Acc=0.7959 ||| Val Loss=0.4167, Val Acc=0.7964\n",
      "Epoch 43: Train Loss=0.4208, Train Acc=0.7939 ||| Val Loss=0.4105, Val Acc=0.7999\n",
      "Epoch 44: Train Loss=0.4205, Train Acc=0.7890 ||| Val Loss=0.4136, Val Acc=0.7953\n",
      "Epoch 45: Train Loss=0.4180, Train Acc=0.7942 ||| Val Loss=0.4098, Val Acc=0.8028\n",
      "Epoch 46: Train Loss=0.4228, Train Acc=0.7863 ||| Val Loss=0.4051, Val Acc=0.7970\n",
      "Epoch 47: Train Loss=0.4210, Train Acc=0.7939 ||| Val Loss=0.4091, Val Acc=0.7953\n",
      "Epoch 48: Train Loss=0.4173, Train Acc=0.7985 ||| Val Loss=0.4098, Val Acc=0.8016\n",
      "Epoch 49: Train Loss=0.4202, Train Acc=0.7971 ||| Val Loss=0.4030, Val Acc=0.8033\n",
      "Epoch 50: Train Loss=0.4186, Train Acc=0.7995 ||| Val Loss=0.4050, Val Acc=0.7907\n",
      "Epoch 51: Train Loss=0.4204, Train Acc=0.7945 ||| Val Loss=0.4228, Val Acc=0.7936\n",
      "Epoch 52: Train Loss=0.4189, Train Acc=0.8008 ||| Val Loss=0.4149, Val Acc=0.7941\n",
      "Epoch 53: Train Loss=0.4234, Train Acc=0.7957 ||| Val Loss=0.4117, Val Acc=0.7976\n",
      "Epoch 54: Train Loss=0.4170, Train Acc=0.8000 ||| Val Loss=0.4194, Val Acc=0.7907\n",
      "Epoch 55: Train Loss=0.4175, Train Acc=0.7982 ||| Val Loss=0.4081, Val Acc=0.7964\n",
      "Epoch 56: Train Loss=0.4194, Train Acc=0.7974 ||| Val Loss=0.4021, Val Acc=0.7987\n",
      "Epoch 57: Train Loss=0.4187, Train Acc=0.7981 ||| Val Loss=0.4038, Val Acc=0.8016\n",
      "Epoch 58: Train Loss=0.4177, Train Acc=0.7977 ||| Val Loss=0.4124, Val Acc=0.7901\n",
      "Epoch 59: Train Loss=0.4139, Train Acc=0.8007 ||| Val Loss=0.4130, Val Acc=0.8005\n",
      "Epoch 60: Train Loss=0.4193, Train Acc=0.8031 ||| Val Loss=0.4173, Val Acc=0.7890\n",
      "Epoch 61: Train Loss=0.4188, Train Acc=0.8013 ||| Val Loss=0.4037, Val Acc=0.8005\n",
      "Epoch 62: Train Loss=0.4170, Train Acc=0.7984 ||| Val Loss=0.4083, Val Acc=0.7941\n",
      "Epoch 63: Train Loss=0.4196, Train Acc=0.8020 ||| Val Loss=0.4079, Val Acc=0.7987\n",
      "Epoch 64: Train Loss=0.4170, Train Acc=0.7997 ||| Val Loss=0.4114, Val Acc=0.7936\n",
      "Epoch 65: Train Loss=0.4166, Train Acc=0.8001 ||| Val Loss=0.4058, Val Acc=0.8039\n",
      "Epoch 66: Train Loss=0.4143, Train Acc=0.7995 ||| Val Loss=0.4089, Val Acc=0.7964\n",
      "Epoch 67: Train Loss=0.4135, Train Acc=0.7981 ||| Val Loss=0.4042, Val Acc=0.8056\n",
      "Epoch 68: Train Loss=0.4127, Train Acc=0.7995 ||| Val Loss=0.4016, Val Acc=0.7999\n",
      "Epoch 69: Train Loss=0.4153, Train Acc=0.7978 ||| Val Loss=0.4138, Val Acc=0.7993\n",
      "Epoch 70: Train Loss=0.4192, Train Acc=0.7972 ||| Val Loss=0.4191, Val Acc=0.8005\n",
      "Epoch 71: Train Loss=0.4155, Train Acc=0.8036 ||| Val Loss=0.4016, Val Acc=0.8028\n",
      "Epoch 72: Train Loss=0.4139, Train Acc=0.8053 ||| Val Loss=0.4051, Val Acc=0.7982\n",
      "Epoch 73: Train Loss=0.4108, Train Acc=0.8053 ||| Val Loss=0.4079, Val Acc=0.8005\n",
      "Epoch 74: Train Loss=0.4120, Train Acc=0.8023 ||| Val Loss=0.3998, Val Acc=0.8016\n",
      "Epoch 75: Train Loss=0.4157, Train Acc=0.8036 ||| Val Loss=0.4059, Val Acc=0.8010\n",
      "Epoch 76: Train Loss=0.4175, Train Acc=0.8005 ||| Val Loss=0.4030, Val Acc=0.8033\n",
      "Epoch 77: Train Loss=0.4134, Train Acc=0.8036 ||| Val Loss=0.4068, Val Acc=0.8028\n",
      "Epoch 78: Train Loss=0.4110, Train Acc=0.7998 ||| Val Loss=0.4004, Val Acc=0.8033\n",
      "Epoch 79: Train Loss=0.4082, Train Acc=0.8053 ||| Val Loss=0.4132, Val Acc=0.7901\n",
      "Epoch 80: Train Loss=0.4156, Train Acc=0.8004 ||| Val Loss=0.4059, Val Acc=0.8039\n",
      "Epoch 81: Train Loss=0.4130, Train Acc=0.8044 ||| Val Loss=0.4146, Val Acc=0.8028\n",
      "Epoch 82: Train Loss=0.4123, Train Acc=0.8041 ||| Val Loss=0.4083, Val Acc=0.7976\n",
      "Epoch 83: Train Loss=0.4187, Train Acc=0.7965 ||| Val Loss=0.4026, Val Acc=0.8028\n",
      "Epoch 84: Train Loss=0.4119, Train Acc=0.8016 ||| Val Loss=0.4038, Val Acc=0.7953\n",
      "Epoch 85: Train Loss=0.4139, Train Acc=0.8016 ||| Val Loss=0.4140, Val Acc=0.7993\n",
      "Epoch 86: Train Loss=0.4134, Train Acc=0.8041 ||| Val Loss=0.4027, Val Acc=0.7970\n",
      "Epoch 87: Train Loss=0.4118, Train Acc=0.8051 ||| Val Loss=0.4117, Val Acc=0.7895\n",
      "Epoch 88: Train Loss=0.4139, Train Acc=0.7967 ||| Val Loss=0.4043, Val Acc=0.7982\n",
      "Epoch 89: Train Loss=0.4132, Train Acc=0.8010 ||| Val Loss=0.4041, Val Acc=0.7987\n",
      "Epoch 90: Train Loss=0.4102, Train Acc=0.7987 ||| Val Loss=0.4036, Val Acc=0.8010\n",
      "Epoch 91: Train Loss=0.4067, Train Acc=0.8060 ||| Val Loss=0.4033, Val Acc=0.8010\n",
      "Epoch 92: Train Loss=0.4107, Train Acc=0.8027 ||| Val Loss=0.4028, Val Acc=0.7987\n",
      "Epoch 93: Train Loss=0.4127, Train Acc=0.8054 ||| Val Loss=0.4102, Val Acc=0.7941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:26:42,161] Trial 46 finished with value: 0.8067855089131685 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.24359651545595912, 'activation': 'ReLU', 'lr': 0.005323721854063274, 'weight_decay': 3.296597682039308e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss=0.4091, Train Acc=0.8082 ||| Val Loss=0.4022, Val Acc=0.8068\n",
      "Early stopping triggered at epoch 94\n",
      "Validation Accuracy: 0.8068\n",
      "\n",
      " Trial 48 with params: {'n_blocks': 5, 'd_block': 512, 'k': 10, 'dropout': 0.27763529693502553, 'activation': 'ReLU', 'lr': 0.005590800833258202, 'weight_decay': 2.9196429704611143e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.4735, Train Acc=0.6799 ||| Val Loss=0.5728, Val Acc=0.7780\n",
      "Epoch 2: Train Loss=0.5665, Train Acc=0.7449 ||| Val Loss=0.5273, Val Acc=0.7798\n",
      "Epoch 3: Train Loss=0.5511, Train Acc=0.7463 ||| Val Loss=0.5349, Val Acc=0.7970\n",
      "Epoch 4: Train Loss=0.5372, Train Acc=0.7632 ||| Val Loss=0.5066, Val Acc=0.7872\n",
      "Epoch 5: Train Loss=0.5364, Train Acc=0.7611 ||| Val Loss=0.5078, Val Acc=0.7775\n",
      "Epoch 6: Train Loss=0.5224, Train Acc=0.7734 ||| Val Loss=0.4972, Val Acc=0.7895\n",
      "Epoch 7: Train Loss=0.5323, Train Acc=0.7649 ||| Val Loss=0.5504, Val Acc=0.7826\n",
      "Epoch 8: Train Loss=0.5138, Train Acc=0.7773 ||| Val Loss=0.5704, Val Acc=0.6722\n",
      "Epoch 9: Train Loss=0.5049, Train Acc=0.7817 ||| Val Loss=0.4776, Val Acc=0.7982\n",
      "Epoch 10: Train Loss=0.4983, Train Acc=0.7821 ||| Val Loss=0.4783, Val Acc=0.7913\n",
      "Epoch 11: Train Loss=0.4919, Train Acc=0.7865 ||| Val Loss=0.4675, Val Acc=0.7987\n",
      "Epoch 12: Train Loss=0.4932, Train Acc=0.7817 ||| Val Loss=0.4755, Val Acc=0.7861\n",
      "Epoch 13: Train Loss=0.5048, Train Acc=0.7747 ||| Val Loss=0.4765, Val Acc=0.7924\n",
      "Epoch 14: Train Loss=0.4928, Train Acc=0.7842 ||| Val Loss=0.4820, Val Acc=0.7987\n",
      "Epoch 15: Train Loss=0.4956, Train Acc=0.7860 ||| Val Loss=0.4717, Val Acc=0.7964\n",
      "Epoch 16: Train Loss=0.4871, Train Acc=0.7892 ||| Val Loss=0.4707, Val Acc=0.7941\n",
      "Epoch 17: Train Loss=0.4861, Train Acc=0.7850 ||| Val Loss=0.4659, Val Acc=0.7976\n",
      "Epoch 18: Train Loss=0.4816, Train Acc=0.7873 ||| Val Loss=0.4660, Val Acc=0.7953\n",
      "Epoch 19: Train Loss=0.4784, Train Acc=0.7885 ||| Val Loss=0.4801, Val Acc=0.7953\n",
      "Epoch 20: Train Loss=0.4835, Train Acc=0.7875 ||| Val Loss=0.4649, Val Acc=0.7924\n",
      "Epoch 21: Train Loss=0.4788, Train Acc=0.7873 ||| Val Loss=0.4586, Val Acc=0.7970\n",
      "Epoch 22: Train Loss=0.4800, Train Acc=0.7889 ||| Val Loss=0.4560, Val Acc=0.7987\n",
      "Epoch 23: Train Loss=0.4723, Train Acc=0.7896 ||| Val Loss=0.4688, Val Acc=0.7970\n",
      "Epoch 24: Train Loss=0.4808, Train Acc=0.7860 ||| Val Loss=0.4642, Val Acc=0.7930\n",
      "Epoch 25: Train Loss=0.4745, Train Acc=0.7888 ||| Val Loss=0.4617, Val Acc=0.7982\n",
      "Epoch 26: Train Loss=0.4691, Train Acc=0.7909 ||| Val Loss=0.4562, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4718, Train Acc=0.7899 ||| Val Loss=0.4627, Val Acc=0.7913\n",
      "Epoch 28: Train Loss=0.4743, Train Acc=0.7903 ||| Val Loss=0.4591, Val Acc=0.7970\n",
      "Epoch 29: Train Loss=0.4710, Train Acc=0.7889 ||| Val Loss=0.4555, Val Acc=0.7970\n",
      "Epoch 30: Train Loss=0.4663, Train Acc=0.7916 ||| Val Loss=0.4672, Val Acc=0.7924\n",
      "Epoch 31: Train Loss=0.4751, Train Acc=0.7862 ||| Val Loss=0.4622, Val Acc=0.7976\n",
      "Epoch 32: Train Loss=0.4683, Train Acc=0.7913 ||| Val Loss=0.4581, Val Acc=0.7970\n",
      "Epoch 33: Train Loss=0.4665, Train Acc=0.7928 ||| Val Loss=0.4579, Val Acc=0.7993\n",
      "Epoch 34: Train Loss=0.4687, Train Acc=0.7915 ||| Val Loss=0.4585, Val Acc=0.7976\n",
      "Epoch 35: Train Loss=0.4685, Train Acc=0.7912 ||| Val Loss=0.4607, Val Acc=0.7947\n",
      "Epoch 36: Train Loss=0.4652, Train Acc=0.7922 ||| Val Loss=0.4583, Val Acc=0.7964\n",
      "Epoch 37: Train Loss=0.4636, Train Acc=0.7909 ||| Val Loss=0.4566, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4630, Train Acc=0.7915 ||| Val Loss=0.4557, Val Acc=0.7982\n",
      "Epoch 39: Train Loss=0.4644, Train Acc=0.7929 ||| Val Loss=0.4652, Val Acc=0.7999\n",
      "Epoch 40: Train Loss=0.4610, Train Acc=0.7918 ||| Val Loss=0.4540, Val Acc=0.7993\n",
      "Epoch 41: Train Loss=0.4652, Train Acc=0.7912 ||| Val Loss=0.4548, Val Acc=0.7993\n",
      "Epoch 42: Train Loss=0.4621, Train Acc=0.7913 ||| Val Loss=0.4602, Val Acc=0.7982\n",
      "Epoch 43: Train Loss=0.4726, Train Acc=0.7928 ||| Val Loss=0.4625, Val Acc=0.7964\n",
      "Epoch 44: Train Loss=0.4673, Train Acc=0.7908 ||| Val Loss=0.4617, Val Acc=0.7947\n",
      "Epoch 45: Train Loss=0.4621, Train Acc=0.7913 ||| Val Loss=0.4636, Val Acc=0.7976\n",
      "Epoch 46: Train Loss=0.4591, Train Acc=0.7945 ||| Val Loss=0.4619, Val Acc=0.7941\n",
      "Epoch 47: Train Loss=0.4619, Train Acc=0.7909 ||| Val Loss=0.4532, Val Acc=0.7941\n",
      "Epoch 48: Train Loss=0.4583, Train Acc=0.7912 ||| Val Loss=0.4678, Val Acc=0.7970\n",
      "Epoch 49: Train Loss=0.4634, Train Acc=0.7916 ||| Val Loss=0.4545, Val Acc=0.7964\n",
      "Epoch 50: Train Loss=0.4628, Train Acc=0.7915 ||| Val Loss=0.4668, Val Acc=0.7936\n",
      "Epoch 51: Train Loss=0.4576, Train Acc=0.7923 ||| Val Loss=0.4550, Val Acc=0.7953\n",
      "Epoch 52: Train Loss=0.4563, Train Acc=0.7896 ||| Val Loss=0.4565, Val Acc=0.7959\n",
      "Epoch 53: Train Loss=0.4612, Train Acc=0.7921 ||| Val Loss=0.4569, Val Acc=0.7941\n",
      "Epoch 54: Train Loss=0.4765, Train Acc=0.7913 ||| Val Loss=0.4481, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4600, Train Acc=0.7915 ||| Val Loss=0.4561, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4634, Train Acc=0.7916 ||| Val Loss=0.4569, Val Acc=0.7959\n",
      "Epoch 57: Train Loss=0.4590, Train Acc=0.7905 ||| Val Loss=0.4568, Val Acc=0.7964\n",
      "Epoch 58: Train Loss=0.4575, Train Acc=0.7939 ||| Val Loss=0.4538, Val Acc=0.7936\n",
      "Epoch 59: Train Loss=0.4588, Train Acc=0.7941 ||| Val Loss=0.4596, Val Acc=0.7936\n",
      "Epoch 60: Train Loss=0.4611, Train Acc=0.7915 ||| Val Loss=0.4530, Val Acc=0.7947\n",
      "Epoch 61: Train Loss=0.4589, Train Acc=0.7913 ||| Val Loss=0.4538, Val Acc=0.7959\n",
      "Epoch 62: Train Loss=0.4615, Train Acc=0.7913 ||| Val Loss=0.4596, Val Acc=0.7987\n",
      "Epoch 63: Train Loss=0.4576, Train Acc=0.7896 ||| Val Loss=0.4574, Val Acc=0.7936\n",
      "Epoch 64: Train Loss=0.4587, Train Acc=0.7925 ||| Val Loss=0.4561, Val Acc=0.7953\n",
      "Epoch 65: Train Loss=0.4642, Train Acc=0.7919 ||| Val Loss=0.4522, Val Acc=0.7982\n",
      "Epoch 66: Train Loss=0.4741, Train Acc=0.7898 ||| Val Loss=0.4864, Val Acc=0.7895\n",
      "Epoch 67: Train Loss=0.4703, Train Acc=0.7885 ||| Val Loss=0.4576, Val Acc=0.7953\n",
      "Epoch 68: Train Loss=0.4614, Train Acc=0.7888 ||| Val Loss=0.4586, Val Acc=0.7999\n",
      "Epoch 69: Train Loss=0.4548, Train Acc=0.7919 ||| Val Loss=0.4504, Val Acc=0.7953\n",
      "Epoch 70: Train Loss=0.4623, Train Acc=0.7899 ||| Val Loss=0.4543, Val Acc=0.8016\n",
      "Epoch 71: Train Loss=0.4587, Train Acc=0.7922 ||| Val Loss=0.4582, Val Acc=0.8016\n",
      "Epoch 72: Train Loss=0.4559, Train Acc=0.7906 ||| Val Loss=0.4599, Val Acc=0.7947\n",
      "Epoch 73: Train Loss=0.4724, Train Acc=0.7900 ||| Val Loss=0.4683, Val Acc=0.7936\n",
      "Epoch 74: Train Loss=0.4630, Train Acc=0.7913 ||| Val Loss=0.4469, Val Acc=0.7970\n",
      "Epoch 75: Train Loss=0.4534, Train Acc=0.7916 ||| Val Loss=0.4570, Val Acc=0.7987\n",
      "Epoch 76: Train Loss=0.4582, Train Acc=0.7921 ||| Val Loss=0.4641, Val Acc=0.7964\n",
      "Epoch 77: Train Loss=0.4574, Train Acc=0.7932 ||| Val Loss=0.4563, Val Acc=0.7970\n",
      "Epoch 78: Train Loss=0.4588, Train Acc=0.7913 ||| Val Loss=0.4583, Val Acc=0.7970\n",
      "Epoch 79: Train Loss=0.4568, Train Acc=0.7909 ||| Val Loss=0.4545, Val Acc=0.7970\n",
      "Epoch 80: Train Loss=0.4546, Train Acc=0.7942 ||| Val Loss=0.4581, Val Acc=0.7976\n",
      "Epoch 81: Train Loss=0.4691, Train Acc=0.7895 ||| Val Loss=0.4747, Val Acc=0.7930\n",
      "Epoch 82: Train Loss=0.4502, Train Acc=0.7895 ||| Val Loss=0.4413, Val Acc=0.7941\n",
      "Epoch 83: Train Loss=0.4343, Train Acc=0.7948 ||| Val Loss=0.4281, Val Acc=0.7924\n",
      "Epoch 84: Train Loss=0.4368, Train Acc=0.7918 ||| Val Loss=0.4371, Val Acc=0.7953\n",
      "Epoch 85: Train Loss=0.4351, Train Acc=0.7895 ||| Val Loss=0.4291, Val Acc=0.7890\n",
      "Epoch 86: Train Loss=0.4334, Train Acc=0.7903 ||| Val Loss=0.4536, Val Acc=0.7936\n",
      "Epoch 87: Train Loss=0.4290, Train Acc=0.7923 ||| Val Loss=0.4385, Val Acc=0.7953\n",
      "Epoch 88: Train Loss=0.4320, Train Acc=0.7935 ||| Val Loss=0.4287, Val Acc=0.7959\n",
      "Epoch 89: Train Loss=0.4273, Train Acc=0.7886 ||| Val Loss=0.4273, Val Acc=0.7953\n",
      "Epoch 90: Train Loss=0.4298, Train Acc=0.7951 ||| Val Loss=0.4173, Val Acc=0.7936\n",
      "Epoch 91: Train Loss=0.4294, Train Acc=0.7912 ||| Val Loss=0.4218, Val Acc=0.7964\n",
      "Epoch 92: Train Loss=0.4325, Train Acc=0.7915 ||| Val Loss=0.4208, Val Acc=0.7924\n",
      "Epoch 93: Train Loss=0.4293, Train Acc=0.7929 ||| Val Loss=0.4173, Val Acc=0.7930\n",
      "Epoch 94: Train Loss=0.4271, Train Acc=0.7900 ||| Val Loss=0.4207, Val Acc=0.7941\n",
      "Epoch 95: Train Loss=0.4274, Train Acc=0.7903 ||| Val Loss=0.4366, Val Acc=0.7947\n",
      "Epoch 96: Train Loss=0.4302, Train Acc=0.7938 ||| Val Loss=0.4168, Val Acc=0.7964\n",
      "Epoch 97: Train Loss=0.4245, Train Acc=0.7902 ||| Val Loss=0.4205, Val Acc=0.7947\n",
      "Epoch 98: Train Loss=0.4262, Train Acc=0.7906 ||| Val Loss=0.4188, Val Acc=0.7959\n",
      "Epoch 99: Train Loss=0.4247, Train Acc=0.7870 ||| Val Loss=0.4218, Val Acc=0.7959\n",
      "Epoch 100: Train Loss=0.4292, Train Acc=0.7888 ||| Val Loss=0.4214, Val Acc=0.7953\n",
      "Epoch 101: Train Loss=0.4274, Train Acc=0.7893 ||| Val Loss=0.4330, Val Acc=0.7895\n",
      "Epoch 102: Train Loss=0.4297, Train Acc=0.7908 ||| Val Loss=0.4170, Val Acc=0.7999\n",
      "Epoch 103: Train Loss=0.4240, Train Acc=0.7942 ||| Val Loss=0.4225, Val Acc=0.7976\n",
      "Epoch 104: Train Loss=0.4227, Train Acc=0.7913 ||| Val Loss=0.4217, Val Acc=0.7964\n",
      "Epoch 105: Train Loss=0.4287, Train Acc=0.7879 ||| Val Loss=0.4158, Val Acc=0.8010\n",
      "Epoch 106: Train Loss=0.4196, Train Acc=0.7936 ||| Val Loss=0.4149, Val Acc=0.7895\n",
      "Epoch 107: Train Loss=0.4176, Train Acc=0.7902 ||| Val Loss=0.4189, Val Acc=0.7953\n",
      "Epoch 108: Train Loss=0.4251, Train Acc=0.7921 ||| Val Loss=0.4166, Val Acc=0.7993\n",
      "Epoch 109: Train Loss=0.4239, Train Acc=0.7932 ||| Val Loss=0.4192, Val Acc=0.7999\n",
      "Epoch 110: Train Loss=0.4221, Train Acc=0.7896 ||| Val Loss=0.4190, Val Acc=0.7982\n",
      "Epoch 111: Train Loss=0.4227, Train Acc=0.7880 ||| Val Loss=0.4208, Val Acc=0.7959\n",
      "Epoch 112: Train Loss=0.4246, Train Acc=0.7951 ||| Val Loss=0.4190, Val Acc=0.7976\n",
      "Epoch 113: Train Loss=0.4244, Train Acc=0.7888 ||| Val Loss=0.4120, Val Acc=0.7959\n",
      "Epoch 114: Train Loss=0.4248, Train Acc=0.7912 ||| Val Loss=0.4191, Val Acc=0.7907\n",
      "Epoch 115: Train Loss=0.4339, Train Acc=0.7895 ||| Val Loss=0.4287, Val Acc=0.7936\n",
      "Epoch 116: Train Loss=0.4236, Train Acc=0.7938 ||| Val Loss=0.4189, Val Acc=0.7959\n",
      "Epoch 117: Train Loss=0.4258, Train Acc=0.7905 ||| Val Loss=0.4152, Val Acc=0.7941\n",
      "Epoch 118: Train Loss=0.4185, Train Acc=0.7915 ||| Val Loss=0.4201, Val Acc=0.7993\n",
      "Epoch 119: Train Loss=0.4239, Train Acc=0.7945 ||| Val Loss=0.4221, Val Acc=0.7993\n",
      "Epoch 120: Train Loss=0.4300, Train Acc=0.7866 ||| Val Loss=0.4202, Val Acc=0.7982\n",
      "Epoch 121: Train Loss=0.4202, Train Acc=0.7931 ||| Val Loss=0.4209, Val Acc=0.7982\n",
      "Epoch 122: Train Loss=0.4176, Train Acc=0.7900 ||| Val Loss=0.4182, Val Acc=0.7976\n",
      "Epoch 123: Train Loss=0.4311, Train Acc=0.7896 ||| Val Loss=0.4131, Val Acc=0.7982\n",
      "Epoch 124: Train Loss=0.4271, Train Acc=0.7895 ||| Val Loss=0.4242, Val Acc=0.7982\n",
      "Epoch 125: Train Loss=0.4245, Train Acc=0.7935 ||| Val Loss=0.4133, Val Acc=0.7987\n",
      "Epoch 126: Train Loss=0.4236, Train Acc=0.7911 ||| Val Loss=0.4255, Val Acc=0.8039\n",
      "Epoch 127: Train Loss=0.4256, Train Acc=0.7903 ||| Val Loss=0.4215, Val Acc=0.7999\n",
      "Epoch 128: Train Loss=0.4231, Train Acc=0.7916 ||| Val Loss=0.4179, Val Acc=0.7959\n",
      "Epoch 129: Train Loss=0.4230, Train Acc=0.7912 ||| Val Loss=0.4184, Val Acc=0.8022\n",
      "Epoch 130: Train Loss=0.4210, Train Acc=0.7911 ||| Val Loss=0.4213, Val Acc=0.7907\n",
      "Epoch 131: Train Loss=0.4371, Train Acc=0.7908 ||| Val Loss=0.4589, Val Acc=0.7964\n",
      "Epoch 132: Train Loss=0.4368, Train Acc=0.7905 ||| Val Loss=0.4279, Val Acc=0.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:29:17,956] Trial 47 finished with value: 0.7906843013225991 and parameters: {'n_blocks': 5, 'd_block': 512, 'k': 10, 'dropout': 0.27763529693502553, 'activation': 'ReLU', 'lr': 0.005590800833258202, 'weight_decay': 2.9196429704611143e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Train Loss=0.4303, Train Acc=0.7908 ||| Val Loss=0.4174, Val Acc=0.7907\n",
      "Early stopping triggered at epoch 133\n",
      "Validation Accuracy: 0.7907\n",
      "\n",
      " Trial 49 with params: {'n_blocks': 6, 'd_block': 128, 'k': 11, 'dropout': 0.24214223333962978, 'activation': 'GELU', 'lr': 0.0007105600562841395, 'weight_decay': 9.134999940592513e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.6737, Train Acc=0.6166 ||| Val Loss=0.5424, Val Acc=0.7677\n",
      "Epoch 2: Train Loss=0.5479, Train Acc=0.7446 ||| Val Loss=0.5256, Val Acc=0.7987\n",
      "Epoch 3: Train Loss=0.5301, Train Acc=0.7699 ||| Val Loss=0.5119, Val Acc=0.7987\n",
      "Epoch 4: Train Loss=0.5195, Train Acc=0.7757 ||| Val Loss=0.4976, Val Acc=0.7867\n",
      "Epoch 5: Train Loss=0.5082, Train Acc=0.7813 ||| Val Loss=0.4850, Val Acc=0.7982\n",
      "Epoch 6: Train Loss=0.5070, Train Acc=0.7830 ||| Val Loss=0.4876, Val Acc=0.7959\n",
      "Epoch 7: Train Loss=0.4988, Train Acc=0.7840 ||| Val Loss=0.4840, Val Acc=0.7930\n",
      "Epoch 8: Train Loss=0.4984, Train Acc=0.7813 ||| Val Loss=0.4932, Val Acc=0.7982\n",
      "Epoch 9: Train Loss=0.4926, Train Acc=0.7852 ||| Val Loss=0.4862, Val Acc=0.7930\n",
      "Epoch 10: Train Loss=0.4936, Train Acc=0.7856 ||| Val Loss=0.4775, Val Acc=0.7947\n",
      "Epoch 11: Train Loss=0.4918, Train Acc=0.7833 ||| Val Loss=0.4893, Val Acc=0.7907\n",
      "Epoch 12: Train Loss=0.4849, Train Acc=0.7831 ||| Val Loss=0.4758, Val Acc=0.7953\n",
      "Epoch 13: Train Loss=0.4806, Train Acc=0.7889 ||| Val Loss=0.4770, Val Acc=0.7941\n",
      "Epoch 14: Train Loss=0.4821, Train Acc=0.7859 ||| Val Loss=0.4777, Val Acc=0.7918\n",
      "Epoch 15: Train Loss=0.4810, Train Acc=0.7900 ||| Val Loss=0.4694, Val Acc=0.7913\n",
      "Epoch 16: Train Loss=0.4770, Train Acc=0.7872 ||| Val Loss=0.4700, Val Acc=0.7947\n",
      "Epoch 17: Train Loss=0.4749, Train Acc=0.7893 ||| Val Loss=0.4667, Val Acc=0.7964\n",
      "Epoch 18: Train Loss=0.4754, Train Acc=0.7882 ||| Val Loss=0.4644, Val Acc=0.7930\n",
      "Epoch 19: Train Loss=0.4716, Train Acc=0.7886 ||| Val Loss=0.4668, Val Acc=0.7976\n",
      "Epoch 20: Train Loss=0.4721, Train Acc=0.7908 ||| Val Loss=0.4670, Val Acc=0.7976\n",
      "Epoch 21: Train Loss=0.4672, Train Acc=0.7900 ||| Val Loss=0.4611, Val Acc=0.7970\n",
      "Epoch 22: Train Loss=0.4688, Train Acc=0.7877 ||| Val Loss=0.4598, Val Acc=0.7924\n",
      "Epoch 23: Train Loss=0.4626, Train Acc=0.7895 ||| Val Loss=0.4584, Val Acc=0.7976\n",
      "Epoch 24: Train Loss=0.4642, Train Acc=0.7896 ||| Val Loss=0.4556, Val Acc=0.7930\n",
      "Epoch 25: Train Loss=0.4609, Train Acc=0.7898 ||| Val Loss=0.4611, Val Acc=0.7970\n",
      "Epoch 26: Train Loss=0.4575, Train Acc=0.7905 ||| Val Loss=0.4522, Val Acc=0.7959\n",
      "Epoch 27: Train Loss=0.4551, Train Acc=0.7913 ||| Val Loss=0.4505, Val Acc=0.7987\n",
      "Epoch 28: Train Loss=0.4557, Train Acc=0.7903 ||| Val Loss=0.4484, Val Acc=0.7976\n",
      "Epoch 29: Train Loss=0.4524, Train Acc=0.7912 ||| Val Loss=0.4506, Val Acc=0.7999\n",
      "Epoch 30: Train Loss=0.4517, Train Acc=0.7889 ||| Val Loss=0.4456, Val Acc=0.8010\n",
      "Epoch 31: Train Loss=0.4510, Train Acc=0.7909 ||| Val Loss=0.4456, Val Acc=0.7959\n",
      "Epoch 32: Train Loss=0.4516, Train Acc=0.7916 ||| Val Loss=0.4451, Val Acc=0.7982\n",
      "Epoch 33: Train Loss=0.4478, Train Acc=0.7926 ||| Val Loss=0.4454, Val Acc=0.7953\n",
      "Epoch 34: Train Loss=0.4454, Train Acc=0.7939 ||| Val Loss=0.4594, Val Acc=0.7993\n",
      "Epoch 35: Train Loss=0.4476, Train Acc=0.7896 ||| Val Loss=0.4475, Val Acc=0.7947\n",
      "Epoch 36: Train Loss=0.4476, Train Acc=0.7912 ||| Val Loss=0.4436, Val Acc=0.7953\n",
      "Epoch 37: Train Loss=0.4446, Train Acc=0.7935 ||| Val Loss=0.4468, Val Acc=0.7947\n",
      "Epoch 38: Train Loss=0.4466, Train Acc=0.7925 ||| Val Loss=0.4444, Val Acc=0.7987\n",
      "Epoch 39: Train Loss=0.4428, Train Acc=0.7921 ||| Val Loss=0.4408, Val Acc=0.7970\n",
      "Epoch 40: Train Loss=0.4432, Train Acc=0.7921 ||| Val Loss=0.4442, Val Acc=0.7987\n",
      "Epoch 41: Train Loss=0.4415, Train Acc=0.7945 ||| Val Loss=0.4448, Val Acc=0.7930\n",
      "Epoch 42: Train Loss=0.4421, Train Acc=0.7922 ||| Val Loss=0.4453, Val Acc=0.7930\n",
      "Epoch 43: Train Loss=0.4416, Train Acc=0.7923 ||| Val Loss=0.4501, Val Acc=0.7941\n",
      "Epoch 44: Train Loss=0.4420, Train Acc=0.7931 ||| Val Loss=0.4424, Val Acc=0.7936\n",
      "Epoch 45: Train Loss=0.4400, Train Acc=0.7964 ||| Val Loss=0.4447, Val Acc=0.7947\n",
      "Epoch 46: Train Loss=0.4395, Train Acc=0.7922 ||| Val Loss=0.4478, Val Acc=0.7970\n",
      "Epoch 47: Train Loss=0.4398, Train Acc=0.7929 ||| Val Loss=0.4424, Val Acc=0.7924\n",
      "Epoch 48: Train Loss=0.4358, Train Acc=0.7949 ||| Val Loss=0.4425, Val Acc=0.7964\n",
      "Epoch 49: Train Loss=0.4346, Train Acc=0.7962 ||| Val Loss=0.4423, Val Acc=0.7959\n",
      "Epoch 50: Train Loss=0.4411, Train Acc=0.7922 ||| Val Loss=0.4454, Val Acc=0.7936\n",
      "Epoch 51: Train Loss=0.4419, Train Acc=0.7939 ||| Val Loss=0.4525, Val Acc=0.7901\n",
      "Epoch 52: Train Loss=0.4394, Train Acc=0.7938 ||| Val Loss=0.4458, Val Acc=0.7895\n",
      "Epoch 53: Train Loss=0.4375, Train Acc=0.7945 ||| Val Loss=0.4434, Val Acc=0.7941\n",
      "Epoch 54: Train Loss=0.4366, Train Acc=0.7944 ||| Val Loss=0.4440, Val Acc=0.7964\n",
      "Epoch 55: Train Loss=0.4359, Train Acc=0.7926 ||| Val Loss=0.4403, Val Acc=0.7936\n",
      "Epoch 56: Train Loss=0.4331, Train Acc=0.7906 ||| Val Loss=0.4446, Val Acc=0.7941\n",
      "Epoch 57: Train Loss=0.4349, Train Acc=0.7954 ||| Val Loss=0.4428, Val Acc=0.7959\n",
      "Epoch 58: Train Loss=0.4395, Train Acc=0.7915 ||| Val Loss=0.4436, Val Acc=0.7947\n",
      "Epoch 59: Train Loss=0.4392, Train Acc=0.7939 ||| Val Loss=0.4436, Val Acc=0.7924\n",
      "Epoch 60: Train Loss=0.4348, Train Acc=0.7944 ||| Val Loss=0.4432, Val Acc=0.7930\n",
      "Epoch 61: Train Loss=0.4357, Train Acc=0.7934 ||| Val Loss=0.4406, Val Acc=0.7953\n",
      "Epoch 62: Train Loss=0.4334, Train Acc=0.7932 ||| Val Loss=0.4423, Val Acc=0.7930\n",
      "Epoch 63: Train Loss=0.4367, Train Acc=0.7925 ||| Val Loss=0.4395, Val Acc=0.7895\n",
      "Epoch 64: Train Loss=0.4349, Train Acc=0.7962 ||| Val Loss=0.4387, Val Acc=0.7918\n",
      "Epoch 65: Train Loss=0.4357, Train Acc=0.7923 ||| Val Loss=0.4443, Val Acc=0.7953\n",
      "Epoch 66: Train Loss=0.4336, Train Acc=0.7938 ||| Val Loss=0.4430, Val Acc=0.7964\n",
      "Epoch 67: Train Loss=0.4361, Train Acc=0.7938 ||| Val Loss=0.4372, Val Acc=0.7941\n",
      "Epoch 68: Train Loss=0.4314, Train Acc=0.7926 ||| Val Loss=0.4443, Val Acc=0.7924\n",
      "Epoch 69: Train Loss=0.4349, Train Acc=0.7934 ||| Val Loss=0.4400, Val Acc=0.7901\n",
      "Epoch 70: Train Loss=0.4356, Train Acc=0.7945 ||| Val Loss=0.4487, Val Acc=0.7907\n",
      "Epoch 71: Train Loss=0.4359, Train Acc=0.7951 ||| Val Loss=0.4398, Val Acc=0.7895\n",
      "Epoch 72: Train Loss=0.4335, Train Acc=0.7944 ||| Val Loss=0.4428, Val Acc=0.7918\n",
      "Epoch 73: Train Loss=0.4320, Train Acc=0.7938 ||| Val Loss=0.4446, Val Acc=0.7924\n",
      "Epoch 74: Train Loss=0.4368, Train Acc=0.7951 ||| Val Loss=0.4418, Val Acc=0.7941\n",
      "Epoch 75: Train Loss=0.4364, Train Acc=0.7906 ||| Val Loss=0.4379, Val Acc=0.7936\n",
      "Epoch 76: Train Loss=0.4342, Train Acc=0.7968 ||| Val Loss=0.4433, Val Acc=0.7878\n",
      "Epoch 77: Train Loss=0.4346, Train Acc=0.7944 ||| Val Loss=0.4385, Val Acc=0.7959\n",
      "Epoch 78: Train Loss=0.4310, Train Acc=0.7962 ||| Val Loss=0.4451, Val Acc=0.7924\n",
      "Epoch 79: Train Loss=0.4322, Train Acc=0.7944 ||| Val Loss=0.4393, Val Acc=0.7936\n",
      "Epoch 80: Train Loss=0.4323, Train Acc=0.7941 ||| Val Loss=0.4417, Val Acc=0.7913\n",
      "Epoch 81: Train Loss=0.4310, Train Acc=0.7967 ||| Val Loss=0.4419, Val Acc=0.7936\n",
      "Epoch 82: Train Loss=0.4305, Train Acc=0.7954 ||| Val Loss=0.4410, Val Acc=0.7901\n",
      "Epoch 83: Train Loss=0.4327, Train Acc=0.7919 ||| Val Loss=0.4436, Val Acc=0.7890\n",
      "Epoch 84: Train Loss=0.4316, Train Acc=0.7938 ||| Val Loss=0.4397, Val Acc=0.7884\n",
      "Epoch 85: Train Loss=0.4335, Train Acc=0.7922 ||| Val Loss=0.4402, Val Acc=0.7947\n",
      "Epoch 86: Train Loss=0.4299, Train Acc=0.7957 ||| Val Loss=0.4426, Val Acc=0.7918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:29:57,685] Trial 48 finished with value: 0.7912593444508338 and parameters: {'n_blocks': 6, 'd_block': 128, 'k': 11, 'dropout': 0.24214223333962978, 'activation': 'GELU', 'lr': 0.0007105600562841395, 'weight_decay': 9.134999940592513e-05}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train Loss=0.4329, Train Acc=0.7980 ||| Val Loss=0.4451, Val Acc=0.7913\n",
      "Early stopping triggered at epoch 87\n",
      "Validation Accuracy: 0.7913\n",
      "\n",
      " Trial 50 with params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.34994928353452004, 'activation': 'ReLU', 'lr': 0.006338294096152983, 'weight_decay': 0.001276334155072742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),                   # learning rate (log scale)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21576\\1656162094.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2) # optimizer regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.7626, Train Acc=0.6923 ||| Val Loss=0.5103, Val Acc=0.7815\n",
      "Epoch 2: Train Loss=0.5301, Train Acc=0.7752 ||| Val Loss=0.4980, Val Acc=0.7913\n",
      "Epoch 3: Train Loss=0.5173, Train Acc=0.7791 ||| Val Loss=0.5021, Val Acc=0.7907\n",
      "Epoch 4: Train Loss=0.5181, Train Acc=0.7787 ||| Val Loss=0.4901, Val Acc=0.7907\n",
      "Epoch 5: Train Loss=0.5172, Train Acc=0.7791 ||| Val Loss=0.4970, Val Acc=0.7855\n",
      "Epoch 6: Train Loss=0.5246, Train Acc=0.7751 ||| Val Loss=0.4902, Val Acc=0.7913\n",
      "Epoch 7: Train Loss=0.5176, Train Acc=0.7787 ||| Val Loss=0.4977, Val Acc=0.7832\n",
      "Epoch 8: Train Loss=0.5210, Train Acc=0.7811 ||| Val Loss=0.5178, Val Acc=0.7872\n",
      "Epoch 9: Train Loss=0.5189, Train Acc=0.7771 ||| Val Loss=0.4955, Val Acc=0.7884\n",
      "Epoch 10: Train Loss=0.5169, Train Acc=0.7785 ||| Val Loss=0.4996, Val Acc=0.7867\n",
      "Epoch 11: Train Loss=0.5159, Train Acc=0.7775 ||| Val Loss=0.4863, Val Acc=0.7878\n",
      "Epoch 12: Train Loss=0.5185, Train Acc=0.7797 ||| Val Loss=0.4898, Val Acc=0.7878\n",
      "Epoch 13: Train Loss=0.5133, Train Acc=0.7803 ||| Val Loss=0.4907, Val Acc=0.7884\n",
      "Epoch 14: Train Loss=0.5110, Train Acc=0.7824 ||| Val Loss=0.4889, Val Acc=0.7901\n",
      "Epoch 15: Train Loss=0.5088, Train Acc=0.7816 ||| Val Loss=0.4999, Val Acc=0.7867\n",
      "Epoch 16: Train Loss=0.5159, Train Acc=0.7775 ||| Val Loss=0.4856, Val Acc=0.7895\n",
      "Epoch 17: Train Loss=0.5059, Train Acc=0.7826 ||| Val Loss=0.4873, Val Acc=0.7861\n",
      "Epoch 18: Train Loss=0.5069, Train Acc=0.7833 ||| Val Loss=0.4964, Val Acc=0.7890\n",
      "Epoch 19: Train Loss=0.5139, Train Acc=0.7781 ||| Val Loss=0.4802, Val Acc=0.7890\n",
      "Epoch 20: Train Loss=0.5069, Train Acc=0.7808 ||| Val Loss=0.4879, Val Acc=0.7907\n",
      "Epoch 21: Train Loss=0.5107, Train Acc=0.7778 ||| Val Loss=0.4851, Val Acc=0.7884\n",
      "Epoch 22: Train Loss=0.5103, Train Acc=0.7807 ||| Val Loss=0.4846, Val Acc=0.7901\n",
      "Epoch 23: Train Loss=0.5023, Train Acc=0.7819 ||| Val Loss=0.4834, Val Acc=0.7907\n",
      "Epoch 24: Train Loss=0.5037, Train Acc=0.7834 ||| Val Loss=0.4797, Val Acc=0.7890\n",
      "Epoch 25: Train Loss=0.5043, Train Acc=0.7807 ||| Val Loss=0.4798, Val Acc=0.7895\n",
      "Epoch 26: Train Loss=0.5047, Train Acc=0.7840 ||| Val Loss=0.4816, Val Acc=0.7895\n",
      "Epoch 27: Train Loss=0.4965, Train Acc=0.7824 ||| Val Loss=0.4810, Val Acc=0.7918\n",
      "Epoch 28: Train Loss=0.5046, Train Acc=0.7829 ||| Val Loss=0.4803, Val Acc=0.7913\n",
      "Epoch 29: Train Loss=0.5016, Train Acc=0.7821 ||| Val Loss=0.4775, Val Acc=0.7907\n",
      "Epoch 30: Train Loss=0.5082, Train Acc=0.7788 ||| Val Loss=0.4858, Val Acc=0.7924\n",
      "Epoch 31: Train Loss=0.5102, Train Acc=0.7823 ||| Val Loss=0.4758, Val Acc=0.7907\n",
      "Epoch 32: Train Loss=0.5011, Train Acc=0.7840 ||| Val Loss=0.4788, Val Acc=0.7901\n",
      "Epoch 33: Train Loss=0.5069, Train Acc=0.7862 ||| Val Loss=0.4911, Val Acc=0.7930\n",
      "Epoch 34: Train Loss=0.5012, Train Acc=0.7836 ||| Val Loss=0.4786, Val Acc=0.7890\n",
      "Epoch 35: Train Loss=0.5012, Train Acc=0.7840 ||| Val Loss=0.4757, Val Acc=0.7930\n",
      "Epoch 36: Train Loss=0.5041, Train Acc=0.7810 ||| Val Loss=0.4806, Val Acc=0.7918\n",
      "Epoch 37: Train Loss=0.5032, Train Acc=0.7856 ||| Val Loss=0.4781, Val Acc=0.7947\n",
      "Epoch 38: Train Loss=0.5142, Train Acc=0.7817 ||| Val Loss=0.4752, Val Acc=0.7918\n",
      "Epoch 39: Train Loss=0.5033, Train Acc=0.7857 ||| Val Loss=0.4719, Val Acc=0.7930\n",
      "Epoch 40: Train Loss=0.4976, Train Acc=0.7862 ||| Val Loss=0.4752, Val Acc=0.7924\n",
      "Epoch 41: Train Loss=0.4993, Train Acc=0.7859 ||| Val Loss=0.4803, Val Acc=0.7941\n",
      "Epoch 42: Train Loss=0.5051, Train Acc=0.7824 ||| Val Loss=0.4788, Val Acc=0.7918\n",
      "Epoch 43: Train Loss=0.5065, Train Acc=0.7814 ||| Val Loss=0.4863, Val Acc=0.7930\n",
      "Epoch 44: Train Loss=0.5066, Train Acc=0.7794 ||| Val Loss=0.4759, Val Acc=0.7907\n",
      "Epoch 45: Train Loss=0.5040, Train Acc=0.7886 ||| Val Loss=0.4814, Val Acc=0.7924\n",
      "Epoch 46: Train Loss=0.5021, Train Acc=0.7872 ||| Val Loss=0.4870, Val Acc=0.7913\n",
      "Epoch 47: Train Loss=0.5004, Train Acc=0.7785 ||| Val Loss=0.4843, Val Acc=0.7855\n",
      "Epoch 48: Train Loss=0.5048, Train Acc=0.7837 ||| Val Loss=0.4765, Val Acc=0.7901\n",
      "Epoch 49: Train Loss=0.5108, Train Acc=0.7852 ||| Val Loss=0.4841, Val Acc=0.7924\n",
      "Epoch 50: Train Loss=0.5031, Train Acc=0.7853 ||| Val Loss=0.4747, Val Acc=0.7913\n",
      "Epoch 51: Train Loss=0.5017, Train Acc=0.7860 ||| Val Loss=0.4796, Val Acc=0.7918\n",
      "Epoch 52: Train Loss=0.5005, Train Acc=0.7866 ||| Val Loss=0.4748, Val Acc=0.7930\n",
      "Epoch 53: Train Loss=0.4972, Train Acc=0.7852 ||| Val Loss=0.4748, Val Acc=0.7924\n",
      "Epoch 54: Train Loss=0.5045, Train Acc=0.7831 ||| Val Loss=0.4846, Val Acc=0.7901\n",
      "Epoch 55: Train Loss=0.5023, Train Acc=0.7844 ||| Val Loss=0.4788, Val Acc=0.7872\n",
      "Epoch 56: Train Loss=0.5041, Train Acc=0.7846 ||| Val Loss=0.4788, Val Acc=0.7918\n",
      "Epoch 57: Train Loss=0.5086, Train Acc=0.7836 ||| Val Loss=0.4853, Val Acc=0.7890\n",
      "Epoch 58: Train Loss=0.5049, Train Acc=0.7857 ||| Val Loss=0.4745, Val Acc=0.7930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 17:30:17,617] Trial 49 finished with value: 0.7924094307073031 and parameters: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.34994928353452004, 'activation': 'ReLU', 'lr': 0.006338294096152983, 'weight_decay': 0.001276334155072742}. Best is trial 30 with value: 0.8125359401955147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss=0.5121, Train Acc=0.7856 ||| Val Loss=0.4849, Val Acc=0.7924\n",
      "Early stopping triggered at epoch 59\n",
      "Validation Accuracy: 0.7924\n",
      "\n",
      "Best Trial Params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.27284433651928997, 'activation': 'ReLU', 'lr': 0.002029456931526584, 'weight_decay': 3.9033694841500456e-06}\n",
      "Best Validation Accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# how many hyperparameter combinations to try\n",
    "n_trials = 50\n",
    "\n",
    "# we define the objective function that Optuna will try to maximize\n",
    "def objective(trial):\n",
    "    # suggest a value for each hyperparameter\n",
    "    ## The parameter space based recommendations from: https://github.com/yandex-research/tabm/tree/main\n",
    "    params = {\n",
    "        'n_blocks': trial.suggest_int('n_blocks', 2, 6),\n",
    "        'd_block': trial.suggest_categorical('d_block', [128, 256, 512]),\n",
    "        'k': trial.suggest_int('k', 4, 12),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['ReLU', 'GELU', 'LeakyReLU']),\n",
    "        'lr': trial.suggest_loguniform('lr', 1e-4, 5e-2),\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n Trial {trial.number+1} with params: {params}\")\n",
    "\n",
    "    # train the model with the chosen parameters\n",
    "    model = run_tabm(**params)\n",
    "\n",
    "    # after we train, we evaluate the final val accuracy\n",
    "    model.eval()  # set model to eval mode. turns off dropout etc.\n",
    "\n",
    "    val_preds = []    # predictions\n",
    "    val_targets = []  # targets\n",
    "\n",
    "    with torch.no_grad():  # disables gradient tracking, faster\n",
    "        for xb, yb in val_loader:  # go over val batches\n",
    "            outputs = model(xb, None)  # forward pass\n",
    "            preds = outputs.mean(dim=1).argmax(dim=1)  # ensemble average, then pick predicted class\n",
    "            val_preds.append(preds)\n",
    "            val_targets.append(yb)\n",
    "\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "\n",
    "    val_acc = accuracy_score(val_targets.cpu(), val_preds.cpu())  # accuracy calculation\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    return val_acc  # optuna will try to maximize this\n",
    "\n",
    "\n",
    "# create a study object\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# save all results\n",
    "results = [(t.params, t.value) for t in study.trials]\n",
    "\n",
    "# best trial found\n",
    "print(f\"\\nBest Trial Params: {study.best_params}\")\n",
    "print(f\"Best Validation Accuracy: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ad1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 parameter combinations:\n",
      "1. Val Accuracy: 0.8125 | Params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.27284433651928997, 'activation': 'ReLU', 'lr': 0.002029456931526584, 'weight_decay': 3.9033694841500456e-06}\n",
      "2. Val Accuracy: 0.8097 | Params: {'n_blocks': 4, 'd_block': 128, 'k': 10, 'dropout': 0.15984630203331762, 'activation': 'ReLU', 'lr': 0.0014769364639454208, 'weight_decay': 9.200748737757358e-06}\n",
      "3. Val Accuracy: 0.8068 | Params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.22242292358131166, 'activation': 'ReLU', 'lr': 0.004070611397840372, 'weight_decay': 4.672432428590436e-06}\n",
      "4. Val Accuracy: 0.8068 | Params: {'n_blocks': 5, 'd_block': 128, 'k': 9, 'dropout': 0.24359651545595912, 'activation': 'ReLU', 'lr': 0.005323721854063274, 'weight_decay': 3.296597682039308e-05}\n",
      "5. Val Accuracy: 0.8062 | Params: {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.2256010105258364, 'activation': 'ReLU', 'lr': 0.003487671318826522, 'weight_decay': 6.9982025049786245e-06}\n"
     ]
    }
   ],
   "source": [
    "# sort the results based on performance and show best parameter combinations\n",
    "best_params = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 parameter combinations:\") # print the top 5 parameter combinations\n",
    "for i, (params, acc) in enumerate(best_params[:5], start=1):\n",
    "    print(f\"{i}. Val Accuracy: {acc:.4f} | Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abb2a0",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "- After 30 trials the best accuracy attained was 0.8125, which is on par/slightly worse than a tuned CatModel, but better than most of the ensemble models, but not quite as good as I expected, but we still have not trained the model on the full dataset which will likely increase it's accuracy.\n",
    "\n",
    "From here we train this model in preperation for the submssion on the full training set, and generate our predictions on the given test data and submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b09552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our parameters:  {'n_blocks': 5, 'd_block': 128, 'k': 10, 'dropout': 0.27284433651928997, 'activation': 'ReLU', 'lr': 0.002029456931526584, 'weight_decay': 3.9033694841500456e-06}\n",
      "\n",
      " ||| Fold number: 1 / 5 |||\n",
      "Epoch 1: Train Loss=0.9427, Train Acc=0.5552 ||| Val Loss=0.6188, Val Acc=0.7694\n",
      "Epoch 2: Train Loss=0.6125, Train Acc=0.6762 ||| Val Loss=0.5430, Val Acc=0.7499\n",
      "Epoch 3: Train Loss=0.5556, Train Acc=0.7327 ||| Val Loss=0.5254, Val Acc=0.7924\n",
      "Epoch 4: Train Loss=0.5386, Train Acc=0.7498 ||| Val Loss=0.5030, Val Acc=0.7964\n",
      "Epoch 5: Train Loss=0.5270, Train Acc=0.7529 ||| Val Loss=0.5024, Val Acc=0.7918\n",
      "Epoch 6: Train Loss=0.5208, Train Acc=0.7714 ||| Val Loss=0.4957, Val Acc=0.7999\n",
      "Epoch 7: Train Loss=0.5182, Train Acc=0.7741 ||| Val Loss=0.4906, Val Acc=0.7959\n",
      "Epoch 8: Train Loss=0.5059, Train Acc=0.7819 ||| Val Loss=0.4880, Val Acc=0.7970\n",
      "Epoch 9: Train Loss=0.5072, Train Acc=0.7787 ||| Val Loss=0.5041, Val Acc=0.7941\n",
      "Epoch 10: Train Loss=0.5073, Train Acc=0.7788 ||| Val Loss=0.4996, Val Acc=0.7890\n",
      "Epoch 11: Train Loss=0.4984, Train Acc=0.7814 ||| Val Loss=0.4948, Val Acc=0.7930\n",
      "Epoch 12: Train Loss=0.4960, Train Acc=0.7804 ||| Val Loss=0.4885, Val Acc=0.7959\n",
      "Epoch 13: Train Loss=0.4987, Train Acc=0.7860 ||| Val Loss=0.4917, Val Acc=0.7976\n",
      "Epoch 14: Train Loss=0.4900, Train Acc=0.7834 ||| Val Loss=0.4788, Val Acc=0.7947\n",
      "Epoch 15: Train Loss=0.4858, Train Acc=0.7857 ||| Val Loss=0.4731, Val Acc=0.7976\n",
      "Epoch 16: Train Loss=0.4849, Train Acc=0.7846 ||| Val Loss=0.4746, Val Acc=0.7964\n",
      "Epoch 17: Train Loss=0.4868, Train Acc=0.7847 ||| Val Loss=0.4702, Val Acc=0.7959\n",
      "Epoch 18: Train Loss=0.4758, Train Acc=0.7886 ||| Val Loss=0.4664, Val Acc=0.7976\n",
      "Epoch 19: Train Loss=0.4777, Train Acc=0.7857 ||| Val Loss=0.4696, Val Acc=0.7936\n",
      "Epoch 20: Train Loss=0.4716, Train Acc=0.7869 ||| Val Loss=0.4551, Val Acc=0.7987\n",
      "Epoch 21: Train Loss=0.4631, Train Acc=0.7860 ||| Val Loss=0.4486, Val Acc=0.7959\n",
      "Epoch 22: Train Loss=0.4652, Train Acc=0.7913 ||| Val Loss=0.4449, Val Acc=0.7936\n",
      "Epoch 23: Train Loss=0.4656, Train Acc=0.7860 ||| Val Loss=0.4636, Val Acc=0.7970\n",
      "Epoch 24: Train Loss=0.4539, Train Acc=0.7886 ||| Val Loss=0.4413, Val Acc=0.7970\n",
      "Epoch 25: Train Loss=0.4561, Train Acc=0.7866 ||| Val Loss=0.4377, Val Acc=0.8010\n",
      "Epoch 26: Train Loss=0.4521, Train Acc=0.7919 ||| Val Loss=0.4475, Val Acc=0.7999\n",
      "Epoch 27: Train Loss=0.4458, Train Acc=0.7888 ||| Val Loss=0.4357, Val Acc=0.8005\n",
      "Epoch 28: Train Loss=0.4447, Train Acc=0.7895 ||| Val Loss=0.4500, Val Acc=0.8022\n",
      "Epoch 29: Train Loss=0.4429, Train Acc=0.7903 ||| Val Loss=0.4351, Val Acc=0.7993\n",
      "Epoch 30: Train Loss=0.4496, Train Acc=0.7860 ||| Val Loss=0.4259, Val Acc=0.8028\n",
      "Epoch 31: Train Loss=0.4435, Train Acc=0.7918 ||| Val Loss=0.4369, Val Acc=0.8010\n",
      "Epoch 32: Train Loss=0.4399, Train Acc=0.7918 ||| Val Loss=0.4310, Val Acc=0.8062\n",
      "Epoch 33: Train Loss=0.4412, Train Acc=0.7862 ||| Val Loss=0.4299, Val Acc=0.8016\n",
      "Epoch 34: Train Loss=0.4352, Train Acc=0.7869 ||| Val Loss=0.4283, Val Acc=0.7941\n",
      "Epoch 35: Train Loss=0.4312, Train Acc=0.7895 ||| Val Loss=0.4205, Val Acc=0.7924\n",
      "Epoch 36: Train Loss=0.4351, Train Acc=0.7945 ||| Val Loss=0.4213, Val Acc=0.7947\n",
      "Epoch 37: Train Loss=0.4294, Train Acc=0.7916 ||| Val Loss=0.4220, Val Acc=0.7982\n",
      "Epoch 38: Train Loss=0.4269, Train Acc=0.7954 ||| Val Loss=0.4229, Val Acc=0.8016\n",
      "Epoch 39: Train Loss=0.4335, Train Acc=0.7918 ||| Val Loss=0.4251, Val Acc=0.7987\n",
      "Epoch 40: Train Loss=0.4281, Train Acc=0.7932 ||| Val Loss=0.4174, Val Acc=0.7999\n",
      "Epoch 41: Train Loss=0.4278, Train Acc=0.7936 ||| Val Loss=0.4191, Val Acc=0.8005\n",
      "Epoch 42: Train Loss=0.4239, Train Acc=0.7908 ||| Val Loss=0.4221, Val Acc=0.8005\n",
      "Epoch 43: Train Loss=0.4275, Train Acc=0.7965 ||| Val Loss=0.4197, Val Acc=0.8005\n",
      "Epoch 44: Train Loss=0.4257, Train Acc=0.7913 ||| Val Loss=0.4323, Val Acc=0.7999\n",
      "Epoch 45: Train Loss=0.4274, Train Acc=0.7898 ||| Val Loss=0.4163, Val Acc=0.7982\n",
      "Epoch 46: Train Loss=0.4250, Train Acc=0.7957 ||| Val Loss=0.4247, Val Acc=0.8016\n",
      "Epoch 47: Train Loss=0.4170, Train Acc=0.7932 ||| Val Loss=0.4209, Val Acc=0.8016\n",
      "Epoch 48: Train Loss=0.4263, Train Acc=0.7923 ||| Val Loss=0.4157, Val Acc=0.7953\n",
      "Epoch 49: Train Loss=0.4260, Train Acc=0.7928 ||| Val Loss=0.4161, Val Acc=0.7959\n",
      "Epoch 50: Train Loss=0.4192, Train Acc=0.7923 ||| Val Loss=0.4189, Val Acc=0.8010\n",
      "Epoch 51: Train Loss=0.4264, Train Acc=0.7935 ||| Val Loss=0.4129, Val Acc=0.8016\n",
      "Epoch 52: Train Loss=0.4262, Train Acc=0.7941 ||| Val Loss=0.4173, Val Acc=0.8028\n",
      "Epoch 53: Train Loss=0.4177, Train Acc=0.7985 ||| Val Loss=0.4196, Val Acc=0.8022\n",
      "Epoch 54: Train Loss=0.4190, Train Acc=0.7959 ||| Val Loss=0.4209, Val Acc=0.7993\n",
      "Epoch 55: Train Loss=0.4130, Train Acc=0.7981 ||| Val Loss=0.4156, Val Acc=0.8028\n",
      "Epoch 56: Train Loss=0.4196, Train Acc=0.7964 ||| Val Loss=0.4270, Val Acc=0.8062\n",
      "Epoch 57: Train Loss=0.4210, Train Acc=0.7980 ||| Val Loss=0.4146, Val Acc=0.8074\n",
      "Epoch 58: Train Loss=0.4186, Train Acc=0.7942 ||| Val Loss=0.4138, Val Acc=0.8074\n",
      "Epoch 59: Train Loss=0.4175, Train Acc=0.7993 ||| Val Loss=0.4110, Val Acc=0.8005\n",
      "Epoch 60: Train Loss=0.4159, Train Acc=0.8000 ||| Val Loss=0.4138, Val Acc=0.7993\n",
      "Epoch 61: Train Loss=0.4201, Train Acc=0.7970 ||| Val Loss=0.4126, Val Acc=0.8016\n",
      "Epoch 62: Train Loss=0.4174, Train Acc=0.8017 ||| Val Loss=0.4143, Val Acc=0.8051\n",
      "Epoch 63: Train Loss=0.4139, Train Acc=0.7987 ||| Val Loss=0.4137, Val Acc=0.8010\n",
      "Epoch 64: Train Loss=0.4165, Train Acc=0.7984 ||| Val Loss=0.4153, Val Acc=0.8051\n",
      "Epoch 65: Train Loss=0.4168, Train Acc=0.7980 ||| Val Loss=0.4133, Val Acc=0.8022\n",
      "Epoch 66: Train Loss=0.4140, Train Acc=0.8016 ||| Val Loss=0.4113, Val Acc=0.8033\n",
      "Epoch 67: Train Loss=0.4158, Train Acc=0.7991 ||| Val Loss=0.4169, Val Acc=0.8039\n",
      "Epoch 68: Train Loss=0.4171, Train Acc=0.7998 ||| Val Loss=0.4117, Val Acc=0.8062\n",
      "Epoch 69: Train Loss=0.4162, Train Acc=0.7993 ||| Val Loss=0.4155, Val Acc=0.7993\n",
      "Epoch 70: Train Loss=0.4139, Train Acc=0.7972 ||| Val Loss=0.4141, Val Acc=0.8091\n",
      "Epoch 71: Train Loss=0.4112, Train Acc=0.7993 ||| Val Loss=0.4125, Val Acc=0.8010\n",
      "Epoch 72: Train Loss=0.4165, Train Acc=0.8010 ||| Val Loss=0.4140, Val Acc=0.8056\n",
      "Epoch 73: Train Loss=0.4150, Train Acc=0.8005 ||| Val Loss=0.4092, Val Acc=0.8039\n",
      "Epoch 74: Train Loss=0.4140, Train Acc=0.8004 ||| Val Loss=0.4128, Val Acc=0.8051\n",
      "Epoch 75: Train Loss=0.4133, Train Acc=0.7955 ||| Val Loss=0.4124, Val Acc=0.8045\n",
      "Epoch 76: Train Loss=0.4133, Train Acc=0.8000 ||| Val Loss=0.4095, Val Acc=0.8045\n",
      "Epoch 77: Train Loss=0.4113, Train Acc=0.7984 ||| Val Loss=0.4147, Val Acc=0.8033\n",
      "Epoch 78: Train Loss=0.4102, Train Acc=0.7988 ||| Val Loss=0.4154, Val Acc=0.8016\n",
      "Epoch 79: Train Loss=0.4157, Train Acc=0.8000 ||| Val Loss=0.4116, Val Acc=0.8051\n",
      "Epoch 80: Train Loss=0.4118, Train Acc=0.7978 ||| Val Loss=0.4088, Val Acc=0.8005\n",
      "Epoch 81: Train Loss=0.4088, Train Acc=0.7995 ||| Val Loss=0.4111, Val Acc=0.8022\n",
      "Epoch 82: Train Loss=0.4117, Train Acc=0.7993 ||| Val Loss=0.4127, Val Acc=0.8022\n",
      "Epoch 83: Train Loss=0.4065, Train Acc=0.7977 ||| Val Loss=0.4098, Val Acc=0.8016\n",
      "Epoch 84: Train Loss=0.4134, Train Acc=0.7968 ||| Val Loss=0.4130, Val Acc=0.8033\n",
      "Epoch 85: Train Loss=0.4070, Train Acc=0.7958 ||| Val Loss=0.4150, Val Acc=0.8079\n",
      "Epoch 86: Train Loss=0.4065, Train Acc=0.8030 ||| Val Loss=0.4082, Val Acc=0.8074\n",
      "Epoch 87: Train Loss=0.4134, Train Acc=0.8034 ||| Val Loss=0.4097, Val Acc=0.8097\n",
      "Epoch 88: Train Loss=0.4148, Train Acc=0.8016 ||| Val Loss=0.4118, Val Acc=0.8039\n",
      "Epoch 89: Train Loss=0.4042, Train Acc=0.8041 ||| Val Loss=0.4087, Val Acc=0.8028\n",
      "Epoch 90: Train Loss=0.4037, Train Acc=0.8031 ||| Val Loss=0.4084, Val Acc=0.7987\n",
      "Epoch 91: Train Loss=0.4018, Train Acc=0.8014 ||| Val Loss=0.4095, Val Acc=0.8074\n",
      "Epoch 92: Train Loss=0.4040, Train Acc=0.8017 ||| Val Loss=0.4062, Val Acc=0.8062\n",
      "Epoch 93: Train Loss=0.4082, Train Acc=0.8008 ||| Val Loss=0.4087, Val Acc=0.8085\n",
      "Epoch 94: Train Loss=0.4079, Train Acc=0.8033 ||| Val Loss=0.4059, Val Acc=0.8108\n",
      "Epoch 95: Train Loss=0.4058, Train Acc=0.7988 ||| Val Loss=0.4074, Val Acc=0.8068\n",
      "Epoch 96: Train Loss=0.4060, Train Acc=0.8027 ||| Val Loss=0.4078, Val Acc=0.8028\n",
      "Epoch 97: Train Loss=0.4067, Train Acc=0.7997 ||| Val Loss=0.4056, Val Acc=0.8148\n",
      "Epoch 98: Train Loss=0.4046, Train Acc=0.7981 ||| Val Loss=0.4077, Val Acc=0.8091\n",
      "Epoch 99: Train Loss=0.4033, Train Acc=0.8018 ||| Val Loss=0.4117, Val Acc=0.8091\n",
      "Epoch 100: Train Loss=0.4057, Train Acc=0.8007 ||| Val Loss=0.4154, Val Acc=0.8079\n",
      "Epoch 101: Train Loss=0.4110, Train Acc=0.8030 ||| Val Loss=0.4091, Val Acc=0.8016\n",
      "Epoch 102: Train Loss=0.4049, Train Acc=0.8031 ||| Val Loss=0.4124, Val Acc=0.8102\n",
      "Epoch 103: Train Loss=0.4050, Train Acc=0.8004 ||| Val Loss=0.4077, Val Acc=0.8079\n",
      "Epoch 104: Train Loss=0.4006, Train Acc=0.8056 ||| Val Loss=0.4186, Val Acc=0.8074\n",
      "Epoch 105: Train Loss=0.4070, Train Acc=0.7993 ||| Val Loss=0.4103, Val Acc=0.8079\n",
      "Epoch 106: Train Loss=0.4066, Train Acc=0.8034 ||| Val Loss=0.4094, Val Acc=0.8108\n",
      "Epoch 107: Train Loss=0.4065, Train Acc=0.8031 ||| Val Loss=0.4119, Val Acc=0.8045\n",
      "Epoch 108: Train Loss=0.3987, Train Acc=0.8047 ||| Val Loss=0.4120, Val Acc=0.8010\n",
      "Epoch 109: Train Loss=0.4056, Train Acc=0.8044 ||| Val Loss=0.4123, Val Acc=0.8068\n",
      "Epoch 110: Train Loss=0.3983, Train Acc=0.8050 ||| Val Loss=0.4143, Val Acc=0.7907\n",
      "Epoch 111: Train Loss=0.4029, Train Acc=0.8083 ||| Val Loss=0.4128, Val Acc=0.8005\n",
      "Epoch 112: Train Loss=0.4017, Train Acc=0.8043 ||| Val Loss=0.4178, Val Acc=0.7976\n",
      "Epoch 113: Train Loss=0.3988, Train Acc=0.8092 ||| Val Loss=0.4133, Val Acc=0.7976\n",
      "Epoch 114: Train Loss=0.4046, Train Acc=0.8028 ||| Val Loss=0.4161, Val Acc=0.7936\n",
      "Epoch 115: Train Loss=0.3972, Train Acc=0.8063 ||| Val Loss=0.4101, Val Acc=0.7970\n",
      "Epoch 116: Train Loss=0.3932, Train Acc=0.8030 ||| Val Loss=0.4112, Val Acc=0.8045\n",
      "Epoch 117: Train Loss=0.4011, Train Acc=0.8039 ||| Val Loss=0.4128, Val Acc=0.8039\n",
      "Early stopping triggered at epoch 117\n",
      "Fold 1 Validation Accuracy: 0.8039\n",
      "\n",
      " ||| Fold number: 2 / 5 |||\n",
      "Epoch 1: Train Loss=0.9567, Train Acc=0.5729 ||| Val Loss=0.6066, Val Acc=0.7763\n",
      "Epoch 2: Train Loss=0.5902, Train Acc=0.6941 ||| Val Loss=0.5179, Val Acc=0.7826\n",
      "Epoch 3: Train Loss=0.5575, Train Acc=0.7439 ||| Val Loss=0.5121, Val Acc=0.7844\n",
      "Epoch 4: Train Loss=0.5388, Train Acc=0.7583 ||| Val Loss=0.5006, Val Acc=0.7901\n",
      "Epoch 5: Train Loss=0.5303, Train Acc=0.7620 ||| Val Loss=0.4966, Val Acc=0.7872\n",
      "Epoch 6: Train Loss=0.5215, Train Acc=0.7734 ||| Val Loss=0.4995, Val Acc=0.7803\n",
      "Epoch 7: Train Loss=0.5217, Train Acc=0.7764 ||| Val Loss=0.4967, Val Acc=0.7855\n",
      "Epoch 8: Train Loss=0.5121, Train Acc=0.7751 ||| Val Loss=0.4924, Val Acc=0.7838\n",
      "Epoch 9: Train Loss=0.5045, Train Acc=0.7817 ||| Val Loss=0.4960, Val Acc=0.7821\n",
      "Epoch 10: Train Loss=0.5073, Train Acc=0.7803 ||| Val Loss=0.4860, Val Acc=0.7849\n",
      "Epoch 11: Train Loss=0.4986, Train Acc=0.7860 ||| Val Loss=0.4841, Val Acc=0.7861\n",
      "Epoch 12: Train Loss=0.5015, Train Acc=0.7879 ||| Val Loss=0.4776, Val Acc=0.7844\n",
      "Epoch 13: Train Loss=0.4914, Train Acc=0.7856 ||| Val Loss=0.4784, Val Acc=0.7832\n",
      "Epoch 14: Train Loss=0.4881, Train Acc=0.7872 ||| Val Loss=0.4755, Val Acc=0.7872\n",
      "Epoch 15: Train Loss=0.4860, Train Acc=0.7883 ||| Val Loss=0.4637, Val Acc=0.7878\n",
      "Epoch 16: Train Loss=0.4852, Train Acc=0.7888 ||| Val Loss=0.4623, Val Acc=0.7872\n",
      "Epoch 17: Train Loss=0.4857, Train Acc=0.7918 ||| Val Loss=0.4811, Val Acc=0.7861\n",
      "Epoch 18: Train Loss=0.4848, Train Acc=0.7873 ||| Val Loss=0.4659, Val Acc=0.7855\n",
      "Epoch 19: Train Loss=0.4705, Train Acc=0.7885 ||| Val Loss=0.4632, Val Acc=0.7821\n",
      "Epoch 20: Train Loss=0.4728, Train Acc=0.7889 ||| Val Loss=0.4546, Val Acc=0.7832\n",
      "Epoch 21: Train Loss=0.4702, Train Acc=0.7931 ||| Val Loss=0.4593, Val Acc=0.7838\n",
      "Epoch 22: Train Loss=0.4595, Train Acc=0.7944 ||| Val Loss=0.4536, Val Acc=0.7849\n",
      "Epoch 23: Train Loss=0.4811, Train Acc=0.7912 ||| Val Loss=0.4611, Val Acc=0.7821\n",
      "Epoch 24: Train Loss=0.4651, Train Acc=0.7918 ||| Val Loss=0.4525, Val Acc=0.7815\n",
      "Epoch 25: Train Loss=0.4622, Train Acc=0.7893 ||| Val Loss=0.4528, Val Acc=0.7849\n",
      "Epoch 26: Train Loss=0.4522, Train Acc=0.7898 ||| Val Loss=0.4559, Val Acc=0.7844\n",
      "Epoch 27: Train Loss=0.4475, Train Acc=0.7957 ||| Val Loss=0.4391, Val Acc=0.7826\n",
      "Epoch 28: Train Loss=0.4511, Train Acc=0.7947 ||| Val Loss=0.4578, Val Acc=0.7424\n",
      "Epoch 29: Train Loss=0.4518, Train Acc=0.7949 ||| Val Loss=0.4404, Val Acc=0.7809\n",
      "Epoch 30: Train Loss=0.4375, Train Acc=0.7959 ||| Val Loss=0.4404, Val Acc=0.7815\n",
      "Epoch 31: Train Loss=0.4380, Train Acc=0.7955 ||| Val Loss=0.4484, Val Acc=0.7826\n",
      "Epoch 32: Train Loss=0.4388, Train Acc=0.7932 ||| Val Loss=0.4367, Val Acc=0.7809\n",
      "Epoch 33: Train Loss=0.4424, Train Acc=0.7971 ||| Val Loss=0.4370, Val Acc=0.7803\n",
      "Epoch 34: Train Loss=0.4295, Train Acc=0.7968 ||| Val Loss=0.4340, Val Acc=0.7855\n",
      "Epoch 35: Train Loss=0.4299, Train Acc=0.7961 ||| Val Loss=0.4337, Val Acc=0.7821\n",
      "Epoch 36: Train Loss=0.4279, Train Acc=0.7984 ||| Val Loss=0.4319, Val Acc=0.7844\n",
      "Epoch 37: Train Loss=0.4340, Train Acc=0.7993 ||| Val Loss=0.4313, Val Acc=0.7826\n",
      "Epoch 38: Train Loss=0.4392, Train Acc=0.7958 ||| Val Loss=0.4348, Val Acc=0.7803\n",
      "Epoch 39: Train Loss=0.4346, Train Acc=0.7955 ||| Val Loss=0.4341, Val Acc=0.7855\n",
      "Epoch 40: Train Loss=0.4368, Train Acc=0.7968 ||| Val Loss=0.4283, Val Acc=0.7861\n",
      "Epoch 41: Train Loss=0.4267, Train Acc=0.7972 ||| Val Loss=0.4237, Val Acc=0.7878\n",
      "Epoch 42: Train Loss=0.4371, Train Acc=0.7967 ||| Val Loss=0.4304, Val Acc=0.7838\n",
      "Epoch 43: Train Loss=0.4285, Train Acc=0.7982 ||| Val Loss=0.4295, Val Acc=0.7890\n",
      "Epoch 44: Train Loss=0.4235, Train Acc=0.7959 ||| Val Loss=0.4299, Val Acc=0.7901\n",
      "Epoch 45: Train Loss=0.4233, Train Acc=0.7993 ||| Val Loss=0.4356, Val Acc=0.7867\n",
      "Epoch 46: Train Loss=0.4214, Train Acc=0.7972 ||| Val Loss=0.4282, Val Acc=0.7821\n",
      "Epoch 47: Train Loss=0.4224, Train Acc=0.7968 ||| Val Loss=0.4282, Val Acc=0.7901\n",
      "Epoch 48: Train Loss=0.4212, Train Acc=0.7972 ||| Val Loss=0.4270, Val Acc=0.7867\n",
      "Epoch 49: Train Loss=0.4227, Train Acc=0.7938 ||| Val Loss=0.4290, Val Acc=0.7890\n",
      "Epoch 50: Train Loss=0.4193, Train Acc=0.8003 ||| Val Loss=0.4294, Val Acc=0.7930\n",
      "Epoch 51: Train Loss=0.4139, Train Acc=0.7978 ||| Val Loss=0.4297, Val Acc=0.7895\n",
      "Epoch 52: Train Loss=0.4176, Train Acc=0.7988 ||| Val Loss=0.4261, Val Acc=0.7913\n",
      "Epoch 53: Train Loss=0.4210, Train Acc=0.7971 ||| Val Loss=0.4267, Val Acc=0.7861\n",
      "Epoch 54: Train Loss=0.4175, Train Acc=0.7984 ||| Val Loss=0.4258, Val Acc=0.7867\n",
      "Epoch 55: Train Loss=0.4231, Train Acc=0.7982 ||| Val Loss=0.4298, Val Acc=0.7901\n",
      "Epoch 56: Train Loss=0.4111, Train Acc=0.7977 ||| Val Loss=0.4247, Val Acc=0.7872\n",
      "Epoch 57: Train Loss=0.4158, Train Acc=0.8011 ||| Val Loss=0.4272, Val Acc=0.7855\n",
      "Epoch 58: Train Loss=0.4163, Train Acc=0.8000 ||| Val Loss=0.4313, Val Acc=0.7890\n",
      "Epoch 59: Train Loss=0.4171, Train Acc=0.7990 ||| Val Loss=0.4262, Val Acc=0.7849\n",
      "Epoch 60: Train Loss=0.4137, Train Acc=0.7977 ||| Val Loss=0.4259, Val Acc=0.7913\n",
      "Epoch 61: Train Loss=0.4151, Train Acc=0.8021 ||| Val Loss=0.4276, Val Acc=0.7867\n",
      "Early stopping triggered at epoch 61\n",
      "Fold 2 Validation Accuracy: 0.7867\n",
      "\n",
      " ||| Fold number: 3 / 5 |||\n",
      "Epoch 1: Train Loss=0.9693, Train Acc=0.5693 ||| Val Loss=0.5761, Val Acc=0.7464\n",
      "Epoch 2: Train Loss=0.5925, Train Acc=0.6983 ||| Val Loss=0.5286, Val Acc=0.7803\n",
      "Epoch 3: Train Loss=0.5576, Train Acc=0.7337 ||| Val Loss=0.5223, Val Acc=0.7907\n",
      "Epoch 4: Train Loss=0.5474, Train Acc=0.7499 ||| Val Loss=0.5195, Val Acc=0.7953\n",
      "Epoch 5: Train Loss=0.5326, Train Acc=0.7624 ||| Val Loss=0.5057, Val Acc=0.7872\n",
      "Epoch 6: Train Loss=0.5321, Train Acc=0.7692 ||| Val Loss=0.5073, Val Acc=0.7936\n",
      "Epoch 7: Train Loss=0.5166, Train Acc=0.7692 ||| Val Loss=0.4982, Val Acc=0.7884\n",
      "Epoch 8: Train Loss=0.5126, Train Acc=0.7777 ||| Val Loss=0.4968, Val Acc=0.7918\n",
      "Epoch 9: Train Loss=0.5121, Train Acc=0.7800 ||| Val Loss=0.5077, Val Acc=0.7872\n",
      "Epoch 10: Train Loss=0.5020, Train Acc=0.7807 ||| Val Loss=0.4913, Val Acc=0.7895\n",
      "Epoch 11: Train Loss=0.5004, Train Acc=0.7824 ||| Val Loss=0.4891, Val Acc=0.7913\n",
      "Epoch 12: Train Loss=0.5005, Train Acc=0.7796 ||| Val Loss=0.4999, Val Acc=0.7924\n",
      "Epoch 13: Train Loss=0.4959, Train Acc=0.7800 ||| Val Loss=0.4839, Val Acc=0.7924\n",
      "Epoch 14: Train Loss=0.4909, Train Acc=0.7842 ||| Val Loss=0.4826, Val Acc=0.7936\n",
      "Epoch 15: Train Loss=0.4885, Train Acc=0.7831 ||| Val Loss=0.4855, Val Acc=0.7895\n",
      "Epoch 16: Train Loss=0.4907, Train Acc=0.7793 ||| Val Loss=0.4807, Val Acc=0.7913\n",
      "Epoch 17: Train Loss=0.4937, Train Acc=0.7816 ||| Val Loss=0.4799, Val Acc=0.7895\n",
      "Epoch 18: Train Loss=0.4841, Train Acc=0.7847 ||| Val Loss=0.4776, Val Acc=0.7930\n",
      "Epoch 19: Train Loss=0.4811, Train Acc=0.7879 ||| Val Loss=0.4878, Val Acc=0.7907\n",
      "Epoch 20: Train Loss=0.4822, Train Acc=0.7842 ||| Val Loss=0.4642, Val Acc=0.7953\n",
      "Epoch 21: Train Loss=0.4720, Train Acc=0.7863 ||| Val Loss=0.4728, Val Acc=0.7890\n",
      "Epoch 22: Train Loss=0.4708, Train Acc=0.7844 ||| Val Loss=0.4563, Val Acc=0.7930\n",
      "Epoch 23: Train Loss=0.4637, Train Acc=0.7870 ||| Val Loss=0.4538, Val Acc=0.7930\n",
      "Epoch 24: Train Loss=0.4628, Train Acc=0.7863 ||| Val Loss=0.4467, Val Acc=0.7970\n",
      "Epoch 25: Train Loss=0.4483, Train Acc=0.7882 ||| Val Loss=0.4427, Val Acc=0.7970\n",
      "Epoch 26: Train Loss=0.4621, Train Acc=0.7872 ||| Val Loss=0.4395, Val Acc=0.7964\n",
      "Epoch 27: Train Loss=0.4498, Train Acc=0.7875 ||| Val Loss=0.4377, Val Acc=0.7987\n",
      "Epoch 28: Train Loss=0.4449, Train Acc=0.7916 ||| Val Loss=0.4389, Val Acc=0.7999\n",
      "Epoch 29: Train Loss=0.4490, Train Acc=0.7911 ||| Val Loss=0.4367, Val Acc=0.7987\n",
      "Epoch 30: Train Loss=0.4419, Train Acc=0.7908 ||| Val Loss=0.4359, Val Acc=0.8005\n",
      "Epoch 31: Train Loss=0.4404, Train Acc=0.7926 ||| Val Loss=0.4399, Val Acc=0.8022\n",
      "Epoch 32: Train Loss=0.4409, Train Acc=0.7898 ||| Val Loss=0.4335, Val Acc=0.7976\n",
      "Epoch 33: Train Loss=0.4430, Train Acc=0.7938 ||| Val Loss=0.4329, Val Acc=0.7993\n",
      "Epoch 34: Train Loss=0.4360, Train Acc=0.7898 ||| Val Loss=0.4269, Val Acc=0.7999\n",
      "Epoch 35: Train Loss=0.4308, Train Acc=0.7921 ||| Val Loss=0.4254, Val Acc=0.7976\n",
      "Epoch 36: Train Loss=0.4325, Train Acc=0.7915 ||| Val Loss=0.4316, Val Acc=0.7982\n",
      "Epoch 37: Train Loss=0.4345, Train Acc=0.7934 ||| Val Loss=0.4279, Val Acc=0.7930\n",
      "Epoch 38: Train Loss=0.4346, Train Acc=0.7860 ||| Val Loss=0.4207, Val Acc=0.8010\n",
      "Epoch 39: Train Loss=0.4324, Train Acc=0.7916 ||| Val Loss=0.4311, Val Acc=0.7987\n",
      "Epoch 40: Train Loss=0.4354, Train Acc=0.7908 ||| Val Loss=0.4308, Val Acc=0.7947\n",
      "Epoch 41: Train Loss=0.4298, Train Acc=0.7913 ||| Val Loss=0.4264, Val Acc=0.8005\n",
      "Epoch 42: Train Loss=0.4213, Train Acc=0.7934 ||| Val Loss=0.4254, Val Acc=0.7993\n",
      "Epoch 43: Train Loss=0.4221, Train Acc=0.7928 ||| Val Loss=0.4272, Val Acc=0.8039\n",
      "Epoch 44: Train Loss=0.4272, Train Acc=0.7932 ||| Val Loss=0.4232, Val Acc=0.7918\n",
      "Epoch 45: Train Loss=0.4181, Train Acc=0.7922 ||| Val Loss=0.4196, Val Acc=0.7964\n",
      "Epoch 46: Train Loss=0.4263, Train Acc=0.7921 ||| Val Loss=0.4214, Val Acc=0.8005\n",
      "Epoch 47: Train Loss=0.4210, Train Acc=0.7939 ||| Val Loss=0.4220, Val Acc=0.7987\n",
      "Epoch 48: Train Loss=0.4160, Train Acc=0.7954 ||| Val Loss=0.4213, Val Acc=0.8033\n",
      "Epoch 49: Train Loss=0.4193, Train Acc=0.7906 ||| Val Loss=0.4235, Val Acc=0.7993\n",
      "Epoch 50: Train Loss=0.4256, Train Acc=0.7912 ||| Val Loss=0.4315, Val Acc=0.7976\n",
      "Epoch 51: Train Loss=0.4229, Train Acc=0.7923 ||| Val Loss=0.4317, Val Acc=0.7947\n",
      "Epoch 52: Train Loss=0.4194, Train Acc=0.7932 ||| Val Loss=0.4199, Val Acc=0.7976\n",
      "Epoch 53: Train Loss=0.4191, Train Acc=0.7962 ||| Val Loss=0.4202, Val Acc=0.8005\n",
      "Epoch 54: Train Loss=0.4178, Train Acc=0.7939 ||| Val Loss=0.4182, Val Acc=0.7993\n",
      "Epoch 55: Train Loss=0.4180, Train Acc=0.7980 ||| Val Loss=0.4256, Val Acc=0.8010\n",
      "Epoch 56: Train Loss=0.4168, Train Acc=0.7935 ||| Val Loss=0.4251, Val Acc=0.7993\n",
      "Epoch 57: Train Loss=0.4200, Train Acc=0.7922 ||| Val Loss=0.4250, Val Acc=0.8039\n",
      "Epoch 58: Train Loss=0.4140, Train Acc=0.7948 ||| Val Loss=0.4225, Val Acc=0.7999\n",
      "Epoch 59: Train Loss=0.4212, Train Acc=0.7984 ||| Val Loss=0.4218, Val Acc=0.7964\n",
      "Epoch 60: Train Loss=0.4161, Train Acc=0.7958 ||| Val Loss=0.4175, Val Acc=0.8028\n",
      "Epoch 61: Train Loss=0.4198, Train Acc=0.7974 ||| Val Loss=0.4316, Val Acc=0.7987\n",
      "Epoch 62: Train Loss=0.4171, Train Acc=0.7962 ||| Val Loss=0.4203, Val Acc=0.8005\n",
      "Epoch 63: Train Loss=0.4100, Train Acc=0.7954 ||| Val Loss=0.4180, Val Acc=0.7987\n",
      "Epoch 64: Train Loss=0.4129, Train Acc=0.7967 ||| Val Loss=0.4184, Val Acc=0.7999\n",
      "Epoch 65: Train Loss=0.4122, Train Acc=0.7947 ||| Val Loss=0.4222, Val Acc=0.8010\n",
      "Epoch 66: Train Loss=0.4137, Train Acc=0.7988 ||| Val Loss=0.4215, Val Acc=0.7982\n",
      "Epoch 67: Train Loss=0.4106, Train Acc=0.7985 ||| Val Loss=0.4199, Val Acc=0.8045\n",
      "Epoch 68: Train Loss=0.4142, Train Acc=0.7974 ||| Val Loss=0.4209, Val Acc=0.7999\n",
      "Epoch 69: Train Loss=0.4172, Train Acc=0.7952 ||| Val Loss=0.4191, Val Acc=0.7993\n",
      "Epoch 70: Train Loss=0.4131, Train Acc=0.7955 ||| Val Loss=0.4209, Val Acc=0.7982\n",
      "Epoch 71: Train Loss=0.4145, Train Acc=0.7985 ||| Val Loss=0.4204, Val Acc=0.7999\n",
      "Epoch 72: Train Loss=0.4106, Train Acc=0.8001 ||| Val Loss=0.4182, Val Acc=0.7970\n",
      "Epoch 73: Train Loss=0.4144, Train Acc=0.7968 ||| Val Loss=0.4204, Val Acc=0.7964\n",
      "Epoch 74: Train Loss=0.4096, Train Acc=0.7949 ||| Val Loss=0.4187, Val Acc=0.7970\n",
      "Epoch 75: Train Loss=0.4068, Train Acc=0.7975 ||| Val Loss=0.4197, Val Acc=0.8022\n",
      "Epoch 76: Train Loss=0.4087, Train Acc=0.7975 ||| Val Loss=0.4227, Val Acc=0.7953\n",
      "Epoch 77: Train Loss=0.4153, Train Acc=0.7994 ||| Val Loss=0.4202, Val Acc=0.8028\n",
      "Epoch 78: Train Loss=0.4083, Train Acc=0.8008 ||| Val Loss=0.4209, Val Acc=0.7947\n",
      "Epoch 79: Train Loss=0.4129, Train Acc=0.7959 ||| Val Loss=0.4263, Val Acc=0.7993\n",
      "Epoch 80: Train Loss=0.4060, Train Acc=0.7982 ||| Val Loss=0.4218, Val Acc=0.8005\n",
      "Early stopping triggered at epoch 80\n",
      "Fold 3 Validation Accuracy: 0.8005\n",
      "\n",
      " ||| Fold number: 4 / 5 |||\n",
      "Epoch 1: Train Loss=1.0220, Train Acc=0.5587 ||| Val Loss=0.6237, Val Acc=0.6818\n",
      "Epoch 2: Train Loss=0.6108, Train Acc=0.6539 ||| Val Loss=0.5200, Val Acc=0.7854\n",
      "Epoch 3: Train Loss=0.5597, Train Acc=0.7298 ||| Val Loss=0.5141, Val Acc=0.7768\n",
      "Epoch 4: Train Loss=0.5422, Train Acc=0.7478 ||| Val Loss=0.5011, Val Acc=0.7917\n",
      "Epoch 5: Train Loss=0.5303, Train Acc=0.7687 ||| Val Loss=0.5030, Val Acc=0.7877\n",
      "Epoch 6: Train Loss=0.5243, Train Acc=0.7730 ||| Val Loss=0.5027, Val Acc=0.7992\n",
      "Epoch 7: Train Loss=0.5215, Train Acc=0.7743 ||| Val Loss=0.4905, Val Acc=0.7952\n",
      "Epoch 8: Train Loss=0.5165, Train Acc=0.7740 ||| Val Loss=0.5109, Val Acc=0.7848\n",
      "Epoch 9: Train Loss=0.5031, Train Acc=0.7861 ||| Val Loss=0.4863, Val Acc=0.7980\n",
      "Epoch 10: Train Loss=0.4941, Train Acc=0.7849 ||| Val Loss=0.4782, Val Acc=0.7934\n",
      "Epoch 11: Train Loss=0.4984, Train Acc=0.7825 ||| Val Loss=0.4803, Val Acc=0.7946\n",
      "Epoch 12: Train Loss=0.4951, Train Acc=0.7830 ||| Val Loss=0.4754, Val Acc=0.7888\n",
      "Epoch 13: Train Loss=0.4885, Train Acc=0.7853 ||| Val Loss=0.4903, Val Acc=0.7883\n",
      "Epoch 14: Train Loss=0.4899, Train Acc=0.7835 ||| Val Loss=0.5100, Val Acc=0.7894\n",
      "Epoch 15: Train Loss=0.4993, Train Acc=0.7786 ||| Val Loss=0.4665, Val Acc=0.7975\n",
      "Epoch 16: Train Loss=0.4844, Train Acc=0.7861 ||| Val Loss=0.4710, Val Acc=0.7929\n",
      "Epoch 17: Train Loss=0.4820, Train Acc=0.7855 ||| Val Loss=0.4676, Val Acc=0.7923\n",
      "Epoch 18: Train Loss=0.4759, Train Acc=0.7868 ||| Val Loss=0.4578, Val Acc=0.7975\n",
      "Epoch 19: Train Loss=0.4742, Train Acc=0.7876 ||| Val Loss=0.4546, Val Acc=0.7957\n",
      "Epoch 20: Train Loss=0.4677, Train Acc=0.7884 ||| Val Loss=0.4498, Val Acc=0.7975\n",
      "Epoch 21: Train Loss=0.4743, Train Acc=0.7872 ||| Val Loss=0.4592, Val Acc=0.7906\n",
      "Epoch 22: Train Loss=0.4827, Train Acc=0.7868 ||| Val Loss=0.4666, Val Acc=0.7940\n",
      "Epoch 23: Train Loss=0.4729, Train Acc=0.7853 ||| Val Loss=0.4496, Val Acc=0.7957\n",
      "Epoch 24: Train Loss=0.4626, Train Acc=0.7886 ||| Val Loss=0.4332, Val Acc=0.7975\n",
      "Epoch 25: Train Loss=0.4459, Train Acc=0.7888 ||| Val Loss=0.4263, Val Acc=0.7998\n",
      "Epoch 26: Train Loss=0.4524, Train Acc=0.7905 ||| Val Loss=0.4234, Val Acc=0.8003\n",
      "Epoch 27: Train Loss=0.4484, Train Acc=0.7921 ||| Val Loss=0.4321, Val Acc=0.8015\n",
      "Epoch 28: Train Loss=0.4519, Train Acc=0.7879 ||| Val Loss=0.4351, Val Acc=0.8015\n",
      "Epoch 29: Train Loss=0.4510, Train Acc=0.7924 ||| Val Loss=0.4257, Val Acc=0.7986\n",
      "Epoch 30: Train Loss=0.4466, Train Acc=0.7915 ||| Val Loss=0.4241, Val Acc=0.7992\n",
      "Epoch 31: Train Loss=0.4388, Train Acc=0.7907 ||| Val Loss=0.4184, Val Acc=0.8015\n",
      "Epoch 32: Train Loss=0.4355, Train Acc=0.7907 ||| Val Loss=0.4324, Val Acc=0.8055\n",
      "Epoch 33: Train Loss=0.4423, Train Acc=0.7907 ||| Val Loss=0.4216, Val Acc=0.7998\n",
      "Epoch 34: Train Loss=0.4356, Train Acc=0.7963 ||| Val Loss=0.4170, Val Acc=0.7969\n",
      "Epoch 35: Train Loss=0.4326, Train Acc=0.7958 ||| Val Loss=0.4202, Val Acc=0.7969\n",
      "Epoch 36: Train Loss=0.4373, Train Acc=0.7965 ||| Val Loss=0.4161, Val Acc=0.7957\n",
      "Epoch 37: Train Loss=0.4326, Train Acc=0.7921 ||| Val Loss=0.4153, Val Acc=0.7957\n",
      "Epoch 38: Train Loss=0.4307, Train Acc=0.7912 ||| Val Loss=0.4210, Val Acc=0.7980\n",
      "Epoch 39: Train Loss=0.4249, Train Acc=0.7960 ||| Val Loss=0.4215, Val Acc=0.7940\n",
      "Epoch 40: Train Loss=0.4268, Train Acc=0.7935 ||| Val Loss=0.4169, Val Acc=0.7957\n",
      "Epoch 41: Train Loss=0.4203, Train Acc=0.7955 ||| Val Loss=0.4220, Val Acc=0.7963\n",
      "Epoch 42: Train Loss=0.4322, Train Acc=0.7948 ||| Val Loss=0.4202, Val Acc=0.7963\n",
      "Epoch 43: Train Loss=0.4236, Train Acc=0.7898 ||| Val Loss=0.4136, Val Acc=0.7946\n",
      "Epoch 44: Train Loss=0.4282, Train Acc=0.7922 ||| Val Loss=0.4152, Val Acc=0.7980\n",
      "Epoch 45: Train Loss=0.4300, Train Acc=0.7932 ||| Val Loss=0.4195, Val Acc=0.7969\n",
      "Epoch 46: Train Loss=0.4296, Train Acc=0.7945 ||| Val Loss=0.4217, Val Acc=0.7923\n",
      "Epoch 47: Train Loss=0.4269, Train Acc=0.7940 ||| Val Loss=0.4118, Val Acc=0.7929\n",
      "Epoch 48: Train Loss=0.4266, Train Acc=0.7944 ||| Val Loss=0.4179, Val Acc=0.7963\n",
      "Epoch 49: Train Loss=0.4267, Train Acc=0.7944 ||| Val Loss=0.4217, Val Acc=0.7946\n",
      "Epoch 50: Train Loss=0.4286, Train Acc=0.7951 ||| Val Loss=0.4190, Val Acc=0.7883\n",
      "Epoch 51: Train Loss=0.4254, Train Acc=0.7964 ||| Val Loss=0.4146, Val Acc=0.7952\n",
      "Epoch 52: Train Loss=0.4241, Train Acc=0.7964 ||| Val Loss=0.4109, Val Acc=0.8009\n",
      "Epoch 53: Train Loss=0.4246, Train Acc=0.8001 ||| Val Loss=0.4089, Val Acc=0.7934\n",
      "Epoch 54: Train Loss=0.4233, Train Acc=0.7984 ||| Val Loss=0.4167, Val Acc=0.7992\n",
      "Epoch 55: Train Loss=0.4224, Train Acc=0.7963 ||| Val Loss=0.4131, Val Acc=0.7934\n",
      "Epoch 56: Train Loss=0.4244, Train Acc=0.7960 ||| Val Loss=0.4195, Val Acc=0.7980\n",
      "Epoch 57: Train Loss=0.4265, Train Acc=0.7928 ||| Val Loss=0.4100, Val Acc=0.7957\n",
      "Epoch 58: Train Loss=0.4213, Train Acc=0.7986 ||| Val Loss=0.4141, Val Acc=0.7952\n",
      "Epoch 59: Train Loss=0.4171, Train Acc=0.7999 ||| Val Loss=0.4101, Val Acc=0.8003\n",
      "Epoch 60: Train Loss=0.4188, Train Acc=0.8007 ||| Val Loss=0.4144, Val Acc=0.7934\n",
      "Epoch 61: Train Loss=0.4217, Train Acc=0.7990 ||| Val Loss=0.4249, Val Acc=0.7911\n",
      "Epoch 62: Train Loss=0.4293, Train Acc=0.7965 ||| Val Loss=0.4129, Val Acc=0.7975\n",
      "Epoch 63: Train Loss=0.4257, Train Acc=0.7954 ||| Val Loss=0.4093, Val Acc=0.7957\n",
      "Epoch 64: Train Loss=0.4216, Train Acc=0.7976 ||| Val Loss=0.4182, Val Acc=0.7963\n",
      "Epoch 65: Train Loss=0.4132, Train Acc=0.7990 ||| Val Loss=0.4326, Val Acc=0.7952\n",
      "Epoch 66: Train Loss=0.4224, Train Acc=0.8024 ||| Val Loss=0.4134, Val Acc=0.7934\n",
      "Epoch 67: Train Loss=0.4180, Train Acc=0.8003 ||| Val Loss=0.4077, Val Acc=0.8003\n",
      "Epoch 68: Train Loss=0.4141, Train Acc=0.7993 ||| Val Loss=0.4112, Val Acc=0.7940\n",
      "Epoch 69: Train Loss=0.4178, Train Acc=0.7973 ||| Val Loss=0.4095, Val Acc=0.7986\n",
      "Epoch 70: Train Loss=0.4213, Train Acc=0.8001 ||| Val Loss=0.4168, Val Acc=0.7975\n",
      "Epoch 71: Train Loss=0.4217, Train Acc=0.8026 ||| Val Loss=0.4089, Val Acc=0.7998\n",
      "Epoch 72: Train Loss=0.4213, Train Acc=0.8007 ||| Val Loss=0.4135, Val Acc=0.7963\n",
      "Epoch 73: Train Loss=0.4146, Train Acc=0.7964 ||| Val Loss=0.4095, Val Acc=0.7963\n",
      "Epoch 74: Train Loss=0.4144, Train Acc=0.7977 ||| Val Loss=0.4060, Val Acc=0.8021\n",
      "Epoch 75: Train Loss=0.4153, Train Acc=0.7986 ||| Val Loss=0.4130, Val Acc=0.7963\n",
      "Epoch 76: Train Loss=0.4164, Train Acc=0.7993 ||| Val Loss=0.4080, Val Acc=0.7911\n",
      "Epoch 77: Train Loss=0.4190, Train Acc=0.8003 ||| Val Loss=0.4136, Val Acc=0.7929\n",
      "Epoch 78: Train Loss=0.4245, Train Acc=0.7978 ||| Val Loss=0.4114, Val Acc=0.8021\n",
      "Epoch 79: Train Loss=0.4132, Train Acc=0.7991 ||| Val Loss=0.4072, Val Acc=0.7969\n",
      "Epoch 80: Train Loss=0.4186, Train Acc=0.7990 ||| Val Loss=0.4093, Val Acc=0.7998\n",
      "Epoch 81: Train Loss=0.4136, Train Acc=0.7994 ||| Val Loss=0.4063, Val Acc=0.7992\n",
      "Epoch 82: Train Loss=0.4141, Train Acc=0.8024 ||| Val Loss=0.4043, Val Acc=0.8009\n",
      "Epoch 83: Train Loss=0.4125, Train Acc=0.7991 ||| Val Loss=0.4123, Val Acc=0.8003\n",
      "Epoch 84: Train Loss=0.4086, Train Acc=0.8006 ||| Val Loss=0.4124, Val Acc=0.7980\n",
      "Epoch 85: Train Loss=0.4114, Train Acc=0.8001 ||| Val Loss=0.4089, Val Acc=0.8044\n",
      "Epoch 86: Train Loss=0.4111, Train Acc=0.8001 ||| Val Loss=0.4095, Val Acc=0.7963\n",
      "Epoch 87: Train Loss=0.4138, Train Acc=0.8022 ||| Val Loss=0.4134, Val Acc=0.7940\n",
      "Epoch 88: Train Loss=0.4111, Train Acc=0.7990 ||| Val Loss=0.4102, Val Acc=0.7963\n",
      "Epoch 89: Train Loss=0.4054, Train Acc=0.7993 ||| Val Loss=0.4083, Val Acc=0.7998\n",
      "Epoch 90: Train Loss=0.4119, Train Acc=0.7990 ||| Val Loss=0.4036, Val Acc=0.8026\n",
      "Epoch 91: Train Loss=0.4146, Train Acc=0.8040 ||| Val Loss=0.4065, Val Acc=0.7998\n",
      "Epoch 92: Train Loss=0.4114, Train Acc=0.8042 ||| Val Loss=0.4149, Val Acc=0.7952\n",
      "Epoch 93: Train Loss=0.4129, Train Acc=0.8001 ||| Val Loss=0.4064, Val Acc=0.8015\n",
      "Epoch 94: Train Loss=0.4140, Train Acc=0.8001 ||| Val Loss=0.4120, Val Acc=0.8009\n",
      "Epoch 95: Train Loss=0.4146, Train Acc=0.8039 ||| Val Loss=0.4097, Val Acc=0.8009\n",
      "Epoch 96: Train Loss=0.4081, Train Acc=0.8040 ||| Val Loss=0.4026, Val Acc=0.8072\n",
      "Epoch 97: Train Loss=0.4117, Train Acc=0.8020 ||| Val Loss=0.4092, Val Acc=0.7969\n",
      "Epoch 98: Train Loss=0.4095, Train Acc=0.8020 ||| Val Loss=0.4069, Val Acc=0.8009\n",
      "Epoch 99: Train Loss=0.4094, Train Acc=0.8017 ||| Val Loss=0.4102, Val Acc=0.7986\n",
      "Epoch 100: Train Loss=0.4082, Train Acc=0.8019 ||| Val Loss=0.4053, Val Acc=0.8026\n",
      "Epoch 101: Train Loss=0.4108, Train Acc=0.7994 ||| Val Loss=0.4105, Val Acc=0.8003\n",
      "Epoch 102: Train Loss=0.4046, Train Acc=0.8030 ||| Val Loss=0.4086, Val Acc=0.8101\n",
      "Epoch 103: Train Loss=0.4067, Train Acc=0.8022 ||| Val Loss=0.4062, Val Acc=0.7940\n",
      "Epoch 104: Train Loss=0.4094, Train Acc=0.8066 ||| Val Loss=0.4059, Val Acc=0.8009\n",
      "Epoch 105: Train Loss=0.4055, Train Acc=0.8027 ||| Val Loss=0.4097, Val Acc=0.7929\n",
      "Epoch 106: Train Loss=0.4049, Train Acc=0.8079 ||| Val Loss=0.4102, Val Acc=0.8015\n",
      "Epoch 107: Train Loss=0.4072, Train Acc=0.8016 ||| Val Loss=0.4116, Val Acc=0.7992\n",
      "Epoch 108: Train Loss=0.4065, Train Acc=0.8027 ||| Val Loss=0.4082, Val Acc=0.7992\n",
      "Epoch 109: Train Loss=0.4033, Train Acc=0.8078 ||| Val Loss=0.4042, Val Acc=0.8067\n",
      "Epoch 110: Train Loss=0.4081, Train Acc=0.8029 ||| Val Loss=0.4039, Val Acc=0.8026\n",
      "Epoch 111: Train Loss=0.4000, Train Acc=0.8027 ||| Val Loss=0.4068, Val Acc=0.7975\n",
      "Epoch 112: Train Loss=0.4076, Train Acc=0.8059 ||| Val Loss=0.4042, Val Acc=0.7980\n",
      "Epoch 113: Train Loss=0.4022, Train Acc=0.8093 ||| Val Loss=0.4029, Val Acc=0.8067\n",
      "Epoch 114: Train Loss=0.4039, Train Acc=0.8045 ||| Val Loss=0.4077, Val Acc=0.7957\n",
      "Epoch 115: Train Loss=0.4019, Train Acc=0.8039 ||| Val Loss=0.4049, Val Acc=0.7923\n",
      "Epoch 116: Train Loss=0.4029, Train Acc=0.8036 ||| Val Loss=0.4061, Val Acc=0.7906\n",
      "Early stopping triggered at epoch 116\n",
      "Fold 4 Validation Accuracy: 0.7906\n",
      "\n",
      " ||| Fold number: 5 / 5 |||\n",
      "Epoch 1: Train Loss=0.9684, Train Acc=0.5600 ||| Val Loss=0.6184, Val Acc=0.6904\n",
      "Epoch 2: Train Loss=0.5947, Train Acc=0.6952 ||| Val Loss=0.5224, Val Acc=0.7848\n",
      "Epoch 3: Train Loss=0.5419, Train Acc=0.7514 ||| Val Loss=0.5237, Val Acc=0.7808\n",
      "Epoch 4: Train Loss=0.5363, Train Acc=0.7633 ||| Val Loss=0.5019, Val Acc=0.7854\n",
      "Epoch 5: Train Loss=0.5282, Train Acc=0.7764 ||| Val Loss=0.5040, Val Acc=0.7791\n",
      "Epoch 6: Train Loss=0.5183, Train Acc=0.7839 ||| Val Loss=0.4917, Val Acc=0.7814\n",
      "Epoch 7: Train Loss=0.5160, Train Acc=0.7848 ||| Val Loss=0.5033, Val Acc=0.7773\n",
      "Epoch 8: Train Loss=0.5110, Train Acc=0.7816 ||| Val Loss=0.4905, Val Acc=0.7802\n",
      "Epoch 9: Train Loss=0.4964, Train Acc=0.7868 ||| Val Loss=0.4927, Val Acc=0.7773\n",
      "Epoch 10: Train Loss=0.4995, Train Acc=0.7868 ||| Val Loss=0.4833, Val Acc=0.7756\n",
      "Epoch 11: Train Loss=0.4922, Train Acc=0.7888 ||| Val Loss=0.4813, Val Acc=0.7808\n",
      "Epoch 12: Train Loss=0.4869, Train Acc=0.7889 ||| Val Loss=0.4767, Val Acc=0.7791\n",
      "Epoch 13: Train Loss=0.4887, Train Acc=0.7876 ||| Val Loss=0.4760, Val Acc=0.7796\n",
      "Epoch 14: Train Loss=0.4796, Train Acc=0.7889 ||| Val Loss=0.4713, Val Acc=0.7773\n",
      "Epoch 15: Train Loss=0.4755, Train Acc=0.7922 ||| Val Loss=0.4686, Val Acc=0.7785\n",
      "Epoch 16: Train Loss=0.4733, Train Acc=0.7892 ||| Val Loss=0.4717, Val Acc=0.7791\n",
      "Epoch 17: Train Loss=0.4811, Train Acc=0.7905 ||| Val Loss=0.4657, Val Acc=0.7802\n",
      "Epoch 18: Train Loss=0.4674, Train Acc=0.7924 ||| Val Loss=0.4642, Val Acc=0.7802\n",
      "Epoch 19: Train Loss=0.4635, Train Acc=0.7917 ||| Val Loss=0.4696, Val Acc=0.7745\n",
      "Epoch 20: Train Loss=0.4664, Train Acc=0.7909 ||| Val Loss=0.4550, Val Acc=0.7837\n",
      "Epoch 21: Train Loss=0.4585, Train Acc=0.7891 ||| Val Loss=0.4513, Val Acc=0.7831\n",
      "Epoch 22: Train Loss=0.4554, Train Acc=0.7919 ||| Val Loss=0.4478, Val Acc=0.7814\n",
      "Epoch 23: Train Loss=0.4530, Train Acc=0.7924 ||| Val Loss=0.4590, Val Acc=0.7842\n",
      "Epoch 24: Train Loss=0.4527, Train Acc=0.7925 ||| Val Loss=0.4528, Val Acc=0.7888\n",
      "Epoch 25: Train Loss=0.4433, Train Acc=0.7945 ||| Val Loss=0.4475, Val Acc=0.7860\n",
      "Epoch 26: Train Loss=0.4487, Train Acc=0.7938 ||| Val Loss=0.4440, Val Acc=0.7854\n",
      "Epoch 27: Train Loss=0.4420, Train Acc=0.7930 ||| Val Loss=0.4378, Val Acc=0.7848\n",
      "Epoch 28: Train Loss=0.4453, Train Acc=0.7915 ||| Val Loss=0.4508, Val Acc=0.7825\n",
      "Epoch 29: Train Loss=0.4411, Train Acc=0.7940 ||| Val Loss=0.4382, Val Acc=0.7854\n",
      "Epoch 30: Train Loss=0.4428, Train Acc=0.7907 ||| Val Loss=0.4350, Val Acc=0.7865\n",
      "Epoch 31: Train Loss=0.4312, Train Acc=0.7951 ||| Val Loss=0.4334, Val Acc=0.7883\n",
      "Epoch 32: Train Loss=0.4248, Train Acc=0.7950 ||| Val Loss=0.4361, Val Acc=0.7865\n",
      "Epoch 33: Train Loss=0.4372, Train Acc=0.7948 ||| Val Loss=0.4413, Val Acc=0.7871\n",
      "Epoch 34: Train Loss=0.4278, Train Acc=0.7951 ||| Val Loss=0.4301, Val Acc=0.7900\n",
      "Epoch 35: Train Loss=0.4238, Train Acc=0.7947 ||| Val Loss=0.4377, Val Acc=0.7860\n",
      "Epoch 36: Train Loss=0.4248, Train Acc=0.7955 ||| Val Loss=0.4358, Val Acc=0.7888\n",
      "Epoch 37: Train Loss=0.4277, Train Acc=0.7951 ||| Val Loss=0.4288, Val Acc=0.7796\n",
      "Epoch 38: Train Loss=0.4347, Train Acc=0.7960 ||| Val Loss=0.4360, Val Acc=0.7877\n",
      "Epoch 39: Train Loss=0.4260, Train Acc=0.7986 ||| Val Loss=0.4293, Val Acc=0.7883\n",
      "Epoch 40: Train Loss=0.4257, Train Acc=0.8023 ||| Val Loss=0.4399, Val Acc=0.7871\n",
      "Epoch 41: Train Loss=0.4280, Train Acc=0.7948 ||| Val Loss=0.4266, Val Acc=0.7796\n",
      "Epoch 42: Train Loss=0.4224, Train Acc=0.7961 ||| Val Loss=0.4345, Val Acc=0.7773\n",
      "Epoch 43: Train Loss=0.4172, Train Acc=0.7991 ||| Val Loss=0.4321, Val Acc=0.7877\n",
      "Epoch 44: Train Loss=0.4214, Train Acc=0.8000 ||| Val Loss=0.4289, Val Acc=0.7883\n",
      "Epoch 45: Train Loss=0.4192, Train Acc=0.7981 ||| Val Loss=0.4283, Val Acc=0.7923\n",
      "Epoch 46: Train Loss=0.4219, Train Acc=0.7961 ||| Val Loss=0.4329, Val Acc=0.7894\n",
      "Epoch 47: Train Loss=0.4204, Train Acc=0.7987 ||| Val Loss=0.4330, Val Acc=0.7923\n",
      "Epoch 48: Train Loss=0.4183, Train Acc=0.7991 ||| Val Loss=0.4335, Val Acc=0.7911\n",
      "Epoch 49: Train Loss=0.4193, Train Acc=0.7983 ||| Val Loss=0.4323, Val Acc=0.7814\n",
      "Epoch 50: Train Loss=0.4119, Train Acc=0.8017 ||| Val Loss=0.4306, Val Acc=0.7785\n",
      "Epoch 51: Train Loss=0.4188, Train Acc=0.7965 ||| Val Loss=0.4316, Val Acc=0.7814\n",
      "Epoch 52: Train Loss=0.4242, Train Acc=0.7970 ||| Val Loss=0.4351, Val Acc=0.7814\n",
      "Epoch 53: Train Loss=0.4202, Train Acc=0.7967 ||| Val Loss=0.4287, Val Acc=0.7883\n",
      "Epoch 54: Train Loss=0.4194, Train Acc=0.8003 ||| Val Loss=0.4288, Val Acc=0.7883\n",
      "Epoch 55: Train Loss=0.4142, Train Acc=0.7981 ||| Val Loss=0.4275, Val Acc=0.7808\n",
      "Epoch 56: Train Loss=0.4184, Train Acc=0.7974 ||| Val Loss=0.4274, Val Acc=0.7819\n",
      "Epoch 57: Train Loss=0.4166, Train Acc=0.7994 ||| Val Loss=0.4260, Val Acc=0.7819\n",
      "Epoch 58: Train Loss=0.4184, Train Acc=0.7968 ||| Val Loss=0.4272, Val Acc=0.7860\n",
      "Epoch 59: Train Loss=0.4130, Train Acc=0.8012 ||| Val Loss=0.4267, Val Acc=0.7825\n",
      "Epoch 60: Train Loss=0.4124, Train Acc=0.8047 ||| Val Loss=0.4286, Val Acc=0.7819\n",
      "Epoch 61: Train Loss=0.4150, Train Acc=0.8022 ||| Val Loss=0.4345, Val Acc=0.7762\n",
      "Epoch 62: Train Loss=0.4148, Train Acc=0.7980 ||| Val Loss=0.4261, Val Acc=0.7860\n",
      "Epoch 63: Train Loss=0.4097, Train Acc=0.8043 ||| Val Loss=0.4335, Val Acc=0.7768\n",
      "Epoch 64: Train Loss=0.4155, Train Acc=0.8014 ||| Val Loss=0.4321, Val Acc=0.7831\n",
      "Epoch 65: Train Loss=0.4056, Train Acc=0.8010 ||| Val Loss=0.4313, Val Acc=0.7802\n",
      "Epoch 66: Train Loss=0.4072, Train Acc=0.8023 ||| Val Loss=0.4279, Val Acc=0.7808\n",
      "Epoch 67: Train Loss=0.4090, Train Acc=0.7990 ||| Val Loss=0.4291, Val Acc=0.7842\n",
      "Epoch 68: Train Loss=0.4109, Train Acc=0.8013 ||| Val Loss=0.4292, Val Acc=0.7837\n",
      "Epoch 69: Train Loss=0.4071, Train Acc=0.8027 ||| Val Loss=0.4306, Val Acc=0.7831\n",
      "Epoch 70: Train Loss=0.4023, Train Acc=0.7991 ||| Val Loss=0.4296, Val Acc=0.7808\n",
      "Epoch 71: Train Loss=0.4093, Train Acc=0.8035 ||| Val Loss=0.4267, Val Acc=0.7837\n",
      "Epoch 72: Train Loss=0.4052, Train Acc=0.8009 ||| Val Loss=0.4377, Val Acc=0.7716\n",
      "Epoch 73: Train Loss=0.4088, Train Acc=0.7971 ||| Val Loss=0.4271, Val Acc=0.7768\n",
      "Epoch 74: Train Loss=0.4093, Train Acc=0.8019 ||| Val Loss=0.4310, Val Acc=0.7773\n",
      "Epoch 75: Train Loss=0.4082, Train Acc=0.8007 ||| Val Loss=0.4336, Val Acc=0.7825\n",
      "Epoch 76: Train Loss=0.4032, Train Acc=0.8063 ||| Val Loss=0.4305, Val Acc=0.7796\n",
      "Epoch 77: Train Loss=0.4037, Train Acc=0.8020 ||| Val Loss=0.4275, Val Acc=0.7819\n",
      "Early stopping triggered at epoch 77\n",
      "Fold 5 Validation Accuracy: 0.7819\n",
      "\n",
      "--- Cross-Validation Results ---\n",
      "Mean Validation Accuracy: 0.7927\n",
      "Validation Accuracies for each fold: [0.8039102932719954, 0.7866589994249569, 0.8004600345025877, 0.7905638665132336, 0.7819332566168009]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "best = best_params[0][0] # get our best found parameters\n",
    "print(\"Our parameters: \", best)\n",
    "\n",
    "# prepare the full training dataset\n",
    "X_tensor = torch.tensor(df_X.values, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(df_Y.values, dtype=torch.long)\n",
    "\n",
    "# The cross-validation setup\n",
    "n_splits = 5 # amount of folds\n",
    "strat_k_fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = [] # contains our\n",
    "\n",
    "# the k fold loop\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(strat_k_fold.split(X_tensor, Y_tensor)):\n",
    "    print(f\"\\n ||| Fold number: {fold_idx + 1} / {n_splits} |||\")\n",
    "\n",
    "    # we split into this folds training and validations subsets\n",
    "    X_train_fold = X_tensor[train_idx]\n",
    "    y_train_fold = Y_tensor[train_idx]\n",
    "    X_val_fold = X_tensor[val_idx]\n",
    "    y_val_fold = Y_tensor[val_idx]\n",
    "\n",
    "    # create the DataLoaders\n",
    "    train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "    val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True) # larger batch sizes to combat overfitting\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    # evaluate on validation set\n",
    "    \n",
    "    # train the model for this fold\n",
    "    fold_model = run_tabm(**best, n_epochs=400)\n",
    "    \n",
    "    fold_model.eval()  # turn off dropout, etc.\n",
    "\n",
    "    val_preds = [] # predictions\n",
    "    val_targets = [] # true labels\n",
    "\n",
    "    with torch.no_grad():  # disables gradient tracking\n",
    "        for xb, yb in val_loader:  # use your validation loader\n",
    "            outputs = fold_model(xb, None)\n",
    "            preds = outputs.mean(dim=1).argmax(dim=1) # generate final prediction from the k experts\n",
    "            val_preds.append(preds)\n",
    "            val_targets.append(yb)\n",
    "\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "\n",
    "    # calculate this folds validation accuracy\n",
    "    val_acc = accuracy_score(val_targets.cpu(), val_preds.cpu())\n",
    "    print(f\"Fold {fold_idx + 1} Validation Accuracy: {val_acc:.4f}\")\n",
    "    cv_scores.append(val_acc)\n",
    "\n",
    "\n",
    "print(\"\\n--- Cross-Validation Results ---\")\n",
    "print(f\"Mean Validation Accuracy: {sum(cv_scores)/len(cv_scores):.4f}\")\n",
    "print(f\"Validation Accuracies for each fold: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a18ed05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ||| Training final model on full dataset |||\n",
      "Epoch 1: Train Loss=0.9117, Train Acc=0.5651 ||| Val Loss=0.6034, Val Acc=0.7468\n",
      "Epoch 2: Train Loss=0.5901, Train Acc=0.6963 ||| Val Loss=0.5344, Val Acc=0.7589\n",
      "Epoch 3: Train Loss=0.5538, Train Acc=0.7438 ||| Val Loss=0.5098, Val Acc=0.7779\n",
      "Epoch 4: Train Loss=0.5356, Train Acc=0.7611 ||| Val Loss=0.4949, Val Acc=0.7722\n",
      "Epoch 5: Train Loss=0.5207, Train Acc=0.7700 ||| Val Loss=0.4986, Val Acc=0.7768\n",
      "Epoch 6: Train Loss=0.5130, Train Acc=0.7741 ||| Val Loss=0.4950, Val Acc=0.7791\n",
      "Epoch 7: Train Loss=0.5068, Train Acc=0.7790 ||| Val Loss=0.4861, Val Acc=0.7756\n",
      "Epoch 8: Train Loss=0.5034, Train Acc=0.7798 ||| Val Loss=0.4840, Val Acc=0.7762\n",
      "Epoch 9: Train Loss=0.4945, Train Acc=0.7858 ||| Val Loss=0.4785, Val Acc=0.7768\n",
      "Epoch 10: Train Loss=0.4998, Train Acc=0.7822 ||| Val Loss=0.4887, Val Acc=0.7831\n",
      "Epoch 11: Train Loss=0.4923, Train Acc=0.7852 ||| Val Loss=0.4795, Val Acc=0.7779\n",
      "Epoch 12: Train Loss=0.4833, Train Acc=0.7873 ||| Val Loss=0.4763, Val Acc=0.7825\n",
      "Epoch 13: Train Loss=0.4860, Train Acc=0.7881 ||| Val Loss=0.4653, Val Acc=0.7802\n",
      "Epoch 14: Train Loss=0.4775, Train Acc=0.7858 ||| Val Loss=0.4675, Val Acc=0.7785\n",
      "Epoch 15: Train Loss=0.4722, Train Acc=0.7887 ||| Val Loss=0.4603, Val Acc=0.7848\n",
      "Epoch 16: Train Loss=0.4759, Train Acc=0.7898 ||| Val Loss=0.4803, Val Acc=0.7854\n",
      "Epoch 17: Train Loss=0.4718, Train Acc=0.7888 ||| Val Loss=0.4599, Val Acc=0.7796\n",
      "Epoch 18: Train Loss=0.4629, Train Acc=0.7911 ||| Val Loss=0.4570, Val Acc=0.7842\n",
      "Epoch 19: Train Loss=0.4615, Train Acc=0.7890 ||| Val Loss=0.4515, Val Acc=0.7837\n",
      "Epoch 20: Train Loss=0.4629, Train Acc=0.7883 ||| Val Loss=0.4628, Val Acc=0.7814\n",
      "Epoch 21: Train Loss=0.4583, Train Acc=0.7931 ||| Val Loss=0.4377, Val Acc=0.7831\n",
      "Epoch 22: Train Loss=0.4497, Train Acc=0.7886 ||| Val Loss=0.4345, Val Acc=0.7900\n",
      "Epoch 23: Train Loss=0.4455, Train Acc=0.7912 ||| Val Loss=0.4411, Val Acc=0.7877\n",
      "Epoch 24: Train Loss=0.4443, Train Acc=0.7943 ||| Val Loss=0.4391, Val Acc=0.7883\n",
      "Epoch 25: Train Loss=0.4440, Train Acc=0.7932 ||| Val Loss=0.4372, Val Acc=0.7837\n",
      "Epoch 26: Train Loss=0.4430, Train Acc=0.7934 ||| Val Loss=0.4491, Val Acc=0.7923\n",
      "Epoch 27: Train Loss=0.4467, Train Acc=0.7958 ||| Val Loss=0.4303, Val Acc=0.7900\n",
      "Epoch 28: Train Loss=0.4377, Train Acc=0.7943 ||| Val Loss=0.4345, Val Acc=0.7911\n",
      "Epoch 29: Train Loss=0.4422, Train Acc=0.7918 ||| Val Loss=0.4457, Val Acc=0.7929\n",
      "Epoch 30: Train Loss=0.4412, Train Acc=0.7951 ||| Val Loss=0.4332, Val Acc=0.7894\n",
      "Epoch 31: Train Loss=0.4353, Train Acc=0.7950 ||| Val Loss=0.4288, Val Acc=0.7917\n",
      "Epoch 32: Train Loss=0.4333, Train Acc=0.7914 ||| Val Loss=0.4372, Val Acc=0.7934\n",
      "Epoch 33: Train Loss=0.4308, Train Acc=0.7936 ||| Val Loss=0.4317, Val Acc=0.7923\n",
      "Epoch 34: Train Loss=0.4331, Train Acc=0.7970 ||| Val Loss=0.4249, Val Acc=0.7946\n",
      "Epoch 35: Train Loss=0.4279, Train Acc=0.7951 ||| Val Loss=0.4230, Val Acc=0.7917\n",
      "Epoch 36: Train Loss=0.4288, Train Acc=0.7942 ||| Val Loss=0.4216, Val Acc=0.7969\n",
      "Epoch 37: Train Loss=0.4304, Train Acc=0.7950 ||| Val Loss=0.4219, Val Acc=0.7917\n",
      "Epoch 38: Train Loss=0.4280, Train Acc=0.7978 ||| Val Loss=0.4198, Val Acc=0.7975\n",
      "Epoch 39: Train Loss=0.4289, Train Acc=0.7980 ||| Val Loss=0.4248, Val Acc=0.7883\n",
      "Epoch 40: Train Loss=0.4273, Train Acc=0.7978 ||| Val Loss=0.4253, Val Acc=0.7917\n",
      "Epoch 41: Train Loss=0.4268, Train Acc=0.7980 ||| Val Loss=0.4234, Val Acc=0.7911\n",
      "Epoch 42: Train Loss=0.4241, Train Acc=0.7945 ||| Val Loss=0.4194, Val Acc=0.7940\n",
      "Epoch 43: Train Loss=0.4192, Train Acc=0.7957 ||| Val Loss=0.4301, Val Acc=0.7929\n",
      "Epoch 44: Train Loss=0.4233, Train Acc=0.7974 ||| Val Loss=0.4218, Val Acc=0.7900\n",
      "Epoch 45: Train Loss=0.4247, Train Acc=0.8011 ||| Val Loss=0.4201, Val Acc=0.7929\n",
      "Epoch 46: Train Loss=0.4206, Train Acc=0.7986 ||| Val Loss=0.4200, Val Acc=0.7929\n",
      "Epoch 47: Train Loss=0.4236, Train Acc=0.7982 ||| Val Loss=0.4200, Val Acc=0.7957\n",
      "Epoch 48: Train Loss=0.4226, Train Acc=0.7957 ||| Val Loss=0.4226, Val Acc=0.7906\n",
      "Epoch 49: Train Loss=0.4206, Train Acc=0.7957 ||| Val Loss=0.4204, Val Acc=0.7917\n",
      "Epoch 50: Train Loss=0.4211, Train Acc=0.7997 ||| Val Loss=0.4200, Val Acc=0.7963\n",
      "Epoch 51: Train Loss=0.4170, Train Acc=0.7998 ||| Val Loss=0.4203, Val Acc=0.7975\n",
      "Epoch 52: Train Loss=0.4200, Train Acc=0.7995 ||| Val Loss=0.4305, Val Acc=0.7923\n",
      "Epoch 53: Train Loss=0.4225, Train Acc=0.7988 ||| Val Loss=0.4152, Val Acc=0.7911\n",
      "Epoch 54: Train Loss=0.4179, Train Acc=0.7960 ||| Val Loss=0.4188, Val Acc=0.7911\n",
      "Epoch 55: Train Loss=0.4213, Train Acc=0.7977 ||| Val Loss=0.4189, Val Acc=0.7952\n",
      "Epoch 56: Train Loss=0.4186, Train Acc=0.7994 ||| Val Loss=0.4133, Val Acc=0.7929\n",
      "Epoch 57: Train Loss=0.4152, Train Acc=0.7986 ||| Val Loss=0.4180, Val Acc=0.7883\n",
      "Epoch 58: Train Loss=0.4166, Train Acc=0.7967 ||| Val Loss=0.4193, Val Acc=0.7888\n",
      "Epoch 59: Train Loss=0.4145, Train Acc=0.8024 ||| Val Loss=0.4137, Val Acc=0.7952\n",
      "Epoch 60: Train Loss=0.4161, Train Acc=0.7994 ||| Val Loss=0.4180, Val Acc=0.7911\n",
      "Epoch 61: Train Loss=0.4205, Train Acc=0.7967 ||| Val Loss=0.4181, Val Acc=0.7906\n",
      "Epoch 62: Train Loss=0.4110, Train Acc=0.7987 ||| Val Loss=0.4136, Val Acc=0.7894\n",
      "Epoch 63: Train Loss=0.4127, Train Acc=0.8016 ||| Val Loss=0.4138, Val Acc=0.7917\n",
      "Epoch 64: Train Loss=0.4116, Train Acc=0.8005 ||| Val Loss=0.4199, Val Acc=0.7940\n",
      "Epoch 65: Train Loss=0.4155, Train Acc=0.7977 ||| Val Loss=0.4215, Val Acc=0.7934\n",
      "Epoch 66: Train Loss=0.4159, Train Acc=0.7983 ||| Val Loss=0.4162, Val Acc=0.7923\n",
      "Epoch 67: Train Loss=0.4135, Train Acc=0.7939 ||| Val Loss=0.4143, Val Acc=0.7975\n",
      "Epoch 68: Train Loss=0.4164, Train Acc=0.8004 ||| Val Loss=0.4166, Val Acc=0.7963\n",
      "Epoch 69: Train Loss=0.4127, Train Acc=0.8005 ||| Val Loss=0.4113, Val Acc=0.7934\n",
      "Epoch 70: Train Loss=0.4125, Train Acc=0.7998 ||| Val Loss=0.4131, Val Acc=0.7911\n",
      "Epoch 71: Train Loss=0.4110, Train Acc=0.7989 ||| Val Loss=0.4176, Val Acc=0.7825\n",
      "Epoch 72: Train Loss=0.4145, Train Acc=0.7996 ||| Val Loss=0.4096, Val Acc=0.7877\n",
      "Epoch 73: Train Loss=0.4109, Train Acc=0.8016 ||| Val Loss=0.4123, Val Acc=0.7940\n",
      "Epoch 74: Train Loss=0.4128, Train Acc=0.8001 ||| Val Loss=0.4201, Val Acc=0.7871\n",
      "Epoch 75: Train Loss=0.4117, Train Acc=0.7996 ||| Val Loss=0.4122, Val Acc=0.7906\n",
      "Epoch 76: Train Loss=0.4119, Train Acc=0.7979 ||| Val Loss=0.4156, Val Acc=0.7952\n",
      "Epoch 77: Train Loss=0.4102, Train Acc=0.8035 ||| Val Loss=0.4118, Val Acc=0.7894\n",
      "Epoch 78: Train Loss=0.4070, Train Acc=0.8001 ||| Val Loss=0.4073, Val Acc=0.7934\n",
      "Epoch 79: Train Loss=0.4102, Train Acc=0.8043 ||| Val Loss=0.4104, Val Acc=0.7923\n",
      "Epoch 80: Train Loss=0.4119, Train Acc=0.8036 ||| Val Loss=0.4092, Val Acc=0.7888\n",
      "Epoch 81: Train Loss=0.4108, Train Acc=0.8005 ||| Val Loss=0.4112, Val Acc=0.7946\n",
      "Epoch 82: Train Loss=0.4091, Train Acc=0.7991 ||| Val Loss=0.4082, Val Acc=0.7946\n",
      "Epoch 83: Train Loss=0.4094, Train Acc=0.7986 ||| Val Loss=0.4079, Val Acc=0.7911\n",
      "Epoch 84: Train Loss=0.4114, Train Acc=0.7996 ||| Val Loss=0.4072, Val Acc=0.7900\n",
      "Epoch 85: Train Loss=0.4072, Train Acc=0.8050 ||| Val Loss=0.4035, Val Acc=0.7969\n",
      "Epoch 86: Train Loss=0.4067, Train Acc=0.8024 ||| Val Loss=0.4111, Val Acc=0.7923\n",
      "Epoch 87: Train Loss=0.4084, Train Acc=0.7982 ||| Val Loss=0.4065, Val Acc=0.7946\n",
      "Epoch 88: Train Loss=0.4076, Train Acc=0.8028 ||| Val Loss=0.4079, Val Acc=0.7946\n",
      "Epoch 89: Train Loss=0.4063, Train Acc=0.8023 ||| Val Loss=0.4128, Val Acc=0.7934\n",
      "Epoch 90: Train Loss=0.4097, Train Acc=0.8025 ||| Val Loss=0.4108, Val Acc=0.7923\n",
      "Epoch 91: Train Loss=0.4076, Train Acc=0.8004 ||| Val Loss=0.4060, Val Acc=0.7923\n",
      "Epoch 92: Train Loss=0.4068, Train Acc=0.8020 ||| Val Loss=0.4036, Val Acc=0.7883\n",
      "Epoch 93: Train Loss=0.4051, Train Acc=0.8034 ||| Val Loss=0.4036, Val Acc=0.7940\n",
      "Epoch 94: Train Loss=0.4044, Train Acc=0.8033 ||| Val Loss=0.4080, Val Acc=0.7969\n",
      "Epoch 95: Train Loss=0.4059, Train Acc=0.8043 ||| Val Loss=0.4114, Val Acc=0.7900\n",
      "Epoch 96: Train Loss=0.4081, Train Acc=0.8005 ||| Val Loss=0.4050, Val Acc=0.7963\n",
      "Epoch 97: Train Loss=0.4075, Train Acc=0.8014 ||| Val Loss=0.4053, Val Acc=0.7906\n",
      "Epoch 98: Train Loss=0.4036, Train Acc=0.8042 ||| Val Loss=0.4055, Val Acc=0.7986\n",
      "Epoch 99: Train Loss=0.4048, Train Acc=0.8024 ||| Val Loss=0.4038, Val Acc=0.7963\n",
      "Epoch 100: Train Loss=0.4055, Train Acc=0.8044 ||| Val Loss=0.4047, Val Acc=0.7969\n",
      "Epoch 101: Train Loss=0.4055, Train Acc=0.8014 ||| Val Loss=0.4046, Val Acc=0.7952\n",
      "Epoch 102: Train Loss=0.4049, Train Acc=0.8033 ||| Val Loss=0.4031, Val Acc=0.7957\n",
      "Epoch 103: Train Loss=0.4083, Train Acc=0.8010 ||| Val Loss=0.4076, Val Acc=0.7934\n",
      "Epoch 104: Train Loss=0.4044, Train Acc=0.8032 ||| Val Loss=0.3990, Val Acc=0.7975\n",
      "Epoch 105: Train Loss=0.4040, Train Acc=0.8039 ||| Val Loss=0.4066, Val Acc=0.7929\n",
      "Epoch 106: Train Loss=0.4047, Train Acc=0.8006 ||| Val Loss=0.4001, Val Acc=0.7992\n",
      "Epoch 107: Train Loss=0.4023, Train Acc=0.8029 ||| Val Loss=0.4023, Val Acc=0.7969\n",
      "Epoch 108: Train Loss=0.4028, Train Acc=0.8041 ||| Val Loss=0.4018, Val Acc=0.7963\n",
      "Epoch 109: Train Loss=0.4050, Train Acc=0.8042 ||| Val Loss=0.4032, Val Acc=0.7940\n",
      "Epoch 110: Train Loss=0.4006, Train Acc=0.8042 ||| Val Loss=0.4069, Val Acc=0.7986\n",
      "Epoch 111: Train Loss=0.4013, Train Acc=0.8036 ||| Val Loss=0.3999, Val Acc=0.7957\n",
      "Epoch 112: Train Loss=0.4006, Train Acc=0.8052 ||| Val Loss=0.4003, Val Acc=0.7952\n",
      "Epoch 113: Train Loss=0.4004, Train Acc=0.8081 ||| Val Loss=0.3990, Val Acc=0.7957\n",
      "Epoch 114: Train Loss=0.4040, Train Acc=0.8048 ||| Val Loss=0.4030, Val Acc=0.7894\n",
      "Epoch 115: Train Loss=0.4006, Train Acc=0.8049 ||| Val Loss=0.4045, Val Acc=0.7969\n",
      "Epoch 116: Train Loss=0.4016, Train Acc=0.8018 ||| Val Loss=0.3990, Val Acc=0.7888\n",
      "Epoch 117: Train Loss=0.4032, Train Acc=0.8064 ||| Val Loss=0.4029, Val Acc=0.7952\n",
      "Epoch 118: Train Loss=0.4026, Train Acc=0.8039 ||| Val Loss=0.4009, Val Acc=0.7906\n",
      "Epoch 119: Train Loss=0.3996, Train Acc=0.8056 ||| Val Loss=0.3998, Val Acc=0.7929\n",
      "Epoch 120: Train Loss=0.3971, Train Acc=0.8061 ||| Val Loss=0.4038, Val Acc=0.8055\n",
      "Epoch 121: Train Loss=0.4018, Train Acc=0.8051 ||| Val Loss=0.4002, Val Acc=0.7969\n",
      "Epoch 122: Train Loss=0.3967, Train Acc=0.8034 ||| Val Loss=0.3977, Val Acc=0.7969\n",
      "Epoch 123: Train Loss=0.4060, Train Acc=0.8054 ||| Val Loss=0.3976, Val Acc=0.7980\n",
      "Epoch 124: Train Loss=0.4028, Train Acc=0.8034 ||| Val Loss=0.4011, Val Acc=0.7934\n",
      "Epoch 125: Train Loss=0.4006, Train Acc=0.8050 ||| Val Loss=0.4024, Val Acc=0.7969\n",
      "Epoch 126: Train Loss=0.3999, Train Acc=0.8031 ||| Val Loss=0.4036, Val Acc=0.7952\n",
      "Epoch 127: Train Loss=0.3994, Train Acc=0.8072 ||| Val Loss=0.3995, Val Acc=0.8015\n",
      "Epoch 128: Train Loss=0.3958, Train Acc=0.8040 ||| Val Loss=0.3971, Val Acc=0.7957\n",
      "Epoch 129: Train Loss=0.4002, Train Acc=0.8072 ||| Val Loss=0.3992, Val Acc=0.7992\n",
      "Epoch 130: Train Loss=0.3991, Train Acc=0.8051 ||| Val Loss=0.3988, Val Acc=0.7975\n",
      "Epoch 131: Train Loss=0.3956, Train Acc=0.8077 ||| Val Loss=0.3971, Val Acc=0.7969\n",
      "Epoch 132: Train Loss=0.3992, Train Acc=0.8036 ||| Val Loss=0.3981, Val Acc=0.8015\n",
      "Epoch 133: Train Loss=0.3967, Train Acc=0.8073 ||| Val Loss=0.4008, Val Acc=0.7986\n",
      "Epoch 134: Train Loss=0.3967, Train Acc=0.8070 ||| Val Loss=0.3990, Val Acc=0.8009\n",
      "Epoch 135: Train Loss=0.3962, Train Acc=0.8048 ||| Val Loss=0.3978, Val Acc=0.7975\n",
      "Epoch 136: Train Loss=0.3947, Train Acc=0.8018 ||| Val Loss=0.3981, Val Acc=0.7992\n",
      "Epoch 137: Train Loss=0.3973, Train Acc=0.8089 ||| Val Loss=0.3999, Val Acc=0.8009\n",
      "Epoch 138: Train Loss=0.3973, Train Acc=0.8103 ||| Val Loss=0.3967, Val Acc=0.7975\n",
      "Epoch 139: Train Loss=0.3979, Train Acc=0.8070 ||| Val Loss=0.4003, Val Acc=0.7975\n",
      "Epoch 140: Train Loss=0.3989, Train Acc=0.8040 ||| Val Loss=0.4014, Val Acc=0.7952\n",
      "Epoch 141: Train Loss=0.3953, Train Acc=0.8090 ||| Val Loss=0.3977, Val Acc=0.8026\n",
      "Epoch 142: Train Loss=0.3974, Train Acc=0.8121 ||| Val Loss=0.3975, Val Acc=0.7963\n",
      "Epoch 143: Train Loss=0.3968, Train Acc=0.8043 ||| Val Loss=0.3984, Val Acc=0.7980\n",
      "Epoch 144: Train Loss=0.3956, Train Acc=0.8079 ||| Val Loss=0.3999, Val Acc=0.8038\n",
      "Epoch 145: Train Loss=0.3949, Train Acc=0.8107 ||| Val Loss=0.3952, Val Acc=0.7957\n",
      "Epoch 146: Train Loss=0.4013, Train Acc=0.8073 ||| Val Loss=0.3978, Val Acc=0.8032\n",
      "Epoch 147: Train Loss=0.3973, Train Acc=0.8052 ||| Val Loss=0.3929, Val Acc=0.7980\n",
      "Epoch 148: Train Loss=0.3966, Train Acc=0.8069 ||| Val Loss=0.3982, Val Acc=0.7963\n",
      "Epoch 149: Train Loss=0.3957, Train Acc=0.8103 ||| Val Loss=0.3968, Val Acc=0.7957\n",
      "Epoch 150: Train Loss=0.3958, Train Acc=0.8104 ||| Val Loss=0.4017, Val Acc=0.7975\n",
      "Epoch 151: Train Loss=0.3926, Train Acc=0.8089 ||| Val Loss=0.3942, Val Acc=0.7963\n",
      "Epoch 152: Train Loss=0.3932, Train Acc=0.8121 ||| Val Loss=0.3938, Val Acc=0.7980\n",
      "Epoch 153: Train Loss=0.3933, Train Acc=0.8100 ||| Val Loss=0.3911, Val Acc=0.7998\n",
      "Epoch 154: Train Loss=0.3919, Train Acc=0.8113 ||| Val Loss=0.3941, Val Acc=0.8032\n",
      "Epoch 155: Train Loss=0.3923, Train Acc=0.8112 ||| Val Loss=0.3917, Val Acc=0.8038\n",
      "Epoch 156: Train Loss=0.3911, Train Acc=0.8117 ||| Val Loss=0.3906, Val Acc=0.8009\n",
      "Epoch 157: Train Loss=0.3919, Train Acc=0.8124 ||| Val Loss=0.4014, Val Acc=0.8021\n",
      "Epoch 158: Train Loss=0.3925, Train Acc=0.8116 ||| Val Loss=0.3902, Val Acc=0.8044\n",
      "Epoch 159: Train Loss=0.3896, Train Acc=0.8104 ||| Val Loss=0.3914, Val Acc=0.8032\n",
      "Epoch 160: Train Loss=0.3912, Train Acc=0.8124 ||| Val Loss=0.3941, Val Acc=0.8078\n",
      "Epoch 161: Train Loss=0.3881, Train Acc=0.8126 ||| Val Loss=0.3887, Val Acc=0.8084\n",
      "Epoch 162: Train Loss=0.3925, Train Acc=0.8107 ||| Val Loss=0.3919, Val Acc=0.8067\n",
      "Epoch 163: Train Loss=0.3930, Train Acc=0.8096 ||| Val Loss=0.3933, Val Acc=0.8130\n",
      "Epoch 164: Train Loss=0.3954, Train Acc=0.8098 ||| Val Loss=0.3931, Val Acc=0.7986\n",
      "Epoch 165: Train Loss=0.3907, Train Acc=0.8128 ||| Val Loss=0.3922, Val Acc=0.8026\n",
      "Epoch 166: Train Loss=0.3940, Train Acc=0.8095 ||| Val Loss=0.3912, Val Acc=0.8032\n",
      "Epoch 167: Train Loss=0.3934, Train Acc=0.8093 ||| Val Loss=0.3932, Val Acc=0.7998\n",
      "Epoch 168: Train Loss=0.3893, Train Acc=0.8128 ||| Val Loss=0.3862, Val Acc=0.8061\n",
      "Epoch 169: Train Loss=0.3925, Train Acc=0.8121 ||| Val Loss=0.3863, Val Acc=0.8055\n",
      "Epoch 170: Train Loss=0.3924, Train Acc=0.8101 ||| Val Loss=0.3889, Val Acc=0.8061\n",
      "Epoch 171: Train Loss=0.3894, Train Acc=0.8157 ||| Val Loss=0.3906, Val Acc=0.8055\n",
      "Epoch 172: Train Loss=0.3908, Train Acc=0.8117 ||| Val Loss=0.3899, Val Acc=0.8090\n",
      "Epoch 173: Train Loss=0.3907, Train Acc=0.8113 ||| Val Loss=0.3869, Val Acc=0.8078\n",
      "Epoch 174: Train Loss=0.3886, Train Acc=0.8116 ||| Val Loss=0.3892, Val Acc=0.8026\n",
      "Epoch 175: Train Loss=0.3880, Train Acc=0.8131 ||| Val Loss=0.3913, Val Acc=0.8072\n",
      "Epoch 176: Train Loss=0.3921, Train Acc=0.8121 ||| Val Loss=0.3901, Val Acc=0.8067\n",
      "Epoch 177: Train Loss=0.3931, Train Acc=0.8096 ||| Val Loss=0.3882, Val Acc=0.8003\n",
      "Epoch 178: Train Loss=0.3870, Train Acc=0.8127 ||| Val Loss=0.3944, Val Acc=0.8049\n",
      "Epoch 179: Train Loss=0.3959, Train Acc=0.8101 ||| Val Loss=0.3862, Val Acc=0.8159\n",
      "Epoch 180: Train Loss=0.3896, Train Acc=0.8121 ||| Val Loss=0.3911, Val Acc=0.8049\n",
      "Epoch 181: Train Loss=0.3856, Train Acc=0.8134 ||| Val Loss=0.3888, Val Acc=0.8090\n",
      "Epoch 182: Train Loss=0.3889, Train Acc=0.8133 ||| Val Loss=0.3889, Val Acc=0.8026\n",
      "Epoch 183: Train Loss=0.3892, Train Acc=0.8128 ||| Val Loss=0.3857, Val Acc=0.8067\n",
      "Epoch 184: Train Loss=0.3882, Train Acc=0.8138 ||| Val Loss=0.3878, Val Acc=0.8061\n",
      "Epoch 185: Train Loss=0.3884, Train Acc=0.8113 ||| Val Loss=0.3878, Val Acc=0.7998\n",
      "Epoch 186: Train Loss=0.3887, Train Acc=0.8118 ||| Val Loss=0.3867, Val Acc=0.8032\n",
      "Epoch 187: Train Loss=0.3852, Train Acc=0.8156 ||| Val Loss=0.3802, Val Acc=0.8147\n",
      "Epoch 188: Train Loss=0.3893, Train Acc=0.8126 ||| Val Loss=0.3861, Val Acc=0.8090\n",
      "Epoch 189: Train Loss=0.3825, Train Acc=0.8179 ||| Val Loss=0.3837, Val Acc=0.8061\n",
      "Epoch 190: Train Loss=0.3868, Train Acc=0.8146 ||| Val Loss=0.3860, Val Acc=0.8090\n",
      "Epoch 191: Train Loss=0.3840, Train Acc=0.8192 ||| Val Loss=0.3869, Val Acc=0.8090\n",
      "Epoch 192: Train Loss=0.3853, Train Acc=0.8110 ||| Val Loss=0.3867, Val Acc=0.8090\n",
      "Epoch 193: Train Loss=0.3858, Train Acc=0.8107 ||| Val Loss=0.3827, Val Acc=0.8078\n",
      "Epoch 194: Train Loss=0.3859, Train Acc=0.8134 ||| Val Loss=0.3864, Val Acc=0.8101\n",
      "Epoch 195: Train Loss=0.3862, Train Acc=0.8172 ||| Val Loss=0.3805, Val Acc=0.8101\n",
      "Epoch 196: Train Loss=0.3806, Train Acc=0.8172 ||| Val Loss=0.3820, Val Acc=0.8072\n",
      "Epoch 197: Train Loss=0.3858, Train Acc=0.8165 ||| Val Loss=0.3819, Val Acc=0.8096\n",
      "Epoch 198: Train Loss=0.3841, Train Acc=0.8173 ||| Val Loss=0.3797, Val Acc=0.8032\n",
      "Epoch 199: Train Loss=0.3854, Train Acc=0.8179 ||| Val Loss=0.3851, Val Acc=0.8072\n",
      "Epoch 200: Train Loss=0.3838, Train Acc=0.8166 ||| Val Loss=0.3826, Val Acc=0.8153\n",
      "Epoch 201: Train Loss=0.3851, Train Acc=0.8172 ||| Val Loss=0.3838, Val Acc=0.8101\n",
      "Epoch 202: Train Loss=0.3832, Train Acc=0.8136 ||| Val Loss=0.3846, Val Acc=0.8084\n",
      "Epoch 203: Train Loss=0.3865, Train Acc=0.8142 ||| Val Loss=0.3815, Val Acc=0.8165\n",
      "Epoch 204: Train Loss=0.3820, Train Acc=0.8138 ||| Val Loss=0.3775, Val Acc=0.8142\n",
      "Epoch 205: Train Loss=0.3843, Train Acc=0.8126 ||| Val Loss=0.3791, Val Acc=0.8084\n",
      "Epoch 206: Train Loss=0.3804, Train Acc=0.8194 ||| Val Loss=0.3779, Val Acc=0.8107\n",
      "Epoch 207: Train Loss=0.3800, Train Acc=0.8173 ||| Val Loss=0.3787, Val Acc=0.8130\n",
      "Epoch 208: Train Loss=0.3844, Train Acc=0.8158 ||| Val Loss=0.3759, Val Acc=0.8061\n",
      "Epoch 209: Train Loss=0.3820, Train Acc=0.8178 ||| Val Loss=0.3811, Val Acc=0.8142\n",
      "Epoch 210: Train Loss=0.3786, Train Acc=0.8166 ||| Val Loss=0.3756, Val Acc=0.8136\n",
      "Epoch 211: Train Loss=0.3841, Train Acc=0.8177 ||| Val Loss=0.3839, Val Acc=0.8142\n",
      "Epoch 212: Train Loss=0.3828, Train Acc=0.8149 ||| Val Loss=0.3810, Val Acc=0.8096\n",
      "Epoch 213: Train Loss=0.3847, Train Acc=0.8162 ||| Val Loss=0.3785, Val Acc=0.8188\n",
      "Epoch 214: Train Loss=0.3811, Train Acc=0.8195 ||| Val Loss=0.3788, Val Acc=0.8165\n",
      "Epoch 215: Train Loss=0.3838, Train Acc=0.8138 ||| Val Loss=0.3840, Val Acc=0.8130\n",
      "Epoch 216: Train Loss=0.3831, Train Acc=0.8174 ||| Val Loss=0.3826, Val Acc=0.8084\n",
      "Epoch 217: Train Loss=0.3833, Train Acc=0.8148 ||| Val Loss=0.3797, Val Acc=0.8113\n",
      "Epoch 218: Train Loss=0.3833, Train Acc=0.8149 ||| Val Loss=0.3837, Val Acc=0.8084\n",
      "Epoch 219: Train Loss=0.3800, Train Acc=0.8164 ||| Val Loss=0.3779, Val Acc=0.8084\n",
      "Epoch 220: Train Loss=0.3803, Train Acc=0.8195 ||| Val Loss=0.3791, Val Acc=0.8159\n",
      "Epoch 221: Train Loss=0.3823, Train Acc=0.8158 ||| Val Loss=0.3799, Val Acc=0.8101\n",
      "Epoch 222: Train Loss=0.3783, Train Acc=0.8181 ||| Val Loss=0.3760, Val Acc=0.8193\n",
      "Epoch 223: Train Loss=0.3796, Train Acc=0.8181 ||| Val Loss=0.3771, Val Acc=0.8147\n",
      "Epoch 224: Train Loss=0.3794, Train Acc=0.8200 ||| Val Loss=0.3777, Val Acc=0.8119\n",
      "Epoch 225: Train Loss=0.3771, Train Acc=0.8165 ||| Val Loss=0.3777, Val Acc=0.8107\n",
      "Epoch 226: Train Loss=0.3778, Train Acc=0.8163 ||| Val Loss=0.3813, Val Acc=0.8107\n",
      "Epoch 227: Train Loss=0.3825, Train Acc=0.8157 ||| Val Loss=0.3749, Val Acc=0.8113\n",
      "Epoch 228: Train Loss=0.3808, Train Acc=0.8179 ||| Val Loss=0.3733, Val Acc=0.8153\n",
      "Epoch 229: Train Loss=0.3777, Train Acc=0.8195 ||| Val Loss=0.3808, Val Acc=0.8067\n",
      "Epoch 230: Train Loss=0.3769, Train Acc=0.8219 ||| Val Loss=0.3747, Val Acc=0.8205\n",
      "Epoch 231: Train Loss=0.3784, Train Acc=0.8203 ||| Val Loss=0.3758, Val Acc=0.8130\n",
      "Epoch 232: Train Loss=0.3816, Train Acc=0.8170 ||| Val Loss=0.3829, Val Acc=0.8193\n",
      "Epoch 233: Train Loss=0.3768, Train Acc=0.8199 ||| Val Loss=0.3800, Val Acc=0.8170\n",
      "Epoch 234: Train Loss=0.3799, Train Acc=0.8209 ||| Val Loss=0.3783, Val Acc=0.8170\n",
      "Epoch 235: Train Loss=0.3801, Train Acc=0.8197 ||| Val Loss=0.3762, Val Acc=0.8130\n",
      "Epoch 236: Train Loss=0.3786, Train Acc=0.8227 ||| Val Loss=0.3715, Val Acc=0.8193\n",
      "Epoch 237: Train Loss=0.3772, Train Acc=0.8196 ||| Val Loss=0.3701, Val Acc=0.8199\n",
      "Epoch 238: Train Loss=0.3766, Train Acc=0.8204 ||| Val Loss=0.3718, Val Acc=0.8228\n",
      "Epoch 239: Train Loss=0.3745, Train Acc=0.8195 ||| Val Loss=0.3782, Val Acc=0.8107\n",
      "Epoch 240: Train Loss=0.3755, Train Acc=0.8207 ||| Val Loss=0.3756, Val Acc=0.8251\n",
      "Epoch 241: Train Loss=0.3733, Train Acc=0.8235 ||| Val Loss=0.3771, Val Acc=0.8153\n",
      "Epoch 242: Train Loss=0.3731, Train Acc=0.8209 ||| Val Loss=0.3750, Val Acc=0.8182\n",
      "Epoch 243: Train Loss=0.3766, Train Acc=0.8194 ||| Val Loss=0.3725, Val Acc=0.8136\n",
      "Epoch 244: Train Loss=0.3787, Train Acc=0.8238 ||| Val Loss=0.3722, Val Acc=0.8153\n",
      "Epoch 245: Train Loss=0.3769, Train Acc=0.8200 ||| Val Loss=0.3705, Val Acc=0.8216\n",
      "Epoch 246: Train Loss=0.3775, Train Acc=0.8217 ||| Val Loss=0.3763, Val Acc=0.8147\n",
      "Epoch 247: Train Loss=0.3756, Train Acc=0.8193 ||| Val Loss=0.3743, Val Acc=0.8136\n",
      "Epoch 248: Train Loss=0.3768, Train Acc=0.8226 ||| Val Loss=0.3709, Val Acc=0.8234\n",
      "Epoch 249: Train Loss=0.3781, Train Acc=0.8194 ||| Val Loss=0.3730, Val Acc=0.8136\n",
      "Epoch 250: Train Loss=0.3766, Train Acc=0.8194 ||| Val Loss=0.3731, Val Acc=0.8153\n",
      "Epoch 251: Train Loss=0.3730, Train Acc=0.8237 ||| Val Loss=0.3727, Val Acc=0.8257\n",
      "Epoch 252: Train Loss=0.3714, Train Acc=0.8219 ||| Val Loss=0.3689, Val Acc=0.8193\n",
      "Epoch 253: Train Loss=0.3721, Train Acc=0.8224 ||| Val Loss=0.3680, Val Acc=0.8211\n",
      "Epoch 254: Train Loss=0.3769, Train Acc=0.8186 ||| Val Loss=0.3726, Val Acc=0.8193\n",
      "Epoch 255: Train Loss=0.3730, Train Acc=0.8196 ||| Val Loss=0.3702, Val Acc=0.8193\n",
      "Epoch 256: Train Loss=0.3711, Train Acc=0.8234 ||| Val Loss=0.3658, Val Acc=0.8182\n",
      "Epoch 257: Train Loss=0.3778, Train Acc=0.8210 ||| Val Loss=0.3680, Val Acc=0.8170\n",
      "Epoch 258: Train Loss=0.3730, Train Acc=0.8216 ||| Val Loss=0.3688, Val Acc=0.8142\n",
      "Epoch 259: Train Loss=0.3719, Train Acc=0.8257 ||| Val Loss=0.3658, Val Acc=0.8216\n",
      "Epoch 260: Train Loss=0.3711, Train Acc=0.8247 ||| Val Loss=0.3654, Val Acc=0.8205\n",
      "Epoch 261: Train Loss=0.3703, Train Acc=0.8251 ||| Val Loss=0.3647, Val Acc=0.8239\n",
      "Epoch 262: Train Loss=0.3722, Train Acc=0.8241 ||| Val Loss=0.3651, Val Acc=0.8222\n",
      "Epoch 263: Train Loss=0.3715, Train Acc=0.8241 ||| Val Loss=0.3692, Val Acc=0.8188\n",
      "Epoch 264: Train Loss=0.3694, Train Acc=0.8230 ||| Val Loss=0.3634, Val Acc=0.8205\n",
      "Epoch 265: Train Loss=0.3715, Train Acc=0.8238 ||| Val Loss=0.3663, Val Acc=0.8216\n",
      "Epoch 266: Train Loss=0.3692, Train Acc=0.8251 ||| Val Loss=0.3622, Val Acc=0.8222\n",
      "Epoch 267: Train Loss=0.3733, Train Acc=0.8248 ||| Val Loss=0.3621, Val Acc=0.8211\n",
      "Epoch 268: Train Loss=0.3690, Train Acc=0.8246 ||| Val Loss=0.3613, Val Acc=0.8280\n",
      "Epoch 269: Train Loss=0.3675, Train Acc=0.8240 ||| Val Loss=0.3633, Val Acc=0.8153\n",
      "Epoch 270: Train Loss=0.3723, Train Acc=0.8220 ||| Val Loss=0.3655, Val Acc=0.8251\n",
      "Epoch 271: Train Loss=0.3697, Train Acc=0.8205 ||| Val Loss=0.3638, Val Acc=0.8205\n",
      "Epoch 272: Train Loss=0.3708, Train Acc=0.8249 ||| Val Loss=0.3609, Val Acc=0.8280\n",
      "Epoch 273: Train Loss=0.3699, Train Acc=0.8222 ||| Val Loss=0.3663, Val Acc=0.8245\n",
      "Epoch 274: Train Loss=0.3726, Train Acc=0.8210 ||| Val Loss=0.3660, Val Acc=0.8228\n",
      "Epoch 275: Train Loss=0.3711, Train Acc=0.8226 ||| Val Loss=0.3658, Val Acc=0.8234\n",
      "Epoch 276: Train Loss=0.3688, Train Acc=0.8262 ||| Val Loss=0.3674, Val Acc=0.8165\n",
      "Epoch 277: Train Loss=0.3701, Train Acc=0.8284 ||| Val Loss=0.3638, Val Acc=0.8251\n",
      "Epoch 278: Train Loss=0.3676, Train Acc=0.8240 ||| Val Loss=0.3636, Val Acc=0.8245\n",
      "Epoch 279: Train Loss=0.3641, Train Acc=0.8262 ||| Val Loss=0.3661, Val Acc=0.8251\n",
      "Epoch 280: Train Loss=0.3650, Train Acc=0.8261 ||| Val Loss=0.3584, Val Acc=0.8257\n",
      "Epoch 281: Train Loss=0.3686, Train Acc=0.8233 ||| Val Loss=0.3581, Val Acc=0.8245\n",
      "Epoch 282: Train Loss=0.3664, Train Acc=0.8232 ||| Val Loss=0.3611, Val Acc=0.8251\n",
      "Epoch 283: Train Loss=0.3657, Train Acc=0.8268 ||| Val Loss=0.3641, Val Acc=0.8291\n",
      "Epoch 284: Train Loss=0.3693, Train Acc=0.8228 ||| Val Loss=0.3606, Val Acc=0.8280\n",
      "Epoch 285: Train Loss=0.3654, Train Acc=0.8258 ||| Val Loss=0.3607, Val Acc=0.8274\n",
      "Epoch 286: Train Loss=0.3660, Train Acc=0.8274 ||| Val Loss=0.3630, Val Acc=0.8239\n",
      "Epoch 287: Train Loss=0.3681, Train Acc=0.8248 ||| Val Loss=0.3582, Val Acc=0.8320\n",
      "Epoch 288: Train Loss=0.3649, Train Acc=0.8270 ||| Val Loss=0.3558, Val Acc=0.8262\n",
      "Epoch 289: Train Loss=0.3700, Train Acc=0.8202 ||| Val Loss=0.3629, Val Acc=0.8234\n",
      "Epoch 290: Train Loss=0.3674, Train Acc=0.8242 ||| Val Loss=0.3632, Val Acc=0.8257\n",
      "Epoch 291: Train Loss=0.3685, Train Acc=0.8256 ||| Val Loss=0.3606, Val Acc=0.8251\n",
      "Epoch 292: Train Loss=0.3657, Train Acc=0.8247 ||| Val Loss=0.3532, Val Acc=0.8280\n",
      "Epoch 293: Train Loss=0.3642, Train Acc=0.8273 ||| Val Loss=0.3624, Val Acc=0.8216\n",
      "Epoch 294: Train Loss=0.3640, Train Acc=0.8269 ||| Val Loss=0.3580, Val Acc=0.8268\n",
      "Epoch 295: Train Loss=0.3640, Train Acc=0.8234 ||| Val Loss=0.3537, Val Acc=0.8262\n",
      "Epoch 296: Train Loss=0.3649, Train Acc=0.8278 ||| Val Loss=0.3548, Val Acc=0.8262\n",
      "Epoch 297: Train Loss=0.3623, Train Acc=0.8309 ||| Val Loss=0.3587, Val Acc=0.8291\n",
      "Epoch 298: Train Loss=0.3589, Train Acc=0.8281 ||| Val Loss=0.3563, Val Acc=0.8222\n",
      "Epoch 299: Train Loss=0.3650, Train Acc=0.8279 ||| Val Loss=0.3569, Val Acc=0.8291\n",
      "Epoch 300: Train Loss=0.3601, Train Acc=0.8270 ||| Val Loss=0.3594, Val Acc=0.8285\n",
      "Epoch 301: Train Loss=0.3651, Train Acc=0.8260 ||| Val Loss=0.3551, Val Acc=0.8303\n",
      "Epoch 302: Train Loss=0.3630, Train Acc=0.8288 ||| Val Loss=0.3616, Val Acc=0.8216\n",
      "Epoch 303: Train Loss=0.3644, Train Acc=0.8263 ||| Val Loss=0.3520, Val Acc=0.8268\n",
      "Epoch 304: Train Loss=0.3632, Train Acc=0.8294 ||| Val Loss=0.3531, Val Acc=0.8326\n",
      "Epoch 305: Train Loss=0.3611, Train Acc=0.8266 ||| Val Loss=0.3527, Val Acc=0.8326\n",
      "Epoch 306: Train Loss=0.3627, Train Acc=0.8302 ||| Val Loss=0.3512, Val Acc=0.8308\n",
      "Epoch 307: Train Loss=0.3602, Train Acc=0.8295 ||| Val Loss=0.3488, Val Acc=0.8349\n",
      "Epoch 308: Train Loss=0.3631, Train Acc=0.8263 ||| Val Loss=0.3549, Val Acc=0.8268\n",
      "Epoch 309: Train Loss=0.3630, Train Acc=0.8279 ||| Val Loss=0.3537, Val Acc=0.8354\n",
      "Epoch 310: Train Loss=0.3588, Train Acc=0.8294 ||| Val Loss=0.3497, Val Acc=0.8274\n",
      "Epoch 311: Train Loss=0.3596, Train Acc=0.8307 ||| Val Loss=0.3459, Val Acc=0.8343\n",
      "Epoch 312: Train Loss=0.3610, Train Acc=0.8269 ||| Val Loss=0.3599, Val Acc=0.8314\n",
      "Epoch 313: Train Loss=0.3589, Train Acc=0.8289 ||| Val Loss=0.3489, Val Acc=0.8297\n",
      "Epoch 314: Train Loss=0.3606, Train Acc=0.8315 ||| Val Loss=0.3549, Val Acc=0.8331\n",
      "Epoch 315: Train Loss=0.3590, Train Acc=0.8303 ||| Val Loss=0.3494, Val Acc=0.8331\n",
      "Epoch 316: Train Loss=0.3578, Train Acc=0.8286 ||| Val Loss=0.3482, Val Acc=0.8343\n",
      "Epoch 317: Train Loss=0.3584, Train Acc=0.8319 ||| Val Loss=0.3525, Val Acc=0.8303\n",
      "Epoch 318: Train Loss=0.3616, Train Acc=0.8262 ||| Val Loss=0.3504, Val Acc=0.8308\n",
      "Epoch 319: Train Loss=0.3580, Train Acc=0.8299 ||| Val Loss=0.3482, Val Acc=0.8360\n",
      "Epoch 320: Train Loss=0.3627, Train Acc=0.8288 ||| Val Loss=0.3471, Val Acc=0.8337\n",
      "Epoch 321: Train Loss=0.3552, Train Acc=0.8302 ||| Val Loss=0.3467, Val Acc=0.8349\n",
      "Epoch 322: Train Loss=0.3605, Train Acc=0.8315 ||| Val Loss=0.3451, Val Acc=0.8291\n",
      "Epoch 323: Train Loss=0.3591, Train Acc=0.8288 ||| Val Loss=0.3485, Val Acc=0.8297\n",
      "Epoch 324: Train Loss=0.3550, Train Acc=0.8294 ||| Val Loss=0.3496, Val Acc=0.8326\n",
      "Epoch 325: Train Loss=0.3547, Train Acc=0.8309 ||| Val Loss=0.3550, Val Acc=0.8262\n",
      "Epoch 326: Train Loss=0.3564, Train Acc=0.8309 ||| Val Loss=0.3511, Val Acc=0.8337\n",
      "Epoch 327: Train Loss=0.3556, Train Acc=0.8334 ||| Val Loss=0.3406, Val Acc=0.8331\n",
      "Epoch 328: Train Loss=0.3596, Train Acc=0.8284 ||| Val Loss=0.3506, Val Acc=0.8308\n",
      "Epoch 329: Train Loss=0.3527, Train Acc=0.8319 ||| Val Loss=0.3495, Val Acc=0.8349\n",
      "Epoch 330: Train Loss=0.3569, Train Acc=0.8329 ||| Val Loss=0.3468, Val Acc=0.8320\n",
      "Epoch 331: Train Loss=0.3578, Train Acc=0.8340 ||| Val Loss=0.3487, Val Acc=0.8343\n",
      "Epoch 332: Train Loss=0.3519, Train Acc=0.8332 ||| Val Loss=0.3397, Val Acc=0.8366\n",
      "Epoch 333: Train Loss=0.3579, Train Acc=0.8322 ||| Val Loss=0.3431, Val Acc=0.8320\n",
      "Epoch 334: Train Loss=0.3550, Train Acc=0.8339 ||| Val Loss=0.3426, Val Acc=0.8412\n",
      "Epoch 335: Train Loss=0.3552, Train Acc=0.8307 ||| Val Loss=0.3512, Val Acc=0.8349\n",
      "Epoch 336: Train Loss=0.3534, Train Acc=0.8332 ||| Val Loss=0.3414, Val Acc=0.8331\n",
      "Epoch 337: Train Loss=0.3530, Train Acc=0.8358 ||| Val Loss=0.3441, Val Acc=0.8349\n",
      "Epoch 338: Train Loss=0.3534, Train Acc=0.8339 ||| Val Loss=0.3394, Val Acc=0.8360\n",
      "Epoch 339: Train Loss=0.3542, Train Acc=0.8311 ||| Val Loss=0.3476, Val Acc=0.8377\n",
      "Epoch 340: Train Loss=0.3557, Train Acc=0.8332 ||| Val Loss=0.3491, Val Acc=0.8320\n",
      "Epoch 341: Train Loss=0.3525, Train Acc=0.8324 ||| Val Loss=0.3430, Val Acc=0.8308\n",
      "Epoch 342: Train Loss=0.3524, Train Acc=0.8370 ||| Val Loss=0.3419, Val Acc=0.8372\n",
      "Epoch 343: Train Loss=0.3492, Train Acc=0.8333 ||| Val Loss=0.3404, Val Acc=0.8337\n",
      "Epoch 344: Train Loss=0.3535, Train Acc=0.8326 ||| Val Loss=0.3429, Val Acc=0.8354\n",
      "Epoch 345: Train Loss=0.3506, Train Acc=0.8338 ||| Val Loss=0.3455, Val Acc=0.8372\n",
      "Epoch 346: Train Loss=0.3535, Train Acc=0.8330 ||| Val Loss=0.3459, Val Acc=0.8372\n",
      "Epoch 347: Train Loss=0.3555, Train Acc=0.8318 ||| Val Loss=0.3451, Val Acc=0.8423\n",
      "Epoch 348: Train Loss=0.3537, Train Acc=0.8350 ||| Val Loss=0.3333, Val Acc=0.8446\n",
      "Epoch 349: Train Loss=0.3507, Train Acc=0.8348 ||| Val Loss=0.3395, Val Acc=0.8446\n",
      "Epoch 350: Train Loss=0.3510, Train Acc=0.8358 ||| Val Loss=0.3389, Val Acc=0.8406\n",
      "Epoch 351: Train Loss=0.3480, Train Acc=0.8357 ||| Val Loss=0.3342, Val Acc=0.8406\n",
      "Epoch 352: Train Loss=0.3516, Train Acc=0.8349 ||| Val Loss=0.3391, Val Acc=0.8377\n",
      "Epoch 353: Train Loss=0.3476, Train Acc=0.8363 ||| Val Loss=0.3326, Val Acc=0.8423\n",
      "Epoch 354: Train Loss=0.3509, Train Acc=0.8332 ||| Val Loss=0.3404, Val Acc=0.8383\n",
      "Epoch 355: Train Loss=0.3534, Train Acc=0.8367 ||| Val Loss=0.3349, Val Acc=0.8349\n",
      "Epoch 356: Train Loss=0.3504, Train Acc=0.8348 ||| Val Loss=0.3371, Val Acc=0.8395\n",
      "Epoch 357: Train Loss=0.3420, Train Acc=0.8380 ||| Val Loss=0.3415, Val Acc=0.8395\n",
      "Epoch 358: Train Loss=0.3515, Train Acc=0.8358 ||| Val Loss=0.3347, Val Acc=0.8412\n",
      "Epoch 359: Train Loss=0.3416, Train Acc=0.8355 ||| Val Loss=0.3304, Val Acc=0.8383\n",
      "Epoch 360: Train Loss=0.3486, Train Acc=0.8363 ||| Val Loss=0.3309, Val Acc=0.8412\n",
      "Epoch 361: Train Loss=0.3480, Train Acc=0.8353 ||| Val Loss=0.3381, Val Acc=0.8418\n",
      "Epoch 362: Train Loss=0.3461, Train Acc=0.8348 ||| Val Loss=0.3303, Val Acc=0.8475\n",
      "Epoch 363: Train Loss=0.3470, Train Acc=0.8383 ||| Val Loss=0.3394, Val Acc=0.8366\n",
      "Epoch 364: Train Loss=0.3455, Train Acc=0.8338 ||| Val Loss=0.3303, Val Acc=0.8395\n",
      "Epoch 365: Train Loss=0.3468, Train Acc=0.8373 ||| Val Loss=0.3346, Val Acc=0.8429\n",
      "Epoch 366: Train Loss=0.3464, Train Acc=0.8394 ||| Val Loss=0.3315, Val Acc=0.8464\n",
      "Epoch 367: Train Loss=0.3457, Train Acc=0.8356 ||| Val Loss=0.3300, Val Acc=0.8475\n",
      "Epoch 368: Train Loss=0.3465, Train Acc=0.8347 ||| Val Loss=0.3279, Val Acc=0.8406\n",
      "Epoch 369: Train Loss=0.3417, Train Acc=0.8391 ||| Val Loss=0.3269, Val Acc=0.8435\n",
      "Epoch 370: Train Loss=0.3432, Train Acc=0.8408 ||| Val Loss=0.3255, Val Acc=0.8435\n",
      "Epoch 371: Train Loss=0.3433, Train Acc=0.8388 ||| Val Loss=0.3304, Val Acc=0.8423\n",
      "Epoch 372: Train Loss=0.3471, Train Acc=0.8370 ||| Val Loss=0.3328, Val Acc=0.8475\n",
      "Epoch 373: Train Loss=0.3431, Train Acc=0.8378 ||| Val Loss=0.3255, Val Acc=0.8470\n",
      "Epoch 374: Train Loss=0.3466, Train Acc=0.8363 ||| Val Loss=0.3357, Val Acc=0.8389\n",
      "Epoch 375: Train Loss=0.3443, Train Acc=0.8417 ||| Val Loss=0.3316, Val Acc=0.8418\n",
      "Epoch 376: Train Loss=0.3471, Train Acc=0.8372 ||| Val Loss=0.3287, Val Acc=0.8521\n",
      "Epoch 377: Train Loss=0.3423, Train Acc=0.8375 ||| Val Loss=0.3291, Val Acc=0.8475\n",
      "Epoch 378: Train Loss=0.3405, Train Acc=0.8407 ||| Val Loss=0.3238, Val Acc=0.8487\n",
      "Epoch 379: Train Loss=0.3427, Train Acc=0.8411 ||| Val Loss=0.3227, Val Acc=0.8516\n",
      "Epoch 380: Train Loss=0.3440, Train Acc=0.8387 ||| Val Loss=0.3241, Val Acc=0.8504\n",
      "Epoch 381: Train Loss=0.3417, Train Acc=0.8400 ||| Val Loss=0.3239, Val Acc=0.8504\n",
      "Epoch 382: Train Loss=0.3455, Train Acc=0.8373 ||| Val Loss=0.3288, Val Acc=0.8429\n",
      "Epoch 383: Train Loss=0.3402, Train Acc=0.8385 ||| Val Loss=0.3269, Val Acc=0.8487\n",
      "Epoch 384: Train Loss=0.3373, Train Acc=0.8410 ||| Val Loss=0.3200, Val Acc=0.8446\n",
      "Epoch 385: Train Loss=0.3386, Train Acc=0.8408 ||| Val Loss=0.3188, Val Acc=0.8504\n",
      "Epoch 386: Train Loss=0.3423, Train Acc=0.8400 ||| Val Loss=0.3262, Val Acc=0.8487\n",
      "Epoch 387: Train Loss=0.3399, Train Acc=0.8392 ||| Val Loss=0.3222, Val Acc=0.8406\n",
      "Epoch 388: Train Loss=0.3482, Train Acc=0.8423 ||| Val Loss=0.3277, Val Acc=0.8498\n",
      "Epoch 389: Train Loss=0.3395, Train Acc=0.8402 ||| Val Loss=0.3237, Val Acc=0.8487\n",
      "Epoch 390: Train Loss=0.3480, Train Acc=0.8408 ||| Val Loss=0.3256, Val Acc=0.8487\n",
      "Epoch 391: Train Loss=0.3373, Train Acc=0.8442 ||| Val Loss=0.3190, Val Acc=0.8533\n",
      "Epoch 392: Train Loss=0.3369, Train Acc=0.8396 ||| Val Loss=0.3222, Val Acc=0.8562\n",
      "Epoch 393: Train Loss=0.3391, Train Acc=0.8411 ||| Val Loss=0.3213, Val Acc=0.8527\n",
      "Epoch 394: Train Loss=0.3406, Train Acc=0.8381 ||| Val Loss=0.3275, Val Acc=0.8510\n",
      "Epoch 395: Train Loss=0.3373, Train Acc=0.8390 ||| Val Loss=0.3243, Val Acc=0.8487\n",
      "Epoch 396: Train Loss=0.3431, Train Acc=0.8362 ||| Val Loss=0.3229, Val Acc=0.8481\n",
      "Epoch 397: Train Loss=0.3432, Train Acc=0.8393 ||| Val Loss=0.3185, Val Acc=0.8510\n",
      "Epoch 398: Train Loss=0.3386, Train Acc=0.8445 ||| Val Loss=0.3244, Val Acc=0.8510\n",
      "Epoch 399: Train Loss=0.3404, Train Acc=0.8393 ||| Val Loss=0.3330, Val Acc=0.8377\n",
      "Epoch 400: Train Loss=0.3361, Train Acc=0.8396 ||| Val Loss=0.3176, Val Acc=0.8470\n",
      "Final Validation Accuracy: 0.8470\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ||| Training final model on full dataset |||\")\n",
    "\n",
    "# use full training dataset on the model\n",
    "full_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "train_loader = DataLoader(full_dataset, batch_size=256, shuffle=True) #  global train_loader variable used inside run_tabm\n",
    "\n",
    "# training final model\n",
    "final_model = run_tabm(**best, n_epochs=400)\n",
    "\n",
    "# evaluate validation accuracy\n",
    "final_model.eval()  # turn off dropout, etc.\n",
    "\n",
    "val_preds = [] # predictions\n",
    "val_targets = [] # true labels\n",
    "\n",
    "with torch.no_grad():  # disables gradient tracking\n",
    "    for xb, yb in val_loader:  # use your validation loader\n",
    "        outputs = final_model(xb, None)\n",
    "        preds = outputs.mean(dim=1).argmax(dim=1)\n",
    "        val_preds.append(preds)\n",
    "        val_targets.append(yb)\n",
    "\n",
    "val_preds = torch.cat(val_preds)\n",
    "val_targets = torch.cat(val_targets)\n",
    "\n",
    "# calculate final validation accuracy\n",
    "final_val_acc = accuracy_score(val_targets.cpu(), val_preds.cpu())\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7415ad",
   "metadata": {},
   "source": [
    "#### Making the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68f43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert test to tensor so that we can feed it into model\n",
    "test_x_tensor = torch.tensor(test.values, dtype=torch.float32)\n",
    "\n",
    "# Predicting\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = final_model(test_x_tensor, None)  # generate predictions for the k models\n",
    "    test_preds = test_outputs.mean(dim=1).argmax(dim=1)  # we take the average prediction over the k ensemble models\n",
    "\n",
    "# we get back the passengerIds (removed in encoding)\n",
    "test_ids = pd.read_csv('data/test.csv')['PassengerId']\n",
    "\n",
    "#  setup the submission df\n",
    "final_submission_tabm = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Transported': test_preds.cpu().numpy().astype(bool)  # convert predictions to bool True/False\n",
    "})\n",
    "\n",
    "# saves the submission df to csv. Ready for kaggle.\n",
    "final_submission_tabm.to_csv('submissions/final_submission_tabm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1ca33",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "\n",
    "- The final model achieved a validation accuracy of **0.8470**, which is a strong result during training.\n",
    "- However, the final Kaggle leaderboard score for the TABM model was **0.79541**, indicating signs of overfitting to the training data.\n",
    "- The five-fold cross-validation gave a mean validation accuracy of **0.7927**, suggesting that the true generalization performance of the model is slightly lower than the single validation split suggested.\n",
    "\n",
    "I hypothesize that the model's complexity — and the high capacity of MLP architectures in general — made it prone to overfitting given the relatively small size of the Spaceship Titanic dataset.  \n",
    "Despite the regularization strategies used (dropout, weight decay, batch normalization), the model likely still overfit subtle patterns in the training data that did not generalize well to unseen test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f1832",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TABM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
